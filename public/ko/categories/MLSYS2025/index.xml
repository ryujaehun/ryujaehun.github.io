<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>MLSYS2025 on Jaehun's Blog</title><link>https://jaehun.me/ko/categories/MLSYS2025/</link><description>Recent content in MLSYS2025 on Jaehun's Blog</description><generator>Hugo</generator><language>ko-kr</language><lastBuildDate>Tue, 10 Jun 2025 00:00:00 +0000</lastBuildDate><atom:link href="https://jaehun.me/ko/categories/MLSYS2025/index.xml" rel="self" type="application/rss+xml"/><item><title>A Bring-Your-Own-Model Approach for ML-Driven Storage Placement in Warehouse-Scale Computers</title><link>https://jaehun.me/ko/ko/posts/2025-06-10-paper-1/</link><pubDate>Tue, 10 Jun 2025 00:00:00 +0000</pubDate><guid>https://jaehun.me/ko/ko/posts/2025-06-10-paper-1/</guid><description>&lt;p>&lt;a href="https://openreview.net/pdf?id=JuGWOSB68T">ë…¼ë¬¸ ë§í¬&lt;/a>&lt;/p>
&lt;h1 id="q--ì´-ë…¼ë¬¸ì„-ì•„ì£¼-ìžì„¸í•˜ê²Œ-ì½ê³ -ë…¼ë¬¸ì˜-ê°•ì ê³¼-ë…ì°½ì ì¸-ì§€ì ì„-ì„¤ëª…í•´ì£¼ê³ -í•µì‹¬-ì•Œê³ ë¦¬ì¦˜ì„-ì˜ˆì‹œ-ìž…ë ¥ì„-ë“¤ì–´ì„œ-ì „ì²´ì ì¸-ê³¼ì •ì„-ì„¤ëª…í•´ì¤˜-ì¶”ê°€ì ìœ¼ë¡œ-ë…¼ë¬¸ì˜-í•œê³„ì ì—-ëŒ€í•´ì„œë„-ì•Œë ¤ì¤˜">Q : ì´ ë…¼ë¬¸ì„ ì•„ì£¼ ìžì„¸í•˜ê²Œ ì½ê³  ë…¼ë¬¸ì˜ ê°•ì ê³¼ ë…ì°½ì ì¸ ì§€ì ì„ ì„¤ëª…í•´ì£¼ê³  í•µì‹¬ ì•Œê³ ë¦¬ì¦˜ì„ ì˜ˆì‹œ ìž…ë ¥ì„ ë“¤ì–´ì„œ ì „ì²´ì ì¸ ê³¼ì •ì„ ì„¤ëª…í•´ì¤˜ ì¶”ê°€ì ìœ¼ë¡œ ë…¼ë¬¸ì˜ í•œê³„ì ì— ëŒ€í•´ì„œë„ ì•Œë ¤ì¤˜&lt;/h1>
&lt;h2 id="bring-your-own-model-ë…¼ë¬¸-ìƒì„¸-ë¶„ì„">&amp;ldquo;Bring-Your-Own-Model&amp;rdquo; ë…¼ë¬¸ ìƒì„¸ ë¶„ì„&lt;/h2>
&lt;p>ìš”ì²­í•˜ì‹  &amp;ldquo;A Bring-Your-Own-Model Approach for ML-Driven Storage Placement in Warehouse-Scale Computers&amp;rdquo; ë…¼ë¬¸ì„ ì‹¬ì¸µì ìœ¼ë¡œ ë¶„ì„í•˜ì—¬ ê°•ì ê³¼ ë…ì°½ì„±, í•µì‹¬ ì•Œê³ ë¦¬ì¦˜, ê·¸ë¦¬ê³  í•œê³„ì ì— ëŒ€í•´ ì„¤ëª…í•´ ë“œë¦¬ê² ìŠµë‹ˆë‹¤.&lt;/p></description></item><item><title>Know Where You're Uncertain When Planning with Multimodal Foundation Models: A Formal Framework</title><link>https://jaehun.me/ko/ko/posts/2025-06-10-paper-5/</link><pubDate>Tue, 10 Jun 2025 00:00:00 +0000</pubDate><guid>https://jaehun.me/ko/ko/posts/2025-06-10-paper-5/</guid><description>&lt;p>&lt;a href="https://openreview.net/pdf?id=HPHrIBlJYw">ë…¼ë¬¸ ë§í¬&lt;/a>&lt;/p>
&lt;h1 id="q--ì´-ë…¼ë¬¸ì„-ì•„ì£¼-ìžì„¸í•˜ê²Œ-ì½ê³ -ë…¼ë¬¸ì˜-ê°•ì ê³¼-ë…ì°½ì ì¸-ì§€ì ì„-ì„¤ëª…í•´ì£¼ê³ -í•µì‹¬-ì•Œê³ ë¦¬ì¦˜ì„-ì˜ˆì‹œ-ìž…ë ¥ì„-ë“¤ì–´ì„œ-ì „ì²´ì ì¸-ê³¼ì •ì„-ì„¤ëª…í•´ì¤˜-ì¶”ê°€ì ìœ¼ë¡œ-ë…¼ë¬¸ì˜-í•œê³„ì ì—-ëŒ€í•´ì„œë„-ì•Œë ¤ì¤˜">Q : ì´ ë…¼ë¬¸ì„ ì•„ì£¼ ìžì„¸í•˜ê²Œ ì½ê³  ë…¼ë¬¸ì˜ ê°•ì ê³¼ ë…ì°½ì ì¸ ì§€ì ì„ ì„¤ëª…í•´ì£¼ê³  í•µì‹¬ ì•Œê³ ë¦¬ì¦˜ì„ ì˜ˆì‹œ ìž…ë ¥ì„ ë“¤ì–´ì„œ ì „ì²´ì ì¸ ê³¼ì •ì„ ì„¤ëª…í•´ì¤˜ ì¶”ê°€ì ìœ¼ë¡œ ë…¼ë¬¸ì˜ í•œê³„ì ì— ëŒ€í•´ì„œë„ ì•Œë ¤ì¤˜&lt;/h1>
&lt;p>ì´ ë…¼ë¬¸(&amp;ldquo;KNOW WHERE YOU&amp;rsquo;RE UNCERTAIN WHEN PLANNING WITH MULTIMODAL FOUNDATION MODELS: A FORMAL FRAMEWORK&amp;rdquo;)ì€ ë¡œë´‡ì´ ë©€í‹°ëª¨ë‹¬ íŒŒìš´ë°ì´ì…˜ ëª¨ë¸(ì‹œê°ê³¼ ì–¸ì–´ë¥¼ í•¨ê»˜ ì´í•´í•˜ëŠ” ëª¨ë¸)ì„ ì‚¬ìš©í•˜ì—¬ ê³„íšì„ ìˆ˜ë¦½í•  ë•Œ ë°œìƒí•˜ëŠ” ë¶ˆí™•ì‹¤ì„±ì„ ì²´ê³„ì ìœ¼ë¡œ ë¶„ì„í•˜ê³  í•´ê²°í•˜ëŠ” ìƒˆë¡œìš´ í”„ë ˆìž„ì›Œí¬ë¥¼ ì œì‹œí•©ë‹ˆë‹¤. ë…¼ë¬¸ì„ ì •ë°€í•˜ê²Œ ë¶„ì„í•˜ì—¬ ê°•ì ê³¼ ë…ì°½ì„±, í•µì‹¬ ì•Œê³ ë¦¬ì¦˜ì˜ ìž‘ë™ ë°©ì‹, ê·¸ë¦¬ê³  ìž ìž¬ì ì¸ í•œê³„ì ì„ ì„¤ëª…í•´ ë“œë¦¬ê² ìŠµë‹ˆë‹¤.&lt;/p></description></item><item><title>ReaL: Efficient RLHF Training of Large Language Models with Parameter Reallocation</title><link>https://jaehun.me/ko/ko/posts/2025-06-10-paper-4/</link><pubDate>Tue, 10 Jun 2025 00:00:00 +0000</pubDate><guid>https://jaehun.me/ko/ko/posts/2025-06-10-paper-4/</guid><description>&lt;p>&lt;a href="https://openreview.net/pdf?id=yLU1zRf95d">ë…¼ë¬¸ ë§í¬&lt;/a>&lt;/p>
&lt;h1 id="q--ì´-ë…¼ë¬¸ì„-ì•„ì£¼-ìžì„¸í•˜ê²Œ-ì½ê³ -ë…¼ë¬¸ì˜-ê°•ì ê³¼-ë…ì°½ì ì¸-ì§€ì ì„-ì„¤ëª…í•´ì£¼ê³ -í•µì‹¬-ì•Œê³ ë¦¬ì¦˜ì„-ì˜ˆì‹œ-ìž…ë ¥ì„-ë“¤ì–´ì„œ-ì „ì²´ì ì¸-ê³¼ì •ì„-ì„¤ëª…í•´ì¤˜-ì¶”ê°€ì ìœ¼ë¡œ-ë…¼ë¬¸ì˜-í•œê³„ì ì—-ëŒ€í•´ì„œë„-ì•Œë ¤ì¤˜">Q : ì´ ë…¼ë¬¸ì„ ì•„ì£¼ ìžì„¸í•˜ê²Œ ì½ê³  ë…¼ë¬¸ì˜ ê°•ì ê³¼ ë…ì°½ì ì¸ ì§€ì ì„ ì„¤ëª…í•´ì£¼ê³  í•µì‹¬ ì•Œê³ ë¦¬ì¦˜ì„ ì˜ˆì‹œ ìž…ë ¥ì„ ë“¤ì–´ì„œ ì „ì²´ì ì¸ ê³¼ì •ì„ ì„¤ëª…í•´ì¤˜ ì¶”ê°€ì ìœ¼ë¡œ ë…¼ë¬¸ì˜ í•œê³„ì ì— ëŒ€í•´ì„œë„ ì•Œë ¤ì¤˜&lt;/h1>
&lt;h2 id="ë…¼ë¬¸-ë¶„ì„-real-ëŒ€ê·œëª¨-ì–¸ì–´-ëª¨ë¸ì˜-íš¨ìœ¨ì ì¸-rlhf-í›ˆë ¨ì„-ìœ„í•œ-ë§¤ê°œë³€ìˆ˜-ìž¬í• ë‹¹">ë…¼ë¬¸ ë¶„ì„: REAL: ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì˜ íš¨ìœ¨ì ì¸ RLHF í›ˆë ¨ì„ ìœ„í•œ ë§¤ê°œë³€ìˆ˜ ìž¬í• ë‹¹&lt;/h2>
&lt;p>ì´ ë¬¸ì„œëŠ” &amp;ldquo;REAL: Efficient RLHF Training of Large Language Models with Parameter Reallocation&amp;rdquo; ë…¼ë¬¸ì„ ì‹¬ì¸µì ìœ¼ë¡œ ë¶„ì„í•˜ì—¬ ë…¼ë¬¸ì˜ í•µì‹¬ ê°•ì ê³¼ ë…ì°½ì„±, ì£¼ìš” ì•Œê³ ë¦¬ì¦˜ì˜ ìž‘ë™ ë°©ì‹, ê·¸ë¦¬ê³  ìž ìž¬ì ì¸ í•œê³„ì ì„ ì„¤ëª…í•©ë‹ˆë‹¤.&lt;/p></description></item><item><title>Rubick: Exploiting Job Reconfigurability for Deep Learning Cluster Scheduling</title><link>https://jaehun.me/ko/ko/posts/2025-06-10-paper-3/</link><pubDate>Tue, 10 Jun 2025 00:00:00 +0000</pubDate><guid>https://jaehun.me/ko/ko/posts/2025-06-10-paper-3/</guid><description>&lt;p>&lt;a href="https://openreview.net/pdf?id=tuziIJjRj5">ë…¼ë¬¸ ë§í¬&lt;/a>&lt;/p>
&lt;h1 id="q--ì´-ë…¼ë¬¸ì„-ì•„ì£¼-ìžì„¸í•˜ê²Œ-ì½ê³ -ë…¼ë¬¸ì˜-ê°•ì ê³¼-ë…ì°½ì ì¸-ì§€ì ì„-ì„¤ëª…í•´ì£¼ê³ -í•µì‹¬-ì•Œê³ ë¦¬ì¦˜ì„-ì˜ˆì‹œ-ìž…ë ¥ì„-ë“¤ì–´ì„œ-ì „ì²´ì ì¸-ê³¼ì •ì„-ì„¤ëª…í•´ì¤˜-ì¶”ê°€ì ìœ¼ë¡œ-ë…¼ë¬¸ì˜-í•œê³„ì ì—-ëŒ€í•´ì„œë„-ì•Œë ¤ì¤˜">Q : ì´ ë…¼ë¬¸ì„ ì•„ì£¼ ìžì„¸í•˜ê²Œ ì½ê³  ë…¼ë¬¸ì˜ ê°•ì ê³¼ ë…ì°½ì ì¸ ì§€ì ì„ ì„¤ëª…í•´ì£¼ê³  í•µì‹¬ ì•Œê³ ë¦¬ì¦˜ì„ ì˜ˆì‹œ ìž…ë ¥ì„ ë“¤ì–´ì„œ ì „ì²´ì ì¸ ê³¼ì •ì„ ì„¤ëª…í•´ì¤˜ ì¶”ê°€ì ìœ¼ë¡œ ë…¼ë¬¸ì˜ í•œê³„ì ì— ëŒ€í•´ì„œë„ ì•Œë ¤ì¤˜&lt;/h1>
&lt;h2 id="rubick-ë…¼ë¬¸-ìƒì„¸-ë¶„ì„-ê°•ì -í•µì‹¬-ì•Œê³ ë¦¬ì¦˜-ê·¸ë¦¬ê³ -í•œê³„ì ">Rubick ë…¼ë¬¸ ìƒì„¸ ë¶„ì„: ê°•ì , í•µì‹¬ ì•Œê³ ë¦¬ì¦˜, ê·¸ë¦¬ê³  í•œê³„ì &lt;/h2>
&lt;p>ì œê³µëœ ë…¼ë¬¸ &amp;ldquo;RUBICK: EXPLOITING JOB RECONFIGURABILITY FOR DEEP LEARNING CLUSTER SCHEDULING&amp;quot;ì— ëŒ€í•œ ì‹¬ì¸µ ë¶„ì„ ê²°ê³¼ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.&lt;/p></description></item><item><title>Supply-Chain Attacks in Machine Learning Frameworks</title><link>https://jaehun.me/ko/ko/posts/2025-06-10-paper-2/</link><pubDate>Tue, 10 Jun 2025 00:00:00 +0000</pubDate><guid>https://jaehun.me/ko/ko/posts/2025-06-10-paper-2/</guid><description>&lt;p>&lt;a href="https://openreview.net/pdf?id=EH5PZW6aCr">ë…¼ë¬¸ ë§í¬&lt;/a>&lt;/p>
&lt;h1 id="q--ì´-ë…¼ë¬¸ì„-ì•„ì£¼-ìžì„¸í•˜ê²Œ-ì½ê³ -ë…¼ë¬¸ì˜-ê°•ì ê³¼-ë…ì°½ì ì¸-ì§€ì ì„-ì„¤ëª…í•´ì£¼ê³ -í•µì‹¬-ì•Œê³ ë¦¬ì¦˜ì„-ì˜ˆì‹œ-ìž…ë ¥ì„-ë“¤ì–´ì„œ-ì „ì²´ì ì¸-ê³¼ì •ì„-ì„¤ëª…í•´ì¤˜-ì¶”ê°€ì ìœ¼ë¡œ-ë…¼ë¬¸ì˜-í•œê³„ì ì—-ëŒ€í•´ì„œë„-ì•Œë ¤ì¤˜">Q : ì´ ë…¼ë¬¸ì„ ì•„ì£¼ ìžì„¸í•˜ê²Œ ì½ê³  ë…¼ë¬¸ì˜ ê°•ì ê³¼ ë…ì°½ì ì¸ ì§€ì ì„ ì„¤ëª…í•´ì£¼ê³  í•µì‹¬ ì•Œê³ ë¦¬ì¦˜ì„ ì˜ˆì‹œ ìž…ë ¥ì„ ë“¤ì–´ì„œ ì „ì²´ì ì¸ ê³¼ì •ì„ ì„¤ëª…í•´ì¤˜ ì¶”ê°€ì ìœ¼ë¡œ ë…¼ë¬¸ì˜ í•œê³„ì ì— ëŒ€í•´ì„œë„ ì•Œë ¤ì¤˜&lt;/h1>
&lt;h2 id="ai-ëª¨ë¸-ê³µê¸‰ë§-ê³µê²©ì—-ëŒ€í•œ-ì—°êµ¬-ë…¼ë¬¸-ì‹¬ì¸µ-ë¶„ì„">AI ëª¨ë¸ ê³µê¸‰ë§ ê³µê²©ì— ëŒ€í•œ ì—°êµ¬ ë…¼ë¬¸ ì‹¬ì¸µ ë¶„ì„&lt;/h2>
&lt;p>ì‚¬ìš©ìžê»˜ì„œ ì œê³µí•˜ì‹  &amp;ldquo;Supply-Chain Attacks in Machine Learning Frameworks&amp;rdquo; ë…¼ë¬¸ì€ ë¨¸ì‹ ëŸ¬ë‹(ML) ì‹œìŠ¤í…œì´ ì§ë©´í•œ ìƒˆë¡œìš´ ìœ í˜•ì˜ ê³µê¸‰ë§ ê³µê²©ì„ ì‹¬ë„ ìžˆê²Œ ë¶„ì„í•˜ê³ , ML ì»¤ë®¤ë‹ˆí‹°ì˜ ë³´ì•ˆ ì¸ì‹ ìˆ˜ì¤€ì„ í‰ê°€í•œ ì¤‘ìš”í•œ ì—°êµ¬ìž…ë‹ˆë‹¤. ì•„ëž˜ì— ë…¼ë¬¸ì˜ í•µì‹¬ ë‚´ìš©, ê°•ì , ë…ì°½ì„±, í•µì‹¬ ê³µê²© ê¸°ë²•, ê·¸ë¦¬ê³  í•œê³„ì ì„ ìƒì„¸ížˆ ì„¤ëª…í•´ ë“œë¦¬ê² ìŠµë‹ˆë‹¤.&lt;/p></description></item><item><title>FlexInfer: Breaking Memory Constraint via Flexible and Efficient Offloading for On-Device LLM Inference</title><link>https://jaehun.me/ko/ko/posts/2025-06-05-paper-2503.03777v1/</link><pubDate>Thu, 05 Jun 2025 00:00:00 +0000</pubDate><guid>https://jaehun.me/ko/ko/posts/2025-06-05-paper-2503.03777v1/</guid><description>&lt;p>&lt;a href="https://arxiv.org/abs/2503.03777v1">ë…¼ë¬¸ ë§í¬&lt;/a>&lt;/p>
&lt;h1 id="q--ì´-ë…¼ë¬¸ì„-ì•„ì£¼-ìžì„¸í•˜ê²Œ-ì½ê³ -ë…¼ë¬¸ì˜-ê°•ì ê³¼-ë…ì°½ì ì¸-ì§€ì ì„-ì„¤ëª…í•´ì£¼ê³ -í•µì‹¬-ì•Œê³ ë¦¬ì¦˜ì„-ì˜ˆì‹œ-ìž…ë ¥ì„-ë“¤ì–´ì„œ-ì „ì²´ì ì¸-ê³¼ì •ì„-ì„¤ëª…í•´ì¤˜-ì¶”ê°€ì ìœ¼ë¡œ-ë…¼ë¬¸ì˜-í•œê³„ì ì—-ëŒ€í•´ì„œë„-ì•Œë ¤ì¤˜">Q : ì´ ë…¼ë¬¸ì„ ì•„ì£¼ ìžì„¸í•˜ê²Œ ì½ê³  ë…¼ë¬¸ì˜ ê°•ì ê³¼ ë…ì°½ì ì¸ ì§€ì ì„ ì„¤ëª…í•´ì£¼ê³  í•µì‹¬ ì•Œê³ ë¦¬ì¦˜ì„ ì˜ˆì‹œ ìž…ë ¥ì„ ë“¤ì–´ì„œ ì „ì²´ì ì¸ ê³¼ì •ì„ ì„¤ëª…í•´ì¤˜ ì¶”ê°€ì ìœ¼ë¡œ ë…¼ë¬¸ì˜ í•œê³„ì ì— ëŒ€í•´ì„œë„ ì•Œë ¤ì¤˜&lt;/h1>
&lt;h2 id="flexinfer-ë…¼ë¬¸-ìƒì„¸-ë¶„ì„-ì˜¨ë””ë°”ì´ìŠ¤-llm-ì¶”ë¡ ì˜-ë©”ëª¨ë¦¬-ì œì•½-ê·¹ë³µ">FlexInfer ë…¼ë¬¸ ìƒì„¸ ë¶„ì„: ì˜¨ë””ë°”ì´ìŠ¤ LLM ì¶”ë¡ ì˜ ë©”ëª¨ë¦¬ ì œì•½ ê·¹ë³µ&lt;/h2>
&lt;p>FlexInfer ë…¼ë¬¸ &amp;ldquo;FlexInfer: Breaking Memory Constraint via Flexible and Efficient Offloading for On-Device LLM Inference&amp;rdquo; [cite: 1]ì€ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)ì„ ë©”ëª¨ë¦¬ê°€ ì œí•œëœ ì˜¨ë””ë°”ì´ìŠ¤ í™˜ê²½ì—ì„œ íš¨ìœ¨ì ìœ¼ë¡œ ì‹¤í–‰í•˜ê¸° ìœ„í•œ í˜ì‹ ì ì¸ ì˜¤í”„ë¡œë”© í”„ë ˆìž„ì›Œí¬ë¥¼ ì œì‹œí•©ë‹ˆë‹¤. ê¸°ì¡´ ë°©ì‹ë“¤ì´ ì„±ëŠ¥ ì €í•˜ë‚˜ ìœ ì—°ì„± ë¶€ì¡±ì˜ í•œê³„ë¥¼ ê°€ì¡Œë˜ ë°˜ë©´[cite: 2], FlexInferëŠ” ë¹„ë™ê¸° í”„ë¦¬íŽ˜ì¹­, ê· í˜• ìž¡ížŒ ë©”ëª¨ë¦¬ ê³ ì •, ìœ ì—°í•œ í…ì„œ ë³´ì¡´ì´ë¼ëŠ” ì„¸ ê°€ì§€ í•µì‹¬ ê¸°ìˆ ì„ í†µí•´ ì´ëŸ¬í•œ ë¬¸ì œ í•´ê²°ì„ ì‹œë„í•©ë‹ˆë‹¤. [cite: 3]&lt;/p></description></item><item><title>ScaleFusion: Scalable Inference of Spatial-Temporal Diffusion Transformers for High-Resolution Long Video Generation</title><link>https://jaehun.me/ko/ko/posts/2025-06-05-paper-SCALEFUSION/</link><pubDate>Thu, 05 Jun 2025 00:00:00 +0000</pubDate><guid>https://jaehun.me/ko/ko/posts/2025-06-05-paper-SCALEFUSION/</guid><description>&lt;p>&lt;a href="https://openreview.net/pdf?id=anZWBeWnWh">ë…¼ë¬¸ ë§í¬&lt;/a>&lt;/p>
&lt;h1 id="q--ì´-ë…¼ë¬¸ì„-ì•„ì£¼-ìžì„¸í•˜ê²Œ-ì½ê³ -ë…¼ë¬¸ì˜-ê°•ì ê³¼-ë…ì°½ì ì¸-ì§€ì ì„-ì„¤ëª…í•´ì£¼ê³ -í•µì‹¬-ì•Œê³ ë¦¬ì¦˜ì„-ì˜ˆì‹œ-ìž…ë ¥ì„-ë“¤ì–´ì„œ-ì „ì²´ì ì¸-ê³¼ì •ì„-ì„¤ëª…í•´ì¤˜-ì¶”ê°€ì ìœ¼ë¡œ-ë…¼ë¬¸ì˜-í•œê³„ì ì—-ëŒ€í•´ì„œë„-ì•Œë ¤ì¤˜">Q : ì´ ë…¼ë¬¸ì„ ì•„ì£¼ ìžì„¸í•˜ê²Œ ì½ê³  ë…¼ë¬¸ì˜ ê°•ì ê³¼ ë…ì°½ì ì¸ ì§€ì ì„ ì„¤ëª…í•´ì£¼ê³  í•µì‹¬ ì•Œê³ ë¦¬ì¦˜ì„ ì˜ˆì‹œ ìž…ë ¥ì„ ë“¤ì–´ì„œ ì „ì²´ì ì¸ ê³¼ì •ì„ ì„¤ëª…í•´ì¤˜ ì¶”ê°€ì ìœ¼ë¡œ ë…¼ë¬¸ì˜ í•œê³„ì ì— ëŒ€í•´ì„œë„ ì•Œë ¤ì¤˜&lt;/h1>
&lt;h2 id="scalefusion-ë…¼ë¬¸-ìƒì„¸-ë¶„ì„-ê³ í•´ìƒë„-ìž¥íŽ¸-ë¹„ë””ì˜¤-ìƒì„±ì„-ìœ„í•œ-ê³µê°„-ì‹œê°„-í™•ì‚°-íŠ¸ëžœìŠ¤í¬ë¨¸ì˜-í™•ìž¥-ê°€ëŠ¥í•œ-ì¶”ë¡ ">ScaleFusion ë…¼ë¬¸ ìƒì„¸ ë¶„ì„: ê³ í•´ìƒë„ ìž¥íŽ¸ ë¹„ë””ì˜¤ ìƒì„±ì„ ìœ„í•œ ê³µê°„-ì‹œê°„ í™•ì‚° íŠ¸ëžœìŠ¤í¬ë¨¸ì˜ í™•ìž¥ ê°€ëŠ¥í•œ ì¶”ë¡ &lt;/h2>
&lt;p>ScaleFusion ë…¼ë¬¸ &amp;ldquo;SCALEFUSION: SCALABLE INFERENCE OF SPATIAL-TEMPORAL DIFFUSION TRANSFORMERS FOR HIGH-RESOLUTION LONG VIDEO GENERATION&amp;quot;ì€ ê³ í•´ìƒë„(ì˜ˆ: 1080p) ë° ìž¥ì‹œê°„(ì˜ˆ: 20ì´ˆ ì´ìƒ) ë¹„ë””ì˜¤ ìƒì„± ì‹œ ê³µê°„-ì‹œê°„ í™•ì‚° íŠ¸ëžœìŠ¤í¬ë¨¸(ST-DiT) ëª¨ë¸ì˜ ë†’ì€ ì¶”ë¡  ì§€ì—° ì‹œê°„ì„ í•´ê²°í•˜ê¸° ìœ„í•œ í˜ì‹ ì ì¸ ë°©ë²•ì„ ì œì‹œí•©ë‹ˆë‹¤. [cite: 1, 2] ì£¼ìš” ëª©í‘œëŠ” ì—¬ëŸ¬ GPU ì‹œìŠ¤í…œì— ê±¸ì³ ST-DiT ì¶”ë¡ ì„ ìµœì ìœ¼ë¡œ í™•ìž¥í•˜ì—¬ ì‹œê°„ ì œì•½ì ì¸ ì‹œë‚˜ë¦¬ì˜¤ì—ì„œì˜ ì ìš© ê°€ëŠ¥ì„±ì„ ë†’ì´ëŠ” ê²ƒìž…ë‹ˆë‹¤. [cite: 3, 4, 5]&lt;/p></description></item><item><title>SOLA: Optimizing SLO Attainment for Large Language Model Serving with State-Aware Scheduling</title><link>https://jaehun.me/ko/ko/posts/2025-06-05-paper-sola/</link><pubDate>Thu, 05 Jun 2025 00:00:00 +0000</pubDate><guid>https://jaehun.me/ko/ko/posts/2025-06-05-paper-sola/</guid><description>&lt;p>&lt;a href="https://openreview.net/pdf?id=ubIvpetAd6">ë…¼ë¬¸ ë§í¬&lt;/a>&lt;/p>
&lt;h1 id="q--ì´-ë…¼ë¬¸ì„-ì•„ì£¼-ìžì„¸í•˜ê²Œ-ì½ê³ -ë…¼ë¬¸ì˜-ê°•ì ê³¼-ë…ì°½ì ì¸-ì§€ì ì„-ì„¤ëª…í•´ì£¼ê³ -í•µì‹¬-ì•Œê³ ë¦¬ì¦˜ì„-ì˜ˆì‹œ-ìž…ë ¥ì„-ë“¤ì–´ì„œ-ì „ì²´ì ì¸-ê³¼ì •ì„-ì„¤ëª…í•´ì¤˜-ì¶”ê°€ì ìœ¼ë¡œ-ë…¼ë¬¸ì˜-í•œê³„ì ì—-ëŒ€í•´ì„œë„-ì•Œë ¤ì¤˜">Q : ì´ ë…¼ë¬¸ì„ ì•„ì£¼ ìžì„¸í•˜ê²Œ ì½ê³  ë…¼ë¬¸ì˜ ê°•ì ê³¼ ë…ì°½ì ì¸ ì§€ì ì„ ì„¤ëª…í•´ì£¼ê³  í•µì‹¬ ì•Œê³ ë¦¬ì¦˜ì„ ì˜ˆì‹œ ìž…ë ¥ì„ ë“¤ì–´ì„œ ì „ì²´ì ì¸ ê³¼ì •ì„ ì„¤ëª…í•´ì¤˜ ì¶”ê°€ì ìœ¼ë¡œ ë…¼ë¬¸ì˜ í•œê³„ì ì— ëŒ€í•´ì„œë„ ì•Œë ¤ì¤˜&lt;/h1>
&lt;p>ì´ SOLA ë…¼ë¬¸ì€ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM) ì„œë¹„ìŠ¤ì—ì„œ ì„œë¹„ìŠ¤ ìˆ˜ì¤€ ëª©í‘œ(SLO), íŠ¹ížˆ ì²« í† í°ê¹Œì§€ì˜ ì‹œê°„(TTFT)ê³¼ ì¶œë ¥ í† í°ë‹¹ ì‹œê°„(TPOT) ë‹¬ì„±ë¥ ì„ ìµœì í™”í•˜ê¸° ìœ„í•œ ìƒˆë¡œìš´ ìŠ¤ì¼€ì¤„ë§ í”„ë ˆìž„ì›Œí¬ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. ê¸°ì¡´ ì‹œìŠ¤í…œì˜ ê³ ì •ëœ ì›ì¹™ì— ë”°ë¥¸ ìŠ¤ì¼€ì¤„ë§ ë°©ì‹ì´ ì•¼ê¸°í•˜ëŠ” TTFTì™€ TPOT ê°„ì˜ ì§€ì—° ì‹œê°„ ë¶„í¬ íŽ¸í–¥ ë° ìš”ì²­ ê°„ ë¶„í¬ ë¶„ì‚° ë¬¸ì œë¥¼ í•´ê²°í•˜ê³ ìž í•©ë‹ˆë‹¤. [cite: 3]&lt;/p></description></item><item><title>XGRAMMAR: FLEXIBLE AND EFFICIENT STRUCTURED GENERATION ENGINE FOR LARGE LANGUAGE MODELS</title><link>https://jaehun.me/ko/ko/posts/2025-06-02-paper-2411.15100v3/</link><pubDate>Mon, 02 Jun 2025 00:00:00 +0000</pubDate><guid>https://jaehun.me/ko/ko/posts/2025-06-02-paper-2411.15100v3/</guid><description>&lt;p>&lt;a href="https://arxiv.org/abs/2411.15100v3">ë…¼ë¬¸ ë§í¬&lt;/a>&lt;/p>
&lt;h1 id="q--ì´-ë…¼ë¬¸ì„-ì•„ì£¼-ìžì„¸í•˜ê²Œ-ì½ê³ -ë…¼ë¬¸ì˜-ê°•ì ê³¼-ë…ì°½ì ì¸-ì§€ì ì„-ì„¤ëª…í•´ì£¼ê³ -í•µì‹¬-ì•Œê³ ë¦¬ì¦˜ì„-ì˜ˆì‹œ-ìž…ë ¥ì„-ë“¤ì–´ì„œ-ì „ì²´ì ì¸-ê³¼ì •ì„-ì„¤ëª…í•´ì¤˜-ì¶”ê°€ì ìœ¼ë¡œ-ë…¼ë¬¸ì˜-í•œê³„ì ì—-ëŒ€í•´ì„œë„-ì•Œë ¤ì¤˜">Q : ì´ ë…¼ë¬¸ì„ ì•„ì£¼ ìžì„¸í•˜ê²Œ ì½ê³  ë…¼ë¬¸ì˜ ê°•ì ê³¼ ë…ì°½ì ì¸ ì§€ì ì„ ì„¤ëª…í•´ì£¼ê³  í•µì‹¬ ì•Œê³ ë¦¬ì¦˜ì„ ì˜ˆì‹œ ìž…ë ¥ì„ ë“¤ì–´ì„œ ì „ì²´ì ì¸ ê³¼ì •ì„ ì„¤ëª…í•´ì¤˜ ì¶”ê°€ì ìœ¼ë¡œ ë…¼ë¬¸ì˜ í•œê³„ì ì— ëŒ€í•´ì„œë„ ì•Œë ¤ì¤˜&lt;/h1>
&lt;h2 id="xgrammar-ë…¼ë¬¸-ìƒì„¸-ë¶„ì„-ìœ ì—°í•˜ê³ -íš¨ìœ¨ì ì¸-llm-êµ¬ì¡°í™”-ìƒì„±-ì—”ì§„">XGrammar ë…¼ë¬¸ ìƒì„¸ ë¶„ì„: ìœ ì—°í•˜ê³  íš¨ìœ¨ì ì¸ LLM êµ¬ì¡°í™” ìƒì„± ì—”ì§„&lt;/h2>
&lt;p>ì œê³µí•´ì£¼ì‹  ë…¼ë¬¸ &amp;ldquo;XGrammar: Flexible and Efficient Structured Generation Engine for Large Language Models&amp;rdquo; [cite: 1]ì€ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)ì´ JSON, SQL, ì½”ë“œ ë“± íŠ¹ì • êµ¬ì¡°ë¥¼ ê°€ì§„ í…ìŠ¤íŠ¸ë¥¼ ìƒì„±í•´ì•¼ í•˜ëŠ” ìš”êµ¬ì— ë¶€ì‘í•˜ê¸° ìœ„í•œ ìƒˆë¡œìš´ ì—”ì§„ XGrammarë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. ê¸°ì¡´ì˜ ë¬¸ë§¥ ìžìœ  ë¬¸ë²•(Context-Free Grammar, CFG) ê¸°ë°˜ ì œì•½ ë””ì½”ë”© ë°©ì‹ì´ ê°€ì§„ ì‹¤í–‰ ì‹œê°„ ì˜¤ë²„í—¤ë“œ ë¬¸ì œë¥¼ í•´ê²°í•˜ëŠ” ë° ì´ˆì ì„ ë§žì¶”ê³  ìžˆìŠµë‹ˆë‹¤. [cite: 2, 3, 4]&lt;/p></description></item><item><title>Context Parallelism for Scalable Million-Token Inference</title><link>https://jaehun.me/ko/ko/posts/2025-03-31-paper-2411.01783/</link><pubDate>Mon, 31 Mar 2025 00:00:00 +0000</pubDate><guid>https://jaehun.me/ko/ko/posts/2025-03-31-paper-2411.01783/</guid><description>&lt;p>&lt;a href="https://arxiv.org/abs/2411.01783">ë…¼ë¬¸ ë§í¬&lt;/a>&lt;/p>
&lt;h1 id="q--ì´-ë…¼ë¬¸ì„-ì•„ì£¼-ìžì„¸í•˜ê²Œ-ì½ê³ -ë…¼ë¬¸ì˜-ê°•ì ê³¼-ë…ì°½ì ì¸-ì§€ì ì„-ì„¤ëª…í•´ì£¼ê³ -í•µì‹¬-ì•Œê³ ë¦¬ì¦˜ì„-ì˜ˆì‹œ-ìž…ë ¥ì„-ë“¤ì–´ì„œ-ì „ì²´ì ì¸-ê³¼ì •ì„-ì„¤ëª…í•´ì¤˜-ì¶”ê°€ì ìœ¼ë¡œ-ë…¼ë¬¸ì˜-í•œê³„ì ì—-ëŒ€í•´ì„œë„-ì•Œë ¤ì¤˜">Q : ì´ ë…¼ë¬¸ì„ ì•„ì£¼ ìžì„¸í•˜ê²Œ ì½ê³  ë…¼ë¬¸ì˜ ê°•ì ê³¼ ë…ì°½ì ì¸ ì§€ì ì„ ì„¤ëª…í•´ì£¼ê³  í•µì‹¬ ì•Œê³ ë¦¬ì¦˜ì„ ì˜ˆì‹œ ìž…ë ¥ì„ ë“¤ì–´ì„œ ì „ì²´ì ì¸ ê³¼ì •ì„ ì„¤ëª…í•´ì¤˜ ì¶”ê°€ì ìœ¼ë¡œ ë…¼ë¬¸ì˜ í•œê³„ì ì— ëŒ€í•´ì„œë„ ì•Œë ¤ì¤˜&lt;/h1>
&lt;p>ë…¼ë¬¸ ã€ŽContext Parallelism for Scalable Million-Token Inferenceã€ëŠ” ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)ì˜ ê¸´ ë¬¸ë§¥ ì²˜ë¦¬ë¥¼ ìœ„í•œ **context parallelism (CP)**ì„ ì œì•ˆí•˜ë©°, íŠ¹ížˆ ê¸´ ë¬¸ë§¥ì—ì„œ ê¸°ì¡´ì˜ í…ì„œ ë³‘ë ¬í™”(Tensor Parallelism, TP)ì— ë¹„í•´ íš¨ìœ¨ì ì¸ ì„±ëŠ¥ì„ ë‹¬ì„±í•˜ëŠ” ë° ì´ˆì ì„ ë§žì¶˜ ì—°êµ¬ìž…ë‹ˆë‹¤.&lt;/p></description></item><item><title>NEO: Saving GPU Memory Crisis with CPU Offloading for Online LLM Inference</title><link>https://jaehun.me/ko/ko/posts/2025-03-31-paper-2411.01142/</link><pubDate>Mon, 31 Mar 2025 00:00:00 +0000</pubDate><guid>https://jaehun.me/ko/ko/posts/2025-03-31-paper-2411.01142/</guid><description>&lt;p>&lt;a href="https://arxiv.org/abs/2411.01142">ë…¼ë¬¸ ë§í¬&lt;/a>&lt;/p>
&lt;h1 id="q--ì´-ë…¼ë¬¸ì„-ì•„ì£¼-ìžì„¸í•˜ê²Œ-ì½ê³ -ë…¼ë¬¸ì˜-ê°•ì ê³¼-ë…ì°½ì ì¸-ì§€ì ì„-ì„¤ëª…í•´ì£¼ê³ -í•µì‹¬-ì•Œê³ ë¦¬ì¦˜ì„-ì˜ˆì‹œ-ìž…ë ¥ì„-ë“¤ì–´ì„œ-ì „ì²´ì ì¸-ê³¼ì •ì„-ì„¤ëª…í•´ì¤˜-ì¶”ê°€ì ìœ¼ë¡œ-ë…¼ë¬¸ì˜-í•œê³„ì ì—-ëŒ€í•´ì„œë„-ì•Œë ¤ì¤˜">Q : ì´ ë…¼ë¬¸ì„ ì•„ì£¼ ìžì„¸í•˜ê²Œ ì½ê³  ë…¼ë¬¸ì˜ ê°•ì ê³¼ ë…ì°½ì ì¸ ì§€ì ì„ ì„¤ëª…í•´ì£¼ê³  í•µì‹¬ ì•Œê³ ë¦¬ì¦˜ì„ ì˜ˆì‹œ ìž…ë ¥ì„ ë“¤ì–´ì„œ ì „ì²´ì ì¸ ê³¼ì •ì„ ì„¤ëª…í•´ì¤˜ ì¶”ê°€ì ìœ¼ë¡œ ë…¼ë¬¸ì˜ í•œê³„ì ì— ëŒ€í•´ì„œë„ ì•Œë ¤ì¤˜&lt;/h1>
&lt;h3 id="-ë…¼ë¬¸-ì œëª©-neo-saving-gpu-memory-crisis-with-cpu-offloading-for-online-llm-inference">ðŸ“Œ &lt;strong>ë…¼ë¬¸ ì œëª©:&lt;/strong> NEO: Saving GPU Memory Crisis with CPU Offloading for Online LLM Inference&lt;/h3>
&lt;h3 id="-ì €ìž-xuanlin-jiang-yang-zhou-shiyi-cao-ion-stoica-minlan-yu">ðŸ“Œ &lt;strong>ì €ìž:&lt;/strong> Xuanlin Jiang, Yang Zhou, Shiyi Cao, Ion Stoica, Minlan Yu&lt;/h3>
&lt;hr>
&lt;h2 id="1-ê²°ë¡ -ìš”ì•½-ê°•ì --ë…ì°½ì ì¸-ì§€ì ">&lt;strong>1. ê²°ë¡  ìš”ì•½ (ê°•ì  &amp;amp; ë…ì°½ì ì¸ ì§€ì )&lt;/strong>&lt;/h2>
&lt;p>NEOëŠ” GPU ë©”ëª¨ë¦¬ì˜ ì œí•œìœ¼ë¡œ ì¸í•´ ë°œìƒí•˜ëŠ” LLM ì¶”ë¡ ì˜ ë³‘ëª©ì„ í•´ê²°í•˜ê¸° ìœ„í•´ &lt;strong>ë¹„ëŒ€ì¹­ GPU-CPU íŒŒì´í”„ë¼ì´ë‹ê³¼ ë¶€í•˜ ì¸ì‹ ìŠ¤ì¼€ì¤„ë§ì„ ì ìš©í•œ ìƒˆë¡œìš´ ì‹œìŠ¤í…œ&lt;/strong>ìž…ë‹ˆë‹¤. ì£¼ìš” ê°•ì ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.&lt;/p></description></item><item><title>AI Metropolis: Scaling Large Language Model-based Multi-Agent Simulation with Out-of-order Execution</title><link>https://jaehun.me/ko/ko/posts/2025-03-17-paper-2411.03519/</link><pubDate>Mon, 17 Mar 2025 00:00:00 +0000</pubDate><guid>https://jaehun.me/ko/ko/posts/2025-03-17-paper-2411.03519/</guid><description>&lt;p>&lt;a href="https://arxiv.org/abs/2411.03519">ë…¼ë¬¸ ë§í¬&lt;/a>&lt;/p>
&lt;h1 id="q--ì´-ë…¼ë¬¸ì„-ì•„ì£¼-ìžì„¸í•˜ê²Œ-ì½ê³ -ë…¼ë¬¸ì˜-ê°•ì ê³¼-ë…ì°½ì ì¸-ì§€ì ì„-ì„¤ëª…í•´ì£¼ê³ -í•µì‹¬-ì•Œê³ ë¦¬ì¦˜ì„-ì˜ˆì‹œ-ìž…ë ¥ì„-ë“¤ì–´ì„œ-ì „ì²´ì ì¸-ê³¼ì •ì„-ì„¤ëª…í•´ì¤˜-ì¶”ê°€ì ìœ¼ë¡œ-ë…¼ë¬¸ì˜-í•œê³„ì ì—-ëŒ€í•´ì„œë„-ì•Œë ¤ì¤˜">Q : ì´ ë…¼ë¬¸ì„ ì•„ì£¼ ìžì„¸í•˜ê²Œ ì½ê³  ë…¼ë¬¸ì˜ ê°•ì ê³¼ ë…ì°½ì ì¸ ì§€ì ì„ ì„¤ëª…í•´ì£¼ê³  í•µì‹¬ ì•Œê³ ë¦¬ì¦˜ì„ ì˜ˆì‹œ ìž…ë ¥ì„ ë“¤ì–´ì„œ ì „ì²´ì ì¸ ê³¼ì •ì„ ì„¤ëª…í•´ì¤˜ ì¶”ê°€ì ìœ¼ë¡œ ë…¼ë¬¸ì˜ í•œê³„ì ì— ëŒ€í•´ì„œë„ ì•Œë ¤ì¤˜&lt;/h1>
&lt;p>ë…¼ë¬¸ã€ŽAI Metropolis: Scaling Large Language Model-based Multi-Agent Simulation with Out-of-order Executionã€ì˜ ì£¼ìš” ê°•ì ê³¼ ë…ì°½ì ì¸ ì§€ì , í•µì‹¬ ì•Œê³ ë¦¬ì¦˜ ë° í•œê³„ì ì„ ì••ì¶•í•˜ì—¬ ì„¤ëª…í•˜ë©´ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.&lt;/p></description></item><item><title>DIFFSERVE: EFFICIENTLY SERVING TEXT-TO-IMAGE DIFFUSION MODELS WITH QUERY-AWARE MODEL SCALING</title><link>https://jaehun.me/ko/ko/posts/2025-03-17-paper-2411.15381/</link><pubDate>Mon, 17 Mar 2025 00:00:00 +0000</pubDate><guid>https://jaehun.me/ko/ko/posts/2025-03-17-paper-2411.15381/</guid><description>&lt;p>&lt;a href="https://arxiv.org/abs/2411.15381">ë…¼ë¬¸ ë§í¬&lt;/a>&lt;/p>
&lt;h1 id="q--ì´-ë…¼ë¬¸ì„-ì•„ì£¼-ìžì„¸í•˜ê²Œ-ì½ê³ -ë…¼ë¬¸ì˜-ê°•ì ê³¼-ë…ì°½ì ì¸-ì§€ì ì„-ì„¤ëª…í•´ì£¼ê³ -í•µì‹¬-ì•Œê³ ë¦¬ì¦˜ì„-ì˜ˆì‹œ-ìž…ë ¥ì„-ë“¤ì–´ì„œ-ì „ì²´ì ì¸-ê³¼ì •ì„-ì„¤ëª…í•´ì¤˜-ì¶”ê°€ì ìœ¼ë¡œ-ë…¼ë¬¸ì˜-í•œê³„ì ì—-ëŒ€í•´ì„œë„-ì•Œë ¤ì¤˜">Q : ì´ ë…¼ë¬¸ì„ ì•„ì£¼ ìžì„¸í•˜ê²Œ ì½ê³  ë…¼ë¬¸ì˜ ê°•ì ê³¼ ë…ì°½ì ì¸ ì§€ì ì„ ì„¤ëª…í•´ì£¼ê³  í•µì‹¬ ì•Œê³ ë¦¬ì¦˜ì„ ì˜ˆì‹œ ìž…ë ¥ì„ ë“¤ì–´ì„œ ì „ì²´ì ì¸ ê³¼ì •ì„ ì„¤ëª…í•´ì¤˜ ì¶”ê°€ì ìœ¼ë¡œ ë…¼ë¬¸ì˜ í•œê³„ì ì— ëŒ€í•´ì„œë„ ì•Œë ¤ì¤˜&lt;/h1>
&lt;h3 id="ë…¼ë¬¸ì˜-í•µì‹¬-ìš”ì•½-ë°-ê¸°ì—¬">&lt;strong>ë…¼ë¬¸ì˜ í•µì‹¬ ìš”ì•½ ë° ê¸°ì—¬&lt;/strong>&lt;/h3>
&lt;p>&lt;strong>DIFFSERVE&lt;/strong>ëŠ” &lt;strong>query-aware model scaling&lt;/strong> ê°œë…ì„ ë„ìž…í•˜ì—¬ &lt;strong>Text-to-Image Diffusion Model&lt;/strong>ì˜ íš¨ìœ¨ì ì¸ ì„œë¹™ì„ ê°€ëŠ¥í•˜ê²Œ í•˜ëŠ” ì‹œìŠ¤í…œì´ë‹¤. ê¸°ì¡´ ì„œë¹™ ì‹œìŠ¤í…œì´ ëª¨ë“  ìš”ì²­ì— ëŒ€í•´ ë™ì¼í•œ í¬ê¸°ì˜ ëª¨ë¸ì„ ì‚¬ìš©í•˜ëŠ” ë°˜ë©´, DIFFSERVEëŠ” ìž…ë ¥ ì¿¼ë¦¬ì˜ ë‚œì´ë„ì— ë”°ë¼ &lt;strong>ê²½ëŸ‰(lightweight) ëª¨ë¸ê³¼ ê³ ì„±ëŠ¥(heavyweight) ëª¨ë¸ì„ ì„ íƒì ìœ¼ë¡œ ì‚¬ìš©&lt;/strong>í•˜ëŠ” &lt;strong>ëª¨ë¸ ìºìŠ¤ì¼€ì´ë“œ(model cascade)&lt;/strong> ê¸°ë²•ì„ ì ìš©í•œë‹¤. ì´ë¥¼ í†µí•´ &lt;strong>ìµœëŒ€ 24% í’ˆì§ˆ í–¥ìƒ&lt;/strong>, &lt;strong>19-70% SLO(ì„œë¹„ìŠ¤ ë ˆë²¨ ëª©í‘œ) ìœ„ë°˜ ê°ì†Œ&lt;/strong>ë¥¼ ë‹¬ì„±í•œë‹¤.&lt;/p></description></item><item><title>EFFICIENT LLM INFERENCE USING DYNAMIC INPUT PRUNING AND CACHE-AWARE MASKING</title><link>https://jaehun.me/ko/ko/posts/2025-03-12-paper-2412.01380/</link><pubDate>Wed, 12 Mar 2025 00:00:00 +0000</pubDate><guid>https://jaehun.me/ko/ko/posts/2025-03-12-paper-2412.01380/</guid><description>&lt;p>&lt;a href="https://arxiv.org/abs/2412.01380">ë…¼ë¬¸ ë§í¬&lt;/a>&lt;/p>
&lt;h1 id="q--ì´-ë…¼ë¬¸ì„-ì•„ì£¼-ìžì„¸í•˜ê²Œ-ì½ê³ -ë…¼ë¬¸ì˜-ê°•ì ê³¼-ë…ì°½ì ì¸-ì§€ì ì„-ì„¤ëª…í•´ì£¼ê³ -í•µì‹¬-ì•Œê³ ë¦¬ì¦˜ì„-ì˜ˆì‹œ-ìž…ë ¥ì„-ë“¤ì–´ì„œ-ì „ì²´ì ì¸-ê³¼ì •ì„-ì„¤ëª…í•´ì¤˜-ì¶”ê°€ì ìœ¼ë¡œ-ë…¼ë¬¸ì˜-í•œê³„ì ì—-ëŒ€í•´ì„œë„-ì•Œë ¤ì¤˜">Q : ì´ ë…¼ë¬¸ì„ ì•„ì£¼ ìžì„¸í•˜ê²Œ ì½ê³  ë…¼ë¬¸ì˜ ê°•ì ê³¼ ë…ì°½ì ì¸ ì§€ì ì„ ì„¤ëª…í•´ì£¼ê³  í•µì‹¬ ì•Œê³ ë¦¬ì¦˜ì„ ì˜ˆì‹œ ìž…ë ¥ì„ ë“¤ì–´ì„œ ì „ì²´ì ì¸ ê³¼ì •ì„ ì„¤ëª…í•´ì¤˜ ì¶”ê°€ì ìœ¼ë¡œ ë…¼ë¬¸ì˜ í•œê³„ì ì— ëŒ€í•´ì„œë„ ì•Œë ¤ì¤˜&lt;/h1>
&lt;h3 id="ë…¼ë¬¸ì˜-í•µì‹¬-ë‚´ìš©ê³¼-ë…ì°½ì ì¸-ê¸°ì—¬">&lt;strong>ë…¼ë¬¸ì˜ í•µì‹¬ ë‚´ìš©ê³¼ ë…ì°½ì ì¸ ê¸°ì—¬&lt;/strong>&lt;/h3>
&lt;p>ì´ ë…¼ë¬¸ì€ &lt;strong>ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì˜ ì¶”ë¡  ì†ë„ë¥¼ í–¥ìƒ&lt;/strong>ì‹œí‚¤ê¸° ìœ„í•´ &lt;strong>Dynamic Input Pruning(DIP)&lt;/strong> ë° &lt;strong>Cache-Aware Masking&lt;/strong> ê¸°ë²•ì„ ì œì•ˆí•œë‹¤. ê¸°ì¡´ LLMë“¤ì€ &lt;strong>ë©”ëª¨ë¦¬ ëŒ€ì—­í­ì˜ ë³‘ëª© í˜„ìƒ&lt;/strong>ìœ¼ë¡œ ì¸í•´ ëª¨ë°”ì¼ ë””ë°”ì´ìŠ¤ì—ì„œ íš¨ìœ¨ì ìœ¼ë¡œ ë™ìž‘í•˜ê¸° ì–´ë ¤ì› ë‹¤. íŠ¹ížˆ ìµœì‹  LLMë“¤ì´ ReLU ëŒ€ì‹  SwiGLUë¥¼ ì‚¬ìš©í•˜ëŠ”ë°, ì´ëŠ” ìžì—°ì ì¸ í™œì„±í™” í¬ì†Œì„±ì´ ë‚®ì•„ ê¸°ì¡´ ë™ì  í¬ì†Œí™” ê¸°ë²•ì´ ë¹„íš¨ìœ¨ì ì´ì—ˆë‹¤.&lt;/p></description></item><item><title>Marconi: Prefix Caching for the Era of Hybrid LLMs</title><link>https://jaehun.me/ko/ko/posts/2025-03-12-paper-2411.19379/</link><pubDate>Wed, 12 Mar 2025 00:00:00 +0000</pubDate><guid>https://jaehun.me/ko/ko/posts/2025-03-12-paper-2411.19379/</guid><description>&lt;p>&lt;a href="https://arxiv.org/abs/2411.19379">ë…¼ë¬¸ ë§í¬&lt;/a>&lt;/p>
&lt;h1 id="q--ì´-ë…¼ë¬¸ì„-ì•„ì£¼-ìžì„¸í•˜ê²Œ-ì½ê³ -ë…¼ë¬¸ì˜-ê°•ì ê³¼-ë…ì°½ì ì¸-ì§€ì ì„-ì„¤ëª…í•´ì£¼ê³ -í•µì‹¬-ì•Œê³ ë¦¬ì¦˜ì„-ì˜ˆì‹œ-ìž…ë ¥ì„-ë“¤ì–´ì„œ-ì „ì²´ì ì¸-ê³¼ì •ì„-ì„¤ëª…í•´ì¤˜-ì¶”ê°€ì ìœ¼ë¡œ-ë…¼ë¬¸ì˜-í•œê³„ì ì—-ëŒ€í•´ì„œë„-ì•Œë ¤ì¤˜">Q : ì´ ë…¼ë¬¸ì„ ì•„ì£¼ ìžì„¸í•˜ê²Œ ì½ê³  ë…¼ë¬¸ì˜ ê°•ì ê³¼ ë…ì°½ì ì¸ ì§€ì ì„ ì„¤ëª…í•´ì£¼ê³  í•µì‹¬ ì•Œê³ ë¦¬ì¦˜ì„ ì˜ˆì‹œ ìž…ë ¥ì„ ë“¤ì–´ì„œ ì „ì²´ì ì¸ ê³¼ì •ì„ ì„¤ëª…í•´ì¤˜ ì¶”ê°€ì ìœ¼ë¡œ ë…¼ë¬¸ì˜ í•œê³„ì ì— ëŒ€í•´ì„œë„ ì•Œë ¤ì¤˜&lt;/h1>
&lt;h3 id="ë…¼ë¬¸ì˜-í•µì‹¬-ìš”ì•½-ë°-í‰ê°€">ë…¼ë¬¸ì˜ í•µì‹¬ ìš”ì•½ ë° í‰ê°€&lt;/h3>
&lt;p>&lt;strong>ë…¼ë¬¸ ì œëª©:&lt;/strong>&lt;br>
&lt;strong>Marconi: Prefix Caching for the Era of Hybrid LLMs&lt;/strong>&lt;/p></description></item><item><title>LAVA: LIFETIME-AWARE VM ALLOCATION WITH LEARNED DISTRIBUTIONS AND ADAPTATION TO MISPREDICTIONS</title><link>https://jaehun.me/ko/ko/posts/2025-03-11-paper-2412.09840/</link><pubDate>Tue, 11 Mar 2025 00:00:00 +0000</pubDate><guid>https://jaehun.me/ko/ko/posts/2025-03-11-paper-2412.09840/</guid><description>&lt;p>&lt;a href="https://arxiv.org/abs/2412.09840">ë…¼ë¬¸ ë§í¬&lt;/a>&lt;/p>
&lt;h1 id="q--ì´-ë…¼ë¬¸ì„-ì•„ì£¼-ìžì„¸í•˜ê²Œ-ì½ê³ -ë…¼ë¬¸ì˜-ê°•ì ê³¼-ë…ì°½ì ì¸-ì§€ì ì„-ì„¤ëª…í•´ì£¼ê³ -í•µì‹¬-ì•Œê³ ë¦¬ì¦˜ì„-ì˜ˆì‹œ-ìž…ë ¥ì„-ë“¤ì–´ì„œ-ì „ì²´ì ì¸-ê³¼ì •ì„-ì„¤ëª…í•´ì¤˜-ì¶”ê°€ì ìœ¼ë¡œ-ë…¼ë¬¸ì˜-í•œê³„ì ì—-ëŒ€í•´ì„œë„-ì•Œë ¤ì¤˜">Q : ì´ ë…¼ë¬¸ì„ ì•„ì£¼ ìžì„¸í•˜ê²Œ ì½ê³  ë…¼ë¬¸ì˜ ê°•ì ê³¼ ë…ì°½ì ì¸ ì§€ì ì„ ì„¤ëª…í•´ì£¼ê³  í•µì‹¬ ì•Œê³ ë¦¬ì¦˜ì„ ì˜ˆì‹œ ìž…ë ¥ì„ ë“¤ì–´ì„œ ì „ì²´ì ì¸ ê³¼ì •ì„ ì„¤ëª…í•´ì¤˜ ì¶”ê°€ì ìœ¼ë¡œ ë…¼ë¬¸ì˜ í•œê³„ì ì— ëŒ€í•´ì„œë„ ì•Œë ¤ì¤˜&lt;/h1>
&lt;h2 id="ë…¼ë¬¸ì˜-ê°•ì ê³¼-ë…ì°½ì„±">&lt;strong>ë…¼ë¬¸ì˜ ê°•ì ê³¼ ë…ì°½ì„±&lt;/strong>&lt;/h2>
&lt;h3 id="ê°•ì ">&lt;strong>ê°•ì &lt;/strong>&lt;/h3>
&lt;ol>
&lt;li>
&lt;p>&lt;strong>ê¸°ì¡´ VM ìŠ¤ì¼€ì¤„ë§ ë°©ì‹ë³´ë‹¤ ë†’ì€ íš¨ìœ¨ì„±&lt;/strong>&lt;/p></description></item><item><title>TurboAttention: Efficient Attention Approximation for High Throughputs LLMs</title><link>https://jaehun.me/ko/ko/posts/2025-03-11-paper-2412.08585/</link><pubDate>Tue, 11 Mar 2025 00:00:00 +0000</pubDate><guid>https://jaehun.me/ko/ko/posts/2025-03-11-paper-2412.08585/</guid><description>&lt;p>&lt;a href="https://arxiv.org/abs/2412.08585">ë…¼ë¬¸ ë§í¬&lt;/a>&lt;/p>
&lt;h1 id="q--ì´-ë…¼ë¬¸ì„-ì•„ì£¼-ìžì„¸í•˜ê²Œ-ì½ê³ -ë…¼ë¬¸ì˜-ê°•ì ê³¼-ë…ì°½ì ì¸-ì§€ì ì„-ì„¤ëª…í•´ì£¼ê³ -í•µì‹¬-ì•Œê³ ë¦¬ì¦˜ì„-ì˜ˆì‹œ-ìž…ë ¥ì„-ë“¤ì–´ì„œ-ì „ì²´ì ì¸-ê³¼ì •ì„-ì„¤ëª…í•´ì¤˜-ì¶”ê°€ì ìœ¼ë¡œ-ë…¼ë¬¸ì˜-í•œê³„ì ì—-ëŒ€í•´ì„œë„-ì•Œë ¤ì¤˜">Q : ì´ ë…¼ë¬¸ì„ ì•„ì£¼ ìžì„¸í•˜ê²Œ ì½ê³  ë…¼ë¬¸ì˜ ê°•ì ê³¼ ë…ì°½ì ì¸ ì§€ì ì„ ì„¤ëª…í•´ì£¼ê³  í•µì‹¬ ì•Œê³ ë¦¬ì¦˜ì„ ì˜ˆì‹œ ìž…ë ¥ì„ ë“¤ì–´ì„œ ì „ì²´ì ì¸ ê³¼ì •ì„ ì„¤ëª…í•´ì¤˜ ì¶”ê°€ì ìœ¼ë¡œ ë…¼ë¬¸ì˜ í•œê³„ì ì— ëŒ€í•´ì„œë„ ì•Œë ¤ì¤˜&lt;/h1>
&lt;p>ë…¼ë¬¸ ã€ŽTurboAttention: Efficient Attention Approximation for High Throughputs LLMsã€ëŠ” ê¸°ì¡´ì˜ Attention ì—°ì‚°ì˜ ì†ë„ì™€ ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±ì„ ë™ì‹œì— ê°œì„ í•œ í†µí•©ì ì¸ ì ‘ê·¼ ë°©ë²•ì„ ì œì•ˆí•˜ê³  ìžˆìœ¼ë©°, ì´ëŠ” ë‘ ê°€ì§€ í•µì‹¬ ì•Œê³ ë¦¬ì¦˜ì¸ FlashQì™€ Sparsity-based Softmax Approximation (SAS)ì„ í†µí•´ êµ¬í˜„ë˜ì—ˆìŠµë‹ˆë‹¤.&lt;/p></description></item><item><title>A PRACTICAL CROSS-LAYER APPROACH FOR ML-DRIVEN STORAGE PLACEMENT IN WAREHOUSE-SCALE COMPUTERS</title><link>https://jaehun.me/ko/ko/posts/2025-03-10-paper-2501.05651/</link><pubDate>Mon, 10 Mar 2025 00:00:00 +0000</pubDate><guid>https://jaehun.me/ko/ko/posts/2025-03-10-paper-2501.05651/</guid><description>&lt;p>&lt;a href="https://arxiv.org/abs/2501.05651">ë…¼ë¬¸ ë§í¬&lt;/a>&lt;/p>
&lt;h1 id="q--ì´-ë…¼ë¬¸ì„-ì•„ì£¼-ìžì„¸í•˜ê²Œ-ì½ê³ -ë…¼ë¬¸ì˜-ê°•ì ê³¼-ë…ì°½ì ì¸-ì§€ì ì„-ì„¤ëª…í•´ì£¼ê³ -í•µì‹¬-ì•Œê³ ë¦¬ì¦˜ì„-ì˜ˆì‹œ-ìž…ë ¥ì„-ë“¤ì–´ì„œ-ì „ì²´ì ì¸-ê³¼ì •ì„-ì„¤ëª…í•´ì¤˜-ì¶”ê°€ì ìœ¼ë¡œ-ë…¼ë¬¸ì˜-í•œê³„ì ì—-ëŒ€í•´ì„œë„-ì•Œë ¤ì¤˜">Q : ì´ ë…¼ë¬¸ì„ ì•„ì£¼ ìžì„¸í•˜ê²Œ ì½ê³  ë…¼ë¬¸ì˜ ê°•ì ê³¼ ë…ì°½ì ì¸ ì§€ì ì„ ì„¤ëª…í•´ì£¼ê³  í•µì‹¬ ì•Œê³ ë¦¬ì¦˜ì„ ì˜ˆì‹œ ìž…ë ¥ì„ ë“¤ì–´ì„œ ì „ì²´ì ì¸ ê³¼ì •ì„ ì„¤ëª…í•´ì¤˜ ì¶”ê°€ì ìœ¼ë¡œ ë…¼ë¬¸ì˜ í•œê³„ì ì— ëŒ€í•´ì„œë„ ì•Œë ¤ì¤˜&lt;/h1>
&lt;h3 id="ë…¼ë¬¸ì˜-ê°•ì -ë°-ë…ì°½ì ì¸-ì§€ì ">&lt;strong>ë…¼ë¬¸ì˜ ê°•ì  ë° ë…ì°½ì ì¸ ì§€ì &lt;/strong>&lt;/h3>
&lt;p>ì´ ë…¼ë¬¸ì€ &lt;strong>ëŒ€ê·œëª¨ ë°ì´í„° ì„¼í„°ì—ì„œ ê¸°ê³„ í•™ìŠµ(ML)ì„ í™œìš©í•œ ì €ìž¥ì†Œ ë°°ì¹˜(Storage Placement) ë¬¸ì œ&lt;/strong>ë¥¼ ë‹¤ë£¨ë©°, ê¸°ì¡´ ì ‘ê·¼ë²•ì˜ í•œê³„ë¥¼ ê·¹ë³µí•˜ê¸° ìœ„í•´ &lt;strong>í¬ë¡œìŠ¤-ë ˆì´ì–´(Cross-Layer) ì ‘ê·¼ ë°©ì‹&lt;/strong>ì„ ì œì•ˆí–ˆë‹¤. ì£¼ìš” ê°•ì ê³¼ ë…ì°½ì ì¸ ì ì€ ë‹¤ìŒê³¼ ê°™ë‹¤.&lt;/p></description></item><item><title>Comet: Fine-grained Computation-communication Overlapping for Mixture-of-Experts</title><link>https://jaehun.me/ko/ko/posts/2025-03-10-paper-2502.16949/</link><pubDate>Mon, 10 Mar 2025 00:00:00 +0000</pubDate><guid>https://jaehun.me/ko/ko/posts/2025-03-10-paper-2502.16949/</guid><description>&lt;p>&lt;a href="https://arxiv.org/abs/2502.16949">ë…¼ë¬¸ ë§í¬&lt;/a>&lt;/p>
&lt;h1 id="q--ì´-ë…¼ë¬¸ì„-ì•„ì£¼-ìžì„¸í•˜ê²Œ-ì½ê³ -ë…¼ë¬¸ì˜-ê°•ì ê³¼-ë…ì°½ì ì¸-ì§€ì ì„-ì„¤ëª…í•´ì£¼ê³ -í•µì‹¬-ì•Œê³ ë¦¬ì¦˜ì„-ì˜ˆì‹œ-ìž…ë ¥ì„-ë“¤ì–´ì„œ-ì „ì²´ì ì¸-ê³¼ì •ì„-ì„¤ëª…í•´ì¤˜-ì¶”ê°€ì ìœ¼ë¡œ-ë…¼ë¬¸ì˜-í•œê³„ì ì—-ëŒ€í•´ì„œë„-ì•Œë ¤ì¤˜">Q : ì´ ë…¼ë¬¸ì„ ì•„ì£¼ ìžì„¸í•˜ê²Œ ì½ê³  ë…¼ë¬¸ì˜ ê°•ì ê³¼ ë…ì°½ì ì¸ ì§€ì ì„ ì„¤ëª…í•´ì£¼ê³  í•µì‹¬ ì•Œê³ ë¦¬ì¦˜ì„ ì˜ˆì‹œ ìž…ë ¥ì„ ë“¤ì–´ì„œ ì „ì²´ì ì¸ ê³¼ì •ì„ ì„¤ëª…í•´ì¤˜ ì¶”ê°€ì ìœ¼ë¡œ ë…¼ë¬¸ì˜ í•œê³„ì ì— ëŒ€í•´ì„œë„ ì•Œë ¤ì¤˜&lt;/h1>
&lt;h3 id="ë…¼ë¬¸ì˜-í•µì‹¬-ìš”ì•½-ë°-ê¸°ì—¬ì ">&lt;strong>ë…¼ë¬¸ì˜ í•µì‹¬ ìš”ì•½ ë° ê¸°ì—¬ì &lt;/strong>&lt;/h3>
&lt;p>ì´ ë…¼ë¬¸ì€ &lt;strong>Comet&lt;/strong>ì´ë¼ëŠ” ìƒˆë¡œìš´ MoE(Mixture-of-Experts) ì‹œìŠ¤í…œì„ ì œì•ˆí•˜ì—¬ &lt;strong>ê³„ì‚°-í†µì‹  ì˜¤ë²„ëž˜í•‘&lt;/strong>ì„ ë”ìš± ì„¸ë°€í•˜ê²Œ ìˆ˜í–‰í•¨ìœ¼ë¡œì¨ MoE ëª¨ë¸ì˜ ì‹¤í–‰ ì†ë„ë¥¼ í¬ê²Œ í–¥ìƒì‹œì¼°ë‹¤. ê¸°ì¡´ MoE ëª¨ë¸ì—ì„œ í†µì‹  ë¹„ìš©ì´ ì „ì²´ ì‹¤í–‰ ì‹œê°„ì˜ 47%ë¥¼ ì°¨ì§€í•˜ëŠ” ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´, &lt;strong>ì„¸ë°€í•œ ìˆ˜ì¤€ì˜(overlapping fine-grained) ê³„ì‚°-í†µì‹  ì˜¤ë²„ëž˜í•‘ ê¸°ë²•&lt;/strong>ì„ ë„ìž…í–ˆë‹¤.&lt;/p></description></item><item><title>Scaling Deep Learning Training with MPMD Pipeline Parallelism</title><link>https://jaehun.me/ko/ko/posts/2025-03-10-paper-2412.14374/</link><pubDate>Mon, 10 Mar 2025 00:00:00 +0000</pubDate><guid>https://jaehun.me/ko/ko/posts/2025-03-10-paper-2412.14374/</guid><description>&lt;p>&lt;a href="https://arxiv.org/abs/2412.14374">ë…¼ë¬¸ ë§í¬&lt;/a>&lt;/p>
&lt;h1 id="q--ì´-ë…¼ë¬¸ì„-ì•„ì£¼-ìžì„¸í•˜ê²Œ-ì½ê³ -ë…¼ë¬¸ì˜-ê°•ì ê³¼-ë…ì°½ì ì¸-ì§€ì ì„-ì„¤ëª…í•´ì£¼ê³ -í•µì‹¬-ì•Œê³ ë¦¬ì¦˜ì„-ì˜ˆì‹œ-ìž…ë ¥ì„-ë“¤ì–´ì„œ-ì „ì²´ì ì¸-ê³¼ì •ì„-ì„¤ëª…í•´ì¤˜-ì¶”ê°€ì ìœ¼ë¡œ-ë…¼ë¬¸ì˜-í•œê³„ì ì—-ëŒ€í•´ì„œë„-ì•Œë ¤ì¤˜">Q : ì´ ë…¼ë¬¸ì„ ì•„ì£¼ ìžì„¸í•˜ê²Œ ì½ê³  ë…¼ë¬¸ì˜ ê°•ì ê³¼ ë…ì°½ì ì¸ ì§€ì ì„ ì„¤ëª…í•´ì£¼ê³  í•µì‹¬ ì•Œê³ ë¦¬ì¦˜ì„ ì˜ˆì‹œ ìž…ë ¥ì„ ë“¤ì–´ì„œ ì „ì²´ì ì¸ ê³¼ì •ì„ ì„¤ëª…í•´ì¤˜ ì¶”ê°€ì ìœ¼ë¡œ ë…¼ë¬¸ì˜ í•œê³„ì ì— ëŒ€í•´ì„œë„ ì•Œë ¤ì¤˜&lt;/h1>
&lt;p>ë³¸ ë…¼ë¬¸ì€ JaxPPë¼ëŠ” ì‹œìŠ¤í…œì„ ì œì•ˆí•˜ì—¬, ê¸°ì¡´ì˜ Single-Program Multiple-Data (SPMD) ë°©ì‹ì˜ í•œê³„ë¥¼ ê·¹ë³µí•˜ê³  Multiple-Program Multiple-Data (MPMD) íŒŒì´í”„ë¼ì¸ ë³‘ë ¬í™”ë¥¼ í†µí•´ ëŒ€ê·œëª¨ ë”¥ëŸ¬ë‹ ëª¨ë¸ í•™ìŠµì˜ í™•ìž¥ì„±ê³¼ ì„±ëŠ¥ì„ í–¥ìƒí•œ ì—°êµ¬ì´ë‹¤. íŠ¹ížˆ, JaxPPëŠ” ì‚¬ìš©ìžê°€ pipeline ìŠ¤ì¼€ì¤„ë§ì„ ìœ ì—°í•˜ê²Œ ì •ì˜í•  ìˆ˜ ìžˆë„ë¡ ì§€ì›í•˜ë©°, ìžë™í™”ëœ ìž‘ì—… ë¶„ë°°ì™€ í†µì‹  íŒ¨í„´ ì¶”ë¡ ì„ í†µí•´ í•˜ë“œì›¨ì–´ ìžì›ì„ íš¨ìœ¨ì ìœ¼ë¡œ ì‚¬ìš©í•˜ì—¬ ê¸°ì¡´ SPMD ëŒ€ë¹„ ìµœëŒ€ 1.11ë°° í–¥ìƒëœ ì„±ëŠ¥ì„ ë³´ì˜€ë‹¤.&lt;/p></description></item><item><title>LSERVE: EFFICIENT LONG-SEQUENCE LLM SERVING WITH UNIFIED SPARSE ATTENTION</title><link>https://jaehun.me/ko/ko/posts/2025-03-06-paper-2502.14866/</link><pubDate>Thu, 06 Mar 2025 00:00:00 +0000</pubDate><guid>https://jaehun.me/ko/ko/posts/2025-03-06-paper-2502.14866/</guid><description>&lt;p>&lt;a href="https://arxiv.org/abs/2502.14866">ë…¼ë¬¸ ë§í¬&lt;/a>&lt;/p>
&lt;h1 id="q--ì´-ë…¼ë¬¸ì„-ì•„ì£¼-ìžì„¸í•˜ê²Œ-ì½ê³ -ë…¼ë¬¸ì˜-ê°•ì ê³¼-ë…ì°½ì ì¸-ì§€ì ì„-ì„¤ëª…í•´ì£¼ê³ -í•µì‹¬-ì•Œê³ ë¦¬ì¦˜ì„-ì˜ˆì‹œ-ìž…ë ¥ì„-ë“¤ì–´ì„œ-ì „ì²´ì ì¸-ê³¼ì •ì„-ì„¤ëª…í•´ì¤˜-ì¶”ê°€ì ìœ¼ë¡œ-ë…¼ë¬¸ì˜-í•œê³„ì ì—-ëŒ€í•´ì„œë„-ì•Œë ¤ì¤˜">Q : ì´ ë…¼ë¬¸ì„ ì•„ì£¼ ìžì„¸í•˜ê²Œ ì½ê³  ë…¼ë¬¸ì˜ ê°•ì ê³¼ ë…ì°½ì ì¸ ì§€ì ì„ ì„¤ëª…í•´ì£¼ê³  í•µì‹¬ ì•Œê³ ë¦¬ì¦˜ì„ ì˜ˆì‹œ ìž…ë ¥ì„ ë“¤ì–´ì„œ ì „ì²´ì ì¸ ê³¼ì •ì„ ì„¤ëª…í•´ì¤˜ ì¶”ê°€ì ìœ¼ë¡œ ë…¼ë¬¸ì˜ í•œê³„ì ì— ëŒ€í•´ì„œë„ ì•Œë ¤ì¤˜&lt;/h1>
&lt;p>ë…¼ë¬¸ì˜ í•µì‹¬ ë‚´ìš©ì„ ë¨¼ì € ê°„ëžµížˆ ìš”ì•½í•œ í›„, ê°•ì ê³¼ ë…ì°½ì ì¸ ì§€ì ì„ ìžì„¸ížˆ ì„¤ëª…í•˜ê³ , í•µì‹¬ ì•Œê³ ë¦¬ì¦˜ì˜ ë™ìž‘ ì›ë¦¬ë¥¼ ì˜ˆì‹œì™€ í•¨ê»˜ ì œì‹œí•œ ë’¤, ë…¼ë¬¸ì˜ í•œê³„ì ì„ ë§ˆì§€ë§‰ìœ¼ë¡œ ì •ë¦¬í•˜ê² ìŠµë‹ˆë‹¤.&lt;/p></description></item><item><title>ThunderServe: High-performance and Cost-efficient LLM Serving in Cloud Environments</title><link>https://jaehun.me/ko/ko/posts/2025-03-06-paper-2502.09334/</link><pubDate>Thu, 06 Mar 2025 00:00:00 +0000</pubDate><guid>https://jaehun.me/ko/ko/posts/2025-03-06-paper-2502.09334/</guid><description>&lt;p>&lt;a href="https://arxiv.org/abs/2502.09334">ë…¼ë¬¸ ë§í¬&lt;/a>&lt;/p>
&lt;h1 id="q--ì´-ë…¼ë¬¸ì„-ì•„ì£¼-ìžì„¸í•˜ê²Œ-ì½ê³ -ë…¼ë¬¸ì˜-ê°•ì ê³¼-ë…ì°½ì ì¸-ì§€ì ì„-ì„¤ëª…í•´ì£¼ê³ -í•µì‹¬-ì•Œê³ ë¦¬ì¦˜ì„-ì˜ˆì‹œ-ìž…ë ¥ì„-ë“¤ì–´ì„œ-ì „ì²´ì ì¸-ê³¼ì •ì„-ì„¤ëª…í•´ì¤˜-ì¶”ê°€ì ìœ¼ë¡œ-ë…¼ë¬¸ì˜-í•œê³„ì ì—-ëŒ€í•´ì„œë„-ì•Œë ¤ì¤˜">Q : ì´ ë…¼ë¬¸ì„ ì•„ì£¼ ìžì„¸í•˜ê²Œ ì½ê³  ë…¼ë¬¸ì˜ ê°•ì ê³¼ ë…ì°½ì ì¸ ì§€ì ì„ ì„¤ëª…í•´ì£¼ê³  í•µì‹¬ ì•Œê³ ë¦¬ì¦˜ì„ ì˜ˆì‹œ ìž…ë ¥ì„ ë“¤ì–´ì„œ ì „ì²´ì ì¸ ê³¼ì •ì„ ì„¤ëª…í•´ì¤˜ ì¶”ê°€ì ìœ¼ë¡œ ë…¼ë¬¸ì˜ í•œê³„ì ì— ëŒ€í•´ì„œë„ ì•Œë ¤ì¤˜&lt;/h1>
&lt;p>ë…¼ë¬¸ ã€ŽThunderServe: High-performance and Cost-efficient LLM Serving in Cloud Environmentsã€ë¥¼ ìƒì„¸ížˆ ë¶„ì„í•˜ì—¬ ë‹¤ìŒê³¼ ê°™ì€ ë‚´ìš©ì„ ì••ì¶•ì ìœ¼ë¡œ ì •ë¦¬í•˜ì˜€ë‹¤.&lt;/p></description></item><item><title>VOLUT: EFFICIENT VOLUMETRIC STREAMING ENHANCED BY LUT-BASED SUPER-RESOLUTION</title><link>https://jaehun.me/ko/ko/posts/2025-03-06-paper-2502.12151/</link><pubDate>Thu, 06 Mar 2025 00:00:00 +0000</pubDate><guid>https://jaehun.me/ko/ko/posts/2025-03-06-paper-2502.12151/</guid><description>&lt;p>&lt;a href="https://arxiv.org/abs/2502.12151">ë…¼ë¬¸ ë§í¬&lt;/a>&lt;/p>
&lt;h1 id="q--ì´-ë…¼ë¬¸ì„-ì•„ì£¼-ìžì„¸í•˜ê²Œ-ì½ê³ -ë…¼ë¬¸ì˜-ê°•ì ê³¼-ë…ì°½ì ì¸-ì§€ì ì„-ì„¤ëª…í•´ì£¼ê³ -í•µì‹¬-ì•Œê³ ë¦¬ì¦˜ì„-ì˜ˆì‹œ-ìž…ë ¥ì„-ë“¤ì–´ì„œ-ì „ì²´ì ì¸-ê³¼ì •ì„-ì„¤ëª…í•´ì¤˜-ì¶”ê°€ì ìœ¼ë¡œ-ë…¼ë¬¸ì˜-í•œê³„ì ì—-ëŒ€í•´ì„œë„-ì•Œë ¤ì¤˜">Q : ì´ ë…¼ë¬¸ì„ ì•„ì£¼ ìžì„¸í•˜ê²Œ ì½ê³  ë…¼ë¬¸ì˜ ê°•ì ê³¼ ë…ì°½ì ì¸ ì§€ì ì„ ì„¤ëª…í•´ì£¼ê³  í•µì‹¬ ì•Œê³ ë¦¬ì¦˜ì„ ì˜ˆì‹œ ìž…ë ¥ì„ ë“¤ì–´ì„œ ì „ì²´ì ì¸ ê³¼ì •ì„ ì„¤ëª…í•´ì¤˜ ì¶”ê°€ì ìœ¼ë¡œ ë…¼ë¬¸ì˜ í•œê³„ì ì— ëŒ€í•´ì„œë„ ì•Œë ¤ì¤˜&lt;/h1>
&lt;p>ë…¼ë¬¸ ã€ŽVoLUT: Efficient Volumetric Streaming Enhanced by LUT-based Super-resolutionã€ì„ ë¶„ì„í•˜ì—¬ í•µì‹¬ ì‚¬í•­ì„ ì•„ëž˜ì™€ ê°™ì´ ì••ì¶•í•˜ì—¬ ì „ë‹¬í•˜ê³ , ê°•ì ê³¼ ë…ì°½ì„±, ì•Œê³ ë¦¬ì¦˜ì˜ ë™ìž‘ ê³¼ì •, í•œê³„ì ì„ ì°¨ë¡€ë¡œ ì œì‹œí•©ë‹ˆë‹¤.&lt;/p></description></item></channel></rss>