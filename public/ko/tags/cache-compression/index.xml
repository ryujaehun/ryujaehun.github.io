<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Cache-Compression on Jaehun's Blog</title><link>https://jaehun.me/ko/tags/cache-compression/</link><description>Recent content in Cache-Compression on Jaehun's Blog</description><generator>Hugo</generator><language>ko-kr</language><lastBuildDate>Thu, 26 Jun 2025 00:00:00 +0000</lastBuildDate><atom:link href="https://jaehun.me/ko/tags/cache-compression/index.xml" rel="self" type="application/rss+xml"/><item><title>KVzip: Query-Agnostic KV Cache Compression with Context Reconstruction</title><link>https://jaehun.me/ko/ko/posts/2025-06-26-paper-2505.23416v1/</link><pubDate>Thu, 26 Jun 2025 00:00:00 +0000</pubDate><guid>https://jaehun.me/ko/ko/posts/2025-06-26-paper-2505.23416v1/</guid><description>&lt;p>&lt;a href="https://arxiv.org/abs/2505.23416v1">논문 링크&lt;/a>&lt;/p>
&lt;h2 id="tldr">⚡️TL;DR&lt;/h2>
&lt;p>&lt;strong>KVzip&lt;/strong>는 LLM의 KV 캐시를 &lt;em>한 번&lt;/em> 압축해도 이후 모든 질의 · 세션에서 재사용할 수 있도록 설계된 &lt;strong>query-agnostic 캐시 컴프레서&lt;/strong>다.
그 결과 &lt;strong>정확도 손실 ≤ 3 pp&lt;/strong>를 유지하면서 **레이턴시 2 × ↓, 메모리 60–394 × ↓**를 동시에 달성한다.&lt;/p></description></item></channel></rss>