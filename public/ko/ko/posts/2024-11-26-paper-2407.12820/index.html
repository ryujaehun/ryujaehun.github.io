<!doctype html><html lang=ko-kr data-theme=claude><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta http-equiv=X-UA-Compatible content="IE=edge"><title>PQCache: Product Quantization-based KVCache for Long Context LLM Inference | Jaehun's Blog</title><meta name=description content="논문 링크
Q : 이 논문을 아주 자세하게 읽고 논문의 강점과 독창적인 지점을 설명해주고 핵심 알고리즘을 예시 입력을 들어서 전체적인 과정을 설명해줘 추가적으로 논문의 한계점에 대해서도 알려줘 논문 분석: &ldquo;PQCache: Product..."><meta name=keywords content="개발,프로그래밍,에세이"><meta name=author content><meta name=language content="ko"><meta name=robots content="index, follow"><link rel=canonical href=https://jaehun.me/ko/ko/posts/2024-11-26-paper-2407.12820/><link rel=icon type=image/svg+xml href=/favicon.svg><link rel=manifest href=/site.webmanifest><meta property="og:url" content="https://jaehun.me/ko/ko/posts/2024-11-26-paper-2407.12820/"><meta property="og:site_name" content="Jaehun's Blog"><meta property="og:title" content="PQCache: Product Quantization-based KVCache for Long Context LLM Inference"><meta property="og:description" content="논문 링크
Q : 이 논문을 아주 자세하게 읽고 논문의 강점과 독창적인 지점을 설명해주고 핵심 알고리즘을 예시 입력을 들어서 전체적인 과정을 설명해줘 추가적으로 논문의 한계점에 대해서도 알려줘 논문 분석: “PQCache: Product Quantization-based KVCache for Long Context LLM Inference” 1. 강점 및 독창성 강점"><meta property="og:locale" content="ko_kr"><meta property="og:type" content="article"><meta property="article:section" content="ko"><meta property="article:published_time" content="2024-11-26T00:00:00+00:00"><meta property="article:modified_time" content="2024-11-26T00:00:00+00:00"><meta property="og:image" content="https://jaehun.me/images/og-default.avif"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://jaehun.me/images/og-default.avif"><meta name=twitter:title content="PQCache: Product Quantization-based KVCache for Long Context LLM Inference"><meta name=twitter:description content="논문 링크
Q : 이 논문을 아주 자세하게 읽고 논문의 강점과 독창적인 지점을 설명해주고 핵심 알고리즘을 예시 입력을 들어서 전체적인 과정을 설명해줘 추가적으로 논문의 한계점에 대해서도 알려줘 논문 분석: “PQCache: Product Quantization-based KVCache for Long Context LLM Inference” 1. 강점 및 독창성 강점"><meta itemprop=name content="PQCache: Product Quantization-based KVCache for Long Context LLM Inference"><meta itemprop=description content="논문 링크
Q : 이 논문을 아주 자세하게 읽고 논문의 강점과 독창적인 지점을 설명해주고 핵심 알고리즘을 예시 입력을 들어서 전체적인 과정을 설명해줘 추가적으로 논문의 한계점에 대해서도 알려줘 논문 분석: “PQCache: Product Quantization-based KVCache for Long Context LLM Inference” 1. 강점 및 독창성 강점"><meta itemprop=datePublished content="2024-11-26T00:00:00+00:00"><meta itemprop=dateModified content="2024-11-26T00:00:00+00:00"><meta itemprop=wordCount content="10018"><meta itemprop=image content="https://jaehun.me/images/og-default.avif"><meta itemprop=keywords content="Paper-Review,With-Gpt"><script>window.HUGO_SEARCH_CONFIG={searchIndexURL:'"/ko/index.json"'}</script><script>window.HUGO_GALLERY_CONFIG={justified_gallery:!1,lightbox:!1,justified:"{}",lightbox_options:"{}"}</script><link rel=stylesheet href=/css/compiled.min.9165cace5b80a5be5daad6ea96eb2abc20a18a3f41d7fed7f0335b689fdf7883.css integrity="sha256-kWXKzluApb5dqtbqlusqvCChij9B1/7X8DNbaJ/feIM=" crossorigin=anonymous><link rel=stylesheet href=/css/chroma.min.491df36221f739b5948a747a0351f100ee7ccaaf466d9f46288bf06de1d59123.css integrity="sha256-SR3zYiH3ObWUinR6A1HxAO58yq9GbZ9GKIvwbeHVkSM=" crossorigin=anonymous><script src=/js/main.ba969e49a7a874e6938fe689a7dcaa00cb64cb4d429c2cf98d09bde512a16c6d.js integrity="sha256-upaeSaeodOaTj+aJp9yqAMtky01CnCz5jQm95RKhbG0=" crossorigin=anonymous></script><script src=/js/gumshoe.polyfills.min.js></script><script src=/js/toc.70654aebf0b738a78ae2df95297cc10ebc6e590f3c942dd1325fa852f50038b2.js integrity="sha256-cGVK6/C3OKeK4t+VKXzBDrxuWQ88lC3RMl+oUvUAOLI=" crossorigin=anonymous defer></script><script src=/js/search.de3eba3540834efb8328121784bff4774e06362412ee41eee665f5b4f987f393.js integrity="sha256-3j66NUCDTvuDKBIXhL/0d04GNiQS7kHu5mX1tPmH85M=" crossorigin=anonymous defer></script><script src=/js/dock.e02f422517e001d9fb6bea1e9e8b0e89e9d2e486ad4641f275bb3e36ce2ae79f.js integrity="sha256-4C9CJRfgAdn7a+oenosOienS5IatRkHydbs+Ns4q558=" crossorigin=anonymous defer></script><script>(function(){const e=localStorage.getItem("theme")||"system",n=localStorage.getItem("colorScheme")||"claude";document.documentElement.setAttribute("data-theme",n);function t(){e==="dark"||e==="system"&&window.matchMedia("(prefers-color-scheme: dark)").matches?document.documentElement.classList.add("dark"):document.documentElement.classList.remove("dark")}t(),e==="system"&&window.matchMedia("(prefers-color-scheme: dark)").addEventListener("change",t)})()</script></head><body class="bg-background text-foreground min-h-screen antialiased"><div id=reading-progress-container class="reading-progress-container pointer-events-none fixed top-0 right-0 left-0 z-50 transition-opacity duration-300 ease-out" data-height=3 data-smooth-scroll=true data-hide-on-complete=false><div class="reading-progress-bg w-full"></div><div id=reading-progress-bar class="from-primary to-primary/80 reading-progress-bar
transition-all duration-150 ease-out
absolute top-0 left-0 w-0 bg-gradient-to-r"></div></div><script>(function(){"use strict";const t=document.getElementById("reading-progress-container"),o=document.getElementById("reading-progress-bar");if(!t||!o)return;const a={smoothScroll:t.dataset.smoothScroll==="true",hideOnComplete:t.dataset.hideOnComplete==="true"};let n=!0,l=null;function r(){const t=window.pageYOffset||document.documentElement.scrollTop,n=document.documentElement.scrollHeight,s=window.innerHeight,e=n-s;return e<=0?0:Math.min(Math.max(t/e*100,0),100)}function c(){const e=r();o.style.width=e+"%",a.hideOnComplete&&e>=99.5?n&&(t.style.opacity="0",n=!1):n||(t.style.opacity="1",n=!0)}let s=!1;function e(){s||(requestAnimationFrame(()=>{c(),s=!1}),s=!0)}function i(){window.addEventListener("scroll",e,{passive:!0}),window.addEventListener("resize",e,{passive:!0}),document.addEventListener("visibilitychange",()=>{document.hidden||e()}),e(),window.addEventListener("beforeunload",()=>{window.removeEventListener("scroll",e),window.removeEventListener("resize",e)})}document.readyState==="loading"?document.addEventListener("DOMContentLoaded",i):i()})()</script><header class="sticky top-0 z-50 mx-auto max-w-4xl px-4 py-6"><div class="border-border bg-card/80 flex items-center rounded-xl border px-6 py-4 shadow-sm backdrop-blur-sm"><div class="hidden w-full items-center md:flex"><div class="flex items-center"><a href=/ko/ class="flex h-10 w-10 items-center justify-center overflow-hidden rounded-full transition-transform duration-200 hover:scale-105" aria-label="Jaehun's Blog"><img src=/images/logo.svg alt="Jaehun's Blog" class="h-full w-full object-cover"></a></div><nav class="mx-8 flex flex-1 items-center justify-center"><div class="flex items-center space-x-1"><a href=/ko/ class="nav-link
text-muted-foreground hover:text-primary hover:bg-primary/10
focus:ring-primary/20 relative flex items-center gap-2 rounded-lg px-4 py-2 text-sm font-medium transition-all duration-300 ease-out hover:-translate-y-0.5 hover:scale-105 focus:ring-2 focus:outline-none"><svg class="h-5 w-5" fill="none" stroke="currentColor" viewBox="0 0 24 24" aria-label="nav.posts"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 20H5a2 2 0 01-2-2V6a2 2 0 012-2h10a2 2 0 012 2v1m2 13a2 2 0 01-2-2V7m2 13a2 2 0 002-2V9a2 2 0 00-2-2h-2m-4-3H9M7 16h6M7 8h6v4H7V8z"/></svg>
<span>게시글
</span></a><a href=/ko/categories/ class="nav-link
text-muted-foreground hover:text-primary hover:bg-primary/10
focus:ring-primary/20 relative flex items-center gap-2 rounded-lg px-4 py-2 text-sm font-medium transition-all duration-300 ease-out hover:-translate-y-0.5 hover:scale-105 focus:ring-2 focus:outline-none"><svg class="h-5 w-5" fill="none" stroke="currentColor" viewBox="0 0 24 24" aria-label="nav.categories"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 11H5m14 0a2 2 0 012 2v6a2 2 0 01-2 2H5a2 2 0 01-2-2v-6a2 2 0 012-2m14 0V9a2 2 0 00-2-2M5 11V9a2 2 0 012-2m0 0V5a2 2 0 012-2h6a2 2 0 012 2v2M7 7h10"/></svg>
<span>카테고리
</span></a><a href=/ko/tags/ class="nav-link
text-muted-foreground hover:text-primary hover:bg-primary/10
focus:ring-primary/20 relative flex items-center gap-2 rounded-lg px-4 py-2 text-sm font-medium transition-all duration-300 ease-out hover:-translate-y-0.5 hover:scale-105 focus:ring-2 focus:outline-none"><svg class="h-5 w-5" fill="none" stroke="currentColor" viewBox="0 0 24 24" aria-label="nav.tags"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M7 7h.01M7 3h5c.512.0 1.024.195 1.414.586l7 7a2 2 0 010 2.828l-7 7a2 2 0 01-2.828.0l-7-7A1.994 1.994.0 013 12V7a4 4 0 014-4z"/></svg>
<span>태그
</span></a><a href=/ko/ class="nav-link
text-muted-foreground hover:text-primary hover:bg-primary/10
focus:ring-primary/20 relative flex items-center gap-2 rounded-lg px-4 py-2 text-sm font-medium transition-all duration-300 ease-out hover:-translate-y-0.5 hover:scale-105 focus:ring-2 focus:outline-none"><svg class="h-5 w-5" fill="none" stroke="currentColor" viewBox="0 0 24 24" aria-label="nav.archives"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M5 8h14M5 8a2 2 0 110-4h14a2 2 0 110 4M5 8v10a2 2 0 002 2h10a2 2 0 002-2V8m-9 4h4"/></svg>
<span>아카이브</span></a></div></nav><div class="flex items-center space-x-2"><div class=relative><button id=language-toggle class="dropdown-toggle border-border bg-background text-muted-foreground hover:text-primary hover:bg-primary/10 focus:ring-primary/20 flex h-10 w-10 items-center justify-center rounded-lg border transition-all duration-300 ease-out hover:scale-105 focus:ring-2 focus:outline-none active:scale-95" data-dropdown-type=language aria-label="언어 변경" aria-expanded=false aria-haspopup=true>
<svg class="h-5 w-5 relative z-10" fill="none" stroke="currentColor" viewBox="0 0 24 24" aria-label="언어 변경"><path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="m5 8 6 6m-7 0 6-6 2-3M2 5h12M7 2h1m14 20-5-10-5 10m2-4h6"/></svg></button><div id=language-dropdown class="dropdown-menu border-border bg-popover/95 absolute top-12 right-0 z-[60] hidden w-40 rounded-lg border p-1 shadow-lg backdrop-blur-sm transition-all duration-200 ease-out" data-dropdown-type=language role=menu aria-labelledby=language-toggle><a href=/ko/ class="text-accent-foreground hover:bg-accent hover:text-accent-foreground focus:bg-accent focus:text-accent-foreground flex w-full items-center rounded-md px-4 py-2 text-sm transition-all duration-200 ease-out focus:outline-none" role=menuitem aria-current=true><span class=font-medium>한국어</span></a><a href=/en/ class="text-accent-foreground hover:bg-accent hover:text-accent-foreground focus:bg-accent focus:text-accent-foreground flex w-full items-center rounded-md px-4 py-2 text-sm transition-all duration-200 ease-out focus:outline-none" role=menuitem><span class=font-medium>English</span></a></div></div><div class=relative><button id=color-scheme-toggle class="dropdown-toggle border-border bg-background text-muted-foreground hover:text-primary hover:bg-primary/10 focus:ring-primary/20 flex h-10 w-10 items-center justify-center rounded-lg border transition-all duration-300 ease-out hover:scale-105 focus:ring-2 focus:outline-none active:scale-95" data-dropdown-type=color-scheme aria-label="테마 변경" aria-expanded=false aria-haspopup=true>
<svg class="h-5 w-5 relative z-10" fill="none" stroke="currentColor" viewBox="0 0 24 24" aria-label="테마 변경"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M7 21a4 4 0 01-4-4V5a2 2 0 012-2h4a2 2 0 012 2v12a4 4 0 01-4 4zM21 5a2 2 0 00-2-2h-4a2 2 0 00-2 2v6a2 2 0 002 2h4a2 2 0 002-2V5z"/></svg></button><div id=color-scheme-dropdown class="dropdown-menu border-border bg-popover/95 absolute top-12 right-0 z-[60] hidden w-44 rounded-lg border p-1 shadow-lg backdrop-blur-sm transition-all duration-200 ease-out" data-dropdown-type=color-scheme><button data-color-scheme=claude class="text-accent-foreground hover:bg-accent hover:text-accent-foreground focus:bg-accent focus:text-accent-foreground flex w-full items-center rounded-md px-4 py-2 text-sm transition-all duration-200 ease-out focus:outline-none"><span>Default</span></button><button data-color-scheme=default class="text-accent-foreground hover:bg-accent hover:text-accent-foreground focus:bg-accent focus:text-accent-foreground flex w-full items-center rounded-md px-4 py-2 text-sm transition-all duration-200 ease-out focus:outline-none"><span>White</span></button><button data-color-scheme=bumblebee class="text-accent-foreground hover:bg-accent hover:text-accent-foreground focus:bg-accent focus:text-accent-foreground flex w-full items-center rounded-md px-4 py-2 text-sm transition-all duration-200 ease-out focus:outline-none"><span>Bumblebee</span></button><button data-color-scheme=emerald class="text-accent-foreground hover:bg-accent hover:text-accent-foreground focus:bg-accent focus:text-accent-foreground flex w-full items-center rounded-md px-4 py-2 text-sm transition-all duration-200 ease-out focus:outline-none"><span>Emerald</span></button><button data-color-scheme=nord class="text-accent-foreground hover:bg-accent hover:text-accent-foreground focus:bg-accent focus:text-accent-foreground flex w-full items-center rounded-md px-4 py-2 text-sm transition-all duration-200 ease-out focus:outline-none"><span>Nord</span></button><button data-color-scheme=sunset class="text-accent-foreground hover:bg-accent hover:text-accent-foreground focus:bg-accent focus:text-accent-foreground flex w-full items-center rounded-md px-4 py-2 text-sm transition-all duration-200 ease-out focus:outline-none"><span>Sunset</span></button><button data-color-scheme=abyss class="text-accent-foreground hover:bg-accent hover:text-accent-foreground focus:bg-accent focus:text-accent-foreground flex w-full items-center rounded-md px-4 py-2 text-sm transition-all duration-200 ease-out focus:outline-none"><span>Abyss</span></button><button data-color-scheme=dracula class="text-accent-foreground hover:bg-accent hover:text-accent-foreground focus:bg-accent focus:text-accent-foreground flex w-full items-center rounded-md px-4 py-2 text-sm transition-all duration-200 ease-out focus:outline-none"><span>Dracula</span></button><button data-color-scheme=amethyst class="text-accent-foreground hover:bg-accent hover:text-accent-foreground focus:bg-accent focus:text-accent-foreground flex w-full items-center rounded-md px-4 py-2 text-sm transition-all duration-200 ease-out focus:outline-none"><span>Amethyst</span></button><button data-color-scheme=slate class="text-accent-foreground hover:bg-accent hover:text-accent-foreground focus:bg-accent focus:text-accent-foreground flex w-full items-center rounded-md px-4 py-2 text-sm transition-all duration-200 ease-out focus:outline-none"><span>Slate</span></button><button data-color-scheme=twitter class="text-accent-foreground hover:bg-accent hover:text-accent-foreground focus:bg-accent focus:text-accent-foreground flex w-full items-center rounded-md px-4 py-2 text-sm transition-all duration-200 ease-out focus:outline-none"><span>Twitter</span></button></div></div><div class=relative><button id=theme-toggle class="dropdown-toggle border-border bg-background text-muted-foreground hover:text-primary hover:bg-primary/10 focus:ring-primary/20 flex h-10 w-10 items-center justify-center rounded-lg border transition-all duration-300 ease-out hover:scale-105 focus:ring-2 focus:outline-none active:scale-95" data-dropdown-type=theme aria-label="테마 변경" aria-expanded=false aria-haspopup=true>
<svg class="h-5 w-5 sun-icon hidden relative z-10" fill="none" stroke="currentColor" viewBox="0 0 24 24" aria-label="라이트"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M12 3v1m0 16v1m9-9h-1M4 12H3m15.364 6.364-.707-.707M6.343 6.343l-.707-.707m12.728.0-.707.707M6.343 17.657l-.707.707M16 12a4 4 0 11-8 0 4 4 0 018 0z"/></svg>
<svg class="h-5 w-5 moon-icon hidden relative z-10" fill="none" stroke="currentColor" viewBox="0 0 24 24" aria-label="다크"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M20.354 15.354A9 9 0 018.646 3.646 9.003 9.003.0 0012 21a9.003 9.003.0 008.354-5.646z"/></svg>
<svg class="h-5 w-5 system-icon hidden relative z-10" fill="none" stroke="currentColor" viewBox="0 0 24 24" aria-label="시스템"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9.75 17 9 20l-1 1h8l-1-1-.75-3M3 13h18M5 17h14a2 2 0 002-2V5a2 2 0 00-2-2H5A2 2 0 003 5v10a2 2 0 002 2z"/></svg></button><div id=theme-dropdown class="dropdown-menu border-border bg-popover/95 absolute top-12 right-0 z-[60] hidden w-40 rounded-lg border p-1 shadow-lg backdrop-blur-sm transition-all duration-200 ease-out" data-dropdown-type=theme><button data-theme=light class="text-accent-foreground hover:bg-accent hover:text-accent-foreground focus:bg-accent focus:text-accent-foreground flex w-full items-center rounded-md px-4 py-2 text-sm transition-all duration-200 ease-out focus:outline-none">
<svg class="h-5 w-5 mr-3 h-4 w-4" fill="none" stroke="currentColor" viewBox="0 0 24 24" aria-label="라이트"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M12 3v1m0 16v1m9-9h-1M4 12H3m15.364 6.364-.707-.707M6.343 6.343l-.707-.707m12.728.0-.707.707M6.343 17.657l-.707.707M16 12a4 4 0 11-8 0 4 4 0 018 0z"/></svg><span>라이트</span></button><button data-theme=dark class="text-accent-foreground hover:bg-accent hover:text-accent-foreground focus:bg-accent focus:text-accent-foreground flex w-full items-center rounded-md px-4 py-2 text-sm transition-all duration-200 ease-out focus:outline-none">
<svg class="h-5 w-5 mr-3 h-4 w-4" fill="none" stroke="currentColor" viewBox="0 0 24 24" aria-label="다크"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M20.354 15.354A9 9 0 018.646 3.646 9.003 9.003.0 0012 21a9.003 9.003.0 008.354-5.646z"/></svg><span>다크</span></button><button data-theme=system class="text-accent-foreground hover:bg-accent hover:text-accent-foreground focus:bg-accent focus:text-accent-foreground flex w-full items-center rounded-md px-4 py-2 text-sm transition-all duration-200 ease-out focus:outline-none">
<svg class="h-5 w-5 mr-3 h-4 w-4" fill="none" stroke="currentColor" viewBox="0 0 24 24" aria-label="시스템"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9.75 17 9 20l-1 1h8l-1-1-.75-3M3 13h18M5 17h14a2 2 0 002-2V5a2 2 0 00-2-2H5A2 2 0 003 5v10a2 2 0 002 2z"/></svg><span>시스템</span></button></div></div></div></div><div class="flex w-full items-center justify-between md:hidden"><div class=relative><button id=mobile-menu-toggle class="dropdown-toggle border-border bg-background text-muted-foreground hover:bg-accent hover:text-foreground flex h-10 w-10 items-center justify-center rounded-lg border transition-colors duration-200" data-dropdown-type=mobile-menu aria-label=메뉴 aria-expanded=false aria-haspopup=true>
<svg class="h-5 w-5" fill="none" stroke="currentColor" viewBox="0 0 24 24" aria-label="메뉴"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M4 6h16M4 12h16M4 18h16"/></svg></button><div id=mobile-menu class="mobile-menu dropdown-menu border-border bg-popover/95 absolute top-12 left-0 z-[60] hidden w-80 max-w-[calc(100vw-2rem)] rounded-lg border p-1 shadow-lg backdrop-blur-sm transition-all duration-200 ease-out md:hidden" data-dropdown-type=mobile-menu role=menu aria-labelledby=mobile-menu-toggle><nav class="flex flex-col"><a href=/ko/ class="nav-link
text-muted-foreground hover:text-primary hover:bg-primary/10
focus:ring-primary/20 relative flex items-center gap-3 rounded-md px-4 py-3 text-sm font-medium transition-all duration-200 ease-out hover:translate-x-1 focus:ring-2 focus:outline-none" role=menuitem><svg class="h-5 w-5" fill="none" stroke="currentColor" viewBox="0 0 24 24" aria-label="nav.posts"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 20H5a2 2 0 01-2-2V6a2 2 0 012-2h10a2 2 0 012 2v1m2 13a2 2 0 01-2-2V7m2 13a2 2 0 002-2V9a2 2 0 00-2-2h-2m-4-3H9M7 16h6M7 8h6v4H7V8z"/></svg>
<span>게시글
</span></a><a href=/ko/categories/ class="nav-link
text-muted-foreground hover:text-primary hover:bg-primary/10
focus:ring-primary/20 relative flex items-center gap-3 rounded-md px-4 py-3 text-sm font-medium transition-all duration-200 ease-out hover:translate-x-1 focus:ring-2 focus:outline-none" role=menuitem><svg class="h-5 w-5" fill="none" stroke="currentColor" viewBox="0 0 24 24" aria-label="nav.categories"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 11H5m14 0a2 2 0 012 2v6a2 2 0 01-2 2H5a2 2 0 01-2-2v-6a2 2 0 012-2m14 0V9a2 2 0 00-2-2M5 11V9a2 2 0 012-2m0 0V5a2 2 0 012-2h6a2 2 0 012 2v2M7 7h10"/></svg>
<span>카테고리
</span></a><a href=/ko/tags/ class="nav-link
text-muted-foreground hover:text-primary hover:bg-primary/10
focus:ring-primary/20 relative flex items-center gap-3 rounded-md px-4 py-3 text-sm font-medium transition-all duration-200 ease-out hover:translate-x-1 focus:ring-2 focus:outline-none" role=menuitem><svg class="h-5 w-5" fill="none" stroke="currentColor" viewBox="0 0 24 24" aria-label="nav.tags"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M7 7h.01M7 3h5c.512.0 1.024.195 1.414.586l7 7a2 2 0 010 2.828l-7 7a2 2 0 01-2.828.0l-7-7A1.994 1.994.0 013 12V7a4 4 0 014-4z"/></svg>
<span>태그
</span></a><a href=/ko/ class="nav-link
text-muted-foreground hover:text-primary hover:bg-primary/10
focus:ring-primary/20 relative flex items-center gap-3 rounded-md px-4 py-3 text-sm font-medium transition-all duration-200 ease-out hover:translate-x-1 focus:ring-2 focus:outline-none" role=menuitem><svg class="h-5 w-5" fill="none" stroke="currentColor" viewBox="0 0 24 24" aria-label="nav.archives"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M5 8h14M5 8a2 2 0 110-4h14a2 2 0 110 4M5 8v10a2 2 0 002 2h10a2 2 0 002-2V8m-9 4h4"/></svg>
<span>아카이브</span></a></nav></div></div><div class="flex items-center space-x-2"><div class=relative><button id=language-toggle class="dropdown-toggle border-border bg-background text-muted-foreground hover:text-primary hover:bg-primary/10 focus:ring-primary/20 flex h-10 w-10 items-center justify-center rounded-lg border transition-all duration-300 ease-out hover:scale-105 focus:ring-2 focus:outline-none active:scale-95" data-dropdown-type=language aria-label="언어 변경" aria-expanded=false aria-haspopup=true>
<svg class="h-5 w-5 relative z-10" fill="none" stroke="currentColor" viewBox="0 0 24 24" aria-label="언어 변경"><path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="m5 8 6 6m-7 0 6-6 2-3M2 5h12M7 2h1m14 20-5-10-5 10m2-4h6"/></svg></button><div id=language-dropdown class="dropdown-menu border-border bg-popover/95 absolute top-12 right-0 z-[60] hidden w-40 rounded-lg border p-1 shadow-lg backdrop-blur-sm transition-all duration-200 ease-out" data-dropdown-type=language role=menu aria-labelledby=language-toggle><a href=/ko/ class="text-accent-foreground hover:bg-accent hover:text-accent-foreground focus:bg-accent focus:text-accent-foreground flex w-full items-center rounded-md px-4 py-2 text-sm transition-all duration-200 ease-out focus:outline-none" role=menuitem aria-current=true><span class=font-medium>한국어</span></a><a href=/en/ class="text-accent-foreground hover:bg-accent hover:text-accent-foreground focus:bg-accent focus:text-accent-foreground flex w-full items-center rounded-md px-4 py-2 text-sm transition-all duration-200 ease-out focus:outline-none" role=menuitem><span class=font-medium>English</span></a></div></div><div class=relative><button id=color-scheme-toggle class="dropdown-toggle border-border bg-background text-muted-foreground hover:text-primary hover:bg-primary/10 focus:ring-primary/20 flex h-10 w-10 items-center justify-center rounded-lg border transition-all duration-300 ease-out hover:scale-105 focus:ring-2 focus:outline-none active:scale-95" data-dropdown-type=color-scheme aria-label="테마 변경" aria-expanded=false aria-haspopup=true>
<svg class="h-5 w-5 relative z-10" fill="none" stroke="currentColor" viewBox="0 0 24 24" aria-label="테마 변경"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M7 21a4 4 0 01-4-4V5a2 2 0 012-2h4a2 2 0 012 2v12a4 4 0 01-4 4zM21 5a2 2 0 00-2-2h-4a2 2 0 00-2 2v6a2 2 0 002 2h4a2 2 0 002-2V5z"/></svg></button><div id=color-scheme-dropdown class="dropdown-menu border-border bg-popover/95 absolute top-12 right-0 z-[60] hidden w-44 rounded-lg border p-1 shadow-lg backdrop-blur-sm transition-all duration-200 ease-out" data-dropdown-type=color-scheme><button data-color-scheme=claude class="text-accent-foreground hover:bg-accent hover:text-accent-foreground focus:bg-accent focus:text-accent-foreground flex w-full items-center rounded-md px-4 py-2 text-sm transition-all duration-200 ease-out focus:outline-none"><span>Default</span></button><button data-color-scheme=default class="text-accent-foreground hover:bg-accent hover:text-accent-foreground focus:bg-accent focus:text-accent-foreground flex w-full items-center rounded-md px-4 py-2 text-sm transition-all duration-200 ease-out focus:outline-none"><span>White</span></button><button data-color-scheme=bumblebee class="text-accent-foreground hover:bg-accent hover:text-accent-foreground focus:bg-accent focus:text-accent-foreground flex w-full items-center rounded-md px-4 py-2 text-sm transition-all duration-200 ease-out focus:outline-none"><span>Bumblebee</span></button><button data-color-scheme=emerald class="text-accent-foreground hover:bg-accent hover:text-accent-foreground focus:bg-accent focus:text-accent-foreground flex w-full items-center rounded-md px-4 py-2 text-sm transition-all duration-200 ease-out focus:outline-none"><span>Emerald</span></button><button data-color-scheme=nord class="text-accent-foreground hover:bg-accent hover:text-accent-foreground focus:bg-accent focus:text-accent-foreground flex w-full items-center rounded-md px-4 py-2 text-sm transition-all duration-200 ease-out focus:outline-none"><span>Nord</span></button><button data-color-scheme=sunset class="text-accent-foreground hover:bg-accent hover:text-accent-foreground focus:bg-accent focus:text-accent-foreground flex w-full items-center rounded-md px-4 py-2 text-sm transition-all duration-200 ease-out focus:outline-none"><span>Sunset</span></button><button data-color-scheme=abyss class="text-accent-foreground hover:bg-accent hover:text-accent-foreground focus:bg-accent focus:text-accent-foreground flex w-full items-center rounded-md px-4 py-2 text-sm transition-all duration-200 ease-out focus:outline-none"><span>Abyss</span></button><button data-color-scheme=dracula class="text-accent-foreground hover:bg-accent hover:text-accent-foreground focus:bg-accent focus:text-accent-foreground flex w-full items-center rounded-md px-4 py-2 text-sm transition-all duration-200 ease-out focus:outline-none"><span>Dracula</span></button><button data-color-scheme=amethyst class="text-accent-foreground hover:bg-accent hover:text-accent-foreground focus:bg-accent focus:text-accent-foreground flex w-full items-center rounded-md px-4 py-2 text-sm transition-all duration-200 ease-out focus:outline-none"><span>Amethyst</span></button><button data-color-scheme=slate class="text-accent-foreground hover:bg-accent hover:text-accent-foreground focus:bg-accent focus:text-accent-foreground flex w-full items-center rounded-md px-4 py-2 text-sm transition-all duration-200 ease-out focus:outline-none"><span>Slate</span></button><button data-color-scheme=twitter class="text-accent-foreground hover:bg-accent hover:text-accent-foreground focus:bg-accent focus:text-accent-foreground flex w-full items-center rounded-md px-4 py-2 text-sm transition-all duration-200 ease-out focus:outline-none"><span>Twitter</span></button></div></div><div class=relative><button id=theme-toggle class="dropdown-toggle border-border bg-background text-muted-foreground hover:text-primary hover:bg-primary/10 focus:ring-primary/20 flex h-10 w-10 items-center justify-center rounded-lg border transition-all duration-300 ease-out hover:scale-105 focus:ring-2 focus:outline-none active:scale-95" data-dropdown-type=theme aria-label="테마 변경" aria-expanded=false aria-haspopup=true>
<svg class="h-5 w-5 sun-icon hidden relative z-10" fill="none" stroke="currentColor" viewBox="0 0 24 24" aria-label="라이트"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M12 3v1m0 16v1m9-9h-1M4 12H3m15.364 6.364-.707-.707M6.343 6.343l-.707-.707m12.728.0-.707.707M6.343 17.657l-.707.707M16 12a4 4 0 11-8 0 4 4 0 018 0z"/></svg>
<svg class="h-5 w-5 moon-icon hidden relative z-10" fill="none" stroke="currentColor" viewBox="0 0 24 24" aria-label="다크"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M20.354 15.354A9 9 0 018.646 3.646 9.003 9.003.0 0012 21a9.003 9.003.0 008.354-5.646z"/></svg>
<svg class="h-5 w-5 system-icon hidden relative z-10" fill="none" stroke="currentColor" viewBox="0 0 24 24" aria-label="시스템"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9.75 17 9 20l-1 1h8l-1-1-.75-3M3 13h18M5 17h14a2 2 0 002-2V5a2 2 0 00-2-2H5A2 2 0 003 5v10a2 2 0 002 2z"/></svg></button><div id=theme-dropdown class="dropdown-menu border-border bg-popover/95 absolute top-12 right-0 z-[60] hidden w-40 rounded-lg border p-1 shadow-lg backdrop-blur-sm transition-all duration-200 ease-out" data-dropdown-type=theme><button data-theme=light class="text-accent-foreground hover:bg-accent hover:text-accent-foreground focus:bg-accent focus:text-accent-foreground flex w-full items-center rounded-md px-4 py-2 text-sm transition-all duration-200 ease-out focus:outline-none">
<svg class="h-5 w-5 mr-3 h-4 w-4" fill="none" stroke="currentColor" viewBox="0 0 24 24" aria-label="라이트"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M12 3v1m0 16v1m9-9h-1M4 12H3m15.364 6.364-.707-.707M6.343 6.343l-.707-.707m12.728.0-.707.707M6.343 17.657l-.707.707M16 12a4 4 0 11-8 0 4 4 0 018 0z"/></svg><span>라이트</span></button><button data-theme=dark class="text-accent-foreground hover:bg-accent hover:text-accent-foreground focus:bg-accent focus:text-accent-foreground flex w-full items-center rounded-md px-4 py-2 text-sm transition-all duration-200 ease-out focus:outline-none">
<svg class="h-5 w-5 mr-3 h-4 w-4" fill="none" stroke="currentColor" viewBox="0 0 24 24" aria-label="다크"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M20.354 15.354A9 9 0 018.646 3.646 9.003 9.003.0 0012 21a9.003 9.003.0 008.354-5.646z"/></svg><span>다크</span></button><button data-theme=system class="text-accent-foreground hover:bg-accent hover:text-accent-foreground focus:bg-accent focus:text-accent-foreground flex w-full items-center rounded-md px-4 py-2 text-sm transition-all duration-200 ease-out focus:outline-none">
<svg class="h-5 w-5 mr-3 h-4 w-4" fill="none" stroke="currentColor" viewBox="0 0 24 24" aria-label="시스템"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9.75 17 9 20l-1 1h8l-1-1-.75-3M3 13h18M5 17h14a2 2 0 002-2V5a2 2 0 00-2-2H5A2 2 0 003 5v10a2 2 0 002 2z"/></svg><span>시스템</span></button></div></div></div></div></div></header><main class="mx-auto max-w-4xl px-4 py-6"><nav class="breadcrumb mb-4 md:mb-6 py-1" aria-label=경로><ol class="text-muted-foreground flex items-center space-x-1 md:space-x-2 text-sm overflow-x-auto whitespace-nowrap scrollbar-hide py-1"><li class=flex-shrink-0><a href=/ko/ class="text-muted-foreground hover:text-primary hover:bg-primary/10 flex items-center gap-0.5 md:gap-1 rounded-lg px-1 md:px-3 py-0.5 md:py-1.5 transition-all duration-200 ease-out hover:-translate-y-0.5 hover:scale-[1.02]"><svg class="h-4 w-4" fill="none" stroke="currentColor" viewBox="0 0 24 24" aria-label="홈"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="m3 12 2-2m0 0 7-7 7 7M5 10v10a1 1 0 001 1h3m10-11 2 2m-2-2v10a1 1 0 01-1 1h-3m-6 0a1 1 0 001-1v-4a1 1 0 011-1h2a1 1 0 011 1v4a1 1 0 001 1m-6 0h6"/></svg>
<span class="max-w-[4rem] md:max-w-none truncate">홈</span></a></li><li class="flex items-center gap-1 md:gap-2 min-w-0"><span class="text-muted-foreground/50 flex-shrink-0"><svg class="h-4 w-4" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 5l7 7-7 7"/></svg></span><div class="flex items-center gap-1 md:gap-2 min-w-0"><a href=/ko class="text-muted-foreground hover:text-primary hover:bg-primary/10 flex items-center gap-0.5 md:gap-1 rounded-lg px-1 md:px-3 py-0.5 md:py-1.5 transition-all duration-200 ease-out hover:-translate-y-0.5 hover:scale-[1.02] flex-shrink-0"><svg class="h-4 w-4" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M3 7v10a2 2 0 002 2h14a2 2 0 002-2V9a2 2 0 00-2-2h-6l-2-2H5A2 2 0 003 7z"/></svg>
<span class="max-w-[4rem] md:max-w-none truncate">Ko</span>
</a><span class="text-muted-foreground/50 flex-shrink-0"><svg class="h-4 w-4" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 5l7 7-7 7"/></svg></span>
<span class="text-foreground flex items-center gap-0.5 md:gap-1 font-medium min-w-0"><svg class="h-4 w-4" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 12h6m-6 4h6m2 5H7a2 2 0 01-2-2V5a2 2 0 012-2h5.586a1 1 0 01.707.293l5.414 5.414a1 1 0 01.293.707V19a2 2 0 01-2 2z"/></svg>
<span class="max-w-[8rem] md:max-w-[16rem] lg:max-w-none truncate">PQCache: Product Quantization-based KVCache for Long Context LLM Inference</span></span></div></li></ol></nav><header class=mb-8><h1 class="text-foreground mb-4 text-3xl font-bold md:text-4xl">PQCache: Product Quantization-based KVCache for Long Context LLM Inference</h1></header><article class="prose prose-neutral dark:prose-invert max-w-none"><p><a href=https://arxiv.org/abs/2407.12820>논문 링크</a></p><h1 id=q--이-논문을-아주-자세하게-읽고-논문의-강점과-독창적인-지점을-설명해주고-핵심-알고리즘을-예시-입력을-들어서-전체적인-과정을-설명해줘-추가적으로-논문의-한계점에-대해서도-알려줘>Q : 이 논문을 아주 자세하게 읽고 논문의 강점과 독창적인 지점을 설명해주고 핵심 알고리즘을 예시 입력을 들어서 전체적인 과정을 설명해줘 추가적으로 논문의 한계점에 대해서도 알려줘</h1><h3 id=논문-분석->논문 분석: <strong>&ldquo;PQCache: Product Quantization-based KVCache for Long Context LLM Inference&rdquo;</strong></h3><hr><h4 id=1-강점-및-독창성><strong>1. 강점 및 독창성</strong></h4><ol><li><p><strong>강점</strong></p><ul><li><strong>메모리 효율성</strong>:<ul><li>KVCache의 메모리 사용 문제를 해결하기 위해 Product Quantization(PQ)를 활용하여 메모리를 압축하고 CPU-GPU 간의 데이터 통신을 최소화함.</li></ul></li><li><strong>모델 품질 유지</strong>:<ul><li>토큰 중 1/5만 활용해도 높은 모델 품질을 유지.</li></ul></li><li><strong>낮은 지연 시간</strong>:<ul><li>PQ 기반의 MIPS(Maximum Inner-Product Search)를 사용하여 선택적 토큰 검색 효율성을 높임.</li></ul></li><li><strong>시스템 설계 최적화</strong>:<ul><li>GPU의 캐시 메커니즘을 활용해 자주 액세스되는 KV 페어를 저장하여 통신 지연 최소화.</li></ul></li><li><strong>실험적 검증</strong>:<ul><li>LLaMA-2와 Mistral 같은 다양한 모델을 활용한 실험으로 제안 방법의 효율성을 입증.</li></ul></li></ul></li><li><p><strong>독창적인 점</strong></p><ul><li><strong>Embedding Retrieval의 응용</strong>:<ul><li>Product Quantization 기술을 LLM의 KVCache 관리에 처음으로 적용.</li></ul></li><li><strong>협력적 시스템-알고리즘 설계</strong>:<ul><li>시스템 레벨에서 PQCache를 최적화하여 추가적인 CPU 연산을 GPU 작업과 병렬화.</li></ul></li></ul></li></ol><hr><h4 id=2-핵심-알고리즘-pqcache의-동작-과정><strong>2. 핵심 알고리즘: PQCache의 동작 과정</strong></h4><h5 id=예시-입력과-함께-설명><strong>예시 입력과 함께 설명</strong></h5><ul><li><strong>입력</strong>:<ul><li>LLM의 길이가 32,000인 긴 텍스트 프롬프트와 현재 생성된 토큰의 Query.</li><li>KVCache에는 이전 토큰들의 Key-Value 페어가 저장되어 있음.</li></ul></li></ul><h5 id=전체-동작-과정><strong>전체 동작 과정</strong></h5><ol><li><p><strong>Prefilling 단계</strong>:</p><ul><li>LLM은 입력 텍스트에서 모든 토큰의 Key와 Value를 계산.</li><li>Key는 PQ(Product Quantization) 기술을 이용해 CPU에서 압축:<ul><li>Key 벡터를 여러 부분으로 나눔 (e.g., 𝑑𝑚 차원의 𝑚개 서브벡터).</li><li>각 부분에 대해 K-means clustering 실행 → Centroid와 PQ Code 생성.</li></ul></li></ul></li><li><p><strong>Decoding 단계</strong>:</p><ul><li>새로 생성된 토큰의 Query가 주어질 때:<ul><li>Query와 Centroid 간의 내적을 계산하여 근사 Attention Score를 생성.</li><li>PQ Code를 사용하여 가장 관련 있는 상위 k개의 Key-Value 페어를 선택.</li></ul></li><li>선택된 Key-Value 페어만 GPU로 가져와 Self-Attention 계산에 사용.</li></ul></li></ol><h5 id=예시><strong>예시</strong>:</h5><ul><li><strong>입력</strong>: 길이 32,000의 텍스트와 새 Query 벡터.</li><li><strong>과정</strong>:<ol><li>Key를 4개 부분으로 나눔(𝑚=4) → 각 부분에서 K-means clustering 실행.</li><li>Query와 Centroid 내적 계산 → 상위 100개의 중요 토큰(Key-Value 페어) 선택.</li><li>GPU에서 Self-Attention 실행.</li></ol></li><li><strong>출력</strong>: 새로 생성된 토큰의 Attention 결과.</li></ul><hr><h4 id=3-한계점><strong>3. 한계점</strong></h4><ol><li><p><strong>초기 구축 비용</strong>:</p><ul><li>Prefilling 단계에서 K-means clustering은 계산적으로 비싸며, CPU 자원을 많이 사용.</li><li>장기적 실행에는 유리하지만 초기 설정 비용이 클 수 있음.</li></ul></li><li><p><strong>근사 계산의 정확도 손실</strong>:</p><ul><li>PQ는 근사화 기법이므로, 특정 경우 정확도가 떨어질 가능성 있음.</li><li>특히 Needle-in-a-Haystack처럼 중요한 정보를 포함하는 긴 텍스트에서 오탐 가능성.</li></ul></li><li><p><strong>구체적 하드웨어 의존성</strong>:</p><ul><li>NVIDIA A800 GPU와 같은 고성능 하드웨어를 가정하고 설계됨.</li><li>일반적인 GPU에서는 성능 최적화가 덜할 수 있음.</li></ul></li><li><p><strong>실시간 작업 한계</strong>:</p><ul><li>실시간으로 매우 짧은 응답 시간을 요구하는 작업에는 부적합할 가능성.</li></ul></li></ol><hr><h4 id=결론><strong>결론</strong></h4><p>PQCache는 Product Quantization을 활용하여 LLM의 메모리 병목 문제를 해결하고 효율적인 긴 문맥 추론을 가능하게 하는 독창적인 접근법입니다. 다만, 초기 설정 비용과 근사화로 인한 성능 저하 가능성을 해결하기 위한 추가 연구가 필요합니다.</p><h1 id=q--논문의-핵심알고리즘을-예시를-들어-아주-자세하게-설명해주고-정리해-줘>Q : 논문의 핵심알고리즘을 예시를 들어 아주 자세하게 설명해주고 정리해 줘</h1><h3 id=pqcache-핵심-알고리즘-자세한-설명-및-예시>PQCache 핵심 알고리즘: 자세한 설명 및 예시</h3><hr><h4 id=1-pqcache의-핵심-아이디어><strong>1. PQCache의 핵심 아이디어</strong></h4><p>PQCache는 LLM의 Key-Value Cache(KVCache)를 효율적으로 관리하기 위해 <strong>Product Quantization(PQ)</strong> 기술을 적용하여 메모리 사용량과 데이터 전송량을 줄이는 알고리즘입니다.</p><ul><li><strong>문제</strong>: 긴 문맥을 처리하기 위해 LLM은 대량의 KVCache를 저장해야 하며, 이는 GPU 메모리에 과부하를 초래함.</li><li><strong>해결책</strong>: KVCache를 CPU에 저장하면서 **토큰의 중요도(Attention Score)**를 계산해 필요한 Key-Value 페어만 GPU로 가져옴.</li></ul><hr><h4 id=2-전체-알고리즘-동작-과정><strong>2. 전체 알고리즘 동작 과정</strong></h4><h5 id=a-prefilling-단계-kvcache-구축-및-압축><strong>A. Prefilling 단계</strong> (KVCache 구축 및 압축)</h5><ol><li><p><strong>Key-Value 계산</strong>:</p><ul><li>입력 토큰에 대해 Key와 Value를 계산.</li><li>Key는 보통 벡터 형태 (길이 <code>d_h</code>)로 나타남.</li></ul></li><li><p><strong>Product Quantization 적용</strong>:</p><ul><li>Key 벡터를 <strong>m개의 서브벡터로 분할</strong>.<ul><li>예: Key 벡터 <code>[1.2, 3.5, 2.1, 4.3]</code>을 두 개의 서브벡터 <code>[1.2, 3.5]</code>와 <code>[2.1, 4.3]</code>로 분할.</li></ul></li><li>각 서브벡터에 대해 K-means clustering 실행:<ul><li>서브벡터의 중심값(Centroid)와 **압축 코드(PQ Code)**를 생성.</li></ul></li><li>결과:<ul><li>압축된 Key는 작은 PQ Code로 대체 (예: 8비트 코드).</li></ul></li></ul></li><li><p><strong>압축 데이터 저장</strong>:</p><ul><li>생성된 Centroid와 PQ Code를 CPU에 저장.</li></ul></li></ol><hr><h5 id=b-decoding-단계-효율적인-self-attention-계산><strong>B. Decoding 단계</strong> (효율적인 Self-Attention 계산)</h5><ol><li><p><strong>Query 처리</strong>:</p><ul><li>새롭게 생성된 토큰의 Query 벡터를 가져옴.</li><li>Query 벡터와 CPU에 저장된 Centroid 간 <strong>내적</strong> 계산:<ul><li>예: Query <code>[0.5, 0.3]</code>와 각 Centroid <code>[1.0, 2.0]</code>, <code>[0.2, 0.8]</code>에 대해 계산.</li></ul></li></ul></li><li><p><strong>Approximate Attention Score 계산</strong>:</p><ul><li>Query와 Centroid의 내적 결과를 PQ Code와 조합하여 <strong>근사 Attention Score</strong> 생성.</li><li>이 과정에서 모든 Key와 연산하지 않고, 압축된 정보를 사용.</li></ul></li><li><p><strong>상위 k개의 Key-Value 페어 선택</strong>:</p><ul><li>가장 높은 Attention Score를 가진 상위 k개의 Key-Value 페어를 선택.</li></ul></li><li><p><strong>GPU로 가져오기</strong>:</p><ul><li>선택된 Key-Value 페어만 GPU로 전송하여 Self-Attention 계산에 사용.</li></ul></li><li><p><strong>Self-Attention 실행 및 KVCache 업데이트</strong>:</p><ul><li>GPU에서 Self-Attention 계산 후 새롭게 생성된 Key-Value를 KVCache에 추가.</li></ul></li></ol><hr><h4 id=3-예시><strong>3. 예시</strong></h4><h5 id=입력-상황><strong>입력 상황</strong></h5><ul><li><strong>문맥</strong>: &ldquo;The quick brown fox jumps over the lazy dog.&rdquo;</li><li><strong>프롬프트 길이</strong>: 10,000 토큰.</li><li><strong>Query 벡터</strong>: 새롭게 생성된 토큰의 Query <code>[0.5, 0.3, -0.2]</code>.</li><li><strong>Key 벡터</strong>: 각 이전 토큰마다 <code>[1.2, 3.5, 2.1]</code>, <code>[0.7, -0.1, 1.4]</code> 등.</li></ul><h5 id=prefilling-단계><strong>Prefilling 단계</strong></h5><ol><li>Key 벡터 <code>[1.2, 3.5, 2.1]</code>을 <strong>2개의 서브벡터</strong> <code>[1.2, 3.5]</code>와 <code>[2.1]</code>로 나눔.</li><li>각 서브벡터에 대해 K-means clustering 실행:<ul><li>서브벡터 <code>[1.2, 3.5]</code> → Centroid <code>[1.0, 3.0]</code>, <code>[2.0, 4.0]</code> 생성.</li><li>서브벡터 <code>[2.1]</code> → Centroid <code>[2.0]</code>, <code>[3.0]</code> 생성.</li></ul></li><li>Key는 Centroid와 가장 가까운 클러스터로 매핑되어 PQ Code로 저장.</li></ol><h5 id=decoding-단계><strong>Decoding 단계</strong></h5><ol><li><p>Query <code>[0.5, 0.3, -0.2]</code>와 Centroid의 내적 계산:</p><ul><li><code>[0.5, 0.3]</code>와 <code>[1.0, 3.0]</code>의 내적 = <code>0.5*1.0 + 0.3*3.0 = 1.4</code>.</li><li><code>[0.5, 0.3]</code>와 <code>[2.0, 4.0]</code>의 내적 = <code>0.5*2.0 + 0.3*4.0 = 2.2</code>.</li><li>가장 높은 값 <code>2.2</code>에 따라 관련 Key 선택.</li></ul></li><li><p>가장 관련된 상위 3개의 Key-Value 페어를 GPU로 전송:</p><ul><li>예: Key <code>[1.2, 3.5, 2.1]</code>, <code>[0.7, -0.1, 1.4]</code> 등.</li></ul></li><li><p>GPU에서 Self-Attention 계산:</p><ul><li>Query와 Key를 이용해 Attention Score 계산 후 Value를 결합해 결과 생성.</li></ul></li></ol><hr><h4 id=4-요약><strong>4. 요약</strong></h4><ul><li><strong>Prefilling 단계</strong>:<ul><li>Key 벡터를 PQ로 압축하고 Centroid 및 PQ Code 생성.</li><li>CPU에 압축된 KVCache 저장.</li></ul></li><li><strong>Decoding 단계</strong>:<ul><li>Query 벡터와 Centroid를 사용해 근사 Attention Score 계산.</li><li>중요도가 높은 Key-Value 페어만 GPU로 전송하여 Self-Attention 계산.</li></ul></li><li><strong>결과</strong>:<ul><li>메모리 효율성 향상과 더불어 긴 문맥에서도 LLM의 성능 유지.</li></ul></li></ul><p>PQCache는 메모리 자원을 절약하고 GPU-CPU 간의 통신을 줄이면서도 높은 품질의 모델 성능을 유지할 수 있는 매우 효율적인 방법입니다.</p><h1 id=q--이-논문에서-사용하는-방법을-학습하기-위하여-어떤-데이터셋이-필요할까-그리고-어떻게-학습을-진행하면-될지-예시를-들어서-아주-자세하게-설명해줘>Q : 이 논문에서 사용하는 방법을 학습하기 위하여 어떤 데이터셋이 필요할까? 그리고 어떻게 학습을 진행하면 될지 예시를 들어서 아주 자세하게 설명해줘</h1><h3 id=pqcache-학습에-필요한-데이터셋과-학습-방법>PQCache 학습에 필요한 데이터셋과 학습 방법</h3><hr><h4 id=1-pqcache의-학습-목표><strong>1. PQCache의 학습 목표</strong></h4><p>PQCache는 LLM의 Key-Value Cache(KVCache)를 효율적으로 압축하고 재활용하기 위한 시스템입니다. 이를 학습하려면 다음 두 가지를 달성해야 합니다:</p><ul><li><strong>Key 벡터를 효율적으로 압축</strong>: Product Quantization(PQ)를 활용하여 Key 벡터를 압축하고, 근사 Attention Score 계산을 최적화.</li><li><strong>Token 중요도 판단 및 선택</strong>: Attention Score 기반으로 중요 토큰을 선별하여 Self-Attention 연산 효율화.</li></ul><hr><h4 id=2-필요한-데이터셋><strong>2. 필요한 데이터셋</strong></h4><p>PQCache 학습을 위해 적합한 데이터셋은 긴 문맥을 가진 텍스트 데이터셋이어야 하며, LLM 모델의 다양한 상황을 실험할 수 있도록 해야 합니다. 아래는 추천 데이터셋들입니다:</p><ol><li><p><strong>LongBench</strong>:</p><ul><li>긴 문맥 처리에 특화된 벤치마크 데이터셋으로, 질문 응답, 요약, 패시지 검색 등의 태스크 포함.</li><li>평균 입력 길이가 8,000 토큰으로 PQCache의 성능 검증에 적합.</li></ul></li><li><p><strong>Needle-in-a-Haystack</strong>:</p><ul><li>매우 긴 문서 내에서 특정 정보를 검색하는 태스크.</li><li>KVCache 압축 시 중요한 정보를 놓치지 않도록 학습 가능.</li></ul></li><li><p><strong>GSM8K (Chain-of-Thought Reasoning)</strong>:</p><ul><li>수학 문제 해결을 위한 체인-오브-쏘트(Chain-of-Thought) 추론 데이터셋.</li><li>LLM이 긴 문맥 속에서 세부 정보를 정확히 유지하며 추론하도록 평가 가능.</li></ul></li><li><p><strong>MultiNews</strong>:</p><ul><li>다중 문서 요약 데이터셋.</li><li>여러 문서에서 중요한 정보를 선택하고 요약하도록 학습 가능.</li></ul></li></ol><hr><h4 id=3-학습-단계-및-방법><strong>3. 학습 단계 및 방법</strong></h4><p>PQCache는 LLM의 사전 학습된 모델 위에서 추가적인 후처리 또는 미세조정 과정을 거칩니다. 학습 과정은 크게 세 단계로 나눌 수 있습니다.</p><hr><h5 id=a-product-quantization-학습><strong>A. Product Quantization 학습</strong></h5><ol><li><p><strong>Key 벡터 생성</strong>:</p><ul><li>사전 학습된 LLM(예: LLaMA-2, GPT 모델)에서 입력 데이터셋을 통해 Key 벡터를 생성.</li><li>예를 들어, 문장 &ldquo;The quick brown fox"의 Key 벡터 <code>[1.2, 3.5, 2.1, 4.3]</code>을 추출.</li></ul></li><li><p><strong>Key 벡터 클러스터링</strong>:</p><ul><li>Key 벡터를 <strong>m개의 서브벡터로 분할</strong>.<ul><li>예: <code>[1.2, 3.5]</code>와 <code>[2.1, 4.3]</code>로 나누기.</li></ul></li><li>각 서브벡터에 대해 <strong>K-means clustering</strong>을 수행.<ul><li>Centroid와 PQ Code를 생성.</li></ul></li></ul></li><li><p><strong>클러스터링 손실 최소화</strong>:</p><ul><li>클러스터링이 Key 벡터의 근사 정확도를 유지하도록 손실 함수 설계:
[
\text{Loss} = \sum_{i=1}^{N} |\text{Original Key}_i - \text{Reconstructed Key}_i|^2
]</li><li>클러스터링 결과를 CPU에 저장.</li></ul></li></ol><hr><h5 id=b-중요-토큰-선택-학습><strong>B. 중요 토큰 선택 학습</strong></h5><ol><li><p><strong>Attention Score 기반 평가</strong>:</p><ul><li>학습 데이터셋에서 생성된 Query와 Key 간의 내적 연산으로 Attention Score를 계산.</li><li>높은 Score를 가진 상위 (k)개의 Key-Value 페어를 선택.</li></ul></li><li><p><strong>토큰 선택 전략 학습</strong>:</p><ul><li>특정 태스크(예: 질문 응답, 요약)의 성능을 최대화하기 위해 선택된 토큰이 중요 정보를 포함하도록 학습.</li><li>Loss 함수:
[
\text{Loss}<em>{\text{selection}} = |\text{Output}</em>{\text{selected tokens}} - \text{Output}_{\text{full tokens}}|^2
]</li><li>이는 선택된 토큰이 전체 토큰을 사용할 때의 결과와 최대한 유사하도록 학습.</li></ul></li></ol><hr><h5 id=c-시스템-최적화-학습><strong>C. 시스템 최적화 학습</strong></h5><ol><li><p><strong>GPU-CPU 통신 최적화</strong>:</p><ul><li>압축된 PQ Code와 Centroid를 GPU로 전송하고 Self-Attention을 수행하는 전체 과정을 병렬화.</li><li><strong>통신 비용</strong>을 줄이도록 시스템 구조 최적화.</li></ul></li><li><p><strong>캐시 적중률 향상 학습</strong>:</p><ul><li>자주 사용되는 Key-Value 페어를 GPU 캐시에 유지.</li><li>LRU(Least Recently Used) 또는 LFU(Least Frequently Used) 정책을 적용해 캐시 사용 패턴 학습.</li></ul></li></ol><hr><h4 id=4-구체적인-학습-예시><strong>4. 구체적인 학습 예시</strong></h4><h5 id=상황><strong>상황</strong></h5><ul><li>데이터셋: LongBench.</li><li>모델: LLaMA-2-7B.</li><li>태스크: 긴 문서 요약.</li></ul><h5 id=학습-과정><strong>학습 과정</strong></h5><ol><li><p><strong>Key 벡터 생성</strong>:</p><ul><li>입력 문장: &ldquo;The quick brown fox jumps over the lazy dog.&rdquo;</li><li>Key 벡터: <code>[1.2, 3.5, 2.1, 4.3]</code>.</li></ul></li><li><p><strong>PQ 학습</strong>:</p><ul><li>벡터를 2개의 서브벡터 <code>[1.2, 3.5]</code>와 <code>[2.1, 4.3]</code>로 나누고 K-means clustering 수행.</li><li>클러스터링 결과:<ul><li>Centroid: <code>[1.0, 3.0]</code>, <code>[2.0, 4.0]</code>.</li><li>PQ Code: <code>[1, 2]</code>.</li></ul></li></ul></li><li><p><strong>토큰 선택 학습</strong>:</p><ul><li>Query 벡터 <code>[0.5, 0.3]</code>와 Centroid의 내적 계산으로 Attention Score 생성:<ul><li><code>[0.5, 0.3]</code>과 <code>[1.0, 3.0]</code> → 1.4.</li><li><code>[0.5, 0.3]</code>과 <code>[2.0, 4.0]</code> → 2.2.</li></ul></li><li>가장 높은 Score(2.2)를 가진 Key-Value 페어를 선택.</li></ul></li><li><p><strong>Self-Attention 실행</strong>:</p><ul><li>선택된 Key-Value 페어를 GPU로 전송하여 Self-Attention 계산 수행.</li></ul></li></ol><hr><h4 id=5-요약><strong>5. 요약</strong></h4><ul><li><strong>데이터셋</strong>:<ul><li>긴 문맥과 다양한 태스크를 포함한 데이터셋(LongBench, Needle-in-a-Haystack 등)을 활용.</li></ul></li><li><strong>학습 방법</strong>:<ul><li>Product Quantization을 통해 Key 벡터를 압축.</li><li>Attention Score를 기반으로 중요한 토큰을 선택.</li><li>캐시 및 통신 효율성을 높이기 위한 시스템 최적화.</li></ul></li><li><strong>결과</strong>:<ul><li>긴 문맥에서도 효율적이고 정확한 추론을 위한 KVCache 관리 시스템 구축.</li></ul></li></ul><h1 id=q--이-논문에서-제시한-결과를-자세하게-보고-다른-방법론에-비하여-특출난-점과-논문에서-제기하는-어떠한-방법이-이러한-결과를-도출하게-되었는지-논문에서-제시하는-이유와-너의-생각을-알려줘>Q : 이 논문에서 제시한 결과를 자세하게 보고 다른 방법론에 비하여 특출난 점과 논문에서 제기하는 어떠한 방법이 이러한 결과를 도출하게 되었는지 논문에서 제시하는 이유와 너의 생각을 알려줘</h1><h3 id=pqcache-논문-결과-분석-및-다른-방법론과의-비교>PQCache 논문 결과 분석 및 다른 방법론과의 비교</h3><hr><h4 id=1-pqcache의-주요-결과><strong>1. PQCache의 주요 결과</strong></h4><ol><li><p><strong>긴 문맥에서도 효율성 유지</strong>:</p><ul><li><strong>LongBench 실험 결과</strong>:<ul><li>PQCache는 전체 토큰의 1/5만을 사용해도 모델 품질을 거의 동일하게 유지하며, 평균 점수에서 H2O, SPARQ, InfLLM 같은 기존 방법보다 더 나은 성능을 보여줌.</li><li>예: Mistral-7B 모델에서 LongBench 평균 점수 6.21점 개선.</li></ul></li></ul></li><li><p><strong>적은 메모리 사용량으로도 높은 정확도</strong>:</p><ul><li>Needle-in-a-Haystack 테스트에서 중요 정보를 거의 모든 시나리오에서 성공적으로 검색.</li><li>1/128 KVCache 크기의 추가 통신 비용만으로도 SPARQ나 InfLLM보다 훨씬 안정적인 성능을 보여줌.</li></ul></li><li><p><strong>낮은 지연 시간</strong>:</p><ul><li><strong>Time Per Output Token (TPOT)</strong>:<ul><li>SPARQ와 InfLLM 대비 낮은 지연 시간 유지.</li><li>GPU 캐시와 Centroid 기반의 계산을 병렬화하여 실시간 응답성을 강화.</li></ul></li></ul></li><li><p><strong>높은 캐시 적중률</strong>:</p><ul><li>Least Recently Used(LRU) 또는 Least Frequently Used(LFU) 정책을 활용한 GPU 캐시에서 약 60% 적중률을 달성, 통신 비용을 크게 감소.</li></ul></li></ol><hr><h4 id=2-다른-방법론과의-비교><strong>2. 다른 방법론과의 비교</strong></h4><h5 id=a-h2o-kvcache-dropping><strong>A. H2O (KVCache Dropping)</strong></h5><ul><li><strong>장점</strong>:<ul><li>토큰의 Attention Score를 계산해 중요도가 낮은 토큰을 제거.</li><li>비교적 간단한 구현.</li></ul></li><li><strong>단점</strong>:<ul><li>일부 낮은 중요도의 토큰이 실제로 중요한 정보를 포함할 가능성 → 성능 저하.</li><li>FlashAttention 같은 최적화를 활용하지 못해 메모리 사용량 증가.</li></ul></li></ul><h5 id=b-sparq-selective-fetching><strong>B. SPARQ (Selective Fetching)</strong></h5><ul><li><strong>장점</strong>:<ul><li>CPU에 저장된 KVCache에서 필요한 정보만 GPU로 가져와 처리.</li><li>GPU 메모리의 효율적 사용.</li></ul></li><li><strong>단점</strong>:<ul><li>각 Query에서 Key-Value 페어를 선택하는 과정에서 과도한 통신 비용 발생.</li><li>Sequential한 처리 방식으로 인해 지연 시간이 높음.</li></ul></li></ul><h5 id=c-infllm-block-level-caching><strong>C. InfLLM (Block-Level Caching)</strong></h5><ul><li><strong>장점</strong>:<ul><li>Key-Value를 블록 단위로 나눠 CPU에서 관리하고 GPU로 전송.</li><li>캐시 사용 최적화를 통해 메모리 비용 감소.</li></ul></li><li><strong>단점</strong>:<ul><li>블록 기반 접근법은 공간 연속성을 가정하므로, 중요도가 높은 정보가 블록에 고르게 분포되지 않으면 성능이 저하될 가능성.</li></ul></li></ul><h5 id=d-pqcache-논문-제안><strong>D. PQCache (논문 제안)</strong></h5><ul><li><strong>장점</strong>:<ul><li>Product Quantization을 통해 Key 벡터를 압축하고, 근사 Attention Score 계산을 활용.</li><li>Centroid와 PQ Code를 조합하여 필요한 Key-Value 페어만 선택해 GPU로 전송.</li><li>높은 Recall 성능과 낮은 통신 비용을 동시에 달성.</li></ul></li><li><strong>단점</strong>:<ul><li>Prefilling 단계에서 K-means clustering이 추가적으로 필요해 초기 설정 시간이 늘어날 수 있음.</li></ul></li></ul><hr><h4 id=3-pqcache가-뛰어난-이유><strong>3. PQCache가 뛰어난 이유</strong></h4><h5 id=논문에서-제시하는-이유>논문에서 제시하는 이유:</h5><ol><li><p><strong>Product Quantization(PQ)의 효율적 사용</strong>:</p><ul><li>Key 벡터를 압축하여 CPU 메모리 사용량을 줄이고 GPU 전송량도 감소.</li><li>Centroid와 PQ Code를 활용해 Approximate Nearest Neighbor Search(MIPS)를 실행, 정확도를 유지하며 계산 비용 감소.</li></ul></li><li><p><strong>시스템-알고리즘 협력 설계</strong>:</p><ul><li>CPU에서 PQ를 생성하는 작업과 GPU에서 Attention Score 계산을 병렬화해 작업을 최적화.</li><li>GPU 캐시를 활용해 자주 액세스되는 토큰을 효율적으로 관리.</li></ul></li><li><p><strong>실험적 성능 개선</strong>:</p><ul><li>긴 문맥 데이터를 처리하면서도 H2O, SPARQ, InfLLM 대비 평균 3-6점의 LongBench 성능 개선.</li><li>캐시 히트율을 높이고 통신 비용을 줄임으로써 지연 시간 최소화.</li></ul></li></ol><h5 id=나의-생각>나의 생각:</h5><ol><li><p><strong>근사 계산의 장점 활용</strong>:</p><ul><li>PQCache는 정확도와 효율성 사이의 균형을 매우 잘 잡은 방법입니다. 특히 Centroid와 PQ Code 조합을 통해 계산 비용을 줄이는 동시에, Attention Score의 핵심적인 패턴을 포착하는 데 성공했다고 봅니다.</li></ul></li><li><p><strong>다양한 데이터셋에서의 일관된 성능</strong>:</p><ul><li>긴 문맥을 처리해야 하는 Needle-in-a-Haystack나 Chain-of-Thought Reasoning 같은 태스크에서도 안정적으로 동작한다는 점에서 PQCache의 설계가 현실적인 시나리오를 잘 반영했다고 판단됩니다.</li></ul></li><li><p><strong>실시간 처리에서의 잠재력</strong>:</p><ul><li>GPU 캐시와 Prefetching 설계 덕분에 PQCache는 실시간 응답이 중요한 애플리케이션에서 강점을 발휘할 것으로 보입니다. 이는 단순히 연구 결과에 그치지 않고, 실제 산업 응용으로도 확장 가능하다는 점에서 특출납니다.</li></ul></li></ol><hr><h4 id=4-결론><strong>4. 결론</strong></h4><p>PQCache의 뛰어난 성능은 <strong>Product Quantization</strong>을 활용한 효율적 메모리 관리와, 시스템-알고리즘의 최적화 설계에서 비롯됩니다. 특히 다른 방법론들이 간과했던 <strong>근사 계산을 통한 계산 효율화</strong>와 <strong>GPU 캐시 최적화</strong>는 PQCache가 제안된 이유를 잘 설명합니다. 나아가, PQCache는 실시간 처리와 메모리 병목 문제를 동시에 해결할 수 있는 잠재력을 갖추고 있습니다.</p><h1 id=q--이-논문에서-제시된-방법을-실제로-사용하려면-기존-방법에서-어떠한-구현이-추가적으로-필요하고-이러한-구현에-소모되는-공수-및-연산에-필요한-컴퓨팅-자원의-크기에-대해서-계산해줄-수-있겠니>Q : 이 논문에서 제시된 방법을 실제로 사용하려면 기존 방법에서 어떠한 구현이 추가적으로 필요하고 이러한 구현에 소모되는 공수 및 연산에 필요한 컴퓨팅 자원의 크기에 대해서 계산해줄 수 있겠니?</h1><h3 id=pqcache-구현에-필요한-추가-작업-및-자원-계산><strong>PQCache 구현에 필요한 추가 작업 및 자원 계산</strong></h3><hr><h4 id=1-pqcache-구현-시-추가적인-작업><strong>1. PQCache 구현 시 추가적인 작업</strong></h4><h5 id=a-product-quantizationpq-구현><strong>A. Product Quantization(PQ) 구현</strong></h5><ol><li><p><strong>Key 벡터 분할</strong>:</p><ul><li>기존 KVCache는 Key-Value를 저장하지만, PQCache는 Key 벡터를 여러 서브벡터로 나눠야 함.</li><li>서브벡터 분할과 관련된 코드는 K-means clustering 이전에 추가적으로 구현해야 함.</li></ul></li><li><p><strong>K-means 클러스터링</strong>:</p><ul><li>각 서브벡터에 대해 K-means 클러스터링을 실행하여 Centroid와 PQ Code를 생성.</li><li>필요 작업:<ul><li>클러스터링 알고리즘 구현 또는 기존 라이브러리(e.g., Scikit-learn, PyTorch) 사용.</li><li>CPU 병렬화를 활용한 클러스터링 최적화.</li></ul></li></ul></li><li><p><strong>Centroid 및 PQ Code 저장</strong>:</p><ul><li>CPU 메모리에 Centroid와 PQ Code를 저장하고 관리하는 추가적인 데이터 관리 계층 필요.</li></ul></li></ol><h5 id=b-query와-centroid-간-내적-계산><strong>B. Query와 Centroid 간 내적 계산</strong></h5><ol><li><p><strong>근사 Attention Score 계산</strong>:</p><ul><li>Query와 Centroid 간 내적 계산 코드 추가.</li><li>기존 GPU 상의 전체 Key와 Query를 직접 계산하는 방식에서, <strong>Centroid 기반 계산</strong>으로 변경.</li></ul></li><li><p><strong>상위 k개의 Key-Value 선택</strong>:</p><ul><li>내적 결과에서 상위 (k)개의 중요 Key를 선택하는 알고리즘 구현.</li></ul></li></ol><h5 id=c-gpu와-cpu-간-데이터-통신-최적화><strong>C. GPU와 CPU 간 데이터 통신 최적화</strong></h5><ol><li><p><strong>Prefetching 및 Caching</strong>:</p><ul><li>GPU와 CPU 간 데이터 통신을 효율적으로 설계.</li><li>자주 액세스되는 Key-Value 페어를 GPU 캐시에 저장하는 로직 추가.</li></ul></li><li><p><strong>동적 캐싱 및 블록 관리</strong>:</p><ul><li>Least Recently Used(LRU) 또는 Least Frequently Used(LFU) 정책 구현.</li></ul></li></ol><h5 id=d-시스템-병렬화><strong>D. 시스템 병렬화</strong></h5><ol><li><strong>병렬화 설계</strong>:<ul><li>GPU에서 Self-Attention 계산 중 CPU에서 PQ 생성 및 Key-Value 페어 관리가 병렬로 수행될 수 있도록 코드 구조 변경.</li><li>PyTorch의 비동기 연산(Await, Future) 또는 CUDA 스트림을 활용.</li></ul></li></ol><hr><h4 id=2-공수-및-컴퓨팅-자원-계산><strong>2. 공수 및 컴퓨팅 자원 계산</strong></h4><h5 id=a-연산-비용-계산><strong>A. 연산 비용 계산</strong></h5><ol><li><p><strong>K-means 클러스터링</strong></p><ul><li>평균 클러스터링 비용:
[
\text{Complexity} = O(N \cdot m \cdot 2^b \cdot T)
]<ul><li>(N): Key의 개수 (e.g., 10,000 토큰 × 32 레이어).</li><li>(m): 서브벡터의 개수 (e.g., 4).</li><li>(2^b): 클러스터 수 (e.g., (b = 6)일 때 (2^6 = 64)).</li><li>(T): K-means 반복 횟수 (e.g., 10회).</li></ul></li></ul><p><strong>예시 계산</strong>:</p><ul><li>(N = 10,000), (m = 4), (2^b = 64), (T = 10)일 때:
[
\text{Total Cost} = 10,000 \cdot 4 \cdot 64 \cdot 10 = 25,600,000 \text{ 연산}
]</li></ul></li><li><p><strong>Query-Centroid 내적 계산</strong></p><ul><li>Query-Centroid 연산 비용:
[
O(m \cdot 2^b)
]<ul><li>한 Query와 Centroid 간 계산 비용은 (m = 4), (2^b = 64)일 때 (256)번 연산.</li></ul></li></ul><p><strong>예시</strong>:</p><ul><li>10,000 Query에 대해:
[
\text{Total Cost} = 10,000 \cdot 256 = 2,560,000 \text{ 연산}
]</li></ul></li><li><p><strong>전체 비용 비교</strong>:</p><ul><li>기존 방식(GPU에서 전체 Key와 Query 계산):
[
O(N \cdot d) \quad (N: 토큰 수, d: Key 벡터 차원)
]
예: (N = 10,000), (d = 128)일 때 (10,000 \cdot 128 = 1,280,000 \text{ 연산}).</li><li>PQCache 방식:<ul><li>클러스터링 및 내적 계산 포함: (25,600,000 + 2,560,000 = 28,160,000) 연산.</li></ul></li></ul><p><strong>결론</strong>: 초기 클러스터링 비용은 높지만, 긴 문맥 처리에서 반복적으로 사용되며 효율성이 증가.</p></li></ol><hr><h5 id=b-메모리-및-통신-비용-계산><strong>B. 메모리 및 통신 비용 계산</strong></h5><ol><li><p><strong>CPU 메모리</strong>:</p><ul><li>Centroid 저장:
[
O(m \cdot 2^b \cdot d_m)
]
예: (m = 4), (2^b = 64), (d_m = d/m = 128/4 = 32)일 때:
[
4 \cdot 64 \cdot 32 = 8,192 \text{ floats 저장 필요}.
]
약 32KB 추가 메모리 필요.</li></ul></li><li><p><strong>GPU-CPU 통신</strong>:</p><ul><li>상위 (k) Key-Value 페어만 전송:
[
O(k \cdot d)
]
예: (k = 100), (d = 128)일 때 (100 \cdot 128 = 12,800 \text{ floats}).</li></ul></li><li><p><strong>GPU 캐시</strong>:</p><ul><li>캐시 크기: 1,000 토큰 × 128 floats = 128,000 floats ≈ 0.5MB.</li></ul></li></ol><hr><h5 id=c-공수-및-구현-난이도><strong>C. 공수 및 구현 난이도</strong></h5><ol><li><p><strong>K-means 클러스터링</strong>:</p><ul><li>추가 구현 공수: 중간.<ul><li>기존 라이브러리 활용 시 약 2-3주 소요.</li><li>GPU를 활용한 병렬화 개발 시 4-6주 추가.</li></ul></li></ul></li><li><p><strong>GPU-CPU 통신 최적화</strong>:</p><ul><li>추가 구현 공수: 중간.<ul><li>Prefetching 및 동적 캐싱 개발에 약 2-4주 소요.</li></ul></li></ul></li><li><p><strong>Attention Score 계산 변경</strong>:</p><ul><li>추가 구현 공수: 낮음.<ul><li>Centroid 기반 계산으로 변경하는 데 1-2주 소요.</li></ul></li></ul></li><li><p><strong>시스템 병렬화</strong>:</p><ul><li>추가 구현 공수: 높음.<ul><li>PyTorch 비동기 연산을 활용한 구조 설계에 4-6주 소요.</li></ul></li></ul></li></ol><hr><h4 id=3-요약><strong>3. 요약</strong></h4><table><thead><tr><th><strong>항목</strong></th><th><strong>추가 구현 요소</strong></th><th><strong>계산 비용</strong></th><th><strong>추가 자원 필요</strong></th></tr></thead><tbody><tr><td><strong>K-means 클러스터링</strong></td><td>Key 분할 및 Centroid 생성</td><td>25,600,000 연산</td><td>CPU 메모리 약 32KB 추가</td></tr><tr><td><strong>Query-Centroid 내적</strong></td><td>내적 계산 및 근사 Score 생성</td><td>2,560,000 연산</td><td>GPU-CPU 통신 감소</td></tr><tr><td><strong>캐싱 및 통신 최적화</strong></td><td>Prefetching 및 동적 캐싱</td><td>통신량: (O(k \cdot d)) 감소</td><td>GPU 캐시 약 0.5MB</td></tr><tr><td><strong>병렬화</strong></td><td>GPU와 CPU 간 작업 병렬화</td><td>초반 구현 공수 필요</td><td>추가 컴퓨팅 자원 없음</td></tr></tbody></table><p>PQCache는 초기 구현에 추가 공수와 클러스터링 연산 비용이 소요되지만, 긴 문맥 처리와 반복적인 활용에서 장기적인 이점을 제공합니다.</p><p>I have calculated the computational and memory requirements for implementing the PQCache algorithm. The results have been provided in a table for your review. Let me know if you need any further explanations or specific details!</p><h1 id=q--이-논문의-입력데이터와-추론-과정에-대해서-예시를-들어-아주-자세하게-설명해-주겠니-추가적으로-모델아키텍처의-구성-및-모델을-구성하는-연산과-메모리-요구량-컴퓨팅-요구량-대해서도-설명해줘>Q : 이 논문의 입력데이터와 추론 과정에 대해서 예시를 들어 아주 자세하게 설명해 주겠니? 추가적으로 모델아키텍처의 구성 및 모델을 구성하는 연산과 메모리 요구량 컴퓨팅 요구량 대해서도 설명해줘</h1><h3 id=논문의-입력-데이터-및-추론-과정><strong>논문의 입력 데이터 및 추론 과정</strong></h3><hr><h4 id=1-입력-데이터-예시><strong>1. 입력 데이터 예시</strong></h4><h5 id=입력-데이터의-특징><strong>입력 데이터의 특징</strong></h5><ol><li><p><strong>긴 문맥 처리</strong>:</p><ul><li>PQCache는 긴 문맥을 가진 입력 데이터를 처리하기 위해 설계되었음.</li><li>예: 길이가 32,000 토큰에 이르는 텍스트 입력.</li></ul></li><li><p><strong>입력 형식</strong>:</p><ul><li>토큰화된 텍스트 시퀀스.</li><li>예: &ldquo;The quick brown fox jumps over the lazy dog.&rdquo;</li></ul></li><li><p><strong>데이터의 사용 목적</strong>:</p><ul><li><strong>Prefilling 단계</strong>: 전체 문맥을 입력하여 KVCache를 생성.</li><li><strong>Decoding 단계</strong>: 이전 토큰을 기반으로 새로운 토큰을 생성.</li></ul></li></ol><hr><h5 id=입력-예시><strong>입력 예시</strong></h5><ul><li>텍스트: <code>"The quick brown fox jumps over the lazy dog repeatedly across the forest."</code></li><li>토큰화:<div class="code-block-container border-border bg-card my-6 overflow-hidden rounded-xl border shadow-sm transition-all duration-200 ease-out hover:-translate-y-0.5 hover:shadow-md"><div class="code-block-header bg-muted/30 border-border flex items-center justify-between border-b px-4 py-3"><div class="flex items-center gap-2"><div class="text-muted-foreground flex-shrink-0"><svg class="h-4 w-4" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M10 20l4-16m4 4 4 4-4 4M6 16l-4-4 4-4"/></svg></div><span class="text-muted-foreground text-sm font-medium">PLAINTEXT</span></div><div class="flex items-center gap-2"><button class="collapse-code-btn text-muted-foreground hover:text-primary hover:bg-primary/10 focus:ring-primary/20 flex items-center gap-1.5 rounded-md px-2 py-1 text-xs font-medium transition-all duration-200 ease-out focus:ring-2 focus:outline-none" data-code-id=code-0 data-default-state=expanded data-collapsed=false data-auto-collapse-lines=30 data-auto-collapse-height=400 data-collapsed-height=120 title=접기 aria-label=접기>
<span class=collapse-icon><svg class="h-3 w-3" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path fill="currentColor" d="M7.41 15.41 12 10.83l4.59 4.58L18 14l-6-6-6 6z"/></svg>
</span><span class="collapse-text hidden sm:inline">접기</span>
</button>
<button class="copy-code-btn text-muted-foreground hover:text-primary hover:bg-primary/10 focus:ring-primary/20 flex items-center gap-1.5 rounded-md px-2 py-1 text-xs font-medium transition-all duration-200 ease-out focus:ring-2 focus:outline-none" data-code-id=code-0 title=복사 aria-label=복사>
<span class=copy-icon><svg class="h-3 w-3" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M8 16H6a2 2 0 01-2-2V6a2 2 0 012-2h8a2 2 0 012 2v2m-6 12h8a2 2 0 002-2v-8a2 2 0 00-2-2h-8a2 2 0 00-2 2v8a2 2 0 002 2z"/></svg>
</span><span class="copy-text hidden sm:inline">복사</span></button></div></div><div class="code-block-content relative" id=code-0><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=ln>1</span><span class=cl>[101, 200, 512, 1200, 503, 104, 320, 2045, 2342, 5321]</span></span></code></pre></div><div class="collapse-overlay to-card/90 pointer-events-none absolute inset-0 bg-gradient-to-b from-transparent via-transparent opacity-0 transition-opacity duration-300"><div class="text-muted-foreground bg-card/80 border-border/50 hover:bg-primary/10 hover:text-primary hover:border-primary/30 absolute bottom-4 left-1/2 -translate-x-1/2 cursor-pointer rounded-full border px-3 py-1.5 text-xs backdrop-blur-sm transition-all duration-200">클릭하여 더 보기</div></div></div></div><script>(function(){const s="code-0",n=document.querySelector('.copy-code-btn[data-code-id="'+s+'"]'),t=document.querySelector('.collapse-code-btn[data-code-id="'+s+'"]'),e=document.getElementById(s);if(!e)return;if(n){const s=n.querySelector(".copy-icon"),t=n.querySelector(".copy-text");n.addEventListener("click",async function(){try{let o="";const i=e.querySelector(".lntd:last-child code");if(i)o=i.textContent||i.innerText;else{const t=e.querySelector("code");if(t){const e=t.querySelector(".ln");if(e){const e=t.querySelectorAll(".cl");if(e.length>0)o=Array.from(e).map(e=>{const t=e.textContent||e.innerText;return t.replace(/\n+$/,"")}).join(`
`).replace(/\n+$/,"");else{const e=t.textContent||t.innerText;o=e.replace(/^\d+/gm,"").replace(/^\s+/gm,"")}}else o=t.textContent||t.innerText}else o=e.textContent||e.innerText}o=o.trim(),await navigator.clipboard.writeText(o),s.innerHTML=`
  <svg class="h-3 w-3"
    fill="none"
    stroke="currentColor"
    viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M5 13l4 4L19 7" />
</svg>`,t&&(t.textContent="복사됨"),n.classList.add("text-green-600"),setTimeout(()=>{s.innerHTML=`
  <svg class="h-3 w-3"
    fill="none"
    stroke="currentColor"
    viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M8 16H6a2 2 0 01-2-2V6a2 2 0 012-2h8a2 2 0 012 2v2m-6 12h8a2 2 0 002-2v-8a2 2 0 00-2-2h-8a2 2 0 00-2 2v8a2 2 0 002 2z" />
</svg>`,t&&(t.textContent="복사"),n.classList.remove("text-green-600")},2e3)}catch(o){console.error("复制失败:",o);const s=document.createRange(),i=e.querySelector("code")||e;s.selectNodeContents(i);const n=window.getSelection();n.removeAllRanges(),n.addRange(s),t&&(t.textContent="선택됨"),setTimeout(()=>{t&&(t.textContent="복사"),n.removeAllRanges()},2e3)}})}if(t){const d=t.querySelector(".collapse-icon"),c=t.querySelector(".collapse-text"),n=e.querySelector(".collapse-overlay");let s=e.querySelector("pre.chroma");s||(s=e.querySelector("pre"));const m=t.dataset.defaultState||"expanded",f=t.dataset.collapsed==="true",u=parseInt(t.dataset.autoCollapseLines)||30,h=parseInt(t.dataset.autoCollapseHeight)||400,p=parseInt(t.dataset.collapsedHeight)||120;let l=!1;function i(){const e=f||m==="collapsed"||a();e&&o(!0,!1)}function a(){if(s){const e=s.querySelectorAll(".line, .cl"),t=s.offsetHeight;return e.length>u||t>h}const t=e.offsetHeight;if(t>h)return!0;const n=e.textContent||e.innerText||"",o=n.split(`
`).length;return o>u}function o(s,o=!0){if(!n)return;l=s,s?(e.style.maxHeight=p+"px",e.style.overflow="hidden",n.style.opacity="1",n.style.pointerEvents="auto",d.innerHTML=`
  <svg class="h-3 w-3"
    fill="none"
    stroke="currentColor"
    viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 9l-7 7-7-7" />
</svg>`,c&&(c.textContent="펼치기"),t.title="펼치기"):(e.style.maxHeight="",e.style.overflow="",n.style.opacity="0",n.style.pointerEvents="none",d.innerHTML=`
  <svg class="h-3 w-3"
    fill="none"
    stroke="currentColor"
    viewBox="0 0 24 24"><path fill="currentColor" d="M7.41 15.41L12 10.83l4.59 4.58L18 14l-6-6l-6 6z"/></svg>`,c&&(c.textContent="접기"),t.title="접기"),o&&(e.style.transition="max-height 0.3s ease-out",setTimeout(()=>{e.style.transition=""},300))}function r(){o(!l,!0)}t.addEventListener("click",r),n&&n.addEventListener("click",()=>{l&&o(!1,!0)}),i()}})()</script>(여기서 각 숫자는 텍스트 토큰을 나타냄)</li></ul><hr><h4 id=2-추론-과정-단계별-설명><strong>2. 추론 과정: 단계별 설명</strong></h4><h5 id=prefilling-단계-1><strong>Prefilling 단계</strong></h5><ol><li><p><strong>입력 처리</strong>:</p><ul><li>전체 토큰 시퀀스 입력.</li><li>각 토큰에 대해 Query, Key, Value 벡터 계산:<ul><li>Key, Value 벡터: 각 벡터의 차원은 모델 차원 (d_h = 128).</li></ul></li></ul></li><li><p><strong>Key 벡터 분할 및 압축</strong>:</p><ul><li>Key 벡터를 (m)개의 서브벡터로 분할 (예: 4개로 분할).</li><li>각 서브벡터에 대해 K-means clustering을 수행하여 Centroid와 PQ Code 생성.</li></ul></li><li><p><strong>KVCache 저장</strong>:</p><ul><li>Value 벡터는 그대로 저장.</li><li>Key 벡터는 압축된 PQ Code와 Centroid로 변환 후 CPU에 저장.</li></ul></li></ol><h5 id=decoding-단계-1><strong>Decoding 단계</strong></h5><ol><li><p><strong>Query 계산</strong>:</p><ul><li>새롭게 생성된 토큰에 대해 Query 벡터 계산.</li></ul></li><li><p><strong>근사 Attention Score 계산</strong>:</p><ul><li>Query와 Centroid 간의 내적을 통해 각 Key의 근사 Attention Score 계산.</li><li>예:<ul><li>Query = ([0.5, 0.3, -0.2])</li><li>Centroid 1 = ([1.0, 3.0, -1.0]), Centroid 2 = ([0.2, 0.8, -0.5])</li><li>Attention Score:
[
\text{Score}_1 = 0.5 \times 1.0 + 0.3 \times 3.0 + (-0.2) \times (-1.0) = 1.6
]
[
\text{Score}_2 = 0.5 \times 0.2 + 0.3 \times 0.8 + (-0.2) \times (-0.5) = 0.74
]</li></ul></li></ul></li><li><p><strong>상위 (k) Key 선택</strong>:</p><ul><li>Attention Score가 높은 상위 (k)개의 Key를 선택하고 대응하는 Value 페어를 GPU로 가져옴.</li></ul></li><li><p><strong>Self-Attention 계산</strong>:</p><ul><li>선택된 Key-Value 페어를 사용하여 Self-Attention 연산 수행.</li><li>결과를 기반으로 새로운 토큰 생성.</li></ul></li></ol><hr><h4 id=3-모델-아키텍처-구성><strong>3. 모델 아키텍처 구성</strong></h4><h5 id=모델의-주요-구성><strong>모델의 주요 구성</strong></h5><ol><li><p><strong>Transformer 아키텍처</strong>:</p><ul><li>Multi-Head Attention (MHA)과 Feedforward Network(FFN)로 구성.</li><li>각 Transformer 레이어는 다음 연산을 포함:<ul><li>Query-Key 간의 Attention Score 계산.</li><li>Softmax 및 Value의 가중합으로 Attention 출력 생성.</li><li>FFN을 통해 각 Attention 출력 후처리.</li></ul></li></ul></li><li><p><strong>KVCache 사용</strong>:</p><ul><li>각 레이어의 Key-Value 페어를 저장하여 반복 계산을 방지.</li></ul></li><li><p><strong>Product Quantization 통합</strong>:</p><ul><li>Key 벡터의 분할 및 압축.</li><li>PQ Code와 Centroid를 통해 Key-Value 페어의 일부만 선택.</li></ul></li></ol><hr><h4 id=4-연산-및-메모리-요구량><strong>4. 연산 및 메모리 요구량</strong></h4><h5 id=a-연산-요구량><strong>A. 연산 요구량</strong></h5><ol><li><p><strong>Attention 연산</strong>:</p><ul><li>Query-Key 간 내적:
[
O(n \cdot d_h)
]<ul><li>(n): 토큰 수 (32,000).</li><li>(d_h): Key 벡터 차원 (128).</li></ul></li></ul><p>예: (n = 32,000), (d_h = 128)일 때:
[
32,000 \cdot 128 = 4,096,000 \text{ 연산}.
]</p></li><li><p><strong>PQ 기반 연산</strong>:</p><ul><li>Centroid-Query 내적:
[
O(m \cdot 2^b)
]<ul><li>(m = 4), (b = 6)일 때 (2^b = 64), 총 256 연산/Query.</li></ul></li></ul><p>예: 32,000 Query에 대해:
[
32,000 \cdot 256 = 8,192,000 \text{ 연산}.
]</p></li><li><p><strong>K-means 클러스터링</strong>:</p><ul><li>클러스터링 반복 비용:
[
O(n \cdot m \cdot 2^b \cdot T)
]<ul><li>(T): 반복 횟수 (10회).
예: (n = 32,000), (m = 4), (2^b = 64), (T = 10)일 때:
[
32,000 \cdot 4 \cdot 64 \cdot 10 = 81,920,000 \text{ 연산}.
]</li></ul></li></ul></li></ol><h5 id=b-메모리-요구량><strong>B. 메모리 요구량</strong></h5><ol><li><p><strong>KVCache 메모리</strong>:</p><ul><li>Key-Value 페어 저장:
[
n \cdot d_h \cdot 2
]
예: (n = 32,000), (d_h = 128)일 때:
[
32,000 \cdot 128 \cdot 2 = 8,192,000 \text{ floats}.
]
약 32MB 메모리 필요.</li></ul></li><li><p><strong>PQ Centroid 저장</strong>:</p><ul><li>Centroid 메모리:
[
m \cdot 2^b \cdot d_m
]
예: (m = 4), (2^b = 64), (d_m = 32)일 때:
[
4 \cdot 64 \cdot 32 = 8,192 \text{ floats}.
]
약 32KB.</li></ul></li><li><p><strong>GPU 캐시</strong>:</p><ul><li>캐시 크기: 1,000 토큰 × 128 floats = 128,000 floats ≈ 0.5MB.</li></ul></li></ol><hr><h4 id=5-요약-1><strong>5. 요약</strong></h4><table><thead><tr><th><strong>요소</strong></th><th><strong>연산량</strong></th><th><strong>메모리 요구량</strong></th></tr></thead><tbody><tr><td><strong>Attention 연산</strong></td><td>(O(n \cdot d_h))</td><td>(32MB) (KVCache)</td></tr><tr><td><strong>PQ 연산</strong></td><td>(O(m \cdot 2^b))</td><td>(32KB) (Centroid)</td></tr><tr><td><strong>K-means 클러스터링</strong></td><td>(O(n \cdot m \cdot 2^b \cdot T))</td><td>CPU 계산 필요</td></tr><tr><td><strong>GPU 캐시</strong></td><td>-</td><td>(0.5MB)</td></tr></tbody></table><p>이와 같은 계산으로 PQCache는 긴 문맥에서도 효율적인 추론을 가능하게 하며, 메모리와 연산량의 균형을 잘 맞춘 설계임을 보여줍니다.</p><h1 id=q--이-논문의-한계를-극복하기-위한-방법으로-어떤-연구흐름이-있는지-정리해서-자세하게-설명해-줘>Q : 이 논문의 한계를 극복하기 위한 방법으로 어떤 연구흐름이 있는지 정리해서 자세하게 설명해 줘</h1><h3 id=논문의-한계-및-이를-극복하기-위한-연구-흐름><strong>논문의 한계 및 이를 극복하기 위한 연구 흐름</strong></h3><hr><h4 id=1-논문의-주요-한계><strong>1. 논문의 주요 한계</strong></h4><h5 id=a-초기-k-means-클러스터링의-높은-계산-비용><strong>A. 초기 K-means 클러스터링의 높은 계산 비용</strong></h5><ul><li><strong>문제</strong>:<ul><li>PQCache는 Key 벡터를 압축하기 위해 Prefilling 단계에서 K-means 클러스터링을 사용하며, 이는 계산 비용이 높음.</li><li>긴 문맥을 처리할 경우, 클러스터링 비용이 더욱 커짐.</li></ul></li></ul><h5 id=b-근사-계산으로-인한-정보-손실><strong>B. 근사 계산으로 인한 정보 손실</strong></h5><ul><li><strong>문제</strong>:<ul><li>Product Quantization은 근사값을 사용하므로 일부 Key 벡터의 세부 정보를 잃을 가능성이 있음.</li><li>Needle-in-a-Haystack처럼 특정 정보의 검색이 중요한 태스크에서 정확도 저하 가능성.</li></ul></li></ul><h5 id=c-캐시-관리의-복잡성><strong>C. 캐시 관리의 복잡성</strong></h5><ul><li><strong>문제</strong>:<ul><li>GPU와 CPU 간 캐시 관리에서 적중률이 낮아지면 추가적인 통신 비용이 발생.</li><li>캐싱 정책(예: LRU, LFU)이 모든 데이터 유형에서 최적의 성능을 보장하지는 않음.</li></ul></li></ul><h5 id=d-하드웨어-의존성><strong>D. 하드웨어 의존성</strong></h5><ul><li><strong>문제</strong>:<ul><li>PQCache는 CPU와 GPU 간의 효율적인 통신을 가정하며 설계됨.</li><li>특정 하드웨어(NVIDIA A800 GPU, 고성능 CPU)에서만 최적의 성능이 보장될 수 있음.</li></ul></li></ul><hr><h4 id=2-한계를-극복하기-위한-연구-흐름><strong>2. 한계를 극복하기 위한 연구 흐름</strong></h4><h5 id=a-계산-비용-감소><strong>A. 계산 비용 감소</strong></h5><ol><li><p><strong>가벼운 클러스터링 알고리즘 개발</strong>:</p><ul><li><strong>대안</strong>:<ul><li>K-means 대신 <strong>Online Clustering</strong>이나 <strong>Streaming K-means</strong>와 같은 경량화된 알고리즘 사용.</li><li>Clustering을 Prefilling 단계가 아닌 실시간으로 동적으로 수행.</li></ul></li><li><strong>연구 흐름</strong>:<ul><li>Adnan et al.의 &ldquo;Keyformer"처럼 중요 토큰을 동적으로 선택하는 방법 연구.</li><li>Online 클러스터링을 통해 GPU 리소스를 활용하는 방법론 연구.</li></ul></li></ul></li><li><p><strong>학습 기반 근사 계산</strong>:</p><ul><li><strong>대안</strong>:<ul><li>Key 벡터를 압축하지 않고, 모델이 직접 중요한 Key-Value 페어를 선택하도록 학습.</li></ul></li><li><strong>연구 흐름</strong>:<ul><li>&ldquo;Scissorhands"와 같은 토큰 중요도 예측을 활용하여 계산량을 줄이는 방법 연구.</li></ul></li></ul></li></ol><h5 id=b-정보-손실-문제-해결><strong>B. 정보 손실 문제 해결</strong></h5><ol><li><p><strong>Residual Quantization(RQ) 사용</strong>:</p><ul><li><strong>대안</strong>:<ul><li>Product Quantization 후에 남은 오차를 Residual Vector로 저장하여 근사 계산의 정확도를 보완.</li></ul></li><li><strong>연구 흐름</strong>:<ul><li>RQ 기반의 LLM 가속화 연구.</li><li>Gear et al.의 KVCache 압축 방법처럼 손실을 줄이기 위한 추가 압축 알고리즘 적용.</li></ul></li></ul></li><li><p><strong>압축-비압축 병렬 처리</strong>:</p><ul><li><strong>대안</strong>:<ul><li>중요도가 높은 Key-Value 페어는 비압축 상태로 유지하고 나머지는 압축.</li></ul></li><li><strong>연구 흐름</strong>:<ul><li>중요도 기반 메모리 관리 연구.</li><li>중요 정보가 포함된 토큰을 학습 기반으로 선택하는 방법 연구.</li></ul></li></ul></li></ol><h5 id=c-캐시-관리-최적화><strong>C. 캐시 관리 최적화</strong></h5><ol><li><p><strong>Dynamic Cache Replacement</strong>:</p><ul><li><strong>대안</strong>:<ul><li>LRU, LFU 대신 딥러닝 기반 캐시 교체 정책(DeepCache) 사용.</li><li>중요도가 높은 토큰을 예측하고 캐시 적중률을 높임.</li></ul></li><li><strong>연구 흐름</strong>:<ul><li>AttentionStore와 같이 다중 대화에서 효율적으로 KVCache를 재활용하는 방법 연구.</li></ul></li></ul></li><li><p><strong>GPU 메모리 확장 기술</strong>:</p><ul><li><strong>대안</strong>:<ul><li>GPU 메모리를 확장하기 위해 NVMe SSD나 고속 인터페이스를 활용하는 하이브리드 메모리 아키텍처 설계.</li></ul></li><li><strong>연구 흐름</strong>:<ul><li>FlexGen처럼 GPU-CPU-NVMe 간의 메모리 계층을 최적화하는 기술 연구.</li></ul></li></ul></li></ol><h5 id=d-하드웨어-독립적-설계><strong>D. 하드웨어 독립적 설계</strong></h5><ol><li><p><strong>컴퓨팅 자원 최소화를 위한 경량화 연구</strong>:</p><ul><li><strong>대안</strong>:<ul><li>CPU 의존성을 줄이고 GPU 내부 연산만으로 처리할 수 있는 방법론 연구.</li></ul></li><li><strong>연구 흐름</strong>:<ul><li>Tensor Slicing이나 Weight Offloading 기법을 활용한 연산 경량화 연구.</li></ul></li></ul></li><li><p><strong>FPGA 또는 ASIC 사용</strong>:</p><ul><li><strong>대안</strong>:<ul><li>특정 연산을 FPGA나 ASIC으로 가속화.</li></ul></li><li><strong>연구 흐름</strong>:<ul><li>KVCache 연산을 전용 하드웨어로 가속화하는 기법.</li></ul></li></ul></li></ol><hr><h4 id=3-추가적인-혁신적-아이디어><strong>3. 추가적인 혁신적 아이디어</strong></h4><h5 id=a-모델-구조-변경><strong>A. 모델 구조 변경</strong></h5><ul><li><strong>Dynamic Attention Mechanism</strong>:<ul><li>모든 토큰에 대해 Attention 계산을 수행하지 않고, 중요 토큰에만 Attention을 수행하도록 모델 구조를 수정.</li><li>예: Sparse Attention이나 Routing Transformer 활용.</li></ul></li></ul><h5 id=b-데이터-중심-접근><strong>B. 데이터 중심 접근</strong></h5><ul><li><strong>학습 데이터의 중요도 기반 분류</strong>:<ul><li>학습 데이터에서 긴 문맥 처리에 중요한 패턴을 사전에 학습시켜 중요 토큰 선택을 최적화.</li></ul></li></ul><h5 id=c-메모리-압축-연구><strong>C. 메모리 압축 연구</strong></h5><ul><li><strong>Hybrid Quantization</strong>:<ul><li>Key-Value 페어에 대해 Mixed Precision Quantization을 적용하여 중요한 정보는 높은 정밀도로, 나머지는 낮은 정밀도로 저장.</li></ul></li></ul><hr><h4 id=4-요약-및-방향성><strong>4. 요약 및 방향성</strong></h4><table><thead><tr><th><strong>한계</strong></th><th><strong>해결 방향</strong></th><th><strong>연구 흐름</strong></th></tr></thead><tbody><tr><td><strong>초기 클러스터링 비용</strong></td><td>Online/Streaming K-means, 중요도 기반 클러스터링</td><td>Keyformer, Scissorhands, Adnan et al.</td></tr><tr><td><strong>정보 손실</strong></td><td>Residual Quantization, 압축-비압축 병렬 처리</td><td>Gear, Hybrid Quantization</td></tr><tr><td><strong>캐시 관리의 복잡성</strong></td><td>Dynamic Cache Replacement, GPU 메모리 확장</td><td>AttentionStore, FlexGen</td></tr><tr><td><strong>하드웨어 의존성</strong></td><td>경량화 설계, FPGA/ASIC 활용</td><td>Tensor Slicing, Weight Offloading</td></tr></tbody></table><p>이와 같은 연구 흐름은 PQCache가 가진 현재 한계를 보완하면서 더욱 효율적이고 실용적인 시스템으로 발전시킬 수 있는 가능성을 열어줍니다.</p></article></main><footer class="mx-auto max-w-4xl px-4 py-8"><div class="px-6 py-6"><nav class=mb-6><div class="flex flex-wrap items-center justify-center gap-1"><a href=/index.xml class="nav-link hover:text-primary hover:bg-primary/10 text-muted-foreground flex items-center gap-2 rounded-lg px-4 py-2 text-sm font-medium transition-all duration-300 hover:scale-105"><svg class="h-5 w-5" fill="none" stroke="currentColor" viewBox="0 0 24 24" aria-label="RSS Feed"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M6 5c7.18.0 13 5.82 13 13M6 11a7 7 0 017 7m-6 0a1 1 0 11-2 0 1 1 0 012 0z"/></svg>
<span>RSS Feed</span></a></div></nav><div class="border-border mb-6 border-t"></div><div class="flex flex-col items-center justify-between gap-4 md:flex-row"><div class="text-muted-foreground text-sm"><p>&copy; 2025 Jaehun's Blog.
모든 권리 보유.</p></div><div class="flex items-center gap-3"><a href=https://github.com/ryujaehun target=_blank rel="noopener noreferrer" class="text-muted-foreground hover:text-primary focus:ring-primary/20 rounded-lg p-1 transition-all duration-300 ease-out hover:scale-110 focus:ring-2 focus:outline-none" title=GitHub aria-label=GitHub><svg class="h-6 w-6" fill="none" stroke="currentColor" viewBox="0 0 24 24" aria-label="GitHub"><g fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2"><path d="M15 22v-4a4.8 4.8.0 00-1-3.5c3 0 6-2 6-5.5.08-1.25-.27-2.48-1-3.5.28-1.15.28-2.35.0-3.5.0.0-1 0-3 1.5-2.64-.5-5.36-.5-8 0C6 2 5 2 5 2c-.3 1.15-.3 2.35.0 3.5A5.4 5.4.0 004 9c0 3.5 3 5.5 6 5.5-.39.49-.68 1.05-.85 1.65S8.93 17.38 9 18v4"/><path d="M9 18c-4.51 2-5-2-7-2"/></g></svg>
</a><a href=https://www.linkedin.com/in/jaehunryu/ target=_blank rel="noopener noreferrer" class="text-muted-foreground hover:text-primary focus:ring-primary/20 rounded-lg p-1 transition-all duration-300 ease-out hover:scale-110 focus:ring-2 focus:outline-none" title=Linkedin aria-label=Linkedin><svg class="h-6 w-6" fill="none" stroke="currentColor" viewBox="0 0 24 24" aria-label="Linkedin"><g fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2"><path d="M16 8a6 6 0 016 6v7h-4v-7a2 2 0 00-2-2 2 2 0 00-2 2v7h-4v-7a6 6 0 016-6M2 9h4v12H2z"/><circle cx="4" cy="4" r="2"/></g></svg>
</a><a href=mailto:jaehunryu@icloud.com class="text-muted-foreground hover:text-primary focus:ring-primary/20 rounded-lg p-1 transition-all duration-300 ease-out hover:scale-110 focus:ring-2 focus:outline-none" title=Email aria-label=Email><svg class="h-6 w-6" fill="none" stroke="currentColor" viewBox="0 0 24 24" aria-label="Email"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M3 8l7.89 5.26a2 2 0 002.22.0L21 8M5 19h14a2 2 0 002-2V7a2 2 0 00-2-2H5A2 2 0 003 7v10a2 2 0 002 2z"/></svg></a></div></div></div></footer><div id=dock class="pointer-events-none fixed bottom-4 left-1/2 z-[9999] w-fit -translate-x-1/2 translate-y-24 opacity-0 transition-all duration-300 ease-out sm:right-0 sm:left-0 sm:mx-auto sm:translate-x-0" role=toolbar aria-label="바로가기 도구 모음"><nav class="border-border bg-card/80 scrollbar-hide xs:px-3 xs:py-2 mx-auto flex max-w-[calc(100vw-2rem)] min-w-fit items-center justify-center overflow-x-auto rounded-2xl border px-4 py-3 shadow-lg backdrop-blur-sm sm:px-4 sm:py-3"><button id=dock-back class="text-muted-foreground hover:text-primary hover:bg-primary/10 focus:ring-primary/20 xs:px-2 xs:py-1.5 flex flex-shrink-0 items-center gap-2 rounded-lg px-3 py-2 text-sm font-medium transition-all duration-300 ease-out hover:-translate-y-0.5 hover:scale-105 focus:ring-2 focus:outline-none sm:px-3 sm:py-2" title=뒤로 aria-label=뒤로>
<svg class="h-4 w-4" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path d="m12 19-7-7 7-7"/><path d="M19 12H5"/></svg>
<span class="hidden sm:inline">뒤로</span></button><div class="bg-border xs:mx-1 mx-2 h-6 w-px sm:mx-2"></div><button id=dock-toc class="text-muted-foreground hover:text-primary hover:bg-primary/10 focus:ring-primary/20 xs:px-2 xs:py-1.5 flex flex-shrink-0 items-center gap-2 rounded-lg px-3 py-2 text-sm font-medium transition-all duration-300 ease-out hover:-translate-y-0.5 hover:scale-105 focus:ring-2 focus:outline-none sm:px-3 sm:py-2" title=목차 aria-label=목차>
<svg class="h-4 w-4" fill="none" stroke="currentColor" viewBox="0 0 24 24"><line x1="8" x2="21" y1="6" y2="6"/><line x1="8" x2="21" y1="12" y2="12"/><line x1="8" x2="21" y1="18" y2="18"/><line x1="3" x2="3.01" y1="6" y2="6"/><line x1="3" x2="3.01" y1="12" y2="12"/><line x1="3" x2="3.01" y1="18" y2="18"/></svg>
<span class="hidden sm:inline">목차</span></button><div class="bg-border xs:mx-1 mx-2 h-6 w-px sm:mx-2"></div><button id=dock-search class="text-muted-foreground hover:text-primary hover:bg-primary/10 focus:ring-primary/20 xs:px-3 xs:py-1.5 flex flex-shrink-0 items-center gap-2 rounded-lg px-4 py-2 text-sm font-medium transition-all duration-300 ease-out hover:-translate-y-0.5 hover:scale-105 focus:ring-2 focus:outline-none sm:px-4 sm:py-2" title=검색 aria-label=검색>
<svg class="h-4 w-4" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="m21 21-6-6m2-5A7 7 0 113 10a7 7 0 0114 0z"/></svg>
<span class="hidden md:inline">검색</span></button><div class="bg-border xs:mx-1 mx-2 h-6 w-px sm:mx-2"></div><button id=dock-top class="text-muted-foreground hover:text-primary hover:bg-primary/10 focus:ring-primary/20 xs:px-2 xs:py-1.5 flex flex-shrink-0 items-center gap-2 rounded-lg px-3 py-2 text-sm font-medium transition-all duration-300 ease-out hover:-translate-y-0.5 hover:scale-105 focus:ring-2 focus:outline-none sm:px-3 sm:py-2" title="맨 위로" aria-label="맨 위로">
<svg class="h-4 w-4" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path d="m18 15-6-6-6 6"/></svg>
<span class="hidden sm:inline">맨 위로</span></button></nav></div><div id=toc-overlay class="pointer-events-none fixed inset-0 z-40 bg-black/50 opacity-0 backdrop-blur-sm transition-all duration-300" role=dialog aria-modal=true aria-labelledby=toc-title></div><div id=toc-card class="pointer-events-none fixed inset-4 z-50 flex w-auto scale-95 items-center justify-center opacity-0 transition-all duration-300 sm:inset-auto sm:top-1/2 sm:left-1/2 sm:block sm:w-full sm:max-w-md sm:-translate-x-1/2 sm:-translate-y-1/2" role=dialog aria-modal=true aria-labelledby=toc-title><div class="bg-card border-border w-full max-w-sm overflow-hidden rounded-xl border shadow-xl sm:max-w-md"><div class="border-border bg-muted/30 flex items-center justify-between border-b p-4"><div class="flex items-center gap-3"><svg class="h-5 w-5" fill="none" stroke="currentColor" viewBox="0 0 24 24"><line x1="8" x2="21" y1="6" y2="6"/><line x1="8" x2="21" y1="12" y2="12"/><line x1="8" x2="21" y1="18" y2="18"/><line x1="3" x2="3.01" y1="6" y2="6"/><line x1="3" x2="3.01" y1="12" y2="12"/><line x1="3" x2="3.01" y1="18" y2="18"/></svg><h2 id=toc-title class="text-foreground text-lg font-semibold">목차</h2></div><button id=toc-close class="text-muted-foreground hover:text-primary hover:bg-primary/10 focus:ring-primary/20 rounded-lg p-2 transition-all duration-200 ease-out hover:-translate-y-0.5 hover:scale-105 focus:ring-2 focus:outline-none" title=닫기 aria-label=닫기>
<svg class="h-4 w-4" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M6 18 18 6M6 6l12 12"/></svg></button></div><div class="max-h-96 overflow-y-auto p-4"><nav id=toc-nav class=toc-scrollbar aria-label="글 목차"><div id=toc-content><nav id=TableOfContents><ul><li><ul><li><a href=#논문-분석->논문 분석: <strong>&ldquo;PQCache: Product Quantization-based KVCache for Long Context LLM Inference&rdquo;</strong></a><ul><li><a href=#1-강점-및-독창성><strong>1. 강점 및 독창성</strong></a></li><li><a href=#2-핵심-알고리즘-pqcache의-동작-과정><strong>2. 핵심 알고리즘: PQCache의 동작 과정</strong></a></li><li><a href=#3-한계점><strong>3. 한계점</strong></a></li><li><a href=#결론><strong>결론</strong></a></li></ul></li></ul></li></ul><ul><li><ul><li><a href=#pqcache-핵심-알고리즘-자세한-설명-및-예시>PQCache 핵심 알고리즘: 자세한 설명 및 예시</a><ul><li><a href=#1-pqcache의-핵심-아이디어><strong>1. PQCache의 핵심 아이디어</strong></a></li><li><a href=#2-전체-알고리즘-동작-과정><strong>2. 전체 알고리즘 동작 과정</strong></a></li><li><a href=#3-예시><strong>3. 예시</strong></a></li><li><a href=#4-요약><strong>4. 요약</strong></a></li></ul></li></ul></li></ul><ul><li><ul><li><a href=#pqcache-학습에-필요한-데이터셋과-학습-방법>PQCache 학습에 필요한 데이터셋과 학습 방법</a><ul><li><a href=#1-pqcache의-학습-목표><strong>1. PQCache의 학습 목표</strong></a></li><li><a href=#2-필요한-데이터셋><strong>2. 필요한 데이터셋</strong></a></li><li><a href=#3-학습-단계-및-방법><strong>3. 학습 단계 및 방법</strong></a></li><li><a href=#4-구체적인-학습-예시><strong>4. 구체적인 학습 예시</strong></a></li><li><a href=#5-요약><strong>5. 요약</strong></a></li></ul></li></ul></li></ul><ul><li><ul><li><a href=#pqcache-논문-결과-분석-및-다른-방법론과의-비교>PQCache 논문 결과 분석 및 다른 방법론과의 비교</a><ul><li><a href=#1-pqcache의-주요-결과><strong>1. PQCache의 주요 결과</strong></a></li><li><a href=#2-다른-방법론과의-비교><strong>2. 다른 방법론과의 비교</strong></a></li><li><a href=#3-pqcache가-뛰어난-이유><strong>3. PQCache가 뛰어난 이유</strong></a></li><li><a href=#4-결론><strong>4. 결론</strong></a></li></ul></li></ul></li></ul><ul><li><ul><li><a href=#pqcache-구현에-필요한-추가-작업-및-자원-계산><strong>PQCache 구현에 필요한 추가 작업 및 자원 계산</strong></a><ul><li><a href=#1-pqcache-구현-시-추가적인-작업><strong>1. PQCache 구현 시 추가적인 작업</strong></a></li><li><a href=#2-공수-및-컴퓨팅-자원-계산><strong>2. 공수 및 컴퓨팅 자원 계산</strong></a></li><li><a href=#3-요약><strong>3. 요약</strong></a></li></ul></li></ul></li></ul><ul><li><ul><li><a href=#논문의-입력-데이터-및-추론-과정><strong>논문의 입력 데이터 및 추론 과정</strong></a><ul><li><a href=#1-입력-데이터-예시><strong>1. 입력 데이터 예시</strong></a></li><li><a href=#2-추론-과정-단계별-설명><strong>2. 추론 과정: 단계별 설명</strong></a></li><li><a href=#3-모델-아키텍처-구성><strong>3. 모델 아키텍처 구성</strong></a></li><li><a href=#4-연산-및-메모리-요구량><strong>4. 연산 및 메모리 요구량</strong></a></li><li><a href=#5-요약-1><strong>5. 요약</strong></a></li></ul></li></ul></li></ul><ul><li><ul><li><a href=#논문의-한계-및-이를-극복하기-위한-연구-흐름><strong>논문의 한계 및 이를 극복하기 위한 연구 흐름</strong></a><ul><li><a href=#1-논문의-주요-한계><strong>1. 논문의 주요 한계</strong></a></li><li><a href=#2-한계를-극복하기-위한-연구-흐름><strong>2. 한계를 극복하기 위한 연구 흐름</strong></a></li><li><a href=#3-추가적인-혁신적-아이디어><strong>3. 추가적인 혁신적 아이디어</strong></a></li><li><a href=#4-요약-및-방향성><strong>4. 요약 및 방향성</strong></a></li></ul></li></ul></li></ul></nav></div></nav></div><div class="border-border bg-muted/20 border-t px-4 py-3"><div class="text-muted-foreground text-center text-xs"><span>제목을 클릭하면 해당 위치로 이동합니다</span></div></div></div></div><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.22/dist/katex.min.css integrity=sha384-5TcZemv2l/9On385z///+d7MSYlvIEw9FuZTIdZ14vJLqWphw7e7ZPuOiCHJcFCP crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.22/dist/katex.min.js integrity=sha384-cMkvdD8LoxVzGF/RPUKAcvmm49FQ0oxwDF3BGKtDXcEc+T1b2N+teh/OJfpU0jr6 crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.22/dist/contrib/auto-render.min.js integrity=sha384-hCXGrW6PitJEwbkoStFjeJxv+fSOOQKOPbJxSfM6G5sWZjAyWhXiTIIAmQqnlLlh crossorigin=anonymous></script><script>function initKaTeX(){if(typeof renderMathInElement=="undefined"){setTimeout(initKaTeX,100);return}var e=[{display:!0,left:"$$",right:"$$"},{display:!1,left:"$",right:"$"}];renderMathInElement(document.body,{delimiters:e,throwOnError:!1,errorColor:"#cc0000",fleqn:!1,leqno:!1,trust:!1})}document.readyState==="loading"?document.addEventListener("DOMContentLoaded",initKaTeX):initKaTeX()</script><div id=search-overlay class="pointer-events-none fixed inset-0 z-40 bg-black/50 opacity-0 transition-opacity duration-300"></div><div id=search-modal class="bg-card border-border pointer-events-none fixed top-1/2 left-1/2 z-50 max-h-[80vh] w-full max-w-2xl -translate-x-1/2 -translate-y-1/2 scale-95 transform overflow-hidden rounded-xl border opacity-0 shadow-xl transition-all duration-300"><div class="border-border flex items-center gap-3 border-b p-4"><div class="text-muted-foreground h-5 w-5 flex-shrink-0"><svg class="h-4 w-4" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="m21 21-6-6m2-5A7 7 0 113 10a7 7 0 0114 0z"/></svg></div><div class="relative flex-1"><button id=search-clear class="text-muted-foreground hover:text-foreground hover:bg-muted/50 pointer-events-none absolute top-1/2 left-0 z-10 h-5 w-5 -translate-y-1/2 rounded opacity-0 transition-all duration-200" title=지우기 aria-label=지우기>
<svg class="h-4 w-4" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M6 18 18 6M6 6l12 12"/></svg>
</button>
<input id=search-input type=text placeholder="게시글 검색..." class="text-foreground placeholder:text-muted-foreground w-full border-none bg-transparent pl-8 text-lg outline-none" autocomplete=off spellcheck=false></div><button id=search-close class="text-muted-foreground hover:text-foreground hover:bg-muted/50 flex h-6 w-6 items-center justify-center rounded-md p-0.5 transition-all duration-200" title=닫기 aria-label=닫기>
<svg class="h-4 w-4" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M6 18 18 6M6 6l12 12"/></svg></button></div><div id=search-results class="max-h-96 overflow-y-auto"><div id=search-empty class="flex flex-col items-center justify-center py-12 text-center"><div class="bg-muted/50 mb-4 flex h-16 w-16 items-center justify-center rounded-full"><svg class="h-6 w-6" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="m21 21-6-6m2-5A7 7 0 113 10a7 7 0 0114 0z"/></svg></div><h3 class="text-foreground mb-2 text-lg font-semibold">검색 시작</h3><p class="text-muted-foreground text-sm">검색어를 입력하세요</p></div><div id=search-loading class="flex hidden items-center justify-center py-8"><div class="mr-3 h-6 w-6 animate-spin rounded-full border-2 border-current border-t-transparent"></div><span class=text-muted-foreground>검색 중...</span></div><div id=search-no-results class="flex hidden flex-col items-center justify-center py-12 text-center"><div class="bg-muted/50 mb-4 flex h-16 w-16 items-center justify-center rounded-full"><svg class="h-6 w-6" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M4 6h16M4 12h16M4 18h7"/></svg></div><h3 class="text-foreground mb-2 text-lg font-semibold">검색 결과 없음</h3><p class="text-muted-foreground text-sm">다른 검색어로 시도해보세요</p></div><div id=search-results-list class=hidden><div id=search-stats class="text-muted-foreground border-border border-b px-4 py-3 text-sm" data-template="%d개의 결과 찾음"></div><div id=search-items class="divide-border divide-y"></div></div></div><div class="border-border bg-muted/20 border-t px-4 py-3"><div class="text-muted-foreground flex items-center justify-between text-xs"><div class="flex items-center gap-2 md:gap-4"><div class="flex items-center gap-1"><kbd class="bg-muted border-border rounded border px-1.5 py-0.5 text-xs">↑↓</kbd>
<span class="hidden sm:inline">이동</span></div><div class="flex items-center gap-1"><kbd class="bg-muted border-border rounded border px-1.5 py-0.5 text-xs">↵</kbd>
<span class="hidden sm:inline">선택</span></div><div class="flex items-center gap-1"><kbd class="bg-muted border-border rounded border px-1.5 py-0.5 text-xs">ESC</kbd>
<span class="hidden sm:inline">닫기</span></div></div><div class="search-hint-desktop flex items-center gap-1"><kbd class="bg-muted border-border rounded border px-1.5 py-0.5 text-xs">⌘K</kbd>
<span>단축키</span></div></div></div></div></body></html>