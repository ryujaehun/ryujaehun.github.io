<!doctype html><html lang=ko-kr data-theme=claude><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta http-equiv=X-UA-Compatible content="IE=edge"><title>DeepSeek-VL: Towards Real-World Vision-Language Understanding | Jaehun's Blog</title><meta name=description content="논문 링크
Q : 이 논문을 아주 자세하게 읽고 논문의 강점과 독창적인 지점을 설명해주고 핵심 알고리즘을 예시 입력을 들어서 전체적인 과정을 설명해줘 추가적으로 논문의 한계점에 대해서도 알려줘 논문의 강점과 독창적인 지점
DeepSeek-VL은 현실 세계의 비전-언어 ..."><meta name=keywords content="개발,프로그래밍,에세이"><meta name=author content><meta name=language content="ko"><meta name=robots content="index, follow"><link rel=canonical href=https://jaehun.me/ko/ko/posts/2025-02-09-paper-2403.05525v2/><link rel=icon type=image/svg+xml href=/favicon.svg><link rel=manifest href=/site.webmanifest><meta property="og:url" content="https://jaehun.me/ko/ko/posts/2025-02-09-paper-2403.05525v2/"><meta property="og:site_name" content="Jaehun's Blog"><meta property="og:title" content="DeepSeek-VL: Towards Real-World Vision-Language Understanding"><meta property="og:description" content="논문 링크
Q : 이 논문을 아주 자세하게 읽고 논문의 강점과 독창적인 지점을 설명해주고 핵심 알고리즘을 예시 입력을 들어서 전체적인 과정을 설명해줘 추가적으로 논문의 한계점에 대해서도 알려줘 논문의 강점과 독창적인 지점"><meta property="og:locale" content="ko_kr"><meta property="og:type" content="article"><meta property="article:section" content="ko"><meta property="article:published_time" content="2025-02-09T00:00:00+00:00"><meta property="article:modified_time" content="2025-02-09T00:00:00+00:00"><meta property="og:image" content="https://jaehun.me/images/og-default.avif"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://jaehun.me/images/og-default.avif"><meta name=twitter:title content="DeepSeek-VL: Towards Real-World Vision-Language Understanding"><meta name=twitter:description content="논문 링크
Q : 이 논문을 아주 자세하게 읽고 논문의 강점과 독창적인 지점을 설명해주고 핵심 알고리즘을 예시 입력을 들어서 전체적인 과정을 설명해줘 추가적으로 논문의 한계점에 대해서도 알려줘 논문의 강점과 독창적인 지점"><meta itemprop=name content="DeepSeek-VL: Towards Real-World Vision-Language Understanding"><meta itemprop=description content="논문 링크
Q : 이 논문을 아주 자세하게 읽고 논문의 강점과 독창적인 지점을 설명해주고 핵심 알고리즘을 예시 입력을 들어서 전체적인 과정을 설명해줘 추가적으로 논문의 한계점에 대해서도 알려줘 논문의 강점과 독창적인 지점"><meta itemprop=datePublished content="2025-02-09T00:00:00+00:00"><meta itemprop=dateModified content="2025-02-09T00:00:00+00:00"><meta itemprop=wordCount content="19855"><meta itemprop=image content="https://jaehun.me/images/og-default.avif"><meta itemprop=keywords content="Paper-Review,With-Gpt"><script>window.HUGO_SEARCH_CONFIG={searchIndexURL:'"/ko/index.json"'}</script><script>window.HUGO_GALLERY_CONFIG={justified_gallery:!1,lightbox:!1,justified:"{}",lightbox_options:"{}"}</script><link rel=stylesheet href=/css/compiled.min.9165cace5b80a5be5daad6ea96eb2abc20a18a3f41d7fed7f0335b689fdf7883.css integrity="sha256-kWXKzluApb5dqtbqlusqvCChij9B1/7X8DNbaJ/feIM=" crossorigin=anonymous><link rel=stylesheet href=/css/chroma.min.491df36221f739b5948a747a0351f100ee7ccaaf466d9f46288bf06de1d59123.css integrity="sha256-SR3zYiH3ObWUinR6A1HxAO58yq9GbZ9GKIvwbeHVkSM=" crossorigin=anonymous><script src=/js/main.ba969e49a7a874e6938fe689a7dcaa00cb64cb4d429c2cf98d09bde512a16c6d.js integrity="sha256-upaeSaeodOaTj+aJp9yqAMtky01CnCz5jQm95RKhbG0=" crossorigin=anonymous></script><script src=/js/gumshoe.polyfills.min.js></script><script src=/js/toc.70654aebf0b738a78ae2df95297cc10ebc6e590f3c942dd1325fa852f50038b2.js integrity="sha256-cGVK6/C3OKeK4t+VKXzBDrxuWQ88lC3RMl+oUvUAOLI=" crossorigin=anonymous defer></script><script src=/js/search.de3eba3540834efb8328121784bff4774e06362412ee41eee665f5b4f987f393.js integrity="sha256-3j66NUCDTvuDKBIXhL/0d04GNiQS7kHu5mX1tPmH85M=" crossorigin=anonymous defer></script><script src=/js/dock.e02f422517e001d9fb6bea1e9e8b0e89e9d2e486ad4641f275bb3e36ce2ae79f.js integrity="sha256-4C9CJRfgAdn7a+oenosOienS5IatRkHydbs+Ns4q558=" crossorigin=anonymous defer></script><script>(function(){const e=localStorage.getItem("theme")||"system",n=localStorage.getItem("colorScheme")||"claude";document.documentElement.setAttribute("data-theme",n);function t(){e==="dark"||e==="system"&&window.matchMedia("(prefers-color-scheme: dark)").matches?document.documentElement.classList.add("dark"):document.documentElement.classList.remove("dark")}t(),e==="system"&&window.matchMedia("(prefers-color-scheme: dark)").addEventListener("change",t)})()</script></head><body class="bg-background text-foreground min-h-screen antialiased"><div id=reading-progress-container class="reading-progress-container pointer-events-none fixed top-0 right-0 left-0 z-50 transition-opacity duration-300 ease-out" data-height=3 data-smooth-scroll=true data-hide-on-complete=false><div class="reading-progress-bg w-full"></div><div id=reading-progress-bar class="from-primary to-primary/80 reading-progress-bar
transition-all duration-150 ease-out
absolute top-0 left-0 w-0 bg-gradient-to-r"></div></div><script>(function(){"use strict";const t=document.getElementById("reading-progress-container"),o=document.getElementById("reading-progress-bar");if(!t||!o)return;const a={smoothScroll:t.dataset.smoothScroll==="true",hideOnComplete:t.dataset.hideOnComplete==="true"};let n=!0,l=null;function r(){const t=window.pageYOffset||document.documentElement.scrollTop,n=document.documentElement.scrollHeight,s=window.innerHeight,e=n-s;return e<=0?0:Math.min(Math.max(t/e*100,0),100)}function c(){const e=r();o.style.width=e+"%",a.hideOnComplete&&e>=99.5?n&&(t.style.opacity="0",n=!1):n||(t.style.opacity="1",n=!0)}let s=!1;function e(){s||(requestAnimationFrame(()=>{c(),s=!1}),s=!0)}function i(){window.addEventListener("scroll",e,{passive:!0}),window.addEventListener("resize",e,{passive:!0}),document.addEventListener("visibilitychange",()=>{document.hidden||e()}),e(),window.addEventListener("beforeunload",()=>{window.removeEventListener("scroll",e),window.removeEventListener("resize",e)})}document.readyState==="loading"?document.addEventListener("DOMContentLoaded",i):i()})()</script><header class="sticky top-0 z-50 mx-auto max-w-4xl px-4 py-6"><div class="border-border bg-card/80 flex items-center rounded-xl border px-6 py-4 shadow-sm backdrop-blur-sm"><div class="hidden w-full items-center md:flex"><div class="flex items-center"><a href=/ko/ class="flex h-10 w-10 items-center justify-center overflow-hidden rounded-full transition-transform duration-200 hover:scale-105" aria-label="Jaehun's Blog"><img src=/images/logo.svg alt="Jaehun's Blog" class="h-full w-full object-cover"></a></div><nav class="mx-8 flex flex-1 items-center justify-center"><div class="flex items-center space-x-1"><a href=/ko/ class="nav-link
text-muted-foreground hover:text-primary hover:bg-primary/10
focus:ring-primary/20 relative flex items-center gap-2 rounded-lg px-4 py-2 text-sm font-medium transition-all duration-300 ease-out hover:-translate-y-0.5 hover:scale-105 focus:ring-2 focus:outline-none"><svg class="h-5 w-5" fill="none" stroke="currentColor" viewBox="0 0 24 24" aria-label="nav.posts"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 20H5a2 2 0 01-2-2V6a2 2 0 012-2h10a2 2 0 012 2v1m2 13a2 2 0 01-2-2V7m2 13a2 2 0 002-2V9a2 2 0 00-2-2h-2m-4-3H9M7 16h6M7 8h6v4H7V8z"/></svg>
<span>게시글
</span></a><a href=/ko/categories/ class="nav-link
text-muted-foreground hover:text-primary hover:bg-primary/10
focus:ring-primary/20 relative flex items-center gap-2 rounded-lg px-4 py-2 text-sm font-medium transition-all duration-300 ease-out hover:-translate-y-0.5 hover:scale-105 focus:ring-2 focus:outline-none"><svg class="h-5 w-5" fill="none" stroke="currentColor" viewBox="0 0 24 24" aria-label="nav.categories"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 11H5m14 0a2 2 0 012 2v6a2 2 0 01-2 2H5a2 2 0 01-2-2v-6a2 2 0 012-2m14 0V9a2 2 0 00-2-2M5 11V9a2 2 0 012-2m0 0V5a2 2 0 012-2h6a2 2 0 012 2v2M7 7h10"/></svg>
<span>카테고리
</span></a><a href=/ko/tags/ class="nav-link
text-muted-foreground hover:text-primary hover:bg-primary/10
focus:ring-primary/20 relative flex items-center gap-2 rounded-lg px-4 py-2 text-sm font-medium transition-all duration-300 ease-out hover:-translate-y-0.5 hover:scale-105 focus:ring-2 focus:outline-none"><svg class="h-5 w-5" fill="none" stroke="currentColor" viewBox="0 0 24 24" aria-label="nav.tags"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M7 7h.01M7 3h5c.512.0 1.024.195 1.414.586l7 7a2 2 0 010 2.828l-7 7a2 2 0 01-2.828.0l-7-7A1.994 1.994.0 013 12V7a4 4 0 014-4z"/></svg>
<span>태그
</span></a><a href=/ko/ class="nav-link
text-muted-foreground hover:text-primary hover:bg-primary/10
focus:ring-primary/20 relative flex items-center gap-2 rounded-lg px-4 py-2 text-sm font-medium transition-all duration-300 ease-out hover:-translate-y-0.5 hover:scale-105 focus:ring-2 focus:outline-none"><svg class="h-5 w-5" fill="none" stroke="currentColor" viewBox="0 0 24 24" aria-label="nav.archives"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M5 8h14M5 8a2 2 0 110-4h14a2 2 0 110 4M5 8v10a2 2 0 002 2h10a2 2 0 002-2V8m-9 4h4"/></svg>
<span>아카이브</span></a></div></nav><div class="flex items-center space-x-2"><div class=relative><button id=language-toggle class="dropdown-toggle border-border bg-background text-muted-foreground hover:text-primary hover:bg-primary/10 focus:ring-primary/20 flex h-10 w-10 items-center justify-center rounded-lg border transition-all duration-300 ease-out hover:scale-105 focus:ring-2 focus:outline-none active:scale-95" data-dropdown-type=language aria-label="언어 변경" aria-expanded=false aria-haspopup=true>
<svg class="h-5 w-5 relative z-10" fill="none" stroke="currentColor" viewBox="0 0 24 24" aria-label="언어 변경"><path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="m5 8 6 6m-7 0 6-6 2-3M2 5h12M7 2h1m14 20-5-10-5 10m2-4h6"/></svg></button><div id=language-dropdown class="dropdown-menu border-border bg-popover/95 absolute top-12 right-0 z-[60] hidden w-40 rounded-lg border p-1 shadow-lg backdrop-blur-sm transition-all duration-200 ease-out" data-dropdown-type=language role=menu aria-labelledby=language-toggle><a href=/ko/ class="text-accent-foreground hover:bg-accent hover:text-accent-foreground focus:bg-accent focus:text-accent-foreground flex w-full items-center rounded-md px-4 py-2 text-sm transition-all duration-200 ease-out focus:outline-none" role=menuitem aria-current=true><span class=font-medium>한국어</span></a><a href=/en/ class="text-accent-foreground hover:bg-accent hover:text-accent-foreground focus:bg-accent focus:text-accent-foreground flex w-full items-center rounded-md px-4 py-2 text-sm transition-all duration-200 ease-out focus:outline-none" role=menuitem><span class=font-medium>English</span></a></div></div><div class=relative><button id=color-scheme-toggle class="dropdown-toggle border-border bg-background text-muted-foreground hover:text-primary hover:bg-primary/10 focus:ring-primary/20 flex h-10 w-10 items-center justify-center rounded-lg border transition-all duration-300 ease-out hover:scale-105 focus:ring-2 focus:outline-none active:scale-95" data-dropdown-type=color-scheme aria-label="테마 변경" aria-expanded=false aria-haspopup=true>
<svg class="h-5 w-5 relative z-10" fill="none" stroke="currentColor" viewBox="0 0 24 24" aria-label="테마 변경"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M7 21a4 4 0 01-4-4V5a2 2 0 012-2h4a2 2 0 012 2v12a4 4 0 01-4 4zM21 5a2 2 0 00-2-2h-4a2 2 0 00-2 2v6a2 2 0 002 2h4a2 2 0 002-2V5z"/></svg></button><div id=color-scheme-dropdown class="dropdown-menu border-border bg-popover/95 absolute top-12 right-0 z-[60] hidden w-44 rounded-lg border p-1 shadow-lg backdrop-blur-sm transition-all duration-200 ease-out" data-dropdown-type=color-scheme><button data-color-scheme=claude class="text-accent-foreground hover:bg-accent hover:text-accent-foreground focus:bg-accent focus:text-accent-foreground flex w-full items-center rounded-md px-4 py-2 text-sm transition-all duration-200 ease-out focus:outline-none"><span>Default</span></button><button data-color-scheme=default class="text-accent-foreground hover:bg-accent hover:text-accent-foreground focus:bg-accent focus:text-accent-foreground flex w-full items-center rounded-md px-4 py-2 text-sm transition-all duration-200 ease-out focus:outline-none"><span>White</span></button><button data-color-scheme=bumblebee class="text-accent-foreground hover:bg-accent hover:text-accent-foreground focus:bg-accent focus:text-accent-foreground flex w-full items-center rounded-md px-4 py-2 text-sm transition-all duration-200 ease-out focus:outline-none"><span>Bumblebee</span></button><button data-color-scheme=emerald class="text-accent-foreground hover:bg-accent hover:text-accent-foreground focus:bg-accent focus:text-accent-foreground flex w-full items-center rounded-md px-4 py-2 text-sm transition-all duration-200 ease-out focus:outline-none"><span>Emerald</span></button><button data-color-scheme=nord class="text-accent-foreground hover:bg-accent hover:text-accent-foreground focus:bg-accent focus:text-accent-foreground flex w-full items-center rounded-md px-4 py-2 text-sm transition-all duration-200 ease-out focus:outline-none"><span>Nord</span></button><button data-color-scheme=sunset class="text-accent-foreground hover:bg-accent hover:text-accent-foreground focus:bg-accent focus:text-accent-foreground flex w-full items-center rounded-md px-4 py-2 text-sm transition-all duration-200 ease-out focus:outline-none"><span>Sunset</span></button><button data-color-scheme=abyss class="text-accent-foreground hover:bg-accent hover:text-accent-foreground focus:bg-accent focus:text-accent-foreground flex w-full items-center rounded-md px-4 py-2 text-sm transition-all duration-200 ease-out focus:outline-none"><span>Abyss</span></button><button data-color-scheme=dracula class="text-accent-foreground hover:bg-accent hover:text-accent-foreground focus:bg-accent focus:text-accent-foreground flex w-full items-center rounded-md px-4 py-2 text-sm transition-all duration-200 ease-out focus:outline-none"><span>Dracula</span></button><button data-color-scheme=amethyst class="text-accent-foreground hover:bg-accent hover:text-accent-foreground focus:bg-accent focus:text-accent-foreground flex w-full items-center rounded-md px-4 py-2 text-sm transition-all duration-200 ease-out focus:outline-none"><span>Amethyst</span></button><button data-color-scheme=slate class="text-accent-foreground hover:bg-accent hover:text-accent-foreground focus:bg-accent focus:text-accent-foreground flex w-full items-center rounded-md px-4 py-2 text-sm transition-all duration-200 ease-out focus:outline-none"><span>Slate</span></button><button data-color-scheme=twitter class="text-accent-foreground hover:bg-accent hover:text-accent-foreground focus:bg-accent focus:text-accent-foreground flex w-full items-center rounded-md px-4 py-2 text-sm transition-all duration-200 ease-out focus:outline-none"><span>Twitter</span></button></div></div><div class=relative><button id=theme-toggle class="dropdown-toggle border-border bg-background text-muted-foreground hover:text-primary hover:bg-primary/10 focus:ring-primary/20 flex h-10 w-10 items-center justify-center rounded-lg border transition-all duration-300 ease-out hover:scale-105 focus:ring-2 focus:outline-none active:scale-95" data-dropdown-type=theme aria-label="테마 변경" aria-expanded=false aria-haspopup=true>
<svg class="h-5 w-5 sun-icon hidden relative z-10" fill="none" stroke="currentColor" viewBox="0 0 24 24" aria-label="라이트"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M12 3v1m0 16v1m9-9h-1M4 12H3m15.364 6.364-.707-.707M6.343 6.343l-.707-.707m12.728.0-.707.707M6.343 17.657l-.707.707M16 12a4 4 0 11-8 0 4 4 0 018 0z"/></svg>
<svg class="h-5 w-5 moon-icon hidden relative z-10" fill="none" stroke="currentColor" viewBox="0 0 24 24" aria-label="다크"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M20.354 15.354A9 9 0 018.646 3.646 9.003 9.003.0 0012 21a9.003 9.003.0 008.354-5.646z"/></svg>
<svg class="h-5 w-5 system-icon hidden relative z-10" fill="none" stroke="currentColor" viewBox="0 0 24 24" aria-label="시스템"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9.75 17 9 20l-1 1h8l-1-1-.75-3M3 13h18M5 17h14a2 2 0 002-2V5a2 2 0 00-2-2H5A2 2 0 003 5v10a2 2 0 002 2z"/></svg></button><div id=theme-dropdown class="dropdown-menu border-border bg-popover/95 absolute top-12 right-0 z-[60] hidden w-40 rounded-lg border p-1 shadow-lg backdrop-blur-sm transition-all duration-200 ease-out" data-dropdown-type=theme><button data-theme=light class="text-accent-foreground hover:bg-accent hover:text-accent-foreground focus:bg-accent focus:text-accent-foreground flex w-full items-center rounded-md px-4 py-2 text-sm transition-all duration-200 ease-out focus:outline-none">
<svg class="h-5 w-5 mr-3 h-4 w-4" fill="none" stroke="currentColor" viewBox="0 0 24 24" aria-label="라이트"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M12 3v1m0 16v1m9-9h-1M4 12H3m15.364 6.364-.707-.707M6.343 6.343l-.707-.707m12.728.0-.707.707M6.343 17.657l-.707.707M16 12a4 4 0 11-8 0 4 4 0 018 0z"/></svg><span>라이트</span></button><button data-theme=dark class="text-accent-foreground hover:bg-accent hover:text-accent-foreground focus:bg-accent focus:text-accent-foreground flex w-full items-center rounded-md px-4 py-2 text-sm transition-all duration-200 ease-out focus:outline-none">
<svg class="h-5 w-5 mr-3 h-4 w-4" fill="none" stroke="currentColor" viewBox="0 0 24 24" aria-label="다크"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M20.354 15.354A9 9 0 018.646 3.646 9.003 9.003.0 0012 21a9.003 9.003.0 008.354-5.646z"/></svg><span>다크</span></button><button data-theme=system class="text-accent-foreground hover:bg-accent hover:text-accent-foreground focus:bg-accent focus:text-accent-foreground flex w-full items-center rounded-md px-4 py-2 text-sm transition-all duration-200 ease-out focus:outline-none">
<svg class="h-5 w-5 mr-3 h-4 w-4" fill="none" stroke="currentColor" viewBox="0 0 24 24" aria-label="시스템"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9.75 17 9 20l-1 1h8l-1-1-.75-3M3 13h18M5 17h14a2 2 0 002-2V5a2 2 0 00-2-2H5A2 2 0 003 5v10a2 2 0 002 2z"/></svg><span>시스템</span></button></div></div></div></div><div class="flex w-full items-center justify-between md:hidden"><div class=relative><button id=mobile-menu-toggle class="dropdown-toggle border-border bg-background text-muted-foreground hover:bg-accent hover:text-foreground flex h-10 w-10 items-center justify-center rounded-lg border transition-colors duration-200" data-dropdown-type=mobile-menu aria-label=메뉴 aria-expanded=false aria-haspopup=true>
<svg class="h-5 w-5" fill="none" stroke="currentColor" viewBox="0 0 24 24" aria-label="메뉴"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M4 6h16M4 12h16M4 18h16"/></svg></button><div id=mobile-menu class="mobile-menu dropdown-menu border-border bg-popover/95 absolute top-12 left-0 z-[60] hidden w-80 max-w-[calc(100vw-2rem)] rounded-lg border p-1 shadow-lg backdrop-blur-sm transition-all duration-200 ease-out md:hidden" data-dropdown-type=mobile-menu role=menu aria-labelledby=mobile-menu-toggle><nav class="flex flex-col"><a href=/ko/ class="nav-link
text-muted-foreground hover:text-primary hover:bg-primary/10
focus:ring-primary/20 relative flex items-center gap-3 rounded-md px-4 py-3 text-sm font-medium transition-all duration-200 ease-out hover:translate-x-1 focus:ring-2 focus:outline-none" role=menuitem><svg class="h-5 w-5" fill="none" stroke="currentColor" viewBox="0 0 24 24" aria-label="nav.posts"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 20H5a2 2 0 01-2-2V6a2 2 0 012-2h10a2 2 0 012 2v1m2 13a2 2 0 01-2-2V7m2 13a2 2 0 002-2V9a2 2 0 00-2-2h-2m-4-3H9M7 16h6M7 8h6v4H7V8z"/></svg>
<span>게시글
</span></a><a href=/ko/categories/ class="nav-link
text-muted-foreground hover:text-primary hover:bg-primary/10
focus:ring-primary/20 relative flex items-center gap-3 rounded-md px-4 py-3 text-sm font-medium transition-all duration-200 ease-out hover:translate-x-1 focus:ring-2 focus:outline-none" role=menuitem><svg class="h-5 w-5" fill="none" stroke="currentColor" viewBox="0 0 24 24" aria-label="nav.categories"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 11H5m14 0a2 2 0 012 2v6a2 2 0 01-2 2H5a2 2 0 01-2-2v-6a2 2 0 012-2m14 0V9a2 2 0 00-2-2M5 11V9a2 2 0 012-2m0 0V5a2 2 0 012-2h6a2 2 0 012 2v2M7 7h10"/></svg>
<span>카테고리
</span></a><a href=/ko/tags/ class="nav-link
text-muted-foreground hover:text-primary hover:bg-primary/10
focus:ring-primary/20 relative flex items-center gap-3 rounded-md px-4 py-3 text-sm font-medium transition-all duration-200 ease-out hover:translate-x-1 focus:ring-2 focus:outline-none" role=menuitem><svg class="h-5 w-5" fill="none" stroke="currentColor" viewBox="0 0 24 24" aria-label="nav.tags"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M7 7h.01M7 3h5c.512.0 1.024.195 1.414.586l7 7a2 2 0 010 2.828l-7 7a2 2 0 01-2.828.0l-7-7A1.994 1.994.0 013 12V7a4 4 0 014-4z"/></svg>
<span>태그
</span></a><a href=/ko/ class="nav-link
text-muted-foreground hover:text-primary hover:bg-primary/10
focus:ring-primary/20 relative flex items-center gap-3 rounded-md px-4 py-3 text-sm font-medium transition-all duration-200 ease-out hover:translate-x-1 focus:ring-2 focus:outline-none" role=menuitem><svg class="h-5 w-5" fill="none" stroke="currentColor" viewBox="0 0 24 24" aria-label="nav.archives"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M5 8h14M5 8a2 2 0 110-4h14a2 2 0 110 4M5 8v10a2 2 0 002 2h10a2 2 0 002-2V8m-9 4h4"/></svg>
<span>아카이브</span></a></nav></div></div><div class="flex items-center space-x-2"><div class=relative><button id=language-toggle class="dropdown-toggle border-border bg-background text-muted-foreground hover:text-primary hover:bg-primary/10 focus:ring-primary/20 flex h-10 w-10 items-center justify-center rounded-lg border transition-all duration-300 ease-out hover:scale-105 focus:ring-2 focus:outline-none active:scale-95" data-dropdown-type=language aria-label="언어 변경" aria-expanded=false aria-haspopup=true>
<svg class="h-5 w-5 relative z-10" fill="none" stroke="currentColor" viewBox="0 0 24 24" aria-label="언어 변경"><path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="m5 8 6 6m-7 0 6-6 2-3M2 5h12M7 2h1m14 20-5-10-5 10m2-4h6"/></svg></button><div id=language-dropdown class="dropdown-menu border-border bg-popover/95 absolute top-12 right-0 z-[60] hidden w-40 rounded-lg border p-1 shadow-lg backdrop-blur-sm transition-all duration-200 ease-out" data-dropdown-type=language role=menu aria-labelledby=language-toggle><a href=/ko/ class="text-accent-foreground hover:bg-accent hover:text-accent-foreground focus:bg-accent focus:text-accent-foreground flex w-full items-center rounded-md px-4 py-2 text-sm transition-all duration-200 ease-out focus:outline-none" role=menuitem aria-current=true><span class=font-medium>한국어</span></a><a href=/en/ class="text-accent-foreground hover:bg-accent hover:text-accent-foreground focus:bg-accent focus:text-accent-foreground flex w-full items-center rounded-md px-4 py-2 text-sm transition-all duration-200 ease-out focus:outline-none" role=menuitem><span class=font-medium>English</span></a></div></div><div class=relative><button id=color-scheme-toggle class="dropdown-toggle border-border bg-background text-muted-foreground hover:text-primary hover:bg-primary/10 focus:ring-primary/20 flex h-10 w-10 items-center justify-center rounded-lg border transition-all duration-300 ease-out hover:scale-105 focus:ring-2 focus:outline-none active:scale-95" data-dropdown-type=color-scheme aria-label="테마 변경" aria-expanded=false aria-haspopup=true>
<svg class="h-5 w-5 relative z-10" fill="none" stroke="currentColor" viewBox="0 0 24 24" aria-label="테마 변경"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M7 21a4 4 0 01-4-4V5a2 2 0 012-2h4a2 2 0 012 2v12a4 4 0 01-4 4zM21 5a2 2 0 00-2-2h-4a2 2 0 00-2 2v6a2 2 0 002 2h4a2 2 0 002-2V5z"/></svg></button><div id=color-scheme-dropdown class="dropdown-menu border-border bg-popover/95 absolute top-12 right-0 z-[60] hidden w-44 rounded-lg border p-1 shadow-lg backdrop-blur-sm transition-all duration-200 ease-out" data-dropdown-type=color-scheme><button data-color-scheme=claude class="text-accent-foreground hover:bg-accent hover:text-accent-foreground focus:bg-accent focus:text-accent-foreground flex w-full items-center rounded-md px-4 py-2 text-sm transition-all duration-200 ease-out focus:outline-none"><span>Default</span></button><button data-color-scheme=default class="text-accent-foreground hover:bg-accent hover:text-accent-foreground focus:bg-accent focus:text-accent-foreground flex w-full items-center rounded-md px-4 py-2 text-sm transition-all duration-200 ease-out focus:outline-none"><span>White</span></button><button data-color-scheme=bumblebee class="text-accent-foreground hover:bg-accent hover:text-accent-foreground focus:bg-accent focus:text-accent-foreground flex w-full items-center rounded-md px-4 py-2 text-sm transition-all duration-200 ease-out focus:outline-none"><span>Bumblebee</span></button><button data-color-scheme=emerald class="text-accent-foreground hover:bg-accent hover:text-accent-foreground focus:bg-accent focus:text-accent-foreground flex w-full items-center rounded-md px-4 py-2 text-sm transition-all duration-200 ease-out focus:outline-none"><span>Emerald</span></button><button data-color-scheme=nord class="text-accent-foreground hover:bg-accent hover:text-accent-foreground focus:bg-accent focus:text-accent-foreground flex w-full items-center rounded-md px-4 py-2 text-sm transition-all duration-200 ease-out focus:outline-none"><span>Nord</span></button><button data-color-scheme=sunset class="text-accent-foreground hover:bg-accent hover:text-accent-foreground focus:bg-accent focus:text-accent-foreground flex w-full items-center rounded-md px-4 py-2 text-sm transition-all duration-200 ease-out focus:outline-none"><span>Sunset</span></button><button data-color-scheme=abyss class="text-accent-foreground hover:bg-accent hover:text-accent-foreground focus:bg-accent focus:text-accent-foreground flex w-full items-center rounded-md px-4 py-2 text-sm transition-all duration-200 ease-out focus:outline-none"><span>Abyss</span></button><button data-color-scheme=dracula class="text-accent-foreground hover:bg-accent hover:text-accent-foreground focus:bg-accent focus:text-accent-foreground flex w-full items-center rounded-md px-4 py-2 text-sm transition-all duration-200 ease-out focus:outline-none"><span>Dracula</span></button><button data-color-scheme=amethyst class="text-accent-foreground hover:bg-accent hover:text-accent-foreground focus:bg-accent focus:text-accent-foreground flex w-full items-center rounded-md px-4 py-2 text-sm transition-all duration-200 ease-out focus:outline-none"><span>Amethyst</span></button><button data-color-scheme=slate class="text-accent-foreground hover:bg-accent hover:text-accent-foreground focus:bg-accent focus:text-accent-foreground flex w-full items-center rounded-md px-4 py-2 text-sm transition-all duration-200 ease-out focus:outline-none"><span>Slate</span></button><button data-color-scheme=twitter class="text-accent-foreground hover:bg-accent hover:text-accent-foreground focus:bg-accent focus:text-accent-foreground flex w-full items-center rounded-md px-4 py-2 text-sm transition-all duration-200 ease-out focus:outline-none"><span>Twitter</span></button></div></div><div class=relative><button id=theme-toggle class="dropdown-toggle border-border bg-background text-muted-foreground hover:text-primary hover:bg-primary/10 focus:ring-primary/20 flex h-10 w-10 items-center justify-center rounded-lg border transition-all duration-300 ease-out hover:scale-105 focus:ring-2 focus:outline-none active:scale-95" data-dropdown-type=theme aria-label="테마 변경" aria-expanded=false aria-haspopup=true>
<svg class="h-5 w-5 sun-icon hidden relative z-10" fill="none" stroke="currentColor" viewBox="0 0 24 24" aria-label="라이트"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M12 3v1m0 16v1m9-9h-1M4 12H3m15.364 6.364-.707-.707M6.343 6.343l-.707-.707m12.728.0-.707.707M6.343 17.657l-.707.707M16 12a4 4 0 11-8 0 4 4 0 018 0z"/></svg>
<svg class="h-5 w-5 moon-icon hidden relative z-10" fill="none" stroke="currentColor" viewBox="0 0 24 24" aria-label="다크"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M20.354 15.354A9 9 0 018.646 3.646 9.003 9.003.0 0012 21a9.003 9.003.0 008.354-5.646z"/></svg>
<svg class="h-5 w-5 system-icon hidden relative z-10" fill="none" stroke="currentColor" viewBox="0 0 24 24" aria-label="시스템"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9.75 17 9 20l-1 1h8l-1-1-.75-3M3 13h18M5 17h14a2 2 0 002-2V5a2 2 0 00-2-2H5A2 2 0 003 5v10a2 2 0 002 2z"/></svg></button><div id=theme-dropdown class="dropdown-menu border-border bg-popover/95 absolute top-12 right-0 z-[60] hidden w-40 rounded-lg border p-1 shadow-lg backdrop-blur-sm transition-all duration-200 ease-out" data-dropdown-type=theme><button data-theme=light class="text-accent-foreground hover:bg-accent hover:text-accent-foreground focus:bg-accent focus:text-accent-foreground flex w-full items-center rounded-md px-4 py-2 text-sm transition-all duration-200 ease-out focus:outline-none">
<svg class="h-5 w-5 mr-3 h-4 w-4" fill="none" stroke="currentColor" viewBox="0 0 24 24" aria-label="라이트"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M12 3v1m0 16v1m9-9h-1M4 12H3m15.364 6.364-.707-.707M6.343 6.343l-.707-.707m12.728.0-.707.707M6.343 17.657l-.707.707M16 12a4 4 0 11-8 0 4 4 0 018 0z"/></svg><span>라이트</span></button><button data-theme=dark class="text-accent-foreground hover:bg-accent hover:text-accent-foreground focus:bg-accent focus:text-accent-foreground flex w-full items-center rounded-md px-4 py-2 text-sm transition-all duration-200 ease-out focus:outline-none">
<svg class="h-5 w-5 mr-3 h-4 w-4" fill="none" stroke="currentColor" viewBox="0 0 24 24" aria-label="다크"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M20.354 15.354A9 9 0 018.646 3.646 9.003 9.003.0 0012 21a9.003 9.003.0 008.354-5.646z"/></svg><span>다크</span></button><button data-theme=system class="text-accent-foreground hover:bg-accent hover:text-accent-foreground focus:bg-accent focus:text-accent-foreground flex w-full items-center rounded-md px-4 py-2 text-sm transition-all duration-200 ease-out focus:outline-none">
<svg class="h-5 w-5 mr-3 h-4 w-4" fill="none" stroke="currentColor" viewBox="0 0 24 24" aria-label="시스템"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9.75 17 9 20l-1 1h8l-1-1-.75-3M3 13h18M5 17h14a2 2 0 002-2V5a2 2 0 00-2-2H5A2 2 0 003 5v10a2 2 0 002 2z"/></svg><span>시스템</span></button></div></div></div></div></div></header><main class="mx-auto max-w-4xl px-4 py-6"><nav class="breadcrumb mb-4 md:mb-6 py-1" aria-label=경로><ol class="text-muted-foreground flex items-center space-x-1 md:space-x-2 text-sm overflow-x-auto whitespace-nowrap scrollbar-hide py-1"><li class=flex-shrink-0><a href=/ko/ class="text-muted-foreground hover:text-primary hover:bg-primary/10 flex items-center gap-0.5 md:gap-1 rounded-lg px-1 md:px-3 py-0.5 md:py-1.5 transition-all duration-200 ease-out hover:-translate-y-0.5 hover:scale-[1.02]"><svg class="h-4 w-4" fill="none" stroke="currentColor" viewBox="0 0 24 24" aria-label="홈"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="m3 12 2-2m0 0 7-7 7 7M5 10v10a1 1 0 001 1h3m10-11 2 2m-2-2v10a1 1 0 01-1 1h-3m-6 0a1 1 0 001-1v-4a1 1 0 011-1h2a1 1 0 011 1v4a1 1 0 001 1m-6 0h6"/></svg>
<span class="max-w-[4rem] md:max-w-none truncate">홈</span></a></li><li class="flex items-center gap-1 md:gap-2 min-w-0"><span class="text-muted-foreground/50 flex-shrink-0"><svg class="h-4 w-4" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 5l7 7-7 7"/></svg></span><div class="flex items-center gap-1 md:gap-2 min-w-0"><a href=/ko class="text-muted-foreground hover:text-primary hover:bg-primary/10 flex items-center gap-0.5 md:gap-1 rounded-lg px-1 md:px-3 py-0.5 md:py-1.5 transition-all duration-200 ease-out hover:-translate-y-0.5 hover:scale-[1.02] flex-shrink-0"><svg class="h-4 w-4" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M3 7v10a2 2 0 002 2h14a2 2 0 002-2V9a2 2 0 00-2-2h-6l-2-2H5A2 2 0 003 7z"/></svg>
<span class="max-w-[4rem] md:max-w-none truncate">Ko</span>
</a><span class="text-muted-foreground/50 flex-shrink-0"><svg class="h-4 w-4" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 5l7 7-7 7"/></svg></span>
<span class="text-foreground flex items-center gap-0.5 md:gap-1 font-medium min-w-0"><svg class="h-4 w-4" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 12h6m-6 4h6m2 5H7a2 2 0 01-2-2V5a2 2 0 012-2h5.586a1 1 0 01.707.293l5.414 5.414a1 1 0 01.293.707V19a2 2 0 01-2 2z"/></svg>
<span class="max-w-[8rem] md:max-w-[16rem] lg:max-w-none truncate">DeepSeek-VL: Towards Real-World Vision-Language Understanding</span></span></div></li></ol></nav><header class=mb-8><h1 class="text-foreground mb-4 text-3xl font-bold md:text-4xl">DeepSeek-VL: Towards Real-World Vision-Language Understanding</h1></header><article class="prose prose-neutral dark:prose-invert max-w-none"><p><a href=https://arxiv.org/abs/2403.05525v2>논문 링크</a></p><h1 id=q--이-논문을-아주-자세하게-읽고-논문의-강점과-독창적인-지점을-설명해주고-핵심-알고리즘을-예시-입력을-들어서-전체적인-과정을-설명해줘-추가적으로-논문의-한계점에-대해서도-알려줘>Q : 이 논문을 아주 자세하게 읽고 논문의 강점과 독창적인 지점을 설명해주고 핵심 알고리즘을 예시 입력을 들어서 전체적인 과정을 설명해줘 추가적으로 논문의 한계점에 대해서도 알려줘</h1><p>논문의 강점과 독창적인 지점</p><p>DeepSeek-VL은 현실 세계의 비전-언어 이해를 목표로 한 오픈 소스 멀티모달 모델로, 1.3B와 7B 크기의 모델을 제공합니다. 이 모델의 강점과 독창성은 다음과 같습니다:
1. 현실적인 데이터 구성:
• 웹 스크린샷, PDF, OCR 데이터, 차트, 전문가 지식 및 교과서 등을 포함한 광범위한 데이터를 사용하여 실제 응용 시나리오를 포괄합니다.
• GPT-4V와 Gemini의 테스트 케이스를 기반으로 현실적인 사용 사례를 분류하고 이에 맞는 지침 튜닝 데이터셋을 구성하여 실제 응용에서의 사용자 경험을 크게 향상시켰습니다.
2. 효율적인 모델 아키텍처:
• 하이브리드 비전 인코더를 도입하여 고해상도 이미지(1024×1024)를 고정된 토큰 예산 내에서 효율적으로 처리합니다.
• SigLIP-L(384×384 해상도)과 SAM-B 기반 ViTDet 인코더(1024×1024 해상도)를 결합하여 세밀한 정보와 고수준 의미 정보를 모두 포착합니다.
3. 혁신적인 훈련 전략:
• 언어 우선 전략: 모델의 언어 능력 저하를 방지하기 위해 훈련 초기에는 언어 데이터 비율을 높게(70% 이상) 유지하고, 점진적으로 비전-언어 데이터를 추가하는 모달리티 워밍업 전략을 도입했습니다.
• 단계적 훈련 프로세스:
• 1단계: 비전-언어 어댑터 학습 (비전 인코더와 LLM 고정)
• 2단계: 비전-언어 공동 사전 훈련 (LLM과 어댑터 동시 학습)
• 3단계: 지도 학습 (명시적인 지침 튜닝)</p><p>핵심 알고리즘 및 전체 과정 설명 (예제 입력 포함)</p><p>DeepSeek-VL의 핵심 알고리즘 흐름은 다음과 같습니다:
1. 하이브리드 비전 인코더:
• 입력 이미지(1024×1024)는 SAM-B 인코더를 통해 저수준 특징(64×64×256 피쳐맵)으로 변환됩니다.
• 동시에, 동일 이미지는 SigLIP-L 인코더로 384×384 해상도의 고수준 의미 정보로 처리됩니다.
2. 비전-언어 어댑터:
• SAM-B 인코더의 출력은 두 개의 합성곱 층을 통해 크기 24×24×1024로 축소되고, 576×1024 크기의 토큰으로 변환됩니다.
• SigLIP-L 인코더의 출력과 결합하여 최종적으로 576개의 시각 토큰(2048 차원)을 생성합니다.
• 이 토큰들은 GeLU 활성화 함수를 통해 활성화된 후, 임베딩 레이어를 거쳐 LLM으로 전달됩니다.
3. 훈련 전략:
• 초기에는 언어 데이터만을 사용하여 LLM의 언어 능력을 유지합니다.
• 이후 70:30 비율로 언어:비전-언어 데이터를 혼합하여 멀티모달 능력을 균형 있게 개발합니다.</p><p>예제 입력:
• 입력 이미지: 복잡한 차트(예: 주식 시장 그래프)
• 질문: “이 차트의 주요 트렌드를 설명해줘.”</p><p>처리 과정:
1. 하이브리드 인코더가 차트를 처리하여 저수준의 시각적 디테일(숫자, 축 레이블)과 고수준의 의미 정보(패턴, 트렌드)를 추출.
2. 비전-언어 어댑터가 이 정보를 576개의 시각 토큰으로 변환하여 LLM에 전달.
3. LLM은 이 시각적 정보를 바탕으로 언어적 설명을 생성: “이 차트는 상승세를 보이며, 특히 2023년 3분기에 급격한 증가가 있습니다.”</p><p>논문의 한계점
1. 수학적 및 논리적 추론의 한계:
• 수학적 문제 해결 능력에서는 GPT-4V 같은 독점 모델에 비해 여전히 성능이 낮습니다. (예: MathVista에서 GPT-4V의 47.8점에 비해 36.1점)
2. 모델 크기와 계산 자원:
• 7B 모델도 GPT-4V 등 대규모 모델에 비해 성능이 낮으며, Mixture of Experts (MoE) 기술을 활용한 대규모 모델 확장이 필요하다는 점을 언급합니다.
3. 언어 능력 저하 위험:
• 모달리티 간 경쟁으로 인해 장기적인 훈련 시 언어 능력이 저하될 수 있으며, 이를 모달리티 워밍업 전략으로 해결하려 하지만 완전한 해결은 아닌 것으로 보입니다.</p><p>종합적으로, DeepSeek-VL은 오픈 소스 멀티모달 모델로서 현실적 데이터 구성, 효율적인 아키텍처, 혁신적인 훈련 전략 등을 통해 강력한 비전-언어 통합 능력을 보여줍니다. 그러나 수학적 논리력과 모델 확장성 면에서 추가적인 발전 가능성이 존재합니다.</p><h1 id=q--논문의-핵심알고리즘을-예시를-들어-아주-자세하게-설명해주고-정리해-줘>Q : 논문의 핵심알고리즘을 예시를 들어 아주 자세하게 설명해주고 정리해 줘</h1><p>DeepSeek-VL 핵심 알고리즘: 단계별 상세 설명</p><p>DeepSeek-VL은 하이브리드 비전 인코더, 비전-언어 어댑터, 그리고 **대형 언어 모델(LLM)**을 통합하여 고해상도 이미지와 텍스트를 동시에 처리하는 멀티모달 모델입니다. 이 과정은 크게 세 단계로 나눌 수 있습니다:
1. 하이브리드 비전 인코딩
2. 비전-언어 어댑터 처리
3. 대형 언어 모델(LLM) 처리 및 출력 생성</p><ol><li>하이브리드 비전 인코딩</li></ol><p>목적: 고해상도 이미지에서 저수준의 세부 정보와 고수준의 의미 정보를 동시에 추출.</p><p>구성 요소:
• SAM-B 인코더 (고해상도 처리):
• 입력: 1024×1024 해상도의 이미지
• 출력: 64×64×256 크기의 저수준 피처맵 (디테일한 시각 정보)
• SigLIP-L 인코더 (저해상도 의미 처리):
• 입력: 384×384 해상도의 이미지
• 출력: 576×1024 크기의 고수준 의미 정보 피처</p><p>예제:
• 입력 이미지: 복잡한 금융 차트 (예: 주식 시장 그래프)</p><p>처리 과정:
1. SAM-B 인코더는 작은 텍스트, 숫자, 그래프의 미세한 디테일(예: 축의 눈금, 레이블)을 인식합니다.
2. SigLIP-L 인코더는 전체적인 패턴(예: 상승/하락 트렌드, 급격한 변화)을 파악합니다.</p><ol start=2><li>비전-언어 어댑터 처리</li></ol><p>목적: 인코더에서 추출된 시각적 피처를 언어 모델이 이해할 수 있는 형식의 토큰으로 변환.</p><p>처리 과정:
1. SAM-B 인코더의 고해상도 피처맵(64×64×256)은 두 개의 합성곱 층을 거쳐 24×24×1024로 축소됨.
2. 이 피처맵은 다시 펼쳐져서 576×1024 크기의 시각 토큰으로 변환.
3. SigLIP-L 인코더의 저해상도 피처와 결합하여 최종적으로 576개의 시각 토큰(2048 차원)을 생성.
4. GeLU 활성화 함수를 거쳐 임베딩 레이어로 전달, LLM 입력에 맞게 변환.</p><p>예제:
• 결합된 시각 토큰은 그래프의 상승/하락 추세뿐 아니라 세부적인 수치(가격, 날짜)를 포함한 복합적인 시각 정보를 LLM에 제공합니다.</p><ol start=3><li>대형 언어 모델(LLM) 처리 및 출력 생성</li></ol><p>목적: 시각 토큰과 텍스트 입력을 기반으로 자연어로 해석된 응답을 생성.</p><p>구성 요소:
• DeepSeek-LLM을 기반으로 한 언어 모델:
• Pre-Norm 구조, Rotary Embedding, SwiGLU 활성화 함수를 사용.
• 70% 이상의 언어 데이터를 사용하여 언어 능력을 유지.</p><p>처리 과정:
1. LLM은 시각 토큰을 텍스트 정보와 결합하여 의미론적 분석을 수행.
2. 이 분석을 통해 논리적인 문장을 생성하거나, 질문에 대한 답변을 제공.</p><p>종합 예제: 주식 차트 분석
1. 입력:
• 이미지: 주식 시장의 변동 그래프 (예: 2023년 1월~12월)
• 질문: “2023년 3분기에 어떤 트렌드가 보이나요?”
2. 하이브리드 인코딩:
• SAM-B 인코더: 그래프의 세부 수치(가격, 날짜)를 추출.
• SigLIP-L 인코더: 3분기 동안의 상승세 패턴을 포착.
3. 비전-언어 어댑터:
• 고해상도 디테일과 패턴 정보를 576개의 시각 토큰으로 변환.
4. LLM 처리:
• 시각 토큰과 질문을 결합하여 분석 수행.
• 출력: “2023년 3분기에 주가는 지속적인 상승세를 보였으며, 특히 9월 중순에 최고치를 기록했습니다.”</p><p>DeepSeek-VL의 알고리즘 차별점</p><p>요소 DeepSeek-VL 접근 방식 기존 멀티모달 모델 (예: CLIP, LLaVA 등)
인코더 해상도 1024×1024 (SAM-B) + 384×384 (SigLIP-L) 대부분 224×224 ~ 512×512
토큰 처리 방식 하이브리드 인코딩으로 576개 토큰 생성 단일 인코더로 의미 중심 토큰 생성
언어 데이터 비율 초기 70% 언어, 30% 비전-언어 대부분 비전-언어 중심 데이터 사용
모달리티 워밍업 전략 언어 유지 후 점진적 비전-언어 통합 초기부터 비전-언어 데이터를 혼합
성능 (SeedBench) 70.4 (GPT-4V: 71.6) LLaVA (68.2), CogVLM (68.8)</p><p>결론</p><p>DeepSeek-VL의 핵심 알고리즘은 고해상도 이미지 처리와 언어 능력 유지에 중점을 두어, 현실 세계의 다양한 비전-언어 과제를 효과적으로 해결합니다. 이 모델은 모달리티 워밍업 전략과 하이브리드 인코딩 방식을 통해, 기존 오픈 소스 모델 대비 우수한 멀티모달 이해 능력을 입증했습니다.</p><h1 id=q--이-논문에서-사용하는-방법을-학습하기-위하여-어떤-데이터셋이-필요할까-그리고-어떻게-학습을-진행하면-될지-예시를-들어서-아주-자세하게-설명해줘>Q : 이 논문에서 사용하는 방법을 학습하기 위하여 어떤 데이터셋이 필요할까? 그리고 어떻게 학습을 진행하면 될지 예시를 들어서 아주 자세하게 설명해줘</h1><p>DeepSeek-VL 학습을 위한 데이터셋 구성 및 학습 방법</p><p>DeepSeek-VL의 학습을 위해서는 다양한 비전-언어 데이터셋과 언어 데이터셋이 필요합니다. 이 모델은 **사전 훈련(pretraining)**과 **지도 학습(supervised fine-tuning)**을 통해 멀티모달 능력을 개발하며, 이 두 과정에 필요한 데이터셋 종류와 학습 전략이 구체적으로 정의되어 있습니다.</p><ol><li>필요한 데이터셋 구성</li></ol><p>DeepSeek-VL은 두 가지 주요 데이터셋 유형을 사용합니다:
1. 비전-언어 사전 학습 데이터 (Vision-Language Pretraining Data)
2. 비전-언어 지도 학습 데이터 (Vision-Language Supervised Fine-Tuning Data)</p><p>1.1. 비전-언어 사전 학습 데이터</p><p>사전 학습 데이터는 모델의 기본적인 멀티모달 이해 능력을 개발하는 데 사용됩니다. 이 데이터는 다양한 시각-텍스트 페어를 포함하며, 주로 다음과 같은 범주로 나눌 수 있습니다:</p><p>데이터 유형 데이터셋 예시 비율
이미지-텍스트 인터리브 MMC4, Wikipedia, Wikihow, Epub Textbooks 13.1%
이미지 캡션 데이터 Capsfusion, TaiSu, Detailed Caption 11.1%
표 및 차트 데이터 Chart2text, Geo170K, Unichart, ScienceQA, ScreenQA 등 2.1%
웹 코드 데이터 Websight, GitHub Jupyter Notebook에서 추출한 시각-코드 페어 0.4%
OCR 데이터 ArT, MLT-17, LSVT, TextOCR, arXiv OCR 데이터 2.1%
텍스트 전용 데이터 DeepSeek-LLM 2T 텍스트 코퍼스 70%</p><p>특징:
• 인터리브 이미지-텍스트 데이터는 모델이 자연스러운 시각-언어 문맥을 이해하도록 도와줍니다.
• 차트 및 표 데이터는 모델의 데이터 시각화 이해 능력을 강화합니다.
• 웹 코드 데이터는 코드와 시각적 UI 요소 간의 관계를 학습하는 데 사용됩니다.
• 텍스트 전용 데이터는 모델의 언어 능력 보존에 필수적입니다.</p><p>1.2. 비전-언어 지도 학습 데이터</p><p>지도 학습 데이터는 사전 학습된 모델에 특정한 태스크 수행 능력을 부여하기 위해 사용됩니다.</p><p>데이터 유형 데이터셋 예시 비율
멀티모달 지침 데이터 ShareGPT4V, LAION-GPTV, LVIS-Instruct4V, textOCR-GPT4V 35.5%
표 및 차트 데이터 Ureader, Geo170K, ScienceQA 4.1%
웹 코드 데이터 Screen-to-code, ScreenQA 2.0%
텍스트 전용 지도 학습 DeepSeek-LLM 지도 학습 데이터 47.9%
인하우스 데이터 (사용자 시나리오 기반) GPT-4V와 Gemini에서 수집한 실제 사용 사례 기반 데이터 10.5%</p><p>특징:
• 멀티모달 지침 데이터는 모델이 복잡한 질문과 명령을 이해하고 수행하도록 도와줍니다.
• 표/차트 및 웹 코드 데이터는 특정 전문 분야(예: 과학, 프로그래밍)에서의 태스크 수행 능력을 강화합니다.
• 인하우스 데이터는 실제 사용 사례에 맞게 설계되어 현실적 성능을 최적화합니다.</p><ol start=2><li>학습 진행 방법</li></ol><p>DeepSeek-VL은 3단계 학습 프로세스를 통해 모델을 개발합니다.</p><p>2.1. 1단계: 비전-언어 어댑터 학습 (Vision-Language Adaptor Training)
• 목적: 시각적 특징과 언어적 표현을 연결하는 어댑터를 학습.
• 사용 데이터:
• 125만 개의 이미지-텍스트 페어 (ShareGPT4V)
• 250만 개의 문서 OCR 데이터
• 방법:
• 비전 인코더와 LLM을 고정(frozen)하고, **어댑터(2-layer MLP)**만 학습.
• 입력된 이미지의 시각적 특징을 언어 임베딩 공간으로 매핑하는 과정을 학습.</p><p>예제:
• 입력: 이미지(웹 페이지 스크린샷), 텍스트(“이 페이지에서 보이는 가장 중요한 정보는?”)
• 출력: “이 페이지의 핵심은 로그인 버튼과 주요 메뉴입니다.”</p><p>2.2. 2단계: 비전-언어 공동 사전 학습 (Joint Vision-Language Pretraining)
• 목적: 모델의 기본적인 멀티모달 이해 능력을 개발.
• 사용 데이터:
• 비전-언어 데이터(30%)와 텍스트 전용 데이터(70%)를 혼합하여 학습.
• 훈련 전략:
• 모달리티 워밍업 전략:
• 초기에는 언어 데이터 비율을 높게 유지하여 LLM의 언어 능력을 보존.
• 점진적으로 비전-언어 데이터의 비율을 증가시켜 멀티모달 능력을 개발.</p><p>예제:
• 입력: 주식 시장 차트, 텍스트(“2023년 3분기의 주가 변동을 설명해줘.”)
• 출력: “2023년 3분기에 주가는 지속적인 상승세를 보였으며, 9월 중순에 최고치를 기록했습니다.”</p><p>2.3. 3단계: 지도 학습 (Supervised Fine-Tuning)
• 목적: 모델이 특정 태스크(예: 질문 답변, 지침 수행)에 최적화되도록 학습.
• 사용 데이터:
• ShareGPT4V, LAION-GPTV 등에서 수집한 멀티모달 지침 데이터.
• DeepSeek-LLM의 텍스트 지도 학습 데이터로 언어 능력을 강화.
• 훈련 전략:
• 멀티모달 대화 데이터와 순수 텍스트 대화 데이터를 결합하여 모델의 대화 능력 강화.
• SAM-B 인코더는 GPU 메모리 제약으로 인해 고정하고, 나머지 구성 요소를 학습.</p><p>예제:
• 입력: 코드 스크린샷, 질문(“이 코드의 버그를 찾아줘.”)
• 출력: “이 코드에서는 변수 max_value가 잘못 초기화되었습니다. sequence[1] 대신 sequence[0]을 사용해야 합니다.”</p><ol start=3><li><p>실전 적용 시 고려사항
• 데이터 다양성: 다양한 데이터 소스를 수집하여 현실적인 멀티모달 시나리오를 반영하는 것이 중요합니다.
• 언어-비전 균형: 언어 능력을 유지하기 위해 충분한 언어 데이터를 포함하는 것이 필수적입니다.
• 모달리티 워밍업 전략 적용: 초기에는 언어 데이터 중심으로 시작하여 점진적으로 비전-언어 데이터 비율을 높이는 것이 효과적입니다.</p></li><li><p>종합 요약</p></li></ol><p>단계 목적 사용 데이터셋 특징
1단계: 어댑터 학습 시각-언어 연결성 강화 ShareGPT4V, OCR 데이터 비전 인코더와 LLM 고정, 어댑터만 학습
2단계: 사전 학습 멀티모달 이해 능력 개발 인터리브 이미지-텍스트, 캡션 데이터, LLM 텍스트 70:30 비율로 언어 능력 유지
3단계: 지도 학습 태스크 수행 능력 최적화 멀티모달 지침 데이터, 표/차트, 코드 데이터 대화형 지침 수행 최적화</p><p>이 과정을 통해 DeepSeek-VL은 다양한 멀티모달 태스크에서 뛰어난 성능을 발휘하게 됩니다.</p><h1 id=q--이-논문에서-제시한-결과를-자세하게-보고-다른-방법론에-비하여-특출난-점과-논문에서-제기하는-어떠한-방법이-이러한-결과를-도출하게-되었는지-논문에서-제시하는-이유와-너의-생각을-알려줘>Q : 이 논문에서 제시한 결과를 자세하게 보고 다른 방법론에 비하여 특출난 점과 논문에서 제기하는 어떠한 방법이 이러한 결과를 도출하게 되었는지 논문에서 제시하는 이유와 너의 생각을 알려줘</h1><ol><li>DeepSeek-VL의 성능 결과 및 특출난 점</li></ol><p>DeepSeek-VL은 다양한 공개 멀티모달 벤치마크와 언어 중심 벤치마크에서 우수한 성능을 보여줍니다. 7B 모델과 1.3B 모델 모두 경쟁 모델 대비 강력한 멀티모달 처리 능력을 입증했습니다.</p><p>1.1. 멀티모달 벤치마크 성능 비교</p><p>모델 MMB MMC SEEDBench MathVista MMVet
GPT-4V (독점 모델) 75.0 74.7 71.6 47.8 49.9
DeepSeek-VL (7B) 73.2 72.8 70.4 36.1 41.5
CogVLM (7B) 63.7 53.8 68.8 34.7 54.5
LLaVA-Next (13B) 70.0 64.4 71.9 35.3 48.4
Yi-VL (6B) 68.2 68.9 67.6 28.0 31.1</p><p>특출난 점:
1. 멀티모달 이해 능력: DeepSeek-VL(7B)은 MMB, MMC, SEEDBench에서 대부분의 오픈 소스 모델을 압도하며, GPT-4V와도 근소한 차이(71.6 vs. 70.4)를 보입니다.
2. 고해상도 이미지 처리: 기존 모델 대비 **고해상도 이미지(1024×1024)**를 효과적으로 처리하여, 차트 해석, OCR 등 시각 중심 태스크에서 우수한 성능을 보여줍니다.</p><p>1.2. 언어 중심 벤치마크 성능 비교</p><p>모델 MMLU HellaSwag GSM8K (수학) MBPP (코드)
DeepSeek-LLM (7B) 49.4 68.5 63.0 35.2
DeepSeek-VL (7B) 52.4 68.4 55.0 35.2
CogVLM (7B) 47.3 - 34.7 -</p><p>특출난 점:
1. 언어 능력 유지: 멀티모달 모델임에도 불구하고 MMLU에서 오히려 DeepSeek-LLM보다 높은 점수(52.4 vs. 49.4)를 기록, 이는 언어와 비전의 균형 잡힌 학습 전략 덕분입니다.
2. 수학 성능 한계: GSM8K(수학)에서는 언어 모델 대비 약간의 성능 저하가 발생, 이는 멀티모달 학습이 일부 복잡한 논리적 추론에 영향을 줄 수 있음을 시사합니다.</p><ol start=2><li>이러한 결과를 도출한 방법론적 차별성</li></ol><p>DeepSeek-VL의 탁월한 성능은 다음과 같은 혁신적인 방법론 덕분입니다:</p><p>2.1. 하이브리드 비전 인코더 (Hybrid Vision Encoder)
• 기존 모델 한계:
• 대부분의 오픈 소스 멀티모달 모델(예: LLaVA, CogVLM)은 저해상도 입력(224×224 ~ 512×512)을 사용하여 복잡한 시각적 정보를 충분히 포착하지 못함.
• DeepSeek-VL의 접근:
• SAM-B 인코더(1024×1024 고해상도)와 SigLIP-L 인코더(384×384)를 결합한 하이브리드 인코더로 저수준 디테일과 고수준 의미 정보를 모두 캡처.
• 이로 인해 차트 해석, OCR, 과학적 시각 정보 처리 능력이 대폭 향상됨.</p><p>논문 설명:
“By fusing high-resolution SAM-B and low-resolution SigLIP-L encoders, DeepSeek-VL efficiently captures both semantic and detailed visual information, achieving superior performance in complex visual tasks.”</p><p>나의 해석:
기존 모델은 시각적 의미 정보에만 집중했지만, DeepSeek-VL은 세부적인 시각 정보를 정확하게 추출하여 복잡한 이미지 태스크(예: 데이터 시각화 해석)에서 압도적인 성능을 보입니다.</p><p>2.2. 모달리티 워밍업 전략 (Modality Warm-up Strategy)
• 기존 모델 한계:
• 비전-언어 데이터를 지나치게 강조하면 모델의 언어 능력 저하 문제가 발생.
• 멀티모달 학습 중 언어 능력 감소(catastrophic forgetting) 문제가 빈번하게 보고됨.
• DeepSeek-VL의 접근:
• 초기에는 언어 데이터 비율을 70% 이상 유지하여 언어 능력 보존.
• 점진적으로 비전-언어 데이터의 비율을 늘리는 모달리티 워밍업 전략으로 멀티모달 능력과 언어 능력의 균형 유지.</p><p>논문 설명:
“Maintaining at least 70% language data during training preserves linguistic capabilities, while gradually introducing vision-language data prevents performance degradation in either modality.”</p><p>나의 해석:
언어와 비전 간의 경쟁적 관계를 인식하고, 이를 균형 있게 조율하는 전략이 DeepSeek-VL의 핵심 성공 요인 중 하나입니다. 이로 인해 멀티모달 태스크 뿐만 아니라 **언어 중심 태스크(MMLU)**에서도 성능이 향상되었습니다.</p><p>2.3. 현실적인 데이터 구성 및 지침 튜닝 (Real-world Data Construction & Instruction Tuning)
• 기존 모델 한계:
• 기존 오픈 소스 모델들은 학술적 데이터셋(예: COCO, Visual Genome)에 의존, 현실 세계 시나리오를 충분히 반영하지 못함.
• DeepSeek-VL의 접근:
• GPT-4V와 Gemini의 테스트 케이스를 수집하여 현실적인 사용 시나리오에 기반한 지침 튜닝 데이터셋을 구성.
• 웹 스크린샷, PDF, OCR, 차트, 전문 지식 데이터 등을 포함하여 현실 세계 문제 해결 능력 강화.</p><p>논문 설명:
“We curate instruction-tuning datasets reflecting real-world usage scenarios, improving the model’s practical application and user experience in real-world tasks.”</p><p>나의 해석:
DeepSeek-VL의 현실적 데이터셋 구성과 실제 사용 사례 기반의 튜닝은 실제 응용 시나리오에서 우수한 성능을 보이는 이유 중 하나입니다. 이로 인해 단순한 벤치마크 성능뿐 아니라 사용자 경험에서도 강점을 가질 수 있습니다.</p><ol start=3><li>종합 결론 및 나의 생각</li></ol><p>DeepSeek-VL의 특출난 성능은 다음과 같은 방법론적 혁신 덕분입니다:
1. 하이브리드 인코더를 통한 고해상도 시각 정보 처리.
2. 모달리티 워밍업 전략으로 언어와 비전 능력의 균형 유지.
3. 현실적 데이터셋 구성으로 실제 사용 사례에 최적화된 성능 달성.</p><p>나의 해석:
DeepSeek-VL은 기존 멀티모달 모델들이 가진 해상도 처리 한계, 언어 능력 저하, 현실 적용성 부족 문제를 효과적으로 해결했습니다. 특히, 언어와 비전 간의 균형 유지 전략은 향후 멀티모달 모델 개발에서 중요한 참고 사례가 될 것입니다. 다만, 수학적 논리 추론(예: MathVista)과 같은 태스크에서는 여전히 독점 모델(GPT-4V)에 비해 성능이 낮으며, 이는 모델 확장과 고급 수학 데이터셋 추가로 보완할 수 있습니다.</p><h1 id=q--이-논문에서-제시된-방법을-실제로-사용하려면-기존-방법에서-어떠한-구현이-추가적으로-필요하고-이러한-구현에-소모되는-공수-및-연산에-필요한-컴퓨팅-자원의-크기에-대해서-계산해줄-수-있겠니>Q : 이 논문에서 제시된 방법을 실제로 사용하려면 기존 방법에서 어떠한 구현이 추가적으로 필요하고 이러한 구현에 소모되는 공수 및 연산에 필요한 컴퓨팅 자원의 크기에 대해서 계산해줄 수 있겠니?</h1><ol><li>DeepSeek-VL 적용을 위한 추가 구현 요소</li></ol><p>DeepSeek-VL을 실제 환경에 적용하기 위해서는 기존의 멀티모달 모델(예: CLIP, LLaVA)과 비교했을 때 하드웨어 및 소프트웨어 측면에서 추가적인 구현이 필요합니다. 주요 추가 요소는 다음과 같습니다:</p><p>1.1. 하이브리드 비전 인코더 구현
• 기존 방법:
• 대부분의 멀티모달 모델들은 단일 비전 인코더(예: ViT, CLIP 인코더)를 사용하여 저해상도 이미지를 처리합니다.
• DeepSeek-VL 추가 구현:
1. **SAM-B 인코더(1024×1024 해상도)**와 **SigLIP-L 인코더(384×384 해상도)**를 결합한 하이브리드 비전 인코더 설계.
2. **저수준 피처(SAM-B)**와 **고수준 의미 피처(SigLIP-L)**를 통합하는 비전-언어 어댑터(2-layer MLP) 개발.
3. 고해상도 이미지의 공간 차원 축소 및 토큰화(576개 토큰) 처리 추가.
• 구현 복잡도:
• 컴퓨팅 자원: 고해상도 이미지 처리로 인해 메모리 사용량 및 GPU 연산량이 크게 증가.
• 추가 개발 시간: 하이브리드 인코더 아키텍처 및 피처 융합 로직 설계에 2~3주의 개발 기간 필요(기존 코드베이스가 있는 경우 기준).</p><p>1.2. 모달리티 워밍업 전략 구현
• 기존 방법:
• 일반적으로 비전-언어 데이터를 고정 비율로 혼합하여 학습.
• DeepSeek-VL 추가 구현:
1. 훈련 초기에는 언어 데이터 비율을 70% 이상으로 유지.
2. 학습이 진행됨에 따라 비전-언어 데이터 비율을 점진적으로 증가시키는 동적 데이터 로더 구현.
3. 모달리티별 훈련 손실 모니터링 및 퍼포먼스 최적화 로직 추가.
• 구현 복잡도:
• 컴퓨팅 자원: 모달리티별로 데이터를 분리 처리하면서 훈련 효율성이 약간 감소할 수 있음.
• 추가 개발 시간: 동적 데이터 로더 및 모달리티 비율 조정 로직 구현에 1~2주 추가 소요.</p><p>1.3. 현실적 데이터셋 수집 및 지침 튜닝
• 기존 방법:
• 주로 COCO, Visual Genome과 같은 학술적 데이터셋 사용.
• DeepSeek-VL 추가 구현:
1. GPT-4V와 Gemini의 테스트 케이스를 기반으로 한 실제 사용 시나리오 데이터셋 수집.
2. 수집된 데이터에 기반하여 지침 튜닝 데이터셋 구성 및 전처리.
3. OCR 데이터, 웹 스크린샷, 차트/표 데이터 등의 추가 수집 및 통합.
• 구현 복잡도:
• 데이터 수집 및 전처리 시간: 수 주에서 수 개월 소요될 수 있음(데이터 규모 및 품질에 따라 다름).
• 컴퓨팅 자원: 다양한 데이터 소스 통합으로 인해 전처리 및 저장 공간 요구 증가.</p><ol start=2><li>컴퓨팅 자원 소모 및 비용 분석</li></ol><p>DeepSeek-VL의 학습은 **세 단계(어댑터 학습, 사전 학습, 지도 학습)**로 진행되며, 각 단계에서 소모되는 컴퓨팅 자원과 시간이 다릅니다.</p><p>2.1. 하드웨어 요구 사항</p><p>모델 크기 GPU 종류 노드 수 총 GPU 수 훈련 시간 소모된 전력
DeepSeek-VL 1.3B NVIDIA A100 40GB 16 128 7일 약 21,504 kWh
DeepSeek-VL 7B NVIDIA A100 80GB 64 512 5일 약 134,400 kWh</p><p>계산 근거:
• NVIDIA A100 40GB의 전력 소모: 400W/GPU
• NVIDIA A100 80GB의 전력 소모: 525W/GPU
• 훈련 시간은 논문에서 직접 언급된 수치를 사용했습니다.</p><p>2.2. 예상 비용 (클라우드 환경 기준)</p><p>AWS EC2 p4d 인스턴스(A100 40GB 8개 장착) 기준으로 계산.
• DeepSeek-VL 1.3B:
• 1노드(8 GPU) 당 시간당 $32 비용.
• 총 16노드 → $512/시간.
• 7일(168시간) 훈련 → $86,016 소요.
• DeepSeek-VL 7B:
• 1노드(8 GPU) 당 시간당 $52 비용 (A100 80GB 기준).
• 총 64노드 → $3,328/시간.
• 5일(120시간) 훈련 → $399,360 소요.</p><ol start=3><li>공수 및 자원 소모 요약</li></ol><p>항목 추가 구현 요소 공수(시간/주) 컴퓨팅 자원
하이브리드 비전 인코더 SAM-B + SigLIP-L 결합, 피처 융합 어댑터 설계 2<del>3주 GPU 메모리 증가, 고해상도 이미지 처리로 연산량 증가
모달리티 워밍업 전략 동적 데이터 로더 구현, 모달리티별 손실 조정 1</del>2주 비전/언어 데이터 균형 유지로 효율성 감소 가능
현실적 데이터셋 수집 GPT-4V 기반 실제 시나리오 데이터 수집 및 전처리 4<del>8주 다양한 데이터 소스 통합으로 저장 및 전처리 비용 증가
훈련 단계 어댑터 학습, 사전 학습, 지도 학습 5</del>7일 (훈련) 1.3B: 128 A100 GPU, 7B: 512 A100 GPU
훈련 비용 (클라우드 기준) 클라우드 환경에서 GPU 인스턴스 사용 $86,016 (1.3B) $399,360 (7B)</p><ol start=4><li>나의 해석 및 조언<ol><li>자원 효율화:
• 하이브리드 비전 인코더는 고해상도 이미지 처리를 위해 필수적이지만, 연산량이 급격히 증가합니다. 따라서 고해상도 인코딩을 필요한 태스크에만 선택적 적용하는 방식을 고려할 수 있습니다.</li><li>모델 경량화 및 최적화:
• 전체 모델 크기(7B)를 유지하기 어렵다면, Mixture of Experts (MoE) 기술이나 파라미터 효율적 튜닝(PET) 방법을 통해 모델을 경량화하면서도 성능을 유지하는 전략이 필요합니다.</li><li>훈련 비용 최적화:
• 프라이빗 클라우드나 온프레미스 GPU 클러스터를 보유하고 있다면, 비용을 크게 절감할 수 있습니다. 그렇지 않다면, 학습 파이프라인 최적화와 모달리티 분리 학습을 통해 훈련 시간을 줄이는 방법을 고려할 수 있습니다.</li><li>데이터셋 재활용:
• 기존 오픈 소스 데이터셋(예: LAION-GPTV, ShareGPT4V)을 활용하고, 현실적인 데이터셋은 작은 규모의 샘플링을 통해 효율적으로 수집하는 방식을 추천합니다.</li></ol></li></ol><p>결론</p><p>DeepSeek-VL을 구현하고 실제 환경에 적용하려면 고해상도 인코더 설계, 모달리티 균형 학습 전략, 그리고 현실적인 데이터셋 수집이 필요합니다. 이러한 구현은 GPU 메모리와 컴퓨팅 자원의 요구를 증가시키며, 전체적인 훈련 비용 또한 상당히 클 수 있습니다. 하지만, 하이브리드 인코딩과 모달리티 워밍업 전략은 기존 모델 대비 우수한 멀티모달 성능을 보장하며, 현실 세계 응용에서 특출난 결과를 도출할 수 있는 강력한 도구가 될 것입니다.</p><h1 id=q--이-논문의-입력데이터와-추론-과정에-대해서-예시를-들어-아주-자세하게-설명해-주겠니-추가적으로-모델아키텍처의-구성-및-모델을-구성하는-연산과-메모리-요구량-컴퓨팅-요구량-대해서도-설명해줘>Q : 이 논문의 입력데이터와 추론 과정에 대해서 예시를 들어 아주 자세하게 설명해 주겠니? 추가적으로 모델아키텍처의 구성 및 모델을 구성하는 연산과 메모리 요구량 컴퓨팅 요구량 대해서도 설명해줘</h1><ol><li>DeepSeek-VL의 입력 데이터 및 추론 과정</li></ol><p>DeepSeek-VL은 고해상도 비전 인코더와 **대형 언어 모델(LLM)**을 결합하여 이미지와 텍스트를 동시에 처리합니다. 이 과정은 입력 데이터 처리, 멀티모달 통합, 그리고 최종 출력 생성의 단계로 나눌 수 있습니다.</p><p>1.1. 입력 데이터 형식</p><p>DeepSeek-VL은 고해상도 이미지와 텍스트 입력을 동시에 받아 멀티모달 추론을 수행합니다.</p><p>입력 유형 설명 예시
이미지 고해상도(1024×1024) 이미지, 표, 차트, 문서 등 주식 시장 차트, PDF 문서, 웹 페이지 스크린샷 등
텍스트 프롬프트 이미지에 대한 질문 또는 지시사항 “이 그래프의 추세를 설명해줘.”, “이 문서의 제목은 무엇인가?”</p><p>1.2. 추론 과정 단계별 설명</p><p>예제:
• 이미지 입력: 주식 시장의 일일 변동을 보여주는 고해상도 차트 이미지 (1024×1024).
• 텍스트 입력: “2023년 3분기의 주가 변동을 설명해줘.”</p><p>단계 1: 하이브리드 비전 인코딩
• SAM-B 인코더:
• 1024×1024 해상도의 이미지를 입력받아 64×64×256 피처맵 생성.
• 주가 그래프의 세부적인 디테일(숫자, 작은 텍스트, 선의 미세한 움직임)을 캡처.
• SigLIP-L 인코더:
• 동일 이미지를 384×384 해상도로 다운샘플링 후 처리, 576×1024 임베딩 벡터 생성.
• 주가의 전체적인 패턴(상승/하락 추세)을 포착.</p><p>단계 2: 비전-언어 어댑터 처리
1. SAM-B 인코더 출력:
• 64×64×256 피처맵을 96×96×256으로 보간 후 두 개의 합성곱 층 적용.
• 결과적으로 24×24×1024 피처맵 생성 → 576×1024 토큰으로 변환.
2. SigLIP-L 출력과 SAM-B 토큰을 결합(concatenate):
• 최종적으로 576개의 비전 토큰(2048 차원) 생성.
3. GeLU 활성화 함수 적용 및 임베딩 레이어를 통해 LLM 입력 형식으로 변환.</p><p>단계 3: 대형 언어 모델(LLM) 처리 및 출력 생성
• DeepSeek-LLM (7B) 모델이 시각 토큰과 텍스트 프롬프트를 통합하여 처리.
• 모델은 주가의 상승/하락 패턴, 특정 날짜의 주요 변동 등을 분석한 후 응답 생성.</p><p>출력:
• “2023년 3분기 동안 주가는 지속적으로 상승했습니다. 특히 9월 중순에 급격한 상승세를 보이며 최고치를 기록했습니다.”</p><ol start=2><li>모델 아키텍처 구성 및 연산 요구량 분석</li></ol><p>DeepSeek-VL의 아키텍처는 하이브리드 비전 인코더, 비전-언어 어댑터, 그리고 **대형 언어 모델(LLM)**로 구성됩니다.</p><p>2.1. 모델 아키텍처 구성</p><p>모듈 구성 요소 입력 크기 출력 크기
하이브리드 비전 인코더 SAM-B 인코더 (ViTDet 기반), SigLIP-L 인코더 1024×1024, 384×384 64×64×256, 576×1024
비전-언어 어댑터 2-layer MLP, 합성곱 층 (stride=2) 64×64×256 (SAM-B 출력) 576개의 2048 차원 토큰
대형 언어 모델 (LLM) DeepSeek-LLM 기반 (7B 파라미터, LLaMA 구조) 576 비전 토큰 + 텍스트 토큰 자연어 출력 생성</p><p>2.2. 연산량 및 메모리 요구량 분석</p><ol><li><p>하이브리드 비전 인코더 연산량 (FLOPs)</p><ol><li>SAM-B 인코더 (ViTDet 기반):
• 입력: 1024×1024 이미지
• FLOPs 계산:
ViT 기반 모델의 연산량은 다음과 같이 근사할 수 있습니다:
￼
• ￼: Transformer 레이어 수 (예: 24)
• ￼: 임베딩 차원 (256)
• ￼: 패치 수 (64×64)
￼</li><li>SigLIP-L 인코더:
• 입력: 384×384 이미지
• FLOPs: 약 2.1×10^10 FLOPs (CLIP 인코더 기준)</li></ol></li><li><p>비전-언어 어댑터 연산량
• 합성곱 층(2개):
• 입력: 96×96×256 → 출력: 24×24×1024
• FLOPs: 약 4×10^9 FLOPs (두 층 합산)
• MLP (2-layer):
• 576개의 2048 차원 토큰 처리
• FLOPs: 약 2.3×10^9 FLOPs</p></li><li><p>대형 언어 모델(LLM) 연산량
• DeepSeek-LLM (7B):
• 7B 파라미터 기준으로, 한 토큰당 약 1.5×10^12 FLOPs.
• 추론 시 576 비전 토큰과 **텍스트 토큰(최대 1024)**를 처리.
• 총 FLOPs (한 번의 추론):
￼</p></li></ol><p>2.3. 총 연산량 및 메모리 요구량</p><p>구성 요소 연산량 (FLOPs) 메모리 요구량
하이브리드 비전 인코더 ￼ 약 2<del>4 GB (고해상도 피처맵 저장)
비전-언어 어댑터 ￼ 약 1 GB (576 토큰 저장)
대형 언어 모델 (LLM) ￼ 30</del>40 GB (7B 파라미터, 토큰 캐시 포함)</p><p>총 연산량 (추론 1회 기준):
￼</p><ol start=3><li>컴퓨팅 요구량 및 현실적 고려사항</li></ol><p>3.1. 컴퓨팅 리소스 요구사항
• GPU 요구사항:
• Inference:
• 최소 A100 40GB 또는 A100 80GB GPU 필요 (특히 고해상도 이미지 처리 및 7B LLM 추론을 위해).
• Training:
• 1.3B 모델: 128 A100 GPU 사용.
• 7B 모델: 512 A100 GPU 사용.
• 추론 속도:
• 1회 추론 시간 (A100 GPU 기준): 약 0.5 ~ 1초 (이미지와 프롬프트 복잡도에 따라 다름).</p><p>3.2. 최적화 및 경량화 전략
1. 하이브리드 인코더 최적화:
• 필요하지 않은 경우 고해상도 인코더(SAM-B) 비활성화 또는 해상도 축소로 연산량 감소.
2. LLM 경량화:
• 7B 모델 대신 1.3B 모델 또는 Mixture of Experts (MoE) 기반 모델로 추론 최적화.
3. 하드웨어 가속기 활용:
• TPU v4 또는 H100 GPU 활용 시 연산 속도 및 효율성 향상 가능.</p><ol start=4><li>결론</li></ol><p>DeepSeek-VL의 추론 과정은 고해상도 이미지 인코딩과 대형 언어 모델 통합을 통해 정교한 멀티모달 이해를 구현합니다. 이는 기존 모델 대비 고해상도 시각 정보 처리와 언어 능력 유지에서 뛰어난 성능을 발휘하게 하지만, 그만큼 **연산량(FLOPs)**과 메모리 사용량이 대폭 증가합니다.</p><p>실제 적용 시, 하이브리드 인코더 최적화 및 모델 경량화 전략을 통해 연산 자원을 절약하면서도 성능을 유지하는 방법을 고려하는 것이 중요합니다. A100 GPU 이상의 하드웨어가 요구되며, 클라우드 환경에서의 활용 시 비용 최적화 전략도 필요합니다.</p><h1 id=q--이-논문의-한계를-극복하기-위한-방법으로-어떤-연구흐름이-있는지-정리해서-자세하게-설명해-줘>Q : 이 논문의 한계를 극복하기 위한 방법으로 어떤 연구흐름이 있는지 정리해서 자세하게 설명해 줘</h1><ol><li>DeepSeek-VL의 주요 한계점</li></ol><p>DeepSeek-VL은 멀티모달 모델로서 다양한 비전-언어 태스크에서 높은 성능을 보여주지만, 몇 가지 명확한 한계점이 존재합니다. 논문에서 제시한 한계와 이를 기반으로 예상되는 추가적인 한계는 다음과 같습니다:</p><p>1.1. 수학적 논리 및 추론 성능의 제한
• 한계점 설명:
• MathVista와 같은 수학적 문제 해결 능력에서 GPT-4V 등 독점 모델 대비 낮은 성능.
• 멀티모달 학습 중 언어 능력과 논리 추론 능력 간 경쟁으로 인해 복잡한 수학 문제 해결에서 약점.
• 원인:
• 멀티모달 데이터 비중이 증가하면서 언어 중심의 추론 능력이 일부 감소.
• 수학적 데이터셋의 규모 부족 및 고급 수학 태스크에 대한 제한된 사전 학습.</p><p>1.2. 모델 크기에 따른 확장성 문제
• 한계점 설명:
• 7B 모델이 GPT-4V와 같은 대규모 모델에 비해 일부 태스크에서 성능이 부족.
• 모델 확장 시 필요한 컴퓨팅 자원과 훈련 비용의 급증.
• 원인:
• 대규모 멀티모달 모델이 요구하는 **연산량(FLOPs)**과 메모리 요구량의 한계.
• 하드웨어 자원의 제한으로 인한 효율적인 모델 확장 방법의 부재.</p><p>1.3. 현실적 시나리오에서의 일반화 문제
• 한계점 설명:
• 실제 환경에서의 일반화 능력이 일부 제한됨.
• 표준 벤치마크 성능은 뛰어나지만, 실제 사용자 인터랙션에서 성능 저하 가능성.
• 원인:
• 학습 데이터가 현실적 시나리오를 반영하긴 했지만, 도메인 다양성 부족.
• 특수한 상황에서의 모달리티 불균형으로 인한 일반화 어려움.</p><ol start=2><li>DeepSeek-VL의 한계를 극복하기 위한 연구 흐름</li></ol><p>DeepSeek-VL의 한계를 극복하기 위해 현재 진행 중인 연구 흐름과 방법론은 다음과 같이 나눌 수 있습니다:</p><p>2.1. 수학 및 논리 추론 능력 강화</p><p>목표: 멀티모달 모델의 수학적 추론과 논리적 문제 해결 능력 향상.</p><p>2.1.1. 수학 및 코드 기반 멀티모달 사전 학습 (Math-Augmented Pretraining)
• 연구 흐름:
• 수학 문제 해결과 시각적 도식(그래프, 차트 등) 해석을 강화하기 위한 수학 기반 멀티모달 데이터셋 개발.
• 예: MathVista와 같은 수학적 평가 벤치마크 외에도 Wolfram Alpha 기반 시각적 데이터셋 사용.
• 적용 방법:
• 수학 문제와 관련된 LaTeX 렌더링 이미지와 텍스트를 결합한 학습.
• 코드-이미지 페어 데이터셋(예: WebPlotDigitizer 기반 데이터) 활용.
• 예상 효과:
• 수학적 시각화(그래프, 차트, 방정식)의 이해 능력 향상.
• 복잡한 논리적 추론 태스크에서 성능 개선.</p><p>2.1.2. 체인 오브 소트 (Chain of Thought) 강화
• 연구 흐름:
• 멀티모달 모델에서 Chain of Thought (CoT) 방식의 단계적 추론 도입.
• 단순 응답이 아닌 논리적 과정 설명을 포함한 멀티모달 학습.
• 적용 방법:
• 이미지 기반 문제 해결 시, 단계별로 생각하는 과정(예: “이 차트에서 먼저 x축을 해석하고, 다음으로 데이터 추세를 분석한다.”)을 학습.
• 멀티모달 CoT 데이터를 포함한 지도 학습 진행.
• 예상 효과:
• 수학 문제 해결 능력과 복잡한 논리 추론 능력 향상.
• 모델의 설명 가능성(Explainability) 향상.</p><p>2.2. 모델 크기 확장 및 효율적 컴퓨팅 활용</p><p>목표: 모델 크기 확장에 따른 연산 자원과 효율성 문제 해결.</p><p>2.2.1. Mixture of Experts (MoE) 기반 모델 확장
• 연구 흐름:
• 모델의 확장성과 효율성을 동시에 달성하기 위한 MoE (Mixture of Experts) 구조 도입.
• 특정 입력에 대해 부분적인 서브 네트워크만 활성화하여 연산량 절감.
• 적용 방법:
• DeepSeek-VL을 모달리티별 전문가 네트워크로 분할:
• 이미지 입력 → 비전 전문가(Expert)
• 수학 문제 → 수학 전문가(Expert)
• 일반 텍스트 → 언어 전문가(Expert)
• 라우팅 네트워크를 통해 입력에 적합한 전문가 네트워크 활성화.
• 예상 효과:
• 모델 크기는 수십억 파라미터로 확장하면서도, 실질적인 추론 비용은 유지.
• 특정 태스크 성능 향상 및 효율적 리소스 사용 가능.</p><p>2.2.2. 하드웨어 최적화 및 경량화 전략
• 연구 흐름:
• GPU 메모리 최적화 및 모델 압축 기술을 통해 연산 자원 효율화.
• Quantization 및 Pruning을 통한 모델 경량화 연구.
• 적용 방법:
• 8-bit 또는 4-bit 양자화(Quantization) 적용으로 메모리 사용량 절감.
• Knowledge Distillation 기법으로 경량화 모델 훈련.
• 예상 효과:
• 모바일 환경 또는 엣지 디바이스에서의 멀티모달 추론 가능.
• 대규모 모델의 실시간 응답 속도 향상.</p><p>2.3. 현실적 시나리오 일반화 및 사용자 맞춤형 모델링</p><p>목표: 실제 환경에서의 일반화 능력 강화 및 사용자 맞춤형 응답 제공.</p><p>2.3.1. 인컨텍스트 학습 및 사용자 맞춤형 튜닝 (Personalized Fine-Tuning)
• 연구 흐름:
• **In-Context Learning (ICL)**을 활용하여 사용자 맞춤형 데이터에 적응.
• **Low-Rank Adaptation (LoRA)**를 활용한 경량화된 사용자 튜닝.
• 적용 방법:
• 사용자 제공 데이터(이미지, 텍스트)를 기반으로 로컬 튜닝 수행.
• 개인화된 지침 튜닝 데이터셋을 소규모로 추가 학습.
• 예상 효과:
• 특정 도메인(예: 의료 영상, 법률 문서)에서 맞춤형 성능 제공.
• 사용자 경험(UX) 향상 및 실시간 적응형 모델 구현.</p><p>2.3.2. 멀티모달 강화 학습 (Reinforcement Learning for Multimodal)
• 연구 흐름:
• 강화 학습(RLHF) 기반 멀티모달 학습을 통해 실제 사용자 피드백 반영.
• 멀티모달 환경에서의 자율 학습 능력 강화.
• 적용 방법:
• 실제 사용 시나리오(예: 로봇 비전, 자율 주행)에서의 피드백을 통한 강화 학습.
• 비전-언어 태스크에 대한 보상 함수 설계.
• 예상 효과:
• 현실적 시나리오에서의 일반화 능력 및 응답 품질 향상.
• 사용자와의 인터랙티브한 상호작용 개선.</p><ol start=3><li>종합 요약</li></ol><p>한계점 극복 방법 예상 효과
수학적 논리 추론 부족 수학/코드 기반 멀티모달 사전 학습, 체인 오브 소트(CoT) 강화 수학 및 복잡한 논리 추론 태스크에서 성능 향상
모델 확장성 및 효율성 부족 MoE 기반 확장, 모델 양자화 및 경량화, 하드웨어 최적화 모델 크기 확장과 동시에 연산 자원 절감, 모바일 환경 적용 가능
현실적 시나리오 일반화 부족 인컨텍스트 학습, 개인화된 지침 튜닝, 멀티모달 강화 학습(RLHF) 적용 실제 환경에서의 일반화 능력 향상, 사용자 맞춤형 응답 제공</p><ol start=4><li>결론</li></ol><p>DeepSeek-VL의 한계를 극복하기 위한 연구는 모델 확장성, 수학 및 논리 추론 능력 강화, 그리고 현실적 시나리오 적용이라는 세 가지 축으로 진행되고 있습니다. 모달리티 간의 균형 유지와 효율적 컴퓨팅 리소스 활용이 핵심 과제로 남아 있으며, 수학적 태스크 성능 개선과 모델 확장성 문제는 특히 중요한 연구 분야로 부상하고 있습니다.</p><p>향후 연구에서는 **모달리티별 전문가 네트워크(MoE)**와 강화 학습 기반 사용자 피드백 반영이 중요한 역할을 할 것으로 예상되며, 모델 경량화 및 모바일 최적화 역시 주요 과제가 될 것입니다.</p><h1 id=q--deepseek-vl의-하이브리드-비전-인코더가-기존-멀티모달-모델과-비교했을-때-실제로-시각적-세부-정보-처리에서-얼마나-성능을-개선했는가>Q : DeepSeek-VL의 하이브리드 비전 인코더가 기존 멀티모달 모델과 비교했을 때 실제로 시각적 세부 정보 처리에서 얼마나 성능을 개선했는가?</h1><p>DeepSeek-VL의 하이브리드 비전 인코더 성능 개선 분석</p><p>결론부터 말하면, DeepSeek-VL의 하이브리드 비전 인코더는 기존 멀티모달 모델보다 고해상도 시각 정보 처리에서 현저한 성능 개선을 이루었습니다. 특히, OCR 태스크, 차트 및 표 해석, 그리고 세밀한 시각적 객체 인식 분야에서 두드러진 성능 차이를 보였습니다.</p><ol><li>하이브리드 비전 인코더 구성 및 차별점</li></ol><p>1.1. 기존 멀티모달 모델의 한계
• CLIP, LLaVA와 같은 기존 오픈소스 멀티모달 모델은 주로 224×224 또는 384×384 해상도의 이미지를 처리.
• 이러한 저해상도 이미지 처리는 복잡한 시각적 세부 정보(예: 작은 텍스트, 복잡한 차트, 미세한 객체 식별)를 충분히 포착하지 못함.</p><p>1.2. DeepSeek-VL의 하이브리드 인코더 구성
• SAM-B 인코더 (1024×1024 해상도):
• 고해상도 이미지에서 세부적인 시각 정보(OCR, 미세한 그래프 선, 작은 객체)를 정확하게 추출.
• SigLIP-L 인코더 (384×384 해상도):
• 이미지의 전반적인 의미 정보(전체적인 패턴, 색상, 구조)를 포착.
• 결합 방식:
• SAM-B 인코더의 저수준 피처와 SigLIP-L 인코더의 고수준 의미 피처를 통합하여, 기존 모델 대비 시각적 정보의 폭넓은 이해가 가능.</p><ol start=2><li>성능 비교 결과</li></ol><p>2.1. 표/차트 해석 태스크 (OCRBench, ScienceQA)</p><p>모델 OCRBench ScienceQA
DeepSeek-VL (7B) 456 66.7
LLaVA-Next (13B) 331 56.6
CogVLM (7B) - 54.5
Qwen-VL-Chat (7B) - 47.3</p><pre><code>•	개선된 점:
•	OCRBench에서 456 점수로 기존 모델 대비 약 37% 향상.
•	ScienceQA에서 66.7 점수로, 복잡한 과학적 차트 및 도표 해석 능력에서 우수한 성능.
</code></pre><p>2.2. 멀티모달 벤치마크 (MMB, MMC, SEEDBench)</p><p>모델 MMB MMC SEEDBench
DeepSeek-VL (7B) 73.2 72.8 70.4
GPT-4V (Proprietary) 75.0 74.7 71.6
LLaVA-Next (13B) 70.0 64.4 71.9
CogVLM (7B) 63.7 53.8 68.8</p><pre><code>•	개선된 점:
•	MMB와 MMC에서 13B 규모의 LLaVA-Next보다 높은 점수 획득.
•	SEEDBench에서는 GPT-4V와 1.2점 차이로 근접한 성능.
</code></pre><ol start=3><li>성능 개선의 원인</li></ol><p>3.1. 고해상도 이미지 처리 능력
• 기존 모델 한계:
• 224×224 또는 384×384 해상도에서는 작은 텍스트나 세부적인 객체 인식이 불가능.
• DeepSeek-VL의 개선:
• 1024×1024 해상도 처리를 통해 OCR 태스크에서 작은 글자, 복잡한 문서, 표 안의 데이터까지 정확하게 인식 가능.
• 예를 들어, PDF 문서 분석이나 과학적 논문 도표 해석에서 미세한 차이를 인식.</p><p>3.2. 저수준 및 고수준 시각 피처 통합
• 기존 모델 한계:
• 의미 정보만을 중시하는 모델들은 세부적인 시각적 차이(예: 유사한 모양의 객체 구분)에 취약.
• DeepSeek-VL의 개선:
• 하이브리드 인코더를 통해 의미 정보(SigLIP)와 세부 피처(SAM-B)를 결합, 의미적 일관성과 시각적 세부 정보를 모두 유지.</p><p>3.3. 토큰 압축 최적화
• 기존 모델 한계:
• 고해상도 이미지를 처리할 때 토큰 수 증가로 인해 추론 속도 저하 및 메모리 사용량 급증.
• DeepSeek-VL의 개선:
• 576개 토큰으로 고해상도 이미지의 정보를 효율적으로 압축하여 처리, 토큰 예산 관리 및 추론 효율성 확보.</p><ol start=4><li>나의 해석 및 추가적인 고려 사항<ol><li>실제 응용 분야 확대:
• 의료 영상 분석, 법률 문서 OCR, 공학적 도면 해석 등 고해상도 정보가 필수적인 분야에서 DeepSeek-VL의 성능 개선이 특히 유효할 것으로 예상됩니다.</li><li>모델 효율성과 자원 요구량:
• 고해상도 인코딩은 **연산량(FLOPs)**과 메모리 사용량 증가를 야기하므로, 추론 최적화와 모델 경량화 전략이 병행되어야 합니다.</li><li>향후 연구 방향:
• SAM-B 인코더의 구조를 경량화하거나, 필요 시 고해상도 처리 모듈을 선택적으로 활성화하는 방식으로 효율성과 성능의 균형을 맞출 수 있습니다.</li></ol></li></ol><p>결론적으로, DeepSeek-VL의 하이브리드 비전 인코더는 OCR, 차트 해석, 복잡한 시각 정보 처리에서 기존 오픈소스 모델 대비 30% 이상의 성능 향상을 달성했습니다. 이로 인해 GPT-4V와 같은 독점 모델과 비교해도 근접한 성능을 보여주는 멀티모달 모델로 자리 잡았습니다.</p><h1 id=q--모달리티-워밍업-전략이-멀티모달-모델의-언어-능력-유지에-어떻게-기여했으며-이-전략이-없는-경우와-비교했을-때-언어-태스크에서의-성능-차이는-어떤가>Q : 모달리티 워밍업 전략이 멀티모달 모델의 언어 능력 유지에 어떻게 기여했으며, 이 전략이 없는 경우와 비교했을 때 언어 태스크에서의 성능 차이는 어떤가?</h1><p>모달리티 워밍업 전략이 언어 능력 유지에 기여한 방식과 성능 차이</p><p>결론부터 말하면, **모달리티 워밍업 전략(Modality Warm-up Strategy)**은 멀티모달 모델에서 **언어 능력 저하(catastrophic forgetting)**를 방지하고, 비전-언어 태스크와 언어 중심 태스크 간 균형 잡힌 성능 유지에 크게 기여했습니다. 이 전략을 적용한 모델은 언어 중심 벤치마크에서 현저히 높은 성능을 보였으며, 적용하지 않은 모델과 비교했을 때 언어 능력 유지와 멀티모달 성능 모두에서 차별화된 결과를 보여주었습니다.</p><ol><li>모달리티 워밍업 전략의 개념과 적용 방식</li></ol><p>1.1. 기존 멀티모달 학습의 문제점
• 문제: 멀티모달 모델을 학습할 때 비전-언어 데이터의 비율이 높아지면, 기존에 잘 작동하던 언어 모델의 성능이 저하되는 문제가 발생.
• 원인:
1. 멀티모달 데이터와 텍스트 데이터의 분포 차이: 이미지-텍스트 페어 데이터는 순수 텍스트 데이터보다 언어적 복잡성이 낮아, 언어 모델의 문맥 이해 능력이 감소할 수 있음.
2. 모달리티 간 경쟁 효과: 비전-언어 데이터가 언어 데이터를 덮어쓰는 모달리티 경쟁 현상으로 인해 언어 능력이 감소.</p><p>1.2. 모달리티 워밍업 전략의 적용 방식
• 핵심 아이디어: 훈련 초기에는 언어 데이터 비율을 높게 유지하여 언어 능력을 충분히 유지하고, 점진적으로 비전-언어 데이터 비율을 증가시키는 방식.</p><pre><code>1.	훈련 초기 (0~30% 훈련 단계):
•	100% 언어 데이터로 훈련 시작.
•	모델의 언어 능력 보존 및 초기화 단계에서 언어적 문맥 이해 능력 강화.
2.	중간 훈련 단계 (30~70% 훈련 단계):
•	언어:비전-언어 데이터 비율을 70:30으로 조정.
•	언어 능력을 유지하면서 멀티모달 처리 능력을 점진적으로 강화.
3.	후반 훈련 단계 (70~100% 훈련 단계):
•	최종적으로 언어:비전-언어 데이터 비율을 60:40 또는 50:50으로 설정.
•	언어와 비전 간의 균형 잡힌 능력을 달성.
</code></pre><ol start=2><li>모달리티 워밍업 전략 적용 여부에 따른 성능 차이</li></ol><p>논문에서는 모달리티 워밍업 전략을 적용한 모델과 적용하지 않은 모델 간의 성능 차이를 다양한 언어 중심 벤치마크와 멀티모달 벤치마크를 통해 평가했습니다.</p><p>2.1. 언어 중심 태스크 성능 (MMLU, HellaSwag)</p><p>모델 MMLU (언어 추론) HellaSwag (문맥 이해)
DeepSeek-VL (워밍업 적용) 52.4 68.4
DeepSeek-VL (워밍업 미적용) 32.5 56.0
DeepSeek-LLM (언어 전용 모델) 49.4 68.5</p><pre><code>•	MMLU 결과 해석:
•	모달리티 워밍업 전략 적용 시, MMLU 점수가 52.4로 **언어 전용 모델(DeepSeek-LLM)**보다 높은 성능을 기록.
•	워밍업 전략 미적용 시, 32.5로 성능이 20점 이상 급락, 이는 **언어 능력 저하(catastrophic forgetting)**의 증거.
•	HellaSwag 결과 해석:
•	문맥 이해 능력에서도 워밍업 적용 모델은 68.4로, 미적용 모델(56.0) 대비 12.4점 높은 성능.
•	언어 전용 모델(68.5)과 근소한 차이로, 멀티모달 학습이 언어 능력에 부정적인 영향을 주지 않음을 시사.
</code></pre><p>2.2. 멀티모달 태스크 성능 (MMBench, SEEDBench)</p><p>모델 MMBench (멀티모달 이해) SEEDBench (복합 태스크)
DeepSeek-VL (워밍업 적용) 73.2 70.4
DeepSeek-VL (워밍업 미적용) 67.4 64.8</p><pre><code>•	MMBench 결과 해석:
•	워밍업 전략을 적용해도 멀티모달 성능이 감소하지 않고, 오히려 5.8점 향상.
•	이는 언어 데이터 비중이 높아도 비전-언어 처리 능력이 유지됨을 의미.
•	SEEDBench 결과 해석:
•	복합적인 태스크에서도 워밍업 전략 적용 시 성능이 70.4로 유지되며, 모달리티 간 균형이 잘 잡혀 있음을 보여줌.
</code></pre><ol start=3><li>모달리티 워밍업 전략의 기여 요인 분석</li></ol><p>3.1. 초기 언어 능력 보존
• 훈련 초기에 언어 데이터로만 모델을 학습시킴으로써 기초 언어 능력과 문맥 이해 능력을 강화.
• 이 초기화 과정 덕분에 모델이 텍스트 중심 태스크에서의 성능을 유지할 수 있음.</p><p>3.2. 모달리티 간 경쟁 효과 최소화
• 비전 데이터가 언어 데이터보다 복잡성이 낮고, 모달리티 경쟁에서 언어 능력을 덮어쓰는 경향이 있음.
• 워밍업 전략을 통해 언어와 비전의 균형을 점진적으로 맞추면서 언어 능력 저하 방지.</p><p>3.3. 토큰 경제성 및 효율적 데이터 분포
• 모델은 576개의 비전 토큰과 1024개의 언어 토큰을 처리하는 구조로, 언어 토큰의 비중을 초기 단계에서 유지하여 언어 능력 보존.
• 데이터 샘플링과 훈련 스케줄링을 조정하여 모달리티별 최적 학습 곡선을 달성.</p><ol start=4><li><p>나의 해석 및 추가 고려 사항</p><ol><li>멀티모달 모델의 언어 능력 강화 방향:
• 모달리티 워밍업 전략은 멀티모달 모델이 언어 능력과 비전 능력 모두를 유지하는데 효과적임.
• 향후에는 Chain of Thought (CoT) 방식과 결합하여 논리적 추론 능력을 더욱 강화할 수 있음.</li><li>모달리티 불균형 해결:
• 워밍업 전략은 언어와 비전 간의 불균형을 해결하는 효과적인 방법.
• 도메인 특화 태스크(예: 법률 문서 OCR, 의료 영상 분석)에서는 이 전략을 태스크 특화 데이터로 조정 가능.</li><li>효율성 및 최적화:
• 훈련 효율성은 유지하면서도 성능을 향상시키는 전략으로, 모델 경량화와 함께 활용 시 더욱 효과적.</li></ol></li><li><p>결론</p></li></ol><p>모달리티 워밍업 전략은 멀티모달 모델에서 언어 능력 유지와 멀티모달 성능 향상 모두에 중요한 역할을 했습니다.
1. 언어 중심 태스크(MMLU, HellaSwag)에서는 20점 이상 성능 향상을 달성했으며,
2. 멀티모달 태스크(MMBench, SEEDBench)에서도 5~6점 성능 개선을 이루었습니다.</p><p>이 전략은 언어 능력 저하 문제를 효과적으로 방지하면서도 비전-언어 균형을 유지하는 강력한 학습 방법론으로, 향후 멀티모달 학습 전략의 중요한 기준점이 될 것입니다.</p><h1 id=q--deepseek-vl이-현실적인-데이터셋웹-스크린샷-pdf-전문가-지식을-활용한-것이-모델의-실제-응용-시나리오에서-어떻게-성능을-개선했는가>Q : DeepSeek-VL이 현실적인 데이터셋(웹 스크린샷, PDF, 전문가 지식)을 활용한 것이 모델의 실제 응용 시나리오에서 어떻게 성능을 개선했는가?</h1><p>DeepSeek-VL이 현실적인 데이터셋 활용으로 실제 응용 시나리오에서 성능을 개선한 방법</p><p>결론부터 말하면, DeepSeek-VL은 현실적인 데이터셋(웹 스크린샷, PDF 문서, 전문가 지식)을 활용함으로써 실제 응용 시나리오에서의 일반화 능력과 **실제 사용자 경험(UX)**을 현저하게 개선했습니다. 이러한 데이터셋은 표준 벤치마크에서는 측정하기 어려운 현실적 문제 해결 능력을 강화하는 데 중점을 두었습니다.</p><ol><li>기존 멀티모달 모델의 데이터셋 한계</li></ol><p>1.1. 기존 데이터셋의 한계
• 전통적 멀티모달 모델(예: CLIP, LLaVA)은 주로 학술적 데이터셋(COCO, Visual Genome, VQA 등)에 의존.
• 이러한 데이터셋은 간단한 이미지-텍스트 페어 중심으로 구성되어, 실제 응용 시나리오와 다양한 현실적 문제를 충분히 반영하지 못함.</p><p>예시:
1. 웹 페이지 스크린샷 해석, 복잡한 문서 분석(PDF), 차트/표 해석과 같은 실제 태스크에서 성능 저하.
2. 전문가 지식이나 특수 도메인(예: 의료, 법률) 관련 질문에 대한 응답 품질 부족.</p><ol start=2><li>DeepSeek-VL의 현실적 데이터셋 구성 및 적용</li></ol><p>2.1. 현실적 데이터셋 구성 방법
1. 웹 스크린샷 및 UI 데이터:
• 웹 페이지, 앱 UI, 소프트웨어 인터페이스 등의 스크린샷을 활용하여 시각적 요소와 텍스트를 동시에 이해하도록 학습.
• 데이터셋 예시: ScreenQA, Websight, Screen-to-Code.
2. PDF 및 문서 OCR 데이터:
• PDF 문서와 스캔된 문서를 활용하여 문서 구조 인식 및 텍스트 추출 능력 강화.
• arXiv 논문, E-book, 교육 자료에서 OCR 데이터 생성.
• 데이터셋 예시: arXiv OCR, Latex-OCR, Document OCR Datasets.
3. 전문가 지식 및 도메인 특화 데이터:
• 전문가 지식(Expert Knowledge), 교과서(Textbooks), 기술 문서 등을 포함.
• 과학 논문, 전문 분야 차트/표 등 복잡한 시각적 데이터를 포함한 학습.
4. GPT-4V 및 Gemini 테스트 케이스 활용:
• GPT-4V와 Gemini 모델의 테스트 케이스를 기반으로 현실적 문제 시나리오를 수집.
• 실제 사용 사례에서의 실제 사용자 인터랙션을 반영하여 학습.</p><p>2.2. 데이터셋 비율 및 구성</p><p>데이터 유형 데이터셋 예시 비율
웹 스크린샷 및 UI ScreenQA, Websight, Screen-to-Code 6.5%
PDF 및 문서 OCR arXiv OCR, Latex-OCR, Document OCR 4.2%
전문가 지식 및 교과서 E-book, Educational Materials, Technical Documents 7.8%
일반 이미지-텍스트 페어 COCO, Visual Genome, VQA 11.1%
텍스트 전용 데이터 DeepSeek-LLM 2T 텍스트 코퍼스 70.0%</p><ol start=3><li>현실적 데이터셋 활용으로 인한 성능 개선</li></ol><p>3.1. 멀티모달 벤치마크 성능 개선</p><p>모델 MMBench (멀티모달 종합) OCRBench (문서 OCR) ScienceQA (과학적 문제)
DeepSeek-VL (7B) 73.2 456 66.7
LLaVA-Next (13B) 70.0 331 56.6
CogVLM (7B) 63.7 - 54.5
Qwen-VL-Chat (7B) 60.6 - 47.3</p><pre><code>•	MMBench 결과 해석:
•	현실적 데이터셋을 활용한 DeepSeek-VL은 73.2점으로 기존 오픈소스 모델 대비 약 3~10점 높은 성능을 기록.
•	실제 사용 시나리오(웹 스크린샷, 문서 해석)에서의 종합적 이해 능력이 향상.
•	OCRBench 결과 해석:
•	456점으로 기존 모델 대비 37% 성능 향상.
•	이는 PDF 문서, 스캔된 문서 등 복잡한 문서 구조를 이해하는 능력 향상을 보여줌.
•	ScienceQA 결과 해석:
•	과학적 차트 및 도표 해석 능력에서 66.7점으로 기존 모델 대비 약 10점 향상.
•	이는 전문가 지식 기반의 데이터셋 활용이 모델의 도메인 특화 태스크 성능을 높인 결과.
</code></pre><p>3.2. 실제 응용 시나리오 개선 사례
1. 웹 페이지 분석 및 UI 이해 능력:
• 웹 스크린샷 기반의 데이터셋으로 인해, DeepSeek-VL은 웹 페이지 구조와 UI 요소를 정확하게 인식.
• 예: “이 웹 페이지에서 로그인 버튼은 어디에 있나요?” 같은 질문에 정확한 답변 가능.
2. 문서 OCR 및 PDF 해석:
• PDF 문서와 OCR 데이터 학습으로 인해 스캔된 문서나 복잡한 서식 문서의 구조를 정확하게 이해.
• 예: “이 PDF 문서의 제목과 저자는 무엇인가요?”, “이 문서에서 표의 내용을 요약해줘.“와 같은 태스크에서 높은 성능.
3. 전문가 지식 기반 문제 해결 능력:
• 과학 논문, 기술 문서 학습을 통해 복잡한 과학적 문제나 전문 분야 질문에 대한 응답 품질 향상.
• 예: “이 차트의 데이터에서 이상치를 찾아 설명해줘.”, “이 논문의 결론을 요약해줘.”</p><ol start=4><li>DeepSeek-VL의 현실적 데이터셋 활용이 가져온 기여 요인</li></ol><p>4.1. 실제 시나리오 일반화 능력 강화
• 기존 모델 한계:
• 학술적 데이터셋 중심의 모델은 실제 환경에서 일반화 능력이 부족.
• DeepSeek-VL의 개선:
• 현실적 데이터셋 활용으로 인해 실제 사용자 환경에서 일관된 성능 유지.
• 예: 웹 페이지 분석, 문서 해석 등의 태스크에서 사용자 경험(UX) 향상.</p><p>4.2. 복잡한 시각-언어 태스크 처리 능력 향상
• 기존 모델 한계:
• 간단한 이미지-텍스트 페어는 잘 처리하지만, 복잡한 시각적 정보(PDF, 차트, UI)는 처리 능력 부족.
• DeepSeek-VL의 개선:
• 복잡한 문서 구조, 차트 해석, 표 데이터 분석 등 고난이도 시각적 태스크 처리 능력 강화.</p><p>4.3. 도메인 특화 태스크 성능 향상
• 기존 모델 한계:
• 전문가 지식이나 특수 도메인 관련 태스크에서 낮은 성능.
• DeepSeek-VL의 개선:
• 전문가 지식 기반 데이터셋 활용으로 의학적 데이터 해석, 공학적 도면 분석 등 도메인 특화 태스크에서 높은 성능.</p><ol start=5><li><p>나의 해석 및 추가적인 고려 사항</p><ol><li>현실적 데이터셋의 중요성:
• DeepSeek-VL의 성공은 현실적인 데이터셋 활용이 얼마나 모델 성능에 중요한지를 보여주는 사례.
• 향후 도메인 특화 모델 개발 시, 현실적 데이터셋의 확보가 성능 향상에 필수적.</li><li>데이터 품질 관리:
• 현실적 데이터셋은 노이즈가 많을 수 있으므로, 데이터 품질 관리 및 전처리 기술이 중요.
• 예: OCR 오류 보정, 웹 페이지 구조 표준화 등의 데이터 전처리 전략 필요.</li><li>응용 분야 확장성:
• 법률 문서 해석, 의료 영상 분석, 소프트웨어 코드 분석 등 특수 분야에서 DeepSeek-VL의 성능을 추가적으로 확장 가능.</li></ol></li><li><p>결론</p></li></ol><p>DeepSeek-VL은 웹 스크린샷, PDF 문서, 전문가 지식과 같은 현실적 데이터셋을 활용함으로써 실제 응용 시나리오에서 일반화 능력과 문제 해결 능력을 대폭 향상시켰습니다. 이는 기존 모델 대비 OCR 태스크, 차트/표 해석, 전문 지식 기반 태스크에서 10~37% 성능 향상으로 나타났으며, **사용자 경험(UX)**과 실제 문제 해결 능력에서도 명확한 개선을 보여줍니다.</p><p>이러한 접근은 향후 도메인 특화 멀티모달 모델 개발의 중요한 방향성을 제시하며, 실제 환경에서의 적용성을 높이는 핵심 전략으로 자리 잡을 것입니다.</p></article></main><footer class="mx-auto max-w-4xl px-4 py-8"><div class="px-6 py-6"><nav class=mb-6><div class="flex flex-wrap items-center justify-center gap-1"><a href=/index.xml class="nav-link hover:text-primary hover:bg-primary/10 text-muted-foreground flex items-center gap-2 rounded-lg px-4 py-2 text-sm font-medium transition-all duration-300 hover:scale-105"><svg class="h-5 w-5" fill="none" stroke="currentColor" viewBox="0 0 24 24" aria-label="RSS Feed"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M6 5c7.18.0 13 5.82 13 13M6 11a7 7 0 017 7m-6 0a1 1 0 11-2 0 1 1 0 012 0z"/></svg>
<span>RSS Feed</span></a></div></nav><div class="border-border mb-6 border-t"></div><div class="flex flex-col items-center justify-between gap-4 md:flex-row"><div class="text-muted-foreground text-sm"><p>&copy; 2025 Jaehun's Blog.
모든 권리 보유.</p></div><div class="flex items-center gap-3"><a href=https://github.com/ryujaehun target=_blank rel="noopener noreferrer" class="text-muted-foreground hover:text-primary focus:ring-primary/20 rounded-lg p-1 transition-all duration-300 ease-out hover:scale-110 focus:ring-2 focus:outline-none" title=GitHub aria-label=GitHub><svg class="h-6 w-6" fill="none" stroke="currentColor" viewBox="0 0 24 24" aria-label="GitHub"><g fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2"><path d="M15 22v-4a4.8 4.8.0 00-1-3.5c3 0 6-2 6-5.5.08-1.25-.27-2.48-1-3.5.28-1.15.28-2.35.0-3.5.0.0-1 0-3 1.5-2.64-.5-5.36-.5-8 0C6 2 5 2 5 2c-.3 1.15-.3 2.35.0 3.5A5.4 5.4.0 004 9c0 3.5 3 5.5 6 5.5-.39.49-.68 1.05-.85 1.65S8.93 17.38 9 18v4"/><path d="M9 18c-4.51 2-5-2-7-2"/></g></svg>
</a><a href=https://www.linkedin.com/in/jaehunryu/ target=_blank rel="noopener noreferrer" class="text-muted-foreground hover:text-primary focus:ring-primary/20 rounded-lg p-1 transition-all duration-300 ease-out hover:scale-110 focus:ring-2 focus:outline-none" title=Linkedin aria-label=Linkedin><svg class="h-6 w-6" fill="none" stroke="currentColor" viewBox="0 0 24 24" aria-label="Linkedin"><g fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2"><path d="M16 8a6 6 0 016 6v7h-4v-7a2 2 0 00-2-2 2 2 0 00-2 2v7h-4v-7a6 6 0 016-6M2 9h4v12H2z"/><circle cx="4" cy="4" r="2"/></g></svg>
</a><a href=mailto:jaehunryu@icloud.com class="text-muted-foreground hover:text-primary focus:ring-primary/20 rounded-lg p-1 transition-all duration-300 ease-out hover:scale-110 focus:ring-2 focus:outline-none" title=Email aria-label=Email><svg class="h-6 w-6" fill="none" stroke="currentColor" viewBox="0 0 24 24" aria-label="Email"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M3 8l7.89 5.26a2 2 0 002.22.0L21 8M5 19h14a2 2 0 002-2V7a2 2 0 00-2-2H5A2 2 0 003 7v10a2 2 0 002 2z"/></svg></a></div></div></div></footer><div id=dock class="pointer-events-none fixed bottom-4 left-1/2 z-[9999] w-fit -translate-x-1/2 translate-y-24 opacity-0 transition-all duration-300 ease-out sm:right-0 sm:left-0 sm:mx-auto sm:translate-x-0" role=toolbar aria-label="바로가기 도구 모음"><nav class="border-border bg-card/80 scrollbar-hide xs:px-3 xs:py-2 mx-auto flex max-w-[calc(100vw-2rem)] min-w-fit items-center justify-center overflow-x-auto rounded-2xl border px-4 py-3 shadow-lg backdrop-blur-sm sm:px-4 sm:py-3"><button id=dock-back class="text-muted-foreground hover:text-primary hover:bg-primary/10 focus:ring-primary/20 xs:px-2 xs:py-1.5 flex flex-shrink-0 items-center gap-2 rounded-lg px-3 py-2 text-sm font-medium transition-all duration-300 ease-out hover:-translate-y-0.5 hover:scale-105 focus:ring-2 focus:outline-none sm:px-3 sm:py-2" title=뒤로 aria-label=뒤로>
<svg class="h-4 w-4" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path d="m12 19-7-7 7-7"/><path d="M19 12H5"/></svg>
<span class="hidden sm:inline">뒤로</span></button><div class="bg-border xs:mx-1 mx-2 h-6 w-px sm:mx-2"></div><button id=dock-toc class="text-muted-foreground hover:text-primary hover:bg-primary/10 focus:ring-primary/20 xs:px-2 xs:py-1.5 flex flex-shrink-0 items-center gap-2 rounded-lg px-3 py-2 text-sm font-medium transition-all duration-300 ease-out hover:-translate-y-0.5 hover:scale-105 focus:ring-2 focus:outline-none sm:px-3 sm:py-2" title=목차 aria-label=목차>
<svg class="h-4 w-4" fill="none" stroke="currentColor" viewBox="0 0 24 24"><line x1="8" x2="21" y1="6" y2="6"/><line x1="8" x2="21" y1="12" y2="12"/><line x1="8" x2="21" y1="18" y2="18"/><line x1="3" x2="3.01" y1="6" y2="6"/><line x1="3" x2="3.01" y1="12" y2="12"/><line x1="3" x2="3.01" y1="18" y2="18"/></svg>
<span class="hidden sm:inline">목차</span></button><div class="bg-border xs:mx-1 mx-2 h-6 w-px sm:mx-2"></div><button id=dock-search class="text-muted-foreground hover:text-primary hover:bg-primary/10 focus:ring-primary/20 xs:px-3 xs:py-1.5 flex flex-shrink-0 items-center gap-2 rounded-lg px-4 py-2 text-sm font-medium transition-all duration-300 ease-out hover:-translate-y-0.5 hover:scale-105 focus:ring-2 focus:outline-none sm:px-4 sm:py-2" title=검색 aria-label=검색>
<svg class="h-4 w-4" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="m21 21-6-6m2-5A7 7 0 113 10a7 7 0 0114 0z"/></svg>
<span class="hidden md:inline">검색</span></button><div class="bg-border xs:mx-1 mx-2 h-6 w-px sm:mx-2"></div><button id=dock-top class="text-muted-foreground hover:text-primary hover:bg-primary/10 focus:ring-primary/20 xs:px-2 xs:py-1.5 flex flex-shrink-0 items-center gap-2 rounded-lg px-3 py-2 text-sm font-medium transition-all duration-300 ease-out hover:-translate-y-0.5 hover:scale-105 focus:ring-2 focus:outline-none sm:px-3 sm:py-2" title="맨 위로" aria-label="맨 위로">
<svg class="h-4 w-4" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path d="m18 15-6-6-6 6"/></svg>
<span class="hidden sm:inline">맨 위로</span></button></nav></div><div id=toc-overlay class="pointer-events-none fixed inset-0 z-40 bg-black/50 opacity-0 backdrop-blur-sm transition-all duration-300" role=dialog aria-modal=true aria-labelledby=toc-title></div><div id=toc-card class="pointer-events-none fixed inset-4 z-50 flex w-auto scale-95 items-center justify-center opacity-0 transition-all duration-300 sm:inset-auto sm:top-1/2 sm:left-1/2 sm:block sm:w-full sm:max-w-md sm:-translate-x-1/2 sm:-translate-y-1/2" role=dialog aria-modal=true aria-labelledby=toc-title><div class="bg-card border-border w-full max-w-sm overflow-hidden rounded-xl border shadow-xl sm:max-w-md"><div class="border-border bg-muted/30 flex items-center justify-between border-b p-4"><div class="flex items-center gap-3"><svg class="h-5 w-5" fill="none" stroke="currentColor" viewBox="0 0 24 24"><line x1="8" x2="21" y1="6" y2="6"/><line x1="8" x2="21" y1="12" y2="12"/><line x1="8" x2="21" y1="18" y2="18"/><line x1="3" x2="3.01" y1="6" y2="6"/><line x1="3" x2="3.01" y1="12" y2="12"/><line x1="3" x2="3.01" y1="18" y2="18"/></svg><h2 id=toc-title class="text-foreground text-lg font-semibold">목차</h2></div><button id=toc-close class="text-muted-foreground hover:text-primary hover:bg-primary/10 focus:ring-primary/20 rounded-lg p-2 transition-all duration-200 ease-out hover:-translate-y-0.5 hover:scale-105 focus:ring-2 focus:outline-none" title=닫기 aria-label=닫기>
<svg class="h-4 w-4" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M6 18 18 6M6 6l12 12"/></svg></button></div><div class="max-h-96 overflow-y-auto p-4"><nav id=toc-nav class=toc-scrollbar aria-label="글 목차"><div id=toc-content><nav id=TableOfContents></nav></div></nav></div><div class="border-border bg-muted/20 border-t px-4 py-3"><div class="text-muted-foreground text-center text-xs"><span>제목을 클릭하면 해당 위치로 이동합니다</span></div></div></div></div><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.22/dist/katex.min.css integrity=sha384-5TcZemv2l/9On385z///+d7MSYlvIEw9FuZTIdZ14vJLqWphw7e7ZPuOiCHJcFCP crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.22/dist/katex.min.js integrity=sha384-cMkvdD8LoxVzGF/RPUKAcvmm49FQ0oxwDF3BGKtDXcEc+T1b2N+teh/OJfpU0jr6 crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.22/dist/contrib/auto-render.min.js integrity=sha384-hCXGrW6PitJEwbkoStFjeJxv+fSOOQKOPbJxSfM6G5sWZjAyWhXiTIIAmQqnlLlh crossorigin=anonymous></script><script>function initKaTeX(){if(typeof renderMathInElement=="undefined"){setTimeout(initKaTeX,100);return}var e=[{display:!0,left:"$$",right:"$$"},{display:!1,left:"$",right:"$"}];renderMathInElement(document.body,{delimiters:e,throwOnError:!1,errorColor:"#cc0000",fleqn:!1,leqno:!1,trust:!1})}document.readyState==="loading"?document.addEventListener("DOMContentLoaded",initKaTeX):initKaTeX()</script><div id=search-overlay class="pointer-events-none fixed inset-0 z-40 bg-black/50 opacity-0 transition-opacity duration-300"></div><div id=search-modal class="bg-card border-border pointer-events-none fixed top-1/2 left-1/2 z-50 max-h-[80vh] w-full max-w-2xl -translate-x-1/2 -translate-y-1/2 scale-95 transform overflow-hidden rounded-xl border opacity-0 shadow-xl transition-all duration-300"><div class="border-border flex items-center gap-3 border-b p-4"><div class="text-muted-foreground h-5 w-5 flex-shrink-0"><svg class="h-4 w-4" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="m21 21-6-6m2-5A7 7 0 113 10a7 7 0 0114 0z"/></svg></div><div class="relative flex-1"><button id=search-clear class="text-muted-foreground hover:text-foreground hover:bg-muted/50 pointer-events-none absolute top-1/2 left-0 z-10 h-5 w-5 -translate-y-1/2 rounded opacity-0 transition-all duration-200" title=지우기 aria-label=지우기>
<svg class="h-4 w-4" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M6 18 18 6M6 6l12 12"/></svg>
</button>
<input id=search-input type=text placeholder="게시글 검색..." class="text-foreground placeholder:text-muted-foreground w-full border-none bg-transparent pl-8 text-lg outline-none" autocomplete=off spellcheck=false></div><button id=search-close class="text-muted-foreground hover:text-foreground hover:bg-muted/50 flex h-6 w-6 items-center justify-center rounded-md p-0.5 transition-all duration-200" title=닫기 aria-label=닫기>
<svg class="h-4 w-4" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M6 18 18 6M6 6l12 12"/></svg></button></div><div id=search-results class="max-h-96 overflow-y-auto"><div id=search-empty class="flex flex-col items-center justify-center py-12 text-center"><div class="bg-muted/50 mb-4 flex h-16 w-16 items-center justify-center rounded-full"><svg class="h-6 w-6" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="m21 21-6-6m2-5A7 7 0 113 10a7 7 0 0114 0z"/></svg></div><h3 class="text-foreground mb-2 text-lg font-semibold">검색 시작</h3><p class="text-muted-foreground text-sm">검색어를 입력하세요</p></div><div id=search-loading class="flex hidden items-center justify-center py-8"><div class="mr-3 h-6 w-6 animate-spin rounded-full border-2 border-current border-t-transparent"></div><span class=text-muted-foreground>검색 중...</span></div><div id=search-no-results class="flex hidden flex-col items-center justify-center py-12 text-center"><div class="bg-muted/50 mb-4 flex h-16 w-16 items-center justify-center rounded-full"><svg class="h-6 w-6" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M4 6h16M4 12h16M4 18h7"/></svg></div><h3 class="text-foreground mb-2 text-lg font-semibold">검색 결과 없음</h3><p class="text-muted-foreground text-sm">다른 검색어로 시도해보세요</p></div><div id=search-results-list class=hidden><div id=search-stats class="text-muted-foreground border-border border-b px-4 py-3 text-sm" data-template="%d개의 결과 찾음"></div><div id=search-items class="divide-border divide-y"></div></div></div><div class="border-border bg-muted/20 border-t px-4 py-3"><div class="text-muted-foreground flex items-center justify-between text-xs"><div class="flex items-center gap-2 md:gap-4"><div class="flex items-center gap-1"><kbd class="bg-muted border-border rounded border px-1.5 py-0.5 text-xs">↑↓</kbd>
<span class="hidden sm:inline">이동</span></div><div class="flex items-center gap-1"><kbd class="bg-muted border-border rounded border px-1.5 py-0.5 text-xs">↵</kbd>
<span class="hidden sm:inline">선택</span></div><div class="flex items-center gap-1"><kbd class="bg-muted border-border rounded border px-1.5 py-0.5 text-xs">ESC</kbd>
<span class="hidden sm:inline">닫기</span></div></div><div class="search-hint-desktop flex items-center gap-1"><kbd class="bg-muted border-border rounded border px-1.5 py-0.5 text-xs">⌘K</kbd>
<span>단축키</span></div></div></div></div></body></html>