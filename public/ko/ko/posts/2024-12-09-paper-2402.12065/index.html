<!doctype html><html lang=ko-kr data-theme=claude><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta http-equiv=X-UA-Compatible content="IE=edge"><title>WKVQuant: Quantizing Weight and Key/Value Cache for Large Language Models Gains More | Jaehun's Blog</title><meta name=description content="논문 링크
Q : 이 논문을 아주 자세하게 읽고 논문의 강점과 독창적인 지점을 설명해주고 핵심 알고리즘을 예시 입력을 들어서 전체적인 과정을 설명해줘 추가적으로 논문의 한계점에 대해서도 알려줘 강점과 독창적인 지점 WKVQuant은 대규모 언어 모델(LLM)의 메모리 ..."><meta name=keywords content="개발,프로그래밍,에세이"><meta name=author content><meta name=language content="ko"><meta name=robots content="index, follow"><link rel=canonical href=https://jaehun.me/ko/ko/posts/2024-12-09-paper-2402.12065/><link rel=icon type=image/svg+xml href=/favicon.svg><link rel=manifest href=/site.webmanifest><meta property="og:url" content="https://jaehun.me/ko/ko/posts/2024-12-09-paper-2402.12065/"><meta property="og:site_name" content="Jaehun's Blog"><meta property="og:title" content="WKVQuant: Quantizing Weight and Key/Value Cache for Large Language Models Gains More"><meta property="og:description" content="논문 링크
Q : 이 논문을 아주 자세하게 읽고 논문의 강점과 독창적인 지점을 설명해주고 핵심 알고리즘을 예시 입력을 들어서 전체적인 과정을 설명해줘 추가적으로 논문의 한계점에 대해서도 알려줘 강점과 독창적인 지점 WKVQuant은 대규모 언어 모델(LLM)의 메모리 사용 문제를 해결하기 위해 설계된 Post-Training Quantization (PTQ) 프레임워크입니다. 주요 강점과 독창적 특징은 다음과 같습니다:"><meta property="og:locale" content="ko_kr"><meta property="og:type" content="article"><meta property="article:section" content="ko"><meta property="article:published_time" content="2024-12-09T00:00:00+00:00"><meta property="article:modified_time" content="2024-12-09T00:00:00+00:00"><meta property="og:image" content="https://jaehun.me/images/og-default.avif"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://jaehun.me/images/og-default.avif"><meta name=twitter:title content="WKVQuant: Quantizing Weight and Key/Value Cache for Large Language Models Gains More"><meta name=twitter:description content="논문 링크
Q : 이 논문을 아주 자세하게 읽고 논문의 강점과 독창적인 지점을 설명해주고 핵심 알고리즘을 예시 입력을 들어서 전체적인 과정을 설명해줘 추가적으로 논문의 한계점에 대해서도 알려줘 강점과 독창적인 지점 WKVQuant은 대규모 언어 모델(LLM)의 메모리 사용 문제를 해결하기 위해 설계된 Post-Training Quantization (PTQ) 프레임워크입니다. 주요 강점과 독창적 특징은 다음과 같습니다:"><meta itemprop=name content="WKVQuant: Quantizing Weight and Key/Value Cache for Large Language Models Gains More"><meta itemprop=description content="논문 링크
Q : 이 논문을 아주 자세하게 읽고 논문의 강점과 독창적인 지점을 설명해주고 핵심 알고리즘을 예시 입력을 들어서 전체적인 과정을 설명해줘 추가적으로 논문의 한계점에 대해서도 알려줘 강점과 독창적인 지점 WKVQuant은 대규모 언어 모델(LLM)의 메모리 사용 문제를 해결하기 위해 설계된 Post-Training Quantization (PTQ) 프레임워크입니다. 주요 강점과 독창적 특징은 다음과 같습니다:"><meta itemprop=datePublished content="2024-12-09T00:00:00+00:00"><meta itemprop=dateModified content="2024-12-09T00:00:00+00:00"><meta itemprop=wordCount content="7982"><meta itemprop=image content="https://jaehun.me/images/og-default.avif"><meta itemprop=keywords content="Paper-Review,With-Gpt,LLM-Inference"><script>window.HUGO_SEARCH_CONFIG={searchIndexURL:'"/ko/index.json"'}</script><script>window.HUGO_GALLERY_CONFIG={justified_gallery:!1,lightbox:!1,justified:"{}",lightbox_options:"{}"}</script><link rel=stylesheet href=/css/compiled.min.9165cace5b80a5be5daad6ea96eb2abc20a18a3f41d7fed7f0335b689fdf7883.css integrity="sha256-kWXKzluApb5dqtbqlusqvCChij9B1/7X8DNbaJ/feIM=" crossorigin=anonymous><link rel=stylesheet href=/css/chroma.min.491df36221f739b5948a747a0351f100ee7ccaaf466d9f46288bf06de1d59123.css integrity="sha256-SR3zYiH3ObWUinR6A1HxAO58yq9GbZ9GKIvwbeHVkSM=" crossorigin=anonymous><script src=/js/main.ba969e49a7a874e6938fe689a7dcaa00cb64cb4d429c2cf98d09bde512a16c6d.js integrity="sha256-upaeSaeodOaTj+aJp9yqAMtky01CnCz5jQm95RKhbG0=" crossorigin=anonymous></script><script src=/js/gumshoe.polyfills.min.js></script><script src=/js/toc.70654aebf0b738a78ae2df95297cc10ebc6e590f3c942dd1325fa852f50038b2.js integrity="sha256-cGVK6/C3OKeK4t+VKXzBDrxuWQ88lC3RMl+oUvUAOLI=" crossorigin=anonymous defer></script><script src=/js/search.de3eba3540834efb8328121784bff4774e06362412ee41eee665f5b4f987f393.js integrity="sha256-3j66NUCDTvuDKBIXhL/0d04GNiQS7kHu5mX1tPmH85M=" crossorigin=anonymous defer></script><script src=/js/dock.e02f422517e001d9fb6bea1e9e8b0e89e9d2e486ad4641f275bb3e36ce2ae79f.js integrity="sha256-4C9CJRfgAdn7a+oenosOienS5IatRkHydbs+Ns4q558=" crossorigin=anonymous defer></script><script>(function(){const e=localStorage.getItem("theme")||"system",n=localStorage.getItem("colorScheme")||"claude";document.documentElement.setAttribute("data-theme",n);function t(){e==="dark"||e==="system"&&window.matchMedia("(prefers-color-scheme: dark)").matches?document.documentElement.classList.add("dark"):document.documentElement.classList.remove("dark")}t(),e==="system"&&window.matchMedia("(prefers-color-scheme: dark)").addEventListener("change",t)})()</script></head><body class="bg-background text-foreground min-h-screen antialiased"><div id=reading-progress-container class="reading-progress-container pointer-events-none fixed top-0 right-0 left-0 z-50 transition-opacity duration-300 ease-out" data-height=3 data-smooth-scroll=true data-hide-on-complete=false><div class="reading-progress-bg w-full"></div><div id=reading-progress-bar class="from-primary to-primary/80 reading-progress-bar
transition-all duration-150 ease-out
absolute top-0 left-0 w-0 bg-gradient-to-r"></div></div><script>(function(){"use strict";const t=document.getElementById("reading-progress-container"),o=document.getElementById("reading-progress-bar");if(!t||!o)return;const a={smoothScroll:t.dataset.smoothScroll==="true",hideOnComplete:t.dataset.hideOnComplete==="true"};let n=!0,l=null;function r(){const t=window.pageYOffset||document.documentElement.scrollTop,n=document.documentElement.scrollHeight,s=window.innerHeight,e=n-s;return e<=0?0:Math.min(Math.max(t/e*100,0),100)}function c(){const e=r();o.style.width=e+"%",a.hideOnComplete&&e>=99.5?n&&(t.style.opacity="0",n=!1):n||(t.style.opacity="1",n=!0)}let s=!1;function e(){s||(requestAnimationFrame(()=>{c(),s=!1}),s=!0)}function i(){window.addEventListener("scroll",e,{passive:!0}),window.addEventListener("resize",e,{passive:!0}),document.addEventListener("visibilitychange",()=>{document.hidden||e()}),e(),window.addEventListener("beforeunload",()=>{window.removeEventListener("scroll",e),window.removeEventListener("resize",e)})}document.readyState==="loading"?document.addEventListener("DOMContentLoaded",i):i()})()</script><header class="sticky top-0 z-50 mx-auto max-w-4xl px-4 py-6"><div class="border-border bg-card/80 flex items-center rounded-xl border px-6 py-4 shadow-sm backdrop-blur-sm"><div class="hidden w-full items-center md:flex"><div class="flex items-center"><a href=/ko/ class="flex h-10 w-10 items-center justify-center overflow-hidden rounded-full transition-transform duration-200 hover:scale-105" aria-label="Jaehun's Blog"><img src=/images/logo.svg alt="Jaehun's Blog" class="h-full w-full object-cover"></a></div><nav class="mx-8 flex flex-1 items-center justify-center"><div class="flex items-center space-x-1"><a href=/ko/ class="nav-link
text-muted-foreground hover:text-primary hover:bg-primary/10
focus:ring-primary/20 relative flex items-center gap-2 rounded-lg px-4 py-2 text-sm font-medium transition-all duration-300 ease-out hover:-translate-y-0.5 hover:scale-105 focus:ring-2 focus:outline-none"><svg class="h-5 w-5" fill="none" stroke="currentColor" viewBox="0 0 24 24" aria-label="nav.posts"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 20H5a2 2 0 01-2-2V6a2 2 0 012-2h10a2 2 0 012 2v1m2 13a2 2 0 01-2-2V7m2 13a2 2 0 002-2V9a2 2 0 00-2-2h-2m-4-3H9M7 16h6M7 8h6v4H7V8z"/></svg>
<span>게시글
</span></a><a href=/ko/categories/ class="nav-link
text-muted-foreground hover:text-primary hover:bg-primary/10
focus:ring-primary/20 relative flex items-center gap-2 rounded-lg px-4 py-2 text-sm font-medium transition-all duration-300 ease-out hover:-translate-y-0.5 hover:scale-105 focus:ring-2 focus:outline-none"><svg class="h-5 w-5" fill="none" stroke="currentColor" viewBox="0 0 24 24" aria-label="nav.categories"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 11H5m14 0a2 2 0 012 2v6a2 2 0 01-2 2H5a2 2 0 01-2-2v-6a2 2 0 012-2m14 0V9a2 2 0 00-2-2M5 11V9a2 2 0 012-2m0 0V5a2 2 0 012-2h6a2 2 0 012 2v2M7 7h10"/></svg>
<span>카테고리
</span></a><a href=/ko/tags/ class="nav-link
text-muted-foreground hover:text-primary hover:bg-primary/10
focus:ring-primary/20 relative flex items-center gap-2 rounded-lg px-4 py-2 text-sm font-medium transition-all duration-300 ease-out hover:-translate-y-0.5 hover:scale-105 focus:ring-2 focus:outline-none"><svg class="h-5 w-5" fill="none" stroke="currentColor" viewBox="0 0 24 24" aria-label="nav.tags"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M7 7h.01M7 3h5c.512.0 1.024.195 1.414.586l7 7a2 2 0 010 2.828l-7 7a2 2 0 01-2.828.0l-7-7A1.994 1.994.0 013 12V7a4 4 0 014-4z"/></svg>
<span>태그
</span></a><a href=/ko/ class="nav-link
text-muted-foreground hover:text-primary hover:bg-primary/10
focus:ring-primary/20 relative flex items-center gap-2 rounded-lg px-4 py-2 text-sm font-medium transition-all duration-300 ease-out hover:-translate-y-0.5 hover:scale-105 focus:ring-2 focus:outline-none"><svg class="h-5 w-5" fill="none" stroke="currentColor" viewBox="0 0 24 24" aria-label="nav.archives"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M5 8h14M5 8a2 2 0 110-4h14a2 2 0 110 4M5 8v10a2 2 0 002 2h10a2 2 0 002-2V8m-9 4h4"/></svg>
<span>아카이브</span></a></div></nav><div class="flex items-center space-x-2"><div class=relative><button id=language-toggle class="dropdown-toggle border-border bg-background text-muted-foreground hover:text-primary hover:bg-primary/10 focus:ring-primary/20 flex h-10 w-10 items-center justify-center rounded-lg border transition-all duration-300 ease-out hover:scale-105 focus:ring-2 focus:outline-none active:scale-95" data-dropdown-type=language aria-label="언어 변경" aria-expanded=false aria-haspopup=true>
<svg class="h-5 w-5 relative z-10" fill="none" stroke="currentColor" viewBox="0 0 24 24" aria-label="언어 변경"><path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="m5 8 6 6m-7 0 6-6 2-3M2 5h12M7 2h1m14 20-5-10-5 10m2-4h6"/></svg></button><div id=language-dropdown class="dropdown-menu border-border bg-popover/95 absolute top-12 right-0 z-[60] hidden w-40 rounded-lg border p-1 shadow-lg backdrop-blur-sm transition-all duration-200 ease-out" data-dropdown-type=language role=menu aria-labelledby=language-toggle><a href=/ko/ class="text-accent-foreground hover:bg-accent hover:text-accent-foreground focus:bg-accent focus:text-accent-foreground flex w-full items-center rounded-md px-4 py-2 text-sm transition-all duration-200 ease-out focus:outline-none" role=menuitem aria-current=true><span class=font-medium>한국어</span></a><a href=/en/ class="text-accent-foreground hover:bg-accent hover:text-accent-foreground focus:bg-accent focus:text-accent-foreground flex w-full items-center rounded-md px-4 py-2 text-sm transition-all duration-200 ease-out focus:outline-none" role=menuitem><span class=font-medium>English</span></a></div></div><div class=relative><button id=color-scheme-toggle class="dropdown-toggle border-border bg-background text-muted-foreground hover:text-primary hover:bg-primary/10 focus:ring-primary/20 flex h-10 w-10 items-center justify-center rounded-lg border transition-all duration-300 ease-out hover:scale-105 focus:ring-2 focus:outline-none active:scale-95" data-dropdown-type=color-scheme aria-label="테마 변경" aria-expanded=false aria-haspopup=true>
<svg class="h-5 w-5 relative z-10" fill="none" stroke="currentColor" viewBox="0 0 24 24" aria-label="테마 변경"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M7 21a4 4 0 01-4-4V5a2 2 0 012-2h4a2 2 0 012 2v12a4 4 0 01-4 4zM21 5a2 2 0 00-2-2h-4a2 2 0 00-2 2v6a2 2 0 002 2h4a2 2 0 002-2V5z"/></svg></button><div id=color-scheme-dropdown class="dropdown-menu border-border bg-popover/95 absolute top-12 right-0 z-[60] hidden w-44 rounded-lg border p-1 shadow-lg backdrop-blur-sm transition-all duration-200 ease-out" data-dropdown-type=color-scheme><button data-color-scheme=claude class="text-accent-foreground hover:bg-accent hover:text-accent-foreground focus:bg-accent focus:text-accent-foreground flex w-full items-center rounded-md px-4 py-2 text-sm transition-all duration-200 ease-out focus:outline-none"><span>Default</span></button><button data-color-scheme=default class="text-accent-foreground hover:bg-accent hover:text-accent-foreground focus:bg-accent focus:text-accent-foreground flex w-full items-center rounded-md px-4 py-2 text-sm transition-all duration-200 ease-out focus:outline-none"><span>White</span></button><button data-color-scheme=bumblebee class="text-accent-foreground hover:bg-accent hover:text-accent-foreground focus:bg-accent focus:text-accent-foreground flex w-full items-center rounded-md px-4 py-2 text-sm transition-all duration-200 ease-out focus:outline-none"><span>Bumblebee</span></button><button data-color-scheme=emerald class="text-accent-foreground hover:bg-accent hover:text-accent-foreground focus:bg-accent focus:text-accent-foreground flex w-full items-center rounded-md px-4 py-2 text-sm transition-all duration-200 ease-out focus:outline-none"><span>Emerald</span></button><button data-color-scheme=nord class="text-accent-foreground hover:bg-accent hover:text-accent-foreground focus:bg-accent focus:text-accent-foreground flex w-full items-center rounded-md px-4 py-2 text-sm transition-all duration-200 ease-out focus:outline-none"><span>Nord</span></button><button data-color-scheme=sunset class="text-accent-foreground hover:bg-accent hover:text-accent-foreground focus:bg-accent focus:text-accent-foreground flex w-full items-center rounded-md px-4 py-2 text-sm transition-all duration-200 ease-out focus:outline-none"><span>Sunset</span></button><button data-color-scheme=abyss class="text-accent-foreground hover:bg-accent hover:text-accent-foreground focus:bg-accent focus:text-accent-foreground flex w-full items-center rounded-md px-4 py-2 text-sm transition-all duration-200 ease-out focus:outline-none"><span>Abyss</span></button><button data-color-scheme=dracula class="text-accent-foreground hover:bg-accent hover:text-accent-foreground focus:bg-accent focus:text-accent-foreground flex w-full items-center rounded-md px-4 py-2 text-sm transition-all duration-200 ease-out focus:outline-none"><span>Dracula</span></button><button data-color-scheme=amethyst class="text-accent-foreground hover:bg-accent hover:text-accent-foreground focus:bg-accent focus:text-accent-foreground flex w-full items-center rounded-md px-4 py-2 text-sm transition-all duration-200 ease-out focus:outline-none"><span>Amethyst</span></button><button data-color-scheme=slate class="text-accent-foreground hover:bg-accent hover:text-accent-foreground focus:bg-accent focus:text-accent-foreground flex w-full items-center rounded-md px-4 py-2 text-sm transition-all duration-200 ease-out focus:outline-none"><span>Slate</span></button><button data-color-scheme=twitter class="text-accent-foreground hover:bg-accent hover:text-accent-foreground focus:bg-accent focus:text-accent-foreground flex w-full items-center rounded-md px-4 py-2 text-sm transition-all duration-200 ease-out focus:outline-none"><span>Twitter</span></button></div></div><div class=relative><button id=theme-toggle class="dropdown-toggle border-border bg-background text-muted-foreground hover:text-primary hover:bg-primary/10 focus:ring-primary/20 flex h-10 w-10 items-center justify-center rounded-lg border transition-all duration-300 ease-out hover:scale-105 focus:ring-2 focus:outline-none active:scale-95" data-dropdown-type=theme aria-label="테마 변경" aria-expanded=false aria-haspopup=true>
<svg class="h-5 w-5 sun-icon hidden relative z-10" fill="none" stroke="currentColor" viewBox="0 0 24 24" aria-label="라이트"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M12 3v1m0 16v1m9-9h-1M4 12H3m15.364 6.364-.707-.707M6.343 6.343l-.707-.707m12.728.0-.707.707M6.343 17.657l-.707.707M16 12a4 4 0 11-8 0 4 4 0 018 0z"/></svg>
<svg class="h-5 w-5 moon-icon hidden relative z-10" fill="none" stroke="currentColor" viewBox="0 0 24 24" aria-label="다크"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M20.354 15.354A9 9 0 018.646 3.646 9.003 9.003.0 0012 21a9.003 9.003.0 008.354-5.646z"/></svg>
<svg class="h-5 w-5 system-icon hidden relative z-10" fill="none" stroke="currentColor" viewBox="0 0 24 24" aria-label="시스템"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9.75 17 9 20l-1 1h8l-1-1-.75-3M3 13h18M5 17h14a2 2 0 002-2V5a2 2 0 00-2-2H5A2 2 0 003 5v10a2 2 0 002 2z"/></svg></button><div id=theme-dropdown class="dropdown-menu border-border bg-popover/95 absolute top-12 right-0 z-[60] hidden w-40 rounded-lg border p-1 shadow-lg backdrop-blur-sm transition-all duration-200 ease-out" data-dropdown-type=theme><button data-theme=light class="text-accent-foreground hover:bg-accent hover:text-accent-foreground focus:bg-accent focus:text-accent-foreground flex w-full items-center rounded-md px-4 py-2 text-sm transition-all duration-200 ease-out focus:outline-none">
<svg class="h-5 w-5 mr-3 h-4 w-4" fill="none" stroke="currentColor" viewBox="0 0 24 24" aria-label="라이트"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M12 3v1m0 16v1m9-9h-1M4 12H3m15.364 6.364-.707-.707M6.343 6.343l-.707-.707m12.728.0-.707.707M6.343 17.657l-.707.707M16 12a4 4 0 11-8 0 4 4 0 018 0z"/></svg><span>라이트</span></button><button data-theme=dark class="text-accent-foreground hover:bg-accent hover:text-accent-foreground focus:bg-accent focus:text-accent-foreground flex w-full items-center rounded-md px-4 py-2 text-sm transition-all duration-200 ease-out focus:outline-none">
<svg class="h-5 w-5 mr-3 h-4 w-4" fill="none" stroke="currentColor" viewBox="0 0 24 24" aria-label="다크"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M20.354 15.354A9 9 0 018.646 3.646 9.003 9.003.0 0012 21a9.003 9.003.0 008.354-5.646z"/></svg><span>다크</span></button><button data-theme=system class="text-accent-foreground hover:bg-accent hover:text-accent-foreground focus:bg-accent focus:text-accent-foreground flex w-full items-center rounded-md px-4 py-2 text-sm transition-all duration-200 ease-out focus:outline-none">
<svg class="h-5 w-5 mr-3 h-4 w-4" fill="none" stroke="currentColor" viewBox="0 0 24 24" aria-label="시스템"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9.75 17 9 20l-1 1h8l-1-1-.75-3M3 13h18M5 17h14a2 2 0 002-2V5a2 2 0 00-2-2H5A2 2 0 003 5v10a2 2 0 002 2z"/></svg><span>시스템</span></button></div></div></div></div><div class="flex w-full items-center justify-between md:hidden"><div class=relative><button id=mobile-menu-toggle class="dropdown-toggle border-border bg-background text-muted-foreground hover:bg-accent hover:text-foreground flex h-10 w-10 items-center justify-center rounded-lg border transition-colors duration-200" data-dropdown-type=mobile-menu aria-label=메뉴 aria-expanded=false aria-haspopup=true>
<svg class="h-5 w-5" fill="none" stroke="currentColor" viewBox="0 0 24 24" aria-label="메뉴"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M4 6h16M4 12h16M4 18h16"/></svg></button><div id=mobile-menu class="mobile-menu dropdown-menu border-border bg-popover/95 absolute top-12 left-0 z-[60] hidden w-80 max-w-[calc(100vw-2rem)] rounded-lg border p-1 shadow-lg backdrop-blur-sm transition-all duration-200 ease-out md:hidden" data-dropdown-type=mobile-menu role=menu aria-labelledby=mobile-menu-toggle><nav class="flex flex-col"><a href=/ko/ class="nav-link
text-muted-foreground hover:text-primary hover:bg-primary/10
focus:ring-primary/20 relative flex items-center gap-3 rounded-md px-4 py-3 text-sm font-medium transition-all duration-200 ease-out hover:translate-x-1 focus:ring-2 focus:outline-none" role=menuitem><svg class="h-5 w-5" fill="none" stroke="currentColor" viewBox="0 0 24 24" aria-label="nav.posts"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 20H5a2 2 0 01-2-2V6a2 2 0 012-2h10a2 2 0 012 2v1m2 13a2 2 0 01-2-2V7m2 13a2 2 0 002-2V9a2 2 0 00-2-2h-2m-4-3H9M7 16h6M7 8h6v4H7V8z"/></svg>
<span>게시글
</span></a><a href=/ko/categories/ class="nav-link
text-muted-foreground hover:text-primary hover:bg-primary/10
focus:ring-primary/20 relative flex items-center gap-3 rounded-md px-4 py-3 text-sm font-medium transition-all duration-200 ease-out hover:translate-x-1 focus:ring-2 focus:outline-none" role=menuitem><svg class="h-5 w-5" fill="none" stroke="currentColor" viewBox="0 0 24 24" aria-label="nav.categories"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 11H5m14 0a2 2 0 012 2v6a2 2 0 01-2 2H5a2 2 0 01-2-2v-6a2 2 0 012-2m14 0V9a2 2 0 00-2-2M5 11V9a2 2 0 012-2m0 0V5a2 2 0 012-2h6a2 2 0 012 2v2M7 7h10"/></svg>
<span>카테고리
</span></a><a href=/ko/tags/ class="nav-link
text-muted-foreground hover:text-primary hover:bg-primary/10
focus:ring-primary/20 relative flex items-center gap-3 rounded-md px-4 py-3 text-sm font-medium transition-all duration-200 ease-out hover:translate-x-1 focus:ring-2 focus:outline-none" role=menuitem><svg class="h-5 w-5" fill="none" stroke="currentColor" viewBox="0 0 24 24" aria-label="nav.tags"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M7 7h.01M7 3h5c.512.0 1.024.195 1.414.586l7 7a2 2 0 010 2.828l-7 7a2 2 0 01-2.828.0l-7-7A1.994 1.994.0 013 12V7a4 4 0 014-4z"/></svg>
<span>태그
</span></a><a href=/ko/ class="nav-link
text-muted-foreground hover:text-primary hover:bg-primary/10
focus:ring-primary/20 relative flex items-center gap-3 rounded-md px-4 py-3 text-sm font-medium transition-all duration-200 ease-out hover:translate-x-1 focus:ring-2 focus:outline-none" role=menuitem><svg class="h-5 w-5" fill="none" stroke="currentColor" viewBox="0 0 24 24" aria-label="nav.archives"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M5 8h14M5 8a2 2 0 110-4h14a2 2 0 110 4M5 8v10a2 2 0 002 2h10a2 2 0 002-2V8m-9 4h4"/></svg>
<span>아카이브</span></a></nav></div></div><div class="flex items-center space-x-2"><div class=relative><button id=language-toggle class="dropdown-toggle border-border bg-background text-muted-foreground hover:text-primary hover:bg-primary/10 focus:ring-primary/20 flex h-10 w-10 items-center justify-center rounded-lg border transition-all duration-300 ease-out hover:scale-105 focus:ring-2 focus:outline-none active:scale-95" data-dropdown-type=language aria-label="언어 변경" aria-expanded=false aria-haspopup=true>
<svg class="h-5 w-5 relative z-10" fill="none" stroke="currentColor" viewBox="0 0 24 24" aria-label="언어 변경"><path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="m5 8 6 6m-7 0 6-6 2-3M2 5h12M7 2h1m14 20-5-10-5 10m2-4h6"/></svg></button><div id=language-dropdown class="dropdown-menu border-border bg-popover/95 absolute top-12 right-0 z-[60] hidden w-40 rounded-lg border p-1 shadow-lg backdrop-blur-sm transition-all duration-200 ease-out" data-dropdown-type=language role=menu aria-labelledby=language-toggle><a href=/ko/ class="text-accent-foreground hover:bg-accent hover:text-accent-foreground focus:bg-accent focus:text-accent-foreground flex w-full items-center rounded-md px-4 py-2 text-sm transition-all duration-200 ease-out focus:outline-none" role=menuitem aria-current=true><span class=font-medium>한국어</span></a><a href=/en/ class="text-accent-foreground hover:bg-accent hover:text-accent-foreground focus:bg-accent focus:text-accent-foreground flex w-full items-center rounded-md px-4 py-2 text-sm transition-all duration-200 ease-out focus:outline-none" role=menuitem><span class=font-medium>English</span></a></div></div><div class=relative><button id=color-scheme-toggle class="dropdown-toggle border-border bg-background text-muted-foreground hover:text-primary hover:bg-primary/10 focus:ring-primary/20 flex h-10 w-10 items-center justify-center rounded-lg border transition-all duration-300 ease-out hover:scale-105 focus:ring-2 focus:outline-none active:scale-95" data-dropdown-type=color-scheme aria-label="테마 변경" aria-expanded=false aria-haspopup=true>
<svg class="h-5 w-5 relative z-10" fill="none" stroke="currentColor" viewBox="0 0 24 24" aria-label="테마 변경"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M7 21a4 4 0 01-4-4V5a2 2 0 012-2h4a2 2 0 012 2v12a4 4 0 01-4 4zM21 5a2 2 0 00-2-2h-4a2 2 0 00-2 2v6a2 2 0 002 2h4a2 2 0 002-2V5z"/></svg></button><div id=color-scheme-dropdown class="dropdown-menu border-border bg-popover/95 absolute top-12 right-0 z-[60] hidden w-44 rounded-lg border p-1 shadow-lg backdrop-blur-sm transition-all duration-200 ease-out" data-dropdown-type=color-scheme><button data-color-scheme=claude class="text-accent-foreground hover:bg-accent hover:text-accent-foreground focus:bg-accent focus:text-accent-foreground flex w-full items-center rounded-md px-4 py-2 text-sm transition-all duration-200 ease-out focus:outline-none"><span>Default</span></button><button data-color-scheme=default class="text-accent-foreground hover:bg-accent hover:text-accent-foreground focus:bg-accent focus:text-accent-foreground flex w-full items-center rounded-md px-4 py-2 text-sm transition-all duration-200 ease-out focus:outline-none"><span>White</span></button><button data-color-scheme=bumblebee class="text-accent-foreground hover:bg-accent hover:text-accent-foreground focus:bg-accent focus:text-accent-foreground flex w-full items-center rounded-md px-4 py-2 text-sm transition-all duration-200 ease-out focus:outline-none"><span>Bumblebee</span></button><button data-color-scheme=emerald class="text-accent-foreground hover:bg-accent hover:text-accent-foreground focus:bg-accent focus:text-accent-foreground flex w-full items-center rounded-md px-4 py-2 text-sm transition-all duration-200 ease-out focus:outline-none"><span>Emerald</span></button><button data-color-scheme=nord class="text-accent-foreground hover:bg-accent hover:text-accent-foreground focus:bg-accent focus:text-accent-foreground flex w-full items-center rounded-md px-4 py-2 text-sm transition-all duration-200 ease-out focus:outline-none"><span>Nord</span></button><button data-color-scheme=sunset class="text-accent-foreground hover:bg-accent hover:text-accent-foreground focus:bg-accent focus:text-accent-foreground flex w-full items-center rounded-md px-4 py-2 text-sm transition-all duration-200 ease-out focus:outline-none"><span>Sunset</span></button><button data-color-scheme=abyss class="text-accent-foreground hover:bg-accent hover:text-accent-foreground focus:bg-accent focus:text-accent-foreground flex w-full items-center rounded-md px-4 py-2 text-sm transition-all duration-200 ease-out focus:outline-none"><span>Abyss</span></button><button data-color-scheme=dracula class="text-accent-foreground hover:bg-accent hover:text-accent-foreground focus:bg-accent focus:text-accent-foreground flex w-full items-center rounded-md px-4 py-2 text-sm transition-all duration-200 ease-out focus:outline-none"><span>Dracula</span></button><button data-color-scheme=amethyst class="text-accent-foreground hover:bg-accent hover:text-accent-foreground focus:bg-accent focus:text-accent-foreground flex w-full items-center rounded-md px-4 py-2 text-sm transition-all duration-200 ease-out focus:outline-none"><span>Amethyst</span></button><button data-color-scheme=slate class="text-accent-foreground hover:bg-accent hover:text-accent-foreground focus:bg-accent focus:text-accent-foreground flex w-full items-center rounded-md px-4 py-2 text-sm transition-all duration-200 ease-out focus:outline-none"><span>Slate</span></button><button data-color-scheme=twitter class="text-accent-foreground hover:bg-accent hover:text-accent-foreground focus:bg-accent focus:text-accent-foreground flex w-full items-center rounded-md px-4 py-2 text-sm transition-all duration-200 ease-out focus:outline-none"><span>Twitter</span></button></div></div><div class=relative><button id=theme-toggle class="dropdown-toggle border-border bg-background text-muted-foreground hover:text-primary hover:bg-primary/10 focus:ring-primary/20 flex h-10 w-10 items-center justify-center rounded-lg border transition-all duration-300 ease-out hover:scale-105 focus:ring-2 focus:outline-none active:scale-95" data-dropdown-type=theme aria-label="테마 변경" aria-expanded=false aria-haspopup=true>
<svg class="h-5 w-5 sun-icon hidden relative z-10" fill="none" stroke="currentColor" viewBox="0 0 24 24" aria-label="라이트"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M12 3v1m0 16v1m9-9h-1M4 12H3m15.364 6.364-.707-.707M6.343 6.343l-.707-.707m12.728.0-.707.707M6.343 17.657l-.707.707M16 12a4 4 0 11-8 0 4 4 0 018 0z"/></svg>
<svg class="h-5 w-5 moon-icon hidden relative z-10" fill="none" stroke="currentColor" viewBox="0 0 24 24" aria-label="다크"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M20.354 15.354A9 9 0 018.646 3.646 9.003 9.003.0 0012 21a9.003 9.003.0 008.354-5.646z"/></svg>
<svg class="h-5 w-5 system-icon hidden relative z-10" fill="none" stroke="currentColor" viewBox="0 0 24 24" aria-label="시스템"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9.75 17 9 20l-1 1h8l-1-1-.75-3M3 13h18M5 17h14a2 2 0 002-2V5a2 2 0 00-2-2H5A2 2 0 003 5v10a2 2 0 002 2z"/></svg></button><div id=theme-dropdown class="dropdown-menu border-border bg-popover/95 absolute top-12 right-0 z-[60] hidden w-40 rounded-lg border p-1 shadow-lg backdrop-blur-sm transition-all duration-200 ease-out" data-dropdown-type=theme><button data-theme=light class="text-accent-foreground hover:bg-accent hover:text-accent-foreground focus:bg-accent focus:text-accent-foreground flex w-full items-center rounded-md px-4 py-2 text-sm transition-all duration-200 ease-out focus:outline-none">
<svg class="h-5 w-5 mr-3 h-4 w-4" fill="none" stroke="currentColor" viewBox="0 0 24 24" aria-label="라이트"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M12 3v1m0 16v1m9-9h-1M4 12H3m15.364 6.364-.707-.707M6.343 6.343l-.707-.707m12.728.0-.707.707M6.343 17.657l-.707.707M16 12a4 4 0 11-8 0 4 4 0 018 0z"/></svg><span>라이트</span></button><button data-theme=dark class="text-accent-foreground hover:bg-accent hover:text-accent-foreground focus:bg-accent focus:text-accent-foreground flex w-full items-center rounded-md px-4 py-2 text-sm transition-all duration-200 ease-out focus:outline-none">
<svg class="h-5 w-5 mr-3 h-4 w-4" fill="none" stroke="currentColor" viewBox="0 0 24 24" aria-label="다크"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M20.354 15.354A9 9 0 018.646 3.646 9.003 9.003.0 0012 21a9.003 9.003.0 008.354-5.646z"/></svg><span>다크</span></button><button data-theme=system class="text-accent-foreground hover:bg-accent hover:text-accent-foreground focus:bg-accent focus:text-accent-foreground flex w-full items-center rounded-md px-4 py-2 text-sm transition-all duration-200 ease-out focus:outline-none">
<svg class="h-5 w-5 mr-3 h-4 w-4" fill="none" stroke="currentColor" viewBox="0 0 24 24" aria-label="시스템"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9.75 17 9 20l-1 1h8l-1-1-.75-3M3 13h18M5 17h14a2 2 0 002-2V5a2 2 0 00-2-2H5A2 2 0 003 5v10a2 2 0 002 2z"/></svg><span>시스템</span></button></div></div></div></div></div></header><main class="mx-auto max-w-4xl px-4 py-6"><nav class="breadcrumb mb-4 md:mb-6 py-1" aria-label=경로><ol class="text-muted-foreground flex items-center space-x-1 md:space-x-2 text-sm overflow-x-auto whitespace-nowrap scrollbar-hide py-1"><li class=flex-shrink-0><a href=/ko/ class="text-muted-foreground hover:text-primary hover:bg-primary/10 flex items-center gap-0.5 md:gap-1 rounded-lg px-1 md:px-3 py-0.5 md:py-1.5 transition-all duration-200 ease-out hover:-translate-y-0.5 hover:scale-[1.02]"><svg class="h-4 w-4" fill="none" stroke="currentColor" viewBox="0 0 24 24" aria-label="홈"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="m3 12 2-2m0 0 7-7 7 7M5 10v10a1 1 0 001 1h3m10-11 2 2m-2-2v10a1 1 0 01-1 1h-3m-6 0a1 1 0 001-1v-4a1 1 0 011-1h2a1 1 0 011 1v4a1 1 0 001 1m-6 0h6"/></svg>
<span class="max-w-[4rem] md:max-w-none truncate">홈</span></a></li><li class="flex items-center gap-1 md:gap-2 min-w-0"><span class="text-muted-foreground/50 flex-shrink-0"><svg class="h-4 w-4" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 5l7 7-7 7"/></svg></span><div class="flex items-center gap-1 md:gap-2 min-w-0"><a href=/ko class="text-muted-foreground hover:text-primary hover:bg-primary/10 flex items-center gap-0.5 md:gap-1 rounded-lg px-1 md:px-3 py-0.5 md:py-1.5 transition-all duration-200 ease-out hover:-translate-y-0.5 hover:scale-[1.02] flex-shrink-0"><svg class="h-4 w-4" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M3 7v10a2 2 0 002 2h14a2 2 0 002-2V9a2 2 0 00-2-2h-6l-2-2H5A2 2 0 003 7z"/></svg>
<span class="max-w-[4rem] md:max-w-none truncate">Ko</span>
</a><span class="text-muted-foreground/50 flex-shrink-0"><svg class="h-4 w-4" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 5l7 7-7 7"/></svg></span>
<span class="text-foreground flex items-center gap-0.5 md:gap-1 font-medium min-w-0"><svg class="h-4 w-4" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 12h6m-6 4h6m2 5H7a2 2 0 01-2-2V5a2 2 0 012-2h5.586a1 1 0 01.707.293l5.414 5.414a1 1 0 01.293.707V19a2 2 0 01-2 2z"/></svg>
<span class="max-w-[8rem] md:max-w-[16rem] lg:max-w-none truncate">WKVQuant: Quantizing Weight and Key/Value Cache for Large Language Models Gains More</span></span></div></li></ol></nav><header class=mb-8><h1 class="text-foreground mb-4 text-3xl font-bold md:text-4xl">WKVQuant: Quantizing Weight and Key/Value Cache for Large Language Models Gains More</h1></header><article class="prose prose-neutral dark:prose-invert max-w-none"><p><a href=https://arxiv.org/abs/2402.12065>논문 링크</a></p><h1 id=q--이-논문을-아주-자세하게-읽고-논문의-강점과-독창적인-지점을-설명해주고-핵심-알고리즘을-예시-입력을-들어서-전체적인-과정을-설명해줘-추가적으로-논문의-한계점에-대해서도-알려줘>Q : 이 논문을 아주 자세하게 읽고 논문의 강점과 독창적인 지점을 설명해주고 핵심 알고리즘을 예시 입력을 들어서 전체적인 과정을 설명해줘 추가적으로 논문의 한계점에 대해서도 알려줘</h1><h3 id=강점과-독창적인-지점><strong>강점과 독창적인 지점</strong></h3><p><strong>WKVQuant</strong>은 대규모 언어 모델(LLM)의 메모리 사용 문제를 해결하기 위해 설계된 <strong>Post-Training Quantization (PTQ)</strong> 프레임워크입니다. 주요 강점과 독창적 특징은 다음과 같습니다:</p><ol><li><p><strong>효율성과 정확성의 균형</strong>:</p><ul><li>기존 방식(Weight-Only Quantization 또는 Weight-Activation Quantization)의 단점을 보완하며, 모델 정확도와 메모리 절약의 균형을 맞췄습니다.</li><li>특히, KV 캐시(Key/Value Cache)와 가중치(Weights)만을 선택적으로 양자화하는 전략으로 메모리 사용량을 대폭 줄이면서도 성능 저하를 최소화했습니다.</li></ul></li><li><p><strong>혁신적 양자화 기술</strong>:</p><ul><li><strong>Past-Only Quantization (POQ)</strong>: 현재 생성된 KV 값을 양자화하지 않고 원래 정밀도를 유지하면서 이전 단계의 KV 캐시만 양자화합니다. 이는 Attention 계산 정확도를 향상시킵니다.</li><li><strong>2D-Quantization</strong>: 채널 간 변동성을 줄이는 <strong>Static Channel Smoothing</strong>과 토큰 간 변동성을 처리하는 <strong>Dynamic Token-wise Quantization</strong>을 결합하여 양자화 오류를 줄였습니다.</li><li><strong>Cross-Block Reconstruction Regularization (CRR)</strong>: 블록 간 손실을 줄이기 위한 정규화를 도입하여 최종 결과와 더 가까운 오류 계산을 가능하게 했습니다.</li></ul></li><li><p><strong>실제 활용 가능성</strong>:</p><ul><li>LLaMA 및 LLaMA-2와 같은 대규모 모델에서 테스트한 결과, 높은 정확도와 메모리 절약을 동시에 달성하며, 기존 방법보다 우수한 성능을 보였습니다.</li></ul></li></ol><hr><h3 id=핵심-알고리즘-예시와-과정><strong>핵심 알고리즘: 예시와 과정</strong></h3><h4 id=1-past-only-quantization-poq>1. <strong>Past-Only Quantization (POQ)</strong></h4><ul><li><p><strong>입력 예시</strong>:</p><ul><li>현재 입력: &ldquo;The cat&rdquo;</li><li>이전 KV 캐시: [Quantized KV] 저장된 4-bit 정밀도의 값들</li></ul></li><li><p><strong>과정</strong>:</p><ol><li>현재 입력에서 생성된 Key/Value(KV) 값은 <strong>Full-Precision</strong>으로 유지.</li><li>이전 단계의 KV 캐시는 4-bit로 양자화된 값을 사용.</li><li>Attention 계산 시, 현재의 정밀도 높은 KV와 양자화된 과거 KV 값을 결합하여 예측.</li></ol></li><li><p><strong>결과</strong>:</p><ul><li>메모리 절약(과거 KV 캐시의 양자화)과 높은 계산 정확도(현재 KV의 Full-Precision 유지)를 동시에 달성.</li></ul></li></ul><h4 id=2-2d-quantization>2. <strong>2D-Quantization</strong></h4><ul><li><p><strong>입력 예시</strong>:</p><ul><li>KV 캐시 값의 분포: 채널 간 큰 변동성, 토큰 간 비균일성</li><li><code>Y = XW + B</code>로 표현된 Key/Value 계산</li></ul></li><li><p><strong>과정</strong>:</p><ol><li><strong>Static Channel Smoothing</strong>: 채널 값의 중심을 조정하고 스케일링하여 채널 간 변동성 감소.</li><li><strong>Dynamic Token-wise Quantization</strong>: 토큰의 평균값과 최대값에 따라 각 토큰 값을 조정.</li><li>값들을 그룹 단위(예: 128)로 세분화하여 세밀하게 양자화.</li></ol></li><li><p><strong>결과</strong>:</p><ul><li>양자화 오류 감소, 특히 큰 값의 아웃라이어에 대한 민감성 완화.</li></ul></li></ul><h4 id=3-cross-block-reconstruction-regularization-crr>3. <strong>Cross-Block Reconstruction Regularization (CRR)</strong></h4><ul><li><p><strong>입력 예시</strong>:</p><ul><li>블록 i에서의 출력 ( y_i ), 블록 ( i+k-1 )에서의 출력 ( \hat{y}_{i+k-1} )</li></ul></li><li><p><strong>과정</strong>:</p><ol><li>( k )개의 연속 블록에서 정량화된 출력과 정밀 출력 간의 차이를 계산.</li><li>평균 절대 오차(Mean Absolute Error, MAE)를 사용하여 최적화.</li></ol></li><li><p><strong>결과</strong>:</p><ul><li>네트워크 최종 출력과 더 밀접한 손실 계산을 통해 정밀도 향상.</li></ul></li></ul><hr><h3 id=논문의-한계><strong>논문의 한계</strong></h3><ol><li><p><strong>임시 활성화(Temporary Activations)의 미양자화</strong>:</p><ul><li>임시 활성화는 양자화되지 않아 메모리 사용량이 증가할 가능성이 있습니다. 특히, 대규모 배치나 긴 시퀀스에서 문제가 될 수 있습니다.</li></ul></li><li><p><strong>가속 하드웨어의 활용 부족</strong>:</p><ul><li>Nvidia의 INT8 가속과 같은 고속 계산 장치를 완전히 활용하지 못합니다.</li></ul></li><li><p><strong>최적화 시간 소요</strong>:</p><ul><li>CRR로 인한 최적화 시간 증가(7B 모델 약 3시간, 13B 모델 약 4시간)가 단점으로 작용할 수 있습니다.</li></ul></li></ol><hr><p><strong>결론적으로</strong>, WKVQuant은 대규모 언어 모델의 메모리 효율성과 정확성을 개선한 혁신적인 프레임워크이지만, 특정 활용 환경에서 제한이 있을 수 있습니다.</p><h1 id=q--논문의-핵심알고리즘을-예시를-들어-아주-자세하게-설명해주고-정리해-줘>Q : 논문의 핵심알고리즘을 예시를 들어 아주 자세하게 설명해주고 정리해 줘</h1><p>논문의 핵심 알고리즘인 <strong>WKVQuant</strong>의 주요 구성 요소는 다음 세 가지입니다. 각각의 과정과 예시를 들어 상세히 설명하고, 종합적으로 정리하겠습니다.</p><hr><h2 id=1-past-only-quantization-poq-1>1. <strong>Past-Only Quantization (POQ)</strong></h2><h3 id=알고리즘-개요><strong>알고리즘 개요</strong></h3><ul><li>현재 입력으로 생성된 Key/Value(KV) 값은 원본의 <strong>Full-Precision</strong> 값을 유지하고, 이전 단계에서 캐시된 KV 값만 양자화합니다.</li><li>Attention 계산에서 고정밀과 양자화된 값을 병합하여 메모리 사용을 줄이면서도 정확도를 유지합니다.</li></ul><h3 id=과정><strong>과정</strong></h3><h4 id=입력><strong>입력</strong></h4><ul><li>현재 입력: <code>"The cat"</code></li><li>이전 KV 캐시:<ul><li>Key: ([1.2, 0.8, -0.5, 1.7]) (Full-Precision)</li><li>Value: ([0.9, -0.3, 0.6, 0.2]) (Full-Precision)</li><li>양자화된 값 (4-bit): Key → ([1.0, 0.5, -0.5, 1.5]), Value → ([0.8, -0.2, 0.5, 0.1])</li></ul></li></ul><h4 id=단계><strong>단계</strong></h4><ol><li><p>현재 입력 <code>"The cat"</code>로 생성된 Key/Value는 **원본 정밀도(Full-Precision)**로 유지:</p><ul><li>Key: ([1.3, 0.7, -0.6, 1.6])</li><li>Value: ([0.95, -0.25, 0.65, 0.15])</li></ul></li><li><p>이전 단계의 KV 캐시는 4-bit로 양자화된 값을 사용:</p><ul><li>Key: ([1.0, 0.5, -0.5, 1.5])</li><li>Value: ([0.8, -0.2, 0.5, 0.1])</li></ul></li><li><p>Attention 계산 시, 양자화된 과거 KV와 현재의 Full-Precision KV 병합:</p><ul><li>Attention 값:
[
\text{Attention} = \text{Softmax}(QK^T)V
]
( Q ): 현재 Key, ( K^T ): 이전 Key (양자화된 값), ( V ): 이전 Value (양자화된 값)</li></ul></li></ol><h4 id=결과><strong>결과</strong></h4><ul><li>정확도를 유지하면서 메모리 사용량이 감소.</li><li>양자화된 이전 KV 캐시를 통해 저장 공간 최적화.</li></ul><hr><h2 id=2-two-dimensional-quantization-2d-quantization>2. <strong>Two-Dimensional Quantization (2D-Quantization)</strong></h2><h3 id=알고리즘-개요-1><strong>알고리즘 개요</strong></h3><ul><li><strong>Static Channel Smoothing</strong>: 채널 간 값의 중심을 정렬하고 스케일링하여 채널 간 변동성을 감소시킴.</li><li><strong>Dynamic Token-wise Quantization</strong>: 토큰별로 평균 및 최대값을 기준으로 정규화하여 아웃라이어의 영향을 완화.</li></ul><h3 id=과정-1><strong>과정</strong></h3><h4 id=입력-1><strong>입력</strong></h4><ul><li>Key/Value 캐시: [
Y = XW + B
]<ul><li>( Y ): KV 캐시, ( X ): 입력 토큰, ( W ): 가중치, ( B ): 바이어스</li><li>초기 값: ( Y = [[10, 200], [50, 100], [20, 400]] )</li></ul></li></ul><h4 id=단계-1><strong>단계</strong></h4><ol><li><p><strong>Static Channel Smoothing</strong>:</p><ul><li>채널별로 이동 매개변수 (\delta)와 스케일링 매개변수 (s)를 학습.</li><li>조정:
[
Y = (Y - \delta) \oslash s \quad \text{(스케일링)}
]</li><li>조정 후 ( Y ): [
Y_{\text{정렬}} = [[0.1, 0.2], [0.5, 0.1], [0.2, 0.4]]
]</li></ul></li><li><p><strong>Dynamic Token-wise Quantization</strong>:</p><ul><li>토큰 단위로 최대값, 평균값 계산.</li><li>정규화:
[
\text{Quantized}(Y) = \text{round}\left(\frac{Y - \text{mean}(Y)}{\text{max}(|Y - \text{mean}(Y)|)}\right)
]</li><li>조정 후 ( Y ): [
Y_{\text{정규화}} = [[0, 1], [1, 0], [0, 1]]
]</li></ul></li></ol><h4 id=결과-1><strong>결과</strong></h4><ul><li>KV 캐시의 양자화 오류 감소.</li><li>아웃라이어로 인한 양자화 오류를 완화.</li></ul><hr><h2 id=3-cross-block-reconstruction-regularization-crr-1>3. <strong>Cross-Block Reconstruction Regularization (CRR)</strong></h2><h3 id=알고리즘-개요-2><strong>알고리즘 개요</strong></h3><ul><li>여러 블록의 결과를 비교하여 전역적인 관점에서 최적의 양자화 매개변수를 학습.</li><li>기존의 MSE 기반 손실 대신, MAE(Mean Absolute Error)를 사용하여 아웃라이어의 영향을 완화.</li></ul><h3 id=과정-2><strong>과정</strong></h3><h4 id=입력-2><strong>입력</strong></h4><ul><li>블록 (i)의 출력: ( y_i )</li><li>블록 (i+k-1)의 출력: ( \hat{y}_{i+k-1} ) (양자화된 값)</li></ul><h4 id=단계-2><strong>단계</strong></h4><ol><li><p>블록 (i)부터 (i+k-1)까지 양자화된 출력 ( \hat{y}<em>{i+k-1} )와 원본 출력 ( y</em>{i+k-1} ) 비교.</p></li><li><p>손실 계산:
[
\text{Loss} = \text{MAE}(\hat{y}<em>{i+k-1}, y</em>{i+k-1})
]</p></li><li><p>손실에 따라 매개변수 ( \gamma, \beta, s, \delta ) 업데이트.</p></li></ol><h4 id=결과-2><strong>결과</strong></h4><ul><li>정량화 매개변수를 최적화하여 양자화 오류를 줄임.</li><li>더 높은 정밀도를 보장.</li></ul><hr><h3 id=정리><strong>정리</strong></h3><ul><li><strong>WKVQuant</strong>는 대규모 언어 모델의 메모리 사용량을 줄이면서 성능을 유지하는 혁신적인 PTQ 방법입니다.<ul><li><strong>Past-Only Quantization</strong>은 현재 KV를 원본 정밀도로 유지하며 과거 KV만 양자화해 메모리 효율성을 높임.</li><li><strong>2D-Quantization</strong>은 채널 및 토큰별 정렬로 양자화 오류를 최소화.</li><li><strong>CRR</strong>은 여러 블록을 통한 전역적 손실 계산으로 최적화된 양자화 매개변수를 학습.</li></ul></li></ul><p>이 방법은 모델의 성능과 효율성을 모두 극대화하는 강력한 양자화 기술로 평가됩니다.</p><h1 id=q--이-논문에서-사용하는-방법을-학습하기-위하여-어떤-데이터셋이-필요할까-그리고-어떻게-학습을-진행하면-될지-예시를-들어서-아주-자세하게-설명해줘>Q : 이 논문에서 사용하는 방법을 학습하기 위하여 어떤 데이터셋이 필요할까? 그리고 어떻게 학습을 진행하면 될지 예시를 들어서 아주 자세하게 설명해줘</h1><h3 id=wkvquant-학습에-필요한-데이터셋><strong>WKVQuant 학습에 필요한 데이터셋</strong></h3><p>이 논문에서 제안된 <strong>WKVQuant</strong>는 Post-Training Quantization (PTQ) 기법으로, 모델을 재학습하는 것이 아니라 양자화를 위한 매개변수를 최적화하는 과정에 중점을 둡니다. 학습에 필요한 데이터셋은 <strong>모델의 특성과 양자화 대상에 따라 선택</strong>되며, 다음과 같은 특징을 가진 데이터셋이 적합합니다.</p><h4 id=필요한-데이터셋의-특징><strong>필요한 데이터셋의 특징</strong></h4><ol><li><p><strong>다양한 토큰 분포</strong>:</p><ul><li>모델이 처리할 텍스트의 다양한 길이와 구조를 포함해야 합니다.</li><li>문장 길이, 주제, 언어적 복잡성이 다양한 데이터셋 필요.</li></ul></li><li><p><strong>대규모 텍스트 데이터</strong>:</p><ul><li>모델이 사용하는 어휘와 토큰 분포를 반영할 수 있는 데이터셋.</li><li>예: WikiText2, C4, OpenWebText.</li></ul></li><li><p><strong>캘리브레이션 데이터</strong>:</p><ul><li>학습 데이터는 모델의 양자화 매개변수를 최적화하기 위한 소규모 샘플로 구성.</li><li>WikiText2와 같은 데이터에서 <strong>128개의 랜덤 2048-토큰 샘플</strong>을 추출하여 활용.</li></ul></li></ol><hr><h3 id=학습-과정과-예시><strong>학습 과정과 예시</strong></h3><p>WKVQuant 학습 과정은 크게 3단계로 나뉩니다: <strong>캘리브레이션 데이터 준비, 양자화 매개변수 초기화, 매개변수 최적화 및 평가</strong>. 아래에 구체적인 학습 과정을 설명합니다.</p><h4 id=1-캘리브레이션-데이터-준비>1. <strong>캘리브레이션 데이터 준비</strong></h4><p>양자화 매개변수를 학습하기 위해 캘리브레이션 데이터셋을 준비합니다.</p><ul><li><p><strong>데이터셋 준비</strong>:</p><ul><li>WikiText2 데이터셋에서 2048-토큰 길이의 128개 샘플을 무작위로 선택.</li><li>예:<div class="code-block-container border-border bg-card my-6 overflow-hidden rounded-xl border shadow-sm transition-all duration-200 ease-out hover:-translate-y-0.5 hover:shadow-md"><div class="code-block-header bg-muted/30 border-border flex items-center justify-between border-b px-4 py-3"><div class="flex items-center gap-2"><div class="text-muted-foreground flex-shrink-0"><svg class="h-4 w-4" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M10 20l4-16m4 4 4 4-4 4M6 16l-4-4 4-4"/></svg></div><span class="text-muted-foreground text-sm font-medium">PLAINTEXT</span></div><div class="flex items-center gap-2"><button class="collapse-code-btn text-muted-foreground hover:text-primary hover:bg-primary/10 focus:ring-primary/20 flex items-center gap-1.5 rounded-md px-2 py-1 text-xs font-medium transition-all duration-200 ease-out focus:ring-2 focus:outline-none" data-code-id=code-0 data-default-state=expanded data-collapsed=false data-auto-collapse-lines=30 data-auto-collapse-height=400 data-collapsed-height=120 title=접기 aria-label=접기>
<span class=collapse-icon><svg class="h-3 w-3" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path fill="currentColor" d="M7.41 15.41 12 10.83l4.59 4.58L18 14l-6-6-6 6z"/></svg>
</span><span class="collapse-text hidden sm:inline">접기</span>
</button>
<button class="copy-code-btn text-muted-foreground hover:text-primary hover:bg-primary/10 focus:ring-primary/20 flex items-center gap-1.5 rounded-md px-2 py-1 text-xs font-medium transition-all duration-200 ease-out focus:ring-2 focus:outline-none" data-code-id=code-0 title=복사 aria-label=복사>
<span class=copy-icon><svg class="h-3 w-3" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M8 16H6a2 2 0 01-2-2V6a2 2 0 012-2h8a2 2 0 012 2v2m-6 12h8a2 2 0 002-2v-8a2 2 0 00-2-2h-8a2 2 0 00-2 2v8a2 2 0 002 2z"/></svg>
</span><span class="copy-text hidden sm:inline">복사</span></button></div></div><div class="code-block-content relative" id=code-0><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=ln>1</span><span class=cl>&#34;The cat sat on the mat. It was a sunny day, and the world felt calm. ...&#34;</span></span></code></pre></div><div class="collapse-overlay to-card/90 pointer-events-none absolute inset-0 bg-gradient-to-b from-transparent via-transparent opacity-0 transition-opacity duration-300"><div class="text-muted-foreground bg-card/80 border-border/50 hover:bg-primary/10 hover:text-primary hover:border-primary/30 absolute bottom-4 left-1/2 -translate-x-1/2 cursor-pointer rounded-full border px-3 py-1.5 text-xs backdrop-blur-sm transition-all duration-200">클릭하여 더 보기</div></div></div></div><script>(function(){const s="code-0",n=document.querySelector('.copy-code-btn[data-code-id="'+s+'"]'),t=document.querySelector('.collapse-code-btn[data-code-id="'+s+'"]'),e=document.getElementById(s);if(!e)return;if(n){const s=n.querySelector(".copy-icon"),t=n.querySelector(".copy-text");n.addEventListener("click",async function(){try{let o="";const i=e.querySelector(".lntd:last-child code");if(i)o=i.textContent||i.innerText;else{const t=e.querySelector("code");if(t){const e=t.querySelector(".ln");if(e){const e=t.querySelectorAll(".cl");if(e.length>0)o=Array.from(e).map(e=>{const t=e.textContent||e.innerText;return t.replace(/\n+$/,"")}).join(`
`).replace(/\n+$/,"");else{const e=t.textContent||t.innerText;o=e.replace(/^\d+/gm,"").replace(/^\s+/gm,"")}}else o=t.textContent||t.innerText}else o=e.textContent||e.innerText}o=o.trim(),await navigator.clipboard.writeText(o),s.innerHTML=`
  <svg class="h-3 w-3"
    fill="none"
    stroke="currentColor"
    viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M5 13l4 4L19 7" />
</svg>`,t&&(t.textContent="복사됨"),n.classList.add("text-green-600"),setTimeout(()=>{s.innerHTML=`
  <svg class="h-3 w-3"
    fill="none"
    stroke="currentColor"
    viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M8 16H6a2 2 0 01-2-2V6a2 2 0 012-2h8a2 2 0 012 2v2m-6 12h8a2 2 0 002-2v-8a2 2 0 00-2-2h-8a2 2 0 00-2 2v8a2 2 0 002 2z" />
</svg>`,t&&(t.textContent="복사"),n.classList.remove("text-green-600")},2e3)}catch(o){console.error("复制失败:",o);const s=document.createRange(),i=e.querySelector("code")||e;s.selectNodeContents(i);const n=window.getSelection();n.removeAllRanges(),n.addRange(s),t&&(t.textContent="선택됨"),setTimeout(()=>{t&&(t.textContent="복사"),n.removeAllRanges()},2e3)}})}if(t){const d=t.querySelector(".collapse-icon"),c=t.querySelector(".collapse-text"),n=e.querySelector(".collapse-overlay");let s=e.querySelector("pre.chroma");s||(s=e.querySelector("pre"));const m=t.dataset.defaultState||"expanded",f=t.dataset.collapsed==="true",u=parseInt(t.dataset.autoCollapseLines)||30,h=parseInt(t.dataset.autoCollapseHeight)||400,p=parseInt(t.dataset.collapsedHeight)||120;let l=!1;function i(){const e=f||m==="collapsed"||a();e&&o(!0,!1)}function a(){if(s){const e=s.querySelectorAll(".line, .cl"),t=s.offsetHeight;return e.length>u||t>h}const t=e.offsetHeight;if(t>h)return!0;const n=e.textContent||e.innerText||"",o=n.split(`
`).length;return o>u}function o(s,o=!0){if(!n)return;l=s,s?(e.style.maxHeight=p+"px",e.style.overflow="hidden",n.style.opacity="1",n.style.pointerEvents="auto",d.innerHTML=`
  <svg class="h-3 w-3"
    fill="none"
    stroke="currentColor"
    viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 9l-7 7-7-7" />
</svg>`,c&&(c.textContent="펼치기"),t.title="펼치기"):(e.style.maxHeight="",e.style.overflow="",n.style.opacity="0",n.style.pointerEvents="none",d.innerHTML=`
  <svg class="h-3 w-3"
    fill="none"
    stroke="currentColor"
    viewBox="0 0 24 24"><path fill="currentColor" d="M7.41 15.41L12 10.83l4.59 4.58L18 14l-6-6l-6 6z"/></svg>`,c&&(c.textContent="접기"),t.title="접기"),o&&(e.style.transition="max-height 0.3s ease-out",setTimeout(()=>{e.style.transition=""},300))}function r(){o(!l,!0)}t.addEventListener("click",r),n&&n.addEventListener("click",()=>{l&&o(!1,!0)}),i()}})()</script></li></ul></li><li><p><strong>목적</strong>:</p><ul><li>가중치 및 KV 캐시의 분포를 모델링하여 매개변수를 학습.</li></ul></li></ul><hr><h4 id=2-양자화-매개변수-초기화>2. <strong>양자화 매개변수 초기화</strong></h4><p>양자화를 위한 매개변수 (\gamma), (\beta), (s), (\delta)를 초기화합니다.</p><ul><li><p><strong>초기화 방법</strong>:</p><ul><li>각 채널 및 토큰별 최대값, 평균값 계산.</li><li>초기 값:<ul><li>(\gamma = \text{max}(\text{Weights}))</li><li>(\beta = \text{min}(\text{Weights}))</li><li>(s = \text{max}(|Y|))</li><li>(\delta = \text{mean}(Y))</li></ul></li></ul></li><li><p><strong>초기화 후 예시</strong>:</p><ul><li>Key/Value 캐시의 채널별 값: ([10, 200], [50, 100], [20, 400])</li><li>초기 매개변수:<ul><li>(s = 200), (\delta = 90)</li></ul></li></ul></li></ul><hr><h4 id=3-매개변수-최적화>3. <strong>매개변수 최적화</strong></h4><p>Cross-block Reconstruction Regularization (CRR) 기법을 사용해 매개변수를 최적화합니다.</p><h5 id=단계-3><strong>단계</strong></h5><ol><li><p><strong>출력 계산</strong>:</p><ul><li>각 블록의 원본 출력 (y_i)와 양자화된 출력 (\hat{y}_i) 비교.</li><li>예:<ul><li>원본 출력 (y_i = [0.9, 0.3, -0.2])</li><li>양자화된 출력 (\hat{y}_i = [1.0, 0.2, -0.3])</li></ul></li></ul></li><li><p><strong>손실 계산</strong>:</p><ul><li>Mean Absolute Error (MAE) 손실:
[
\text{Loss} = \text{MAE}(\hat{y}<em>{i+k-1}, y</em>{i+k-1})
]</li><li>예:
[
\text{Loss} = \frac{|1.0 - 0.9| + |0.2 - 0.3| + |-0.3 - (-0.2)|}{3} = 0.1
]</li></ul></li><li><p><strong>매개변수 업데이트</strong>:</p><ul><li>AdamW 옵티마이저를 사용해 매개변수 업데이트.</li><li>학습률 설정: ( \text{lr}<em>{s,\delta} = 5e^{-4} ), ( \text{lr}</em>{\gamma,\beta} = 1e^{-2} ).</li></ul></li><li><p><strong>최적화 반복</strong>:</p><ul><li>한 번의 업데이트 후, 동일한 데이터로 5 에포크 반복.</li></ul></li></ol><hr><h4 id=학습-완료-후-평가><strong>학습 완료 후 평가</strong></h4><p>최적화된 모델을 평가하여 성능과 메모리 절감을 확인합니다.</p><ul><li><p><strong>평가 데이터</strong>:</p><ul><li>WikiText2, PTB(Penn Treebank), C4 등의 데이터셋 사용.</li><li>Perplexity(PPL)와 LongBench 점수를 활용하여 성능 비교.</li></ul></li><li><p><strong>결과</strong>:</p><ul><li>W4KV4(가중치 및 KV 캐시 양자화)는 원본(FP16) 모델에 근접한 정확도를 유지하면서 메모리 사용량을 대폭 절감.</li></ul></li></ul><hr><h3 id=종합-정리><strong>종합 정리</strong></h3><h4 id=학습-프로세스-요약><strong>학습 프로세스 요약</strong></h4><ol><li><strong>캘리브레이션 데이터 준비</strong>: WikiText2 데이터셋에서 샘플을 추출.</li><li><strong>초기 매개변수 설정</strong>: 채널 및 토큰의 분포를 기반으로 초기화.</li><li><strong>CRR을 사용한 최적화</strong>: MAE 손실을 통해 양자화 매개변수 업데이트.</li></ol><h4 id=결과-3><strong>결과</strong></h4><ul><li>WKVQuant는 <strong>KV 캐시와 가중치를 양자화</strong>하여 메모리를 절약하고, <strong>최적화된 양자화 매개변수</strong>를 통해 모델의 정확도를 유지합니다.</li><li>학습은 비교적 적은 데이터와 계산으로 수행되므로 실제 환경에서 효율적으로 적용 가능합니다.</li></ul><h1 id=q--이-논문에서-제시한-결과를-자세하게-보고-다른-방법론에-비하여-특출난-점과-논문에서-제기하는-어떠한-방법이-이러한-결과를-도출하게-되었는지-논문에서-제시하는-이유와-너의-생각을-알려줘>Q : 이 논문에서 제시한 결과를 자세하게 보고 다른 방법론에 비하여 특출난 점과 논문에서 제기하는 어떠한 방법이 이러한 결과를 도출하게 되었는지 논문에서 제시하는 이유와 너의 생각을 알려줘</h1><h3 id=논문에서-제시한-결과><strong>논문에서 제시한 결과</strong></h3><p>이 논문은 <strong>WKVQuant</strong>가 대규모 언어 모델(LLMs)의 메모리 사용량을 줄이면서 높은 정확도를 유지하는 데 뛰어난 성능을 발휘한다고 주장합니다. 주요 결과는 다음과 같습니다:</p><hr><h4 id=1-정확도와-메모리-효율성><strong>1. 정확도와 메모리 효율성</strong></h4><ul><li>**WKVQuant (W4KV4)**는 FP16 (Full-Precision)과 비슷한 정확도를 유지하면서도 메모리 소비를 크게 줄였습니다.</li><li>다른 방법론 (OmniQuant의 W4A4 등)에 비해 높은 정확도를 유지합니다.</li></ul><table><thead><tr><th><strong>모델</strong></th><th><strong>Method</strong></th><th><strong>Longtext avg</strong></th><th><strong>Zero-shot avg</strong></th><th><strong>Memory (GB)</strong></th></tr></thead><tbody><tr><td>FP16</td><td>-</td><td>34.12</td><td>61.32%</td><td>27.1</td></tr><tr><td>GPTQ (W4)</td><td>-</td><td>34.06</td><td>60.55%</td><td>8.0</td></tr><tr><td>OmniQuant (W4A4)</td><td>-</td><td>16.35</td><td>47.46%</td><td>6.8</td></tr><tr><td><strong>WKVQuant (W4KV4)</strong></td><td>-</td><td>32.52</td><td>60.34%</td><td>6.8</td></tr></tbody></table><ul><li><strong>Longtext avg</strong>는 긴 입력 텍스트에서의 성능 평가이며, FP16에 비해 약간의 정확도 감소가 있지만 <strong>OmniQuant보다 월등히 우수</strong>합니다.</li><li><strong>Memory</strong>는 동일한 메모리 소비량(6.8GB)을 유지하며 정확도를 극대화한 것이 특징입니다.</li></ul><hr><h4 id=2-다른-방법론과의-비교><strong>2. 다른 방법론과의 비교</strong></h4><ul><li><strong>GPTQ (W4)</strong>: 높은 정확도를 유지하지만 KV 캐시를 양자화하지 않아 메모리 절약 효과가 부족합니다.</li><li><strong>OmniQuant (W4A4)</strong>: 메모리 절약 효과는 크지만, 활성화(Activation) 양자화로 인해 정확도가 크게 감소.</li><li><strong>WKVQuant (W4KV4)</strong>:<ul><li>정확도: FP16에 근접하며 GPTQ를 초월.</li><li>메모리 사용량: OmniQuant 수준으로 절약.</li></ul></li></ul><hr><h3 id=특출난-점><strong>특출난 점</strong></h3><h4 id=1-past-only-quantization-poq의-효과><strong>1. Past-Only Quantization (POQ)의 효과</strong></h4><ul><li><p><strong>논문에서 제시하는 이유</strong>:</p><ul><li>기존 양자화 방법에서 현재의 Key/Value 값을 양자화하면 Attention 계산 정확도가 크게 손상됩니다.</li><li>POQ는 현재 값은 Full-Precision 상태로 유지하고 과거 값만 양자화하여, 메모리 절약과 정확도 모두를 달성.</li></ul></li><li><p><strong>내 생각</strong>:</p><ul><li>POQ는 매우 설득력 있는 방식으로, 양자화의 주요 문제인 <strong>계산 정확도의 손실</strong>을 최소화하면서 <strong>메모리 효율성</strong>을 극대화합니다.</li><li>특히, LLMs의 Attention 메커니즘이 Key/Value 계산에 매우 민감하므로, POQ는 성능 저하 없이 양자화를 구현하는 효과적인 접근 방식입니다.</li></ul></li></ul><hr><h4 id=2-two-dimensional-quantization-2d-quantization-1><strong>2. Two-Dimensional Quantization (2D-Quantization)</strong></h4><ul><li><p><strong>논문에서 제시하는 이유</strong>:</p><ul><li>KV 캐시의 채널 간 및 토큰 간 값 변동성이 매우 크기 때문에, 단일한 양자화 매개변수를 사용하는 경우 양자화 오류가 증가.</li><li>2D-Quantization은 채널 정렬(Static Channel Smoothing)과 토큰 단위 동적 양자화(Dynamic Token-wise Quantization)를 결합하여 오류를 최소화.</li></ul></li><li><p><strong>내 생각</strong>:</p><ul><li>LLM에서 Outlier(극단 값)의 문제를 해결하려는 기존 방식들(예: SmoothQuant)과 비교할 때, 2D-Quantization은 보다 세밀하게 값을 조정하여 <strong>양자화 오류를 체계적으로 줄이는 방식</strong>입니다.</li><li>특히, Fine-grained Quantization(그룹 단위로 매개변수를 조정)이 추가적으로 정밀도를 보장하는 중요한 요소로 보입니다.</li></ul></li></ul><hr><h4 id=3-cross-block-reconstruction-regularization-crr의-기여><strong>3. Cross-block Reconstruction Regularization (CRR)의 기여</strong></h4><ul><li><p><strong>논문에서 제시하는 이유</strong>:</p><ul><li>기존 방법들은 양자화된 출력과 원본 출력 간의 지역적 손실(예: 블록 단위의 MSE)을 계산했지만, 이는 최종 모델 출력과의 차이를 적절히 반영하지 못함.</li><li>CRR은 여러 블록의 출력 간 전역적 손실을 계산하고, MAE를 사용해 아웃라이어로 인한 오류를 줄임.</li></ul></li><li><p><strong>내 생각</strong>:</p><ul><li>CRR은 양자화된 출력이 모델의 <strong>최종 성능과 더 직접적으로 연결</strong>되도록 하는 중요한 정규화 방식입니다.</li><li>특히, <strong>MAE</strong>를 사용해 아웃라이어의 영향을 완화한 점은 대규모 모델의 특성을 잘 이해한 설계로 보입니다.</li></ul></li></ul><hr><h3 id=왜-이러한-결과가-도출되었는가><strong>왜 이러한 결과가 도출되었는가?</strong></h3><ol><li><strong>POQ</strong>: 현재 값의 Full-Precision 유지로 Attention 계산의 핵심 정보를 보존.</li><li><strong>2D-Quantization</strong>: KV 캐시의 특성을 반영하여 채널 및 토큰 간 양자화 오류를 최소화.</li><li><strong>CRR</strong>: 전역적 손실 계산과 아웃라이어 완화로 정밀한 양자화 매개변수 학습.</li></ol><hr><h3 id=내-생각><strong>내 생각</strong></h3><ul><li>이 논문은 대규모 모델의 양자화에서 <strong>현실적이고 효과적인 해결책</strong>을 제시했다고 생각합니다.</li><li>특히, <strong>메모리 효율성과 정확성 간의 균형</strong>을 맞춘 점에서 GPTQ나 OmniQuant 같은 기존 방법론보다 우수합니다.</li><li>다만, POQ로 인해 임시 활성화(Temporary Activations)가 양자화되지 않는 부분은 메모리 사용에서 한계를 남길 수 있지만, 대부분의 LLM 사용 사례에서는 큰 문제가 되지 않을 것입니다.</li></ul><hr><h3 id=결론><strong>결론</strong></h3><p><strong>WKVQuant</strong>는 <strong>대규모 언어 모델의 메모리 사용량을 최소화하면서 정확도를 유지</strong>하는 데 뛰어난 기법입니다. POQ, 2D-Quantization, CRR의 조합이 이러한 결과를 가능하게 했으며, 실제 적용 가능한 혁신적인 방법론으로 평가됩니다.</p><h1 id=q--이-논문의-입력데이터와-추론-과정에-대해서-예시를-들어-아주-자세하게-설명해-주겠니-추가적으로-모델아키텍처의-구성-및-모델을-구성하는-연산과-메모리-요구량-컴퓨팅-요구량-대해서도-설명해줘>Q : 이 논문의 입력데이터와 추론 과정에 대해서 예시를 들어 아주 자세하게 설명해 주겠니? 추가적으로 모델아키텍처의 구성 및 모델을 구성하는 연산과 메모리 요구량 컴퓨팅 요구량 대해서도 설명해줘</h1><h3 id=1-입력-데이터와-추론-과정><strong>1. 입력 데이터와 추론 과정</strong></h3><p>이 논문에서 제안된 <strong>WKVQuant</strong>는 대규모 언어 모델(LLM)에서 양자화된 Key/Value(KV) 캐시를 활용합니다. 이를 기반으로 입력 데이터와 추론 과정을 자세히 설명합니다.</p><hr><h4 id=입력-데이터><strong>입력 데이터</strong></h4><ul><li><p><strong>입력 형식</strong>:</p><ul><li>토큰 시퀀스, 예: <code>"The cat sits on the mat."</code></li><li>모델에 입력되는 시퀀스는 토큰화된 숫자 배열로 변환됩니다.<ul><li>예: [101, 203, 402, 78, 512] (각 숫자는 어휘에 매핑된 토큰 ID)</li></ul></li></ul></li><li><p><strong>특징</strong>:</p><ul><li>입력 데이터의 길이(시퀀스 길이)가 중요하며, 메모리 사용량은 길이에 따라 선형적으로 증가.</li><li>예: 시퀀스 길이가 2048인 경우, 각 토큰의 Key와 Value를 저장해야 함.</li></ul></li></ul><hr><h4 id=추론-과정><strong>추론 과정</strong></h4><h5 id=1-입력-처리><strong>1) 입력 처리</strong></h5><ul><li>입력 시퀀스 (X = {x_1, x_2, &mldr;, x_T})를 모델에 전달.<ul><li>예: 입력 <code>"The cat"</code> → 토큰 시퀀스 [101, 203].</li></ul></li></ul><h5 id=2-transformer-블록-계산><strong>2) Transformer 블록 계산</strong></h5><ul><li>각 블록은 다음 연산을 수행합니다:<ol><li><p><strong>Attention Mechanism</strong>:</p><ul><li>Key ((K)), Value ((V)), Query ((Q)) 계산.
[
Q = XW_Q, \quad K = XW_K, \quad V = XW_V
]
예:<ul><li>(W_Q, W_K, W_V): 선형 변환을 위한 가중치.</li><li>(Q = [0.8, 0.5]), (K = [0.7, 0.6]), (V = [0.4, 0.3]).</li></ul></li></ul></li><li><p><strong>Scaled Dot-Product Attention</strong>:
[
\text{Attention}(Q, K, V) = \text{Softmax}\left(\frac{QK^T}{\sqrt{d}}\right)V
]
예:</p><ul><li>(QK^T = [0.56]), Softmax 결과 = ([1.0]), 출력 = (V = [0.4, 0.3]).</li></ul></li><li><p><strong>Feedforward Layer</strong>:</p><ul><li>출력에 비선형 변환 적용.
[
\text{Output} = \text{ReLU}(XW_1 + b_1)W_2 + b_2
]</li></ul></li></ol></li></ul><h5 id=3-keyvalue-캐시-관리><strong>3) Key/Value 캐시 관리</strong></h5><ul><li><p><strong>Prefill 단계</strong> (초기 입력 처리):</p><ul><li>입력 데이터의 Key와 Value를 생성하여 캐시에 저장.</li><li>예: KV 캐시 = ([K: 0.7, 0.6], [V: 0.4, 0.3]) (양자화).</li></ul></li><li><p><strong>Decode 단계</strong> (새 토큰 생성):</p><ul><li>이전 Key/Value 캐시를 활용하여 새로운 입력 (Q)와 결합해 계산.</li><li>예:<ul><li>현재 (Q = [0.9, 0.4]), 과거 (K)와 (V) 사용.</li></ul></li></ul></li></ul><h5 id=4-출력-생성><strong>4) 출력 생성</strong></h5><ul><li>모델의 최종 출력은 다음 토큰의 확률 분포:
[
\text{Output Probabilities} = \text{Softmax}(WX + b)
]</li><li>예: 확률 분포 ([0.1, 0.7, 0.2]) → 토큰 203(&ldquo;cat&rdquo;) 생성.</li></ul><hr><h3 id=2-모델-아키텍처-구성><strong>2. 모델 아키텍처 구성</strong></h3><h4 id=1-transformer-블록><strong>1) Transformer 블록</strong></h4><ul><li><strong>구성 요소</strong>:<ul><li>Multi-Head Attention: Key, Query, Value를 사용한 주요 연산.</li><li>Feedforward Layer: 비선형 변환을 수행하는 MLP.</li><li>Layer Normalization: 안정적 학습을 위한 정규화.</li></ul></li></ul><h4 id=2-wkvquant의-변형><strong>2) WKVQuant의 변형</strong></h4><ul><li>기존 Transformer 모델에 KV 캐시 양자화를 추가:<ol><li><strong>Past-Only Quantization (POQ)</strong>: 현재 (K, V)는 Full-Precision 유지, 이전 (K, V)만 양자화.</li><li><strong>Two-Dimensional Quantization (2D-Quantization)</strong>: KV 캐시의 채널 및 토큰 간 정밀도 조정.</li></ol></li></ul><hr><h3 id=3-연산-및-메모리-요구량><strong>3. 연산 및 메모리 요구량</strong></h3><h4 id=1-주요-연산><strong>1) 주요 연산</strong></h4><ul><li><p><strong>Attention 계산</strong>:</p><ul><li>(QK^T) 연산은 (O(T^2d)) (시퀀스 길이 (T), 차원 (d)).</li><li>메모리 사용량은 (T \times d)에 비례.</li></ul></li><li><p><strong>양자화 연산</strong>:</p><ul><li>양자화된 (K, V)는 (4)-bit로 저장되므로 메모리 요구량 대폭 감소.</li></ul></li></ul><h4 id=2-메모리-요구량><strong>2) 메모리 요구량</strong></h4><ul><li>LLaMA-13B 모델 (FP16, 2048-토큰 입력):<ul><li><strong>Weights</strong>: 13B * 2 bytes = 26GB.</li><li><strong>KV Cache</strong>: 2 * (2048 \times d) = 약 2.6GB (FP16 기준).</li><li><strong>양자화 후</strong>:<ul><li>KV 캐시는 (2048 \times d)의 4-bit 값으로 저장 → 약 0.65GB로 감소.</li></ul></li></ul></li></ul><h4 id=3-컴퓨팅-요구량><strong>3) 컴퓨팅 요구량</strong></h4><ul><li><p><strong>Attention 중심 병목</strong>:</p><ul><li>Scaled Dot-Product Attention에서의 (QK^T) 연산이 병목.</li><li>양자화로 인해 KV 캐시 메모리 접근 시간이 단축되어 병목 완화.</li></ul></li><li><p><strong>WKVQuant의 영향</strong>:</p><ul><li>POQ와 2D-Quantization을 사용하여 계산 정확도는 유지하면서 메모리 접근 및 전송 속도를 향상.</li></ul></li></ul><hr><h3 id=종합><strong>종합</strong></h3><ol><li><p><strong>입력 데이터와 추론 과정</strong>:</p><ul><li>입력 토큰은 Transformer 블록을 거쳐 출력 확률로 변환되며, KV 캐시를 통해 효율적으로 연산.</li><li>POQ로 현재 KV 값을 Full-Precision 상태로 유지하여 정확도를 보장.</li></ul></li><li><p><strong>모델 아키텍처</strong>:</p><ul><li>WKVQuant는 기존 Transformer 구조에 KV 캐시 양자화와 추가 최적화를 결합.</li></ul></li><li><p><strong>연산 및 메모리 효율성</strong>:</p><ul><li>KV 캐시 양자화로 메모리 사용량을 기존 대비 4배 감소.</li><li>Attention 병목 완화를 통해 추론 속도 향상.</li></ul></li></ol><h1 id=q--이-논문의-한계를-극복하기-위한-방법으로-어떤-연구흐름이-있는지-정리해서-자세하게-설명해-줘>Q : 이 논문의 한계를 극복하기 위한 방법으로 어떤 연구흐름이 있는지 정리해서 자세하게 설명해 줘</h1><h3 id=1-논문의-한계><strong>1. 논문의 한계</strong></h3><p>논문에서 제시한 WKVQuant의 한계는 다음과 같습니다:</p><ol><li><p><strong>임시 활성화(Temporary Activations)의 미양자화</strong>:</p><ul><li>POQ 전략은 Key/Value 캐시만 양자화하고 임시 활성화는 Full-Precision으로 유지.</li><li>긴 시퀀스나 대규모 배치에서 임시 활성화의 메모리 사용량 증가 가능성.</li><li>이는 메모리 제한이 있는 환경에서 문제가 될 수 있음.</li></ul></li><li><p><strong>하드웨어 가속 최적화 부족</strong>:</p><ul><li>임시 활성화를 양자화하지 않음으로써 Nvidia INT8과 같은 고속 계산 유닛의 사용 제한.</li><li>결과적으로 계산 효율성에서 손실이 있을 가능성.</li></ul></li><li><p><strong>CRR(Cross-Block Reconstruction Regularization)의 시간 비용</strong>:</p><ul><li>CRR을 활용한 매개변수 최적화는 학습 시간 증가를 초래.</li><li>13B 모델 기준 약 4시간의 추가 최적화 시간이 필요.</li></ul></li></ol><hr><h3 id=2-한계를-극복하기-위한-연구-흐름><strong>2. 한계를 극복하기 위한 연구 흐름</strong></h3><p>이러한 한계를 극복하기 위해 다음과 같은 연구 흐름이 가능합니다:</p><hr><h4 id=1-임시-활성화의-양자화><strong>1) 임시 활성화의 양자화</strong></h4><ul><li><strong>문제</strong>:<ul><li>임시 활성화를 양자화하지 않아 메모리 사용량이 여전히 높음.</li></ul></li><li><strong>해결 가능성</strong>:<ul><li><strong>Dynamic Precision Quantization</strong>:<ul><li>임시 활성화의 중요도에 따라 가변적인 정밀도를 적용.</li><li>중요도가 낮은 활성화에는 8-bit 또는 4-bit 정밀도를 적용.</li></ul></li><li><strong>Adaptive Quantization</strong>:<ul><li>임시 활성화의 민감도를 동적으로 평가하여 양자화 수준을 조정.</li><li>예: Layer-wise Sensitivity Analysis를 통해 민감도를 분석.</li></ul></li></ul></li><li><strong>관련 연구</strong>:<ul><li>ZeroQuant (Yao et al., 2022): Fine-grained 양자화를 활용하여 활성화와 가중치를 동시에 양자화.</li></ul></li></ul><hr><h4 id=2-하드웨어-가속-최적화><strong>2) 하드웨어 가속 최적화</strong></h4><ul><li><strong>문제</strong>:<ul><li>POQ는 Full-Precision 연산이 포함되어 INT8과 같은 가속 유닛 사용이 제한됨.</li></ul></li><li><strong>해결 가능성</strong>:<ul><li><strong>Low-bit Arithmetic Compatibility</strong>:<ul><li>INT8 가속 유닛에서 POQ를 활용할 수 있도록 현재 값의 양자화를 정밀하게 조정.</li></ul></li><li><strong>Unified Quantization Framework</strong>:<ul><li>가중치, KV 캐시, 임시 활성화를 동일한 비트 폭으로 양자화해 하드웨어 친화적 설계.</li></ul></li></ul></li><li><strong>관련 연구</strong>:<ul><li>SmoothQuant (Xiao et al., 2022): 활성화와 가중치 간의 양자화 변환을 통해 하드웨어 가속 호환성 향상.</li><li>GPTQ (Frantar et al., 2022): INT8 환경에서의 연산 최적화를 목표로 설계된 PTQ 기법.</li></ul></li></ul><hr><h4 id=3-crr의-시간-비용-감소><strong>3) CRR의 시간 비용 감소</strong></h4><ul><li><strong>문제</strong>:<ul><li>CRR을 통한 매개변수 최적화가 학습 시간 증가를 초래.</li></ul></li><li><strong>해결 가능성</strong>:<ul><li><strong>Gradient-Free Optimization</strong>:<ul><li>CRR 대신 비경사 기반 최적화 기법(예: 진화 알고리즘) 활용.</li></ul></li><li><strong>Parallel Block Optimization</strong>:<ul><li>CRR을 병렬화하여 여러 블록에서 동시에 최적화 수행.</li></ul></li><li><strong>Reduced Block-wise Sampling</strong>:<ul><li>최적화에 필요한 블록 샘플 수를 줄여 계산 비용 감소.</li></ul></li></ul></li><li><strong>관련 연구</strong>:<ul><li>OmniQuant (Shao et al., 2023): 계층 간 병렬 최적화를 활용해 양자화 시간을 단축.</li><li>RPTQ (Yuan et al., 2023): 양자화 매개변수를 클러스터링하여 최적화 속도 향상.</li></ul></li></ul><hr><h4 id=4-모델-구조-최적화><strong>4) 모델 구조 최적화</strong></h4><ul><li><strong>문제</strong>:<ul><li>Attention 메커니즘의 계산 비용이 높고 메모리 사용량이 시퀀스 길이에 따라 선형적으로 증가.</li></ul></li><li><strong>해결 가능성</strong>:<ul><li><strong>Sparse Attention Mechanism</strong>:<ul><li>중요한 토큰 간의 상호작용만 계산하여 연산 비용 감소.</li></ul></li><li><strong>Efficient Transformer Variants</strong>:<ul><li>Linear Transformer나 Performer와 같은 효율적인 구조를 활용.</li></ul></li></ul></li><li><strong>관련 연구</strong>:<ul><li>BigBird (Zaheer et al., 2020): 희소 Attention으로 긴 시퀀스를 처리.</li><li>FlashAttention (Dao et al., 2022): 메모리 사용량을 줄이고 계산 효율성을 향상.</li></ul></li></ul><hr><h3 id=3-결론-및-새로운-연구-방향><strong>3. 결론 및 새로운 연구 방향</strong></h3><ol><li><p><strong>임시 활성화 양자화</strong>:</p><ul><li>임시 활성화 양자화의 적용은 메모리 사용량 문제를 해결할 중요한 방향.</li></ul></li><li><p><strong>하드웨어 친화적 양자화</strong>:</p><ul><li>POQ와 같은 정밀도 유지 기법을 INT8 가속과 통합하는 연구가 필요.</li></ul></li><li><p><strong>CRR 최적화 시간 감소</strong>:</p><ul><li>병렬화 또는 경량화된 정규화 기법을 통해 최적화 시간을 단축.</li></ul></li><li><p><strong>모델 구조 개선</strong>:</p><ul><li>Sparse Attention 또는 Linear Transformer 기법으로 계산 비용을 줄이는 방향이 유망.</li></ul></li></ol><hr><h3 id=요약><strong>요약</strong></h3><ul><li>WKVQuant는 혁신적인 양자화 프레임워크지만, 임시 활성화 양자화, 하드웨어 가속 최적화, CRR 시간 비용 등의 문제가 여전히 존재.</li><li>이를 해결하기 위해 Dynamic Precision, Sparse Attention, Parallel Optimization 같은 기법이 적용될 수 있으며, 관련 연구 흐름이 이미 활발히 진행 중.</li><li>이러한 방향은 WKVQuant를 더욱 확장하고, 메모리 및 계산 효율성을 극대화할 잠재력을 제공합니다.</li></ul></article></main><footer class="mx-auto max-w-4xl px-4 py-8"><div class="px-6 py-6"><nav class=mb-6><div class="flex flex-wrap items-center justify-center gap-1"><a href=/index.xml class="nav-link hover:text-primary hover:bg-primary/10 text-muted-foreground flex items-center gap-2 rounded-lg px-4 py-2 text-sm font-medium transition-all duration-300 hover:scale-105"><svg class="h-5 w-5" fill="none" stroke="currentColor" viewBox="0 0 24 24" aria-label="RSS Feed"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M6 5c7.18.0 13 5.82 13 13M6 11a7 7 0 017 7m-6 0a1 1 0 11-2 0 1 1 0 012 0z"/></svg>
<span>RSS Feed</span></a></div></nav><div class="border-border mb-6 border-t"></div><div class="flex flex-col items-center justify-between gap-4 md:flex-row"><div class="text-muted-foreground text-sm"><p>&copy; 2025 Jaehun's Blog.
모든 권리 보유.</p></div><div class="flex items-center gap-3"><a href=https://github.com/ryujaehun target=_blank rel="noopener noreferrer" class="text-muted-foreground hover:text-primary focus:ring-primary/20 rounded-lg p-1 transition-all duration-300 ease-out hover:scale-110 focus:ring-2 focus:outline-none" title=GitHub aria-label=GitHub><svg class="h-6 w-6" fill="none" stroke="currentColor" viewBox="0 0 24 24" aria-label="GitHub"><g fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2"><path d="M15 22v-4a4.8 4.8.0 00-1-3.5c3 0 6-2 6-5.5.08-1.25-.27-2.48-1-3.5.28-1.15.28-2.35.0-3.5.0.0-1 0-3 1.5-2.64-.5-5.36-.5-8 0C6 2 5 2 5 2c-.3 1.15-.3 2.35.0 3.5A5.4 5.4.0 004 9c0 3.5 3 5.5 6 5.5-.39.49-.68 1.05-.85 1.65S8.93 17.38 9 18v4"/><path d="M9 18c-4.51 2-5-2-7-2"/></g></svg>
</a><a href=https://www.linkedin.com/in/jaehunryu/ target=_blank rel="noopener noreferrer" class="text-muted-foreground hover:text-primary focus:ring-primary/20 rounded-lg p-1 transition-all duration-300 ease-out hover:scale-110 focus:ring-2 focus:outline-none" title=Linkedin aria-label=Linkedin><svg class="h-6 w-6" fill="none" stroke="currentColor" viewBox="0 0 24 24" aria-label="Linkedin"><g fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2"><path d="M16 8a6 6 0 016 6v7h-4v-7a2 2 0 00-2-2 2 2 0 00-2 2v7h-4v-7a6 6 0 016-6M2 9h4v12H2z"/><circle cx="4" cy="4" r="2"/></g></svg>
</a><a href=mailto:jaehunryu@icloud.com class="text-muted-foreground hover:text-primary focus:ring-primary/20 rounded-lg p-1 transition-all duration-300 ease-out hover:scale-110 focus:ring-2 focus:outline-none" title=Email aria-label=Email><svg class="h-6 w-6" fill="none" stroke="currentColor" viewBox="0 0 24 24" aria-label="Email"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M3 8l7.89 5.26a2 2 0 002.22.0L21 8M5 19h14a2 2 0 002-2V7a2 2 0 00-2-2H5A2 2 0 003 7v10a2 2 0 002 2z"/></svg></a></div></div></div></footer><div id=dock class="pointer-events-none fixed bottom-4 left-1/2 z-[9999] w-fit -translate-x-1/2 translate-y-24 opacity-0 transition-all duration-300 ease-out sm:right-0 sm:left-0 sm:mx-auto sm:translate-x-0" role=toolbar aria-label="바로가기 도구 모음"><nav class="border-border bg-card/80 scrollbar-hide xs:px-3 xs:py-2 mx-auto flex max-w-[calc(100vw-2rem)] min-w-fit items-center justify-center overflow-x-auto rounded-2xl border px-4 py-3 shadow-lg backdrop-blur-sm sm:px-4 sm:py-3"><button id=dock-back class="text-muted-foreground hover:text-primary hover:bg-primary/10 focus:ring-primary/20 xs:px-2 xs:py-1.5 flex flex-shrink-0 items-center gap-2 rounded-lg px-3 py-2 text-sm font-medium transition-all duration-300 ease-out hover:-translate-y-0.5 hover:scale-105 focus:ring-2 focus:outline-none sm:px-3 sm:py-2" title=뒤로 aria-label=뒤로>
<svg class="h-4 w-4" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path d="m12 19-7-7 7-7"/><path d="M19 12H5"/></svg>
<span class="hidden sm:inline">뒤로</span></button><div class="bg-border xs:mx-1 mx-2 h-6 w-px sm:mx-2"></div><button id=dock-toc class="text-muted-foreground hover:text-primary hover:bg-primary/10 focus:ring-primary/20 xs:px-2 xs:py-1.5 flex flex-shrink-0 items-center gap-2 rounded-lg px-3 py-2 text-sm font-medium transition-all duration-300 ease-out hover:-translate-y-0.5 hover:scale-105 focus:ring-2 focus:outline-none sm:px-3 sm:py-2" title=목차 aria-label=목차>
<svg class="h-4 w-4" fill="none" stroke="currentColor" viewBox="0 0 24 24"><line x1="8" x2="21" y1="6" y2="6"/><line x1="8" x2="21" y1="12" y2="12"/><line x1="8" x2="21" y1="18" y2="18"/><line x1="3" x2="3.01" y1="6" y2="6"/><line x1="3" x2="3.01" y1="12" y2="12"/><line x1="3" x2="3.01" y1="18" y2="18"/></svg>
<span class="hidden sm:inline">목차</span></button><div class="bg-border xs:mx-1 mx-2 h-6 w-px sm:mx-2"></div><button id=dock-search class="text-muted-foreground hover:text-primary hover:bg-primary/10 focus:ring-primary/20 xs:px-3 xs:py-1.5 flex flex-shrink-0 items-center gap-2 rounded-lg px-4 py-2 text-sm font-medium transition-all duration-300 ease-out hover:-translate-y-0.5 hover:scale-105 focus:ring-2 focus:outline-none sm:px-4 sm:py-2" title=검색 aria-label=검색>
<svg class="h-4 w-4" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="m21 21-6-6m2-5A7 7 0 113 10a7 7 0 0114 0z"/></svg>
<span class="hidden md:inline">검색</span></button><div class="bg-border xs:mx-1 mx-2 h-6 w-px sm:mx-2"></div><button id=dock-top class="text-muted-foreground hover:text-primary hover:bg-primary/10 focus:ring-primary/20 xs:px-2 xs:py-1.5 flex flex-shrink-0 items-center gap-2 rounded-lg px-3 py-2 text-sm font-medium transition-all duration-300 ease-out hover:-translate-y-0.5 hover:scale-105 focus:ring-2 focus:outline-none sm:px-3 sm:py-2" title="맨 위로" aria-label="맨 위로">
<svg class="h-4 w-4" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path d="m18 15-6-6-6 6"/></svg>
<span class="hidden sm:inline">맨 위로</span></button></nav></div><div id=toc-overlay class="pointer-events-none fixed inset-0 z-40 bg-black/50 opacity-0 backdrop-blur-sm transition-all duration-300" role=dialog aria-modal=true aria-labelledby=toc-title></div><div id=toc-card class="pointer-events-none fixed inset-4 z-50 flex w-auto scale-95 items-center justify-center opacity-0 transition-all duration-300 sm:inset-auto sm:top-1/2 sm:left-1/2 sm:block sm:w-full sm:max-w-md sm:-translate-x-1/2 sm:-translate-y-1/2" role=dialog aria-modal=true aria-labelledby=toc-title><div class="bg-card border-border w-full max-w-sm overflow-hidden rounded-xl border shadow-xl sm:max-w-md"><div class="border-border bg-muted/30 flex items-center justify-between border-b p-4"><div class="flex items-center gap-3"><svg class="h-5 w-5" fill="none" stroke="currentColor" viewBox="0 0 24 24"><line x1="8" x2="21" y1="6" y2="6"/><line x1="8" x2="21" y1="12" y2="12"/><line x1="8" x2="21" y1="18" y2="18"/><line x1="3" x2="3.01" y1="6" y2="6"/><line x1="3" x2="3.01" y1="12" y2="12"/><line x1="3" x2="3.01" y1="18" y2="18"/></svg><h2 id=toc-title class="text-foreground text-lg font-semibold">목차</h2></div><button id=toc-close class="text-muted-foreground hover:text-primary hover:bg-primary/10 focus:ring-primary/20 rounded-lg p-2 transition-all duration-200 ease-out hover:-translate-y-0.5 hover:scale-105 focus:ring-2 focus:outline-none" title=닫기 aria-label=닫기>
<svg class="h-4 w-4" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M6 18 18 6M6 6l12 12"/></svg></button></div><div class="max-h-96 overflow-y-auto p-4"><nav id=toc-nav class=toc-scrollbar aria-label="글 목차"><div id=toc-content><nav id=TableOfContents><ul><li><ul><li><a href=#강점과-독창적인-지점><strong>강점과 독창적인 지점</strong></a></li><li><a href=#핵심-알고리즘-예시와-과정><strong>핵심 알고리즘: 예시와 과정</strong></a><ul><li><a href=#1-past-only-quantization-poq>1. <strong>Past-Only Quantization (POQ)</strong></a></li><li><a href=#2-2d-quantization>2. <strong>2D-Quantization</strong></a></li><li><a href=#3-cross-block-reconstruction-regularization-crr>3. <strong>Cross-Block Reconstruction Regularization (CRR)</strong></a></li></ul></li><li><a href=#논문의-한계><strong>논문의 한계</strong></a></li></ul></li></ul><ul><li><a href=#1-past-only-quantization-poq-1>1. <strong>Past-Only Quantization (POQ)</strong></a><ul><li><a href=#알고리즘-개요><strong>알고리즘 개요</strong></a></li><li><a href=#과정><strong>과정</strong></a><ul><li><a href=#입력><strong>입력</strong></a></li><li><a href=#단계><strong>단계</strong></a></li><li><a href=#결과><strong>결과</strong></a></li></ul></li></ul></li><li><a href=#2-two-dimensional-quantization-2d-quantization>2. <strong>Two-Dimensional Quantization (2D-Quantization)</strong></a><ul><li><a href=#알고리즘-개요-1><strong>알고리즘 개요</strong></a></li><li><a href=#과정-1><strong>과정</strong></a><ul><li><a href=#입력-1><strong>입력</strong></a></li><li><a href=#단계-1><strong>단계</strong></a></li><li><a href=#결과-1><strong>결과</strong></a></li></ul></li></ul></li><li><a href=#3-cross-block-reconstruction-regularization-crr-1>3. <strong>Cross-Block Reconstruction Regularization (CRR)</strong></a><ul><li><a href=#알고리즘-개요-2><strong>알고리즘 개요</strong></a></li><li><a href=#과정-2><strong>과정</strong></a><ul><li><a href=#입력-2><strong>입력</strong></a></li><li><a href=#단계-2><strong>단계</strong></a></li><li><a href=#결과-2><strong>결과</strong></a></li></ul></li><li><a href=#정리><strong>정리</strong></a></li></ul></li></ul><ul><li><ul><li><a href=#wkvquant-학습에-필요한-데이터셋><strong>WKVQuant 학습에 필요한 데이터셋</strong></a><ul><li><a href=#필요한-데이터셋의-특징><strong>필요한 데이터셋의 특징</strong></a></li></ul></li><li><a href=#학습-과정과-예시><strong>학습 과정과 예시</strong></a><ul><li><a href=#1-캘리브레이션-데이터-준비>1. <strong>캘리브레이션 데이터 준비</strong></a></li><li><a href=#2-양자화-매개변수-초기화>2. <strong>양자화 매개변수 초기화</strong></a></li><li><a href=#3-매개변수-최적화>3. <strong>매개변수 최적화</strong></a></li><li><a href=#학습-완료-후-평가><strong>학습 완료 후 평가</strong></a></li></ul></li><li><a href=#종합-정리><strong>종합 정리</strong></a><ul><li><a href=#학습-프로세스-요약><strong>학습 프로세스 요약</strong></a></li><li><a href=#결과-3><strong>결과</strong></a></li></ul></li></ul></li></ul><ul><li><ul><li><a href=#논문에서-제시한-결과><strong>논문에서 제시한 결과</strong></a><ul><li><a href=#1-정확도와-메모리-효율성><strong>1. 정확도와 메모리 효율성</strong></a></li><li><a href=#2-다른-방법론과의-비교><strong>2. 다른 방법론과의 비교</strong></a></li></ul></li><li><a href=#특출난-점><strong>특출난 점</strong></a><ul><li><a href=#1-past-only-quantization-poq의-효과><strong>1. Past-Only Quantization (POQ)의 효과</strong></a></li><li><a href=#2-two-dimensional-quantization-2d-quantization-1><strong>2. Two-Dimensional Quantization (2D-Quantization)</strong></a></li><li><a href=#3-cross-block-reconstruction-regularization-crr의-기여><strong>3. Cross-block Reconstruction Regularization (CRR)의 기여</strong></a></li></ul></li><li><a href=#왜-이러한-결과가-도출되었는가><strong>왜 이러한 결과가 도출되었는가?</strong></a></li><li><a href=#내-생각><strong>내 생각</strong></a></li><li><a href=#결론><strong>결론</strong></a></li></ul></li></ul><ul><li><ul><li><a href=#1-입력-데이터와-추론-과정><strong>1. 입력 데이터와 추론 과정</strong></a><ul><li><a href=#입력-데이터><strong>입력 데이터</strong></a></li><li><a href=#추론-과정><strong>추론 과정</strong></a></li></ul></li><li><a href=#2-모델-아키텍처-구성><strong>2. 모델 아키텍처 구성</strong></a><ul><li><a href=#1-transformer-블록><strong>1) Transformer 블록</strong></a></li><li><a href=#2-wkvquant의-변형><strong>2) WKVQuant의 변형</strong></a></li></ul></li><li><a href=#3-연산-및-메모리-요구량><strong>3. 연산 및 메모리 요구량</strong></a><ul><li><a href=#1-주요-연산><strong>1) 주요 연산</strong></a></li><li><a href=#2-메모리-요구량><strong>2) 메모리 요구량</strong></a></li><li><a href=#3-컴퓨팅-요구량><strong>3) 컴퓨팅 요구량</strong></a></li></ul></li><li><a href=#종합><strong>종합</strong></a></li></ul></li></ul><ul><li><ul><li><a href=#1-논문의-한계><strong>1. 논문의 한계</strong></a></li><li><a href=#2-한계를-극복하기-위한-연구-흐름><strong>2. 한계를 극복하기 위한 연구 흐름</strong></a><ul><li><a href=#1-임시-활성화의-양자화><strong>1) 임시 활성화의 양자화</strong></a></li><li><a href=#2-하드웨어-가속-최적화><strong>2) 하드웨어 가속 최적화</strong></a></li><li><a href=#3-crr의-시간-비용-감소><strong>3) CRR의 시간 비용 감소</strong></a></li><li><a href=#4-모델-구조-최적화><strong>4) 모델 구조 최적화</strong></a></li></ul></li><li><a href=#3-결론-및-새로운-연구-방향><strong>3. 결론 및 새로운 연구 방향</strong></a></li><li><a href=#요약><strong>요약</strong></a></li></ul></li></ul></nav></div></nav></div><div class="border-border bg-muted/20 border-t px-4 py-3"><div class="text-muted-foreground text-center text-xs"><span>제목을 클릭하면 해당 위치로 이동합니다</span></div></div></div></div><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.22/dist/katex.min.css integrity=sha384-5TcZemv2l/9On385z///+d7MSYlvIEw9FuZTIdZ14vJLqWphw7e7ZPuOiCHJcFCP crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.22/dist/katex.min.js integrity=sha384-cMkvdD8LoxVzGF/RPUKAcvmm49FQ0oxwDF3BGKtDXcEc+T1b2N+teh/OJfpU0jr6 crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.22/dist/contrib/auto-render.min.js integrity=sha384-hCXGrW6PitJEwbkoStFjeJxv+fSOOQKOPbJxSfM6G5sWZjAyWhXiTIIAmQqnlLlh crossorigin=anonymous></script><script>function initKaTeX(){if(typeof renderMathInElement=="undefined"){setTimeout(initKaTeX,100);return}var e=[{display:!0,left:"$$",right:"$$"},{display:!1,left:"$",right:"$"}];renderMathInElement(document.body,{delimiters:e,throwOnError:!1,errorColor:"#cc0000",fleqn:!1,leqno:!1,trust:!1})}document.readyState==="loading"?document.addEventListener("DOMContentLoaded",initKaTeX):initKaTeX()</script><div id=search-overlay class="pointer-events-none fixed inset-0 z-40 bg-black/50 opacity-0 transition-opacity duration-300"></div><div id=search-modal class="bg-card border-border pointer-events-none fixed top-1/2 left-1/2 z-50 max-h-[80vh] w-full max-w-2xl -translate-x-1/2 -translate-y-1/2 scale-95 transform overflow-hidden rounded-xl border opacity-0 shadow-xl transition-all duration-300"><div class="border-border flex items-center gap-3 border-b p-4"><div class="text-muted-foreground h-5 w-5 flex-shrink-0"><svg class="h-4 w-4" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="m21 21-6-6m2-5A7 7 0 113 10a7 7 0 0114 0z"/></svg></div><div class="relative flex-1"><button id=search-clear class="text-muted-foreground hover:text-foreground hover:bg-muted/50 pointer-events-none absolute top-1/2 left-0 z-10 h-5 w-5 -translate-y-1/2 rounded opacity-0 transition-all duration-200" title=지우기 aria-label=지우기>
<svg class="h-4 w-4" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M6 18 18 6M6 6l12 12"/></svg>
</button>
<input id=search-input type=text placeholder="게시글 검색..." class="text-foreground placeholder:text-muted-foreground w-full border-none bg-transparent pl-8 text-lg outline-none" autocomplete=off spellcheck=false></div><button id=search-close class="text-muted-foreground hover:text-foreground hover:bg-muted/50 flex h-6 w-6 items-center justify-center rounded-md p-0.5 transition-all duration-200" title=닫기 aria-label=닫기>
<svg class="h-4 w-4" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M6 18 18 6M6 6l12 12"/></svg></button></div><div id=search-results class="max-h-96 overflow-y-auto"><div id=search-empty class="flex flex-col items-center justify-center py-12 text-center"><div class="bg-muted/50 mb-4 flex h-16 w-16 items-center justify-center rounded-full"><svg class="h-6 w-6" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="m21 21-6-6m2-5A7 7 0 113 10a7 7 0 0114 0z"/></svg></div><h3 class="text-foreground mb-2 text-lg font-semibold">검색 시작</h3><p class="text-muted-foreground text-sm">검색어를 입력하세요</p></div><div id=search-loading class="flex hidden items-center justify-center py-8"><div class="mr-3 h-6 w-6 animate-spin rounded-full border-2 border-current border-t-transparent"></div><span class=text-muted-foreground>검색 중...</span></div><div id=search-no-results class="flex hidden flex-col items-center justify-center py-12 text-center"><div class="bg-muted/50 mb-4 flex h-16 w-16 items-center justify-center rounded-full"><svg class="h-6 w-6" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M4 6h16M4 12h16M4 18h7"/></svg></div><h3 class="text-foreground mb-2 text-lg font-semibold">검색 결과 없음</h3><p class="text-muted-foreground text-sm">다른 검색어로 시도해보세요</p></div><div id=search-results-list class=hidden><div id=search-stats class="text-muted-foreground border-border border-b px-4 py-3 text-sm" data-template="%d개의 결과 찾음"></div><div id=search-items class="divide-border divide-y"></div></div></div><div class="border-border bg-muted/20 border-t px-4 py-3"><div class="text-muted-foreground flex items-center justify-between text-xs"><div class="flex items-center gap-2 md:gap-4"><div class="flex items-center gap-1"><kbd class="bg-muted border-border rounded border px-1.5 py-0.5 text-xs">↑↓</kbd>
<span class="hidden sm:inline">이동</span></div><div class="flex items-center gap-1"><kbd class="bg-muted border-border rounded border px-1.5 py-0.5 text-xs">↵</kbd>
<span class="hidden sm:inline">선택</span></div><div class="flex items-center gap-1"><kbd class="bg-muted border-border rounded border px-1.5 py-0.5 text-xs">ESC</kbd>
<span class="hidden sm:inline">닫기</span></div></div><div class="search-hint-desktop flex items-center gap-1"><kbd class="bg-muted border-border rounded border px-1.5 py-0.5 text-xs">⌘K</kbd>
<span>단축키</span></div></div></div></div></body></html>