<!doctype html>
<html
  lang="ko-kr"
  data-theme="claude">
  <head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1314&amp;path=livereload" data-no-instant defer></script>
    <meta charset="utf-8" />
<meta
  name="viewport"
  content="width=device-width, initial-scale=1, shrink-to-fit=no" />
<meta http-equiv="X-UA-Compatible" content="IE=edge" />

<title>Janus:DecouplingVisualEncoding for Unified Multimodal Understanding and Generation | Jaehun&#39;s Blog</title>

<meta name="description" content="논문 링크
Q : 이 논문을 아주 자세하게 읽고 논문의 강점과 독창적인 지점을 설명해주고 핵심 알고리즘을 예시 입력을 들어서 전체적인 과정을 설명해줘 추가적으로 논문의 한계점에 대해서도 알려줘 논문 요약 및 분석: Janus - Decoupling Visual..." />
<meta name="keywords" content="개발, 컴파일러, 프로그래밍, 에세이" />
<meta name="author" content="" />
<meta name="language" content="ko-kr" />

<meta name="robots" content="index, follow" />
<link rel="canonical" href="http://192.168.1.11:1314/posts/JanusDecouplingVisualEncoding-for-Unified-Multimodal-Understanding-and-Generation/" />



  <link rel="icon" type="image/svg+xml" href="/favicon.svg" />



<link rel="manifest" href="/site.webmanifest" />
<meta property="og:url" content="http://192.168.1.11:1314/posts/JanusDecouplingVisualEncoding-for-Unified-Multimodal-Understanding-and-Generation/">
  <meta property="og:site_name" content="Jaehun&#39;s Blog">
  <meta property="og:title" content="Janus:DecouplingVisualEncoding for Unified Multimodal Understanding and Generation">
  <meta property="og:description" content="논문 링크
Q : 이 논문을 아주 자세하게 읽고 논문의 강점과 독창적인 지점을 설명해주고 핵심 알고리즘을 예시 입력을 들어서 전체적인 과정을 설명해줘 추가적으로 논문의 한계점에 대해서도 알려줘 논문 요약 및 분석: Janus - Decoupling Visual Encoding for Unified Multimodal Understanding and Generation 1. 연구의 주요 기여 Janus는 멀티모달 이해(Understanding)와 생성(Generation)을 통합한 자율회귀(Autoregressive) 모델로, 기존 접근 방식의 한계를 해결하기 위해 시각적 인코딩(Visual Encoding)을 분리하는 전략을 제안한다.">
  <meta property="og:locale" content="ko_kr">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2025-02-03T00:00:00+00:00">
    <meta property="article:modified_time" content="2025-02-03T00:00:00+00:00">
    <meta property="og:image" content="http://192.168.1.11:1314/images/og-default.avif">


  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:image" content="http://192.168.1.11:1314/images/og-default.avif">
  <meta name="twitter:title" content="Janus:DecouplingVisualEncoding for Unified Multimodal Understanding and Generation">
  <meta name="twitter:description" content="논문 링크
Q : 이 논문을 아주 자세하게 읽고 논문의 강점과 독창적인 지점을 설명해주고 핵심 알고리즘을 예시 입력을 들어서 전체적인 과정을 설명해줘 추가적으로 논문의 한계점에 대해서도 알려줘 논문 요약 및 분석: Janus - Decoupling Visual Encoding for Unified Multimodal Understanding and Generation 1. 연구의 주요 기여 Janus는 멀티모달 이해(Understanding)와 생성(Generation)을 통합한 자율회귀(Autoregressive) 모델로, 기존 접근 방식의 한계를 해결하기 위해 시각적 인코딩(Visual Encoding)을 분리하는 전략을 제안한다.">


  <meta itemprop="name" content="Janus:DecouplingVisualEncoding for Unified Multimodal Understanding and Generation">
  <meta itemprop="description" content="논문 링크
Q : 이 논문을 아주 자세하게 읽고 논문의 강점과 독창적인 지점을 설명해주고 핵심 알고리즘을 예시 입력을 들어서 전체적인 과정을 설명해줘 추가적으로 논문의 한계점에 대해서도 알려줘 논문 요약 및 분석: Janus - Decoupling Visual Encoding for Unified Multimodal Understanding and Generation 1. 연구의 주요 기여 Janus는 멀티모달 이해(Understanding)와 생성(Generation)을 통합한 자율회귀(Autoregressive) 모델로, 기존 접근 방식의 한계를 해결하기 위해 시각적 인코딩(Visual Encoding)을 분리하는 전략을 제안한다.">
  <meta itemprop="datePublished" content="2025-02-03T00:00:00+00:00">
  <meta itemprop="dateModified" content="2025-02-03T00:00:00+00:00">
  <meta itemprop="wordCount" content="19632">
  <meta itemprop="image" content="http://192.168.1.11:1314/images/og-default.avif">
  <meta itemprop="keywords" content="Paper-Review,With-Gpt">







<script>
  window.HUGO_SEARCH_CONFIG = {
    searchIndexURL: "\"/index.json\""
  };
</script>


































<script>

  window.HUGO_GALLERY_CONFIG = {
    justified_gallery:  false ,
    lightbox:  false ,
    justified: "{}",
    lightbox_options: "{}"
  };
</script>




  
    <link rel="stylesheet" href="/css/compiled.css" />
  





  
    <link rel="stylesheet" href="/css/chroma.css" />
  












      <script src="/js/main.js"></script>



  <script src="/js/gumshoe.polyfills.min.js"></script>



        <script src="/js/toc.js" defer></script>



      <script src="/js/search.js" defer></script>



      <script src="/js/dock.js" defer></script>











  











    <script>
      
      (function() {
        const theme = localStorage.getItem('theme') || 'system';
        const colorScheme = localStorage.getItem('colorScheme') || 'claude';

        
        document.documentElement.setAttribute('data-theme', colorScheme);

        
        function applyTheme() {
          if (theme === 'dark' || (theme === 'system' && window.matchMedia('(prefers-color-scheme: dark)').matches)) {
            document.documentElement.classList.add('dark');
          } else {
            document.documentElement.classList.remove('dark');
          }
        }

        applyTheme();

        
        if (theme === 'system') {
          window.matchMedia('(prefers-color-scheme: dark)').addEventListener('change', applyTheme);
        }
      })();
    </script>
  </head>

  <body class="bg-background text-foreground min-h-screen antialiased">
    
    
  <div
    id="reading-progress-container"
    class="reading-progress-container pointer-events-none fixed top-0 right-0 left-0 z-50 transition-opacity duration-300 ease-out"
    data-height="3"
    data-smooth-scroll="true"
    data-hide-on-complete="false">
    
    <div class="reading-progress-bg w-full"></div>

    
    <div
      id="reading-progress-bar"
      class="from-primary to-primary/80 reading-progress-bar 
        transition-all duration-150 ease-out
       absolute top-0 left-0 w-0 bg-gradient-to-r"></div>
  </div>

  <script>
    (function () {
      "use strict";

      const progressContainer = document.getElementById(
        "reading-progress-container",
      );
      const progressBar = document.getElementById("reading-progress-bar");

      if (!progressContainer || !progressBar) return;

      
      const config = {
        smoothScroll: progressContainer.dataset.smoothScroll === "true",
        hideOnComplete: progressContainer.dataset.hideOnComplete === "true",
      };

      let isVisible = true;
      let gumshoeInstance = null;

      
      function calculateProgress() {
        const scrollTop =
          window.pageYOffset || document.documentElement.scrollTop;
        const documentHeight = document.documentElement.scrollHeight;
        const windowHeight = window.innerHeight;
        const scrollableHeight = documentHeight - windowHeight;

        if (scrollableHeight <= 0) return 0;

        return Math.min(Math.max((scrollTop / scrollableHeight) * 100, 0), 100);
      }

      
      function updateProgress() {
        const progress = calculateProgress();
        progressBar.style.width = progress + "%";

        
        if (config.hideOnComplete && progress >= 99.5) {
          if (isVisible) {
            progressContainer.style.opacity = "0";
            isVisible = false;
          }
        } else if (!isVisible) {
          progressContainer.style.opacity = "1";
          isVisible = true;
        }
      }

      
      let ticking = false;
      function requestTick() {
        if (!ticking) {
          requestAnimationFrame(() => {
            updateProgress();
            ticking = false;
          });
          ticking = true;
        }
      }

      
      function init() {
        
        window.addEventListener("scroll", requestTick, { passive: true });
        window.addEventListener("resize", requestTick, { passive: true });
        document.addEventListener("visibilitychange", () => {
          if (!document.hidden) requestTick();
        });

        
        requestTick();

        
        window.addEventListener("beforeunload", () => {
          window.removeEventListener("scroll", requestTick);
          window.removeEventListener("resize", requestTick);
        });
      }

      
      if (document.readyState === "loading") {
        document.addEventListener("DOMContentLoaded", init);
      } else {
        init();
      }
    })();
  </script>

    <header class="sticky top-0 z-50 mx-auto max-w-4xl px-4 py-6">
  <div
    class="border-border bg-card/80 flex items-center rounded-xl border px-6 py-4 shadow-sm backdrop-blur-sm">
    
    <div class="hidden w-full items-center md:flex">
      
      <div class="flex items-center">
        
          
          <a
            href="/"
            class="bg-primary text-primary-foreground hover:bg-primary/90 flex h-10 w-10 items-center justify-center rounded-full text-lg font-bold transition-transform duration-200 hover:scale-105"
            aria-label="Jaehun&#39;s Blog">
            J
          </a>
        
      </div>

      
      <nav class="mx-8 flex flex-1 items-center justify-center">
        <div class="flex items-center space-x-1">
          
          
            
            
            
              
                
              
            
            
            <a
              href="/posts/"
              class="nav-link 
                text-muted-foreground hover:text-primary hover:bg-primary/10
               focus:ring-primary/20 relative flex items-center gap-2 rounded-lg px-4 py-2 text-sm font-medium transition-all duration-300 ease-out hover:-translate-y-0.5 hover:scale-105 focus:ring-2 focus:outline-none">
              
                
  <svg class="h-5 w-5"
    fill="none"
    stroke="currentColor"
    viewBox="0 0 24 24" aria-label="nav.posts">
  <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 20H5a2 2 0 01-2-2V6a2 2 0 012-2h10a2 2 0 012 2v1m2 13a2 2 0 01-2-2V7m2 13a2 2 0 002-2V9a2 2 0 00-2-2h-2m-4-3H9M7 16h6M7 8h6v4H7V8z" />

</svg>
              
              <span
                >
                  게시글
                </span
              >
            </a>
          
            
            
            
              
                
              
            
            
            <a
              href="/categories/"
              class="nav-link 
                text-muted-foreground hover:text-primary hover:bg-primary/10
               focus:ring-primary/20 relative flex items-center gap-2 rounded-lg px-4 py-2 text-sm font-medium transition-all duration-300 ease-out hover:-translate-y-0.5 hover:scale-105 focus:ring-2 focus:outline-none">
              
                
  <svg class="h-5 w-5"
    fill="none"
    stroke="currentColor"
    viewBox="0 0 24 24" aria-label="nav.categories">
  <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 11H5m14 0a2 2 0 012 2v6a2 2 0 01-2 2H5a2 2 0 01-2-2v-6a2 2 0 012-2m14 0V9a2 2 0 00-2-2M5 11V9a2 2 0 012-2m0 0V5a2 2 0 012-2h6a2 2 0 012 2v2M7 7h10" />

</svg>
              
              <span
                >
                  카테고리
                </span
              >
            </a>
          
            
            
            
              
                
              
            
            
            <a
              href="/tags/"
              class="nav-link 
                text-muted-foreground hover:text-primary hover:bg-primary/10
               focus:ring-primary/20 relative flex items-center gap-2 rounded-lg px-4 py-2 text-sm font-medium transition-all duration-300 ease-out hover:-translate-y-0.5 hover:scale-105 focus:ring-2 focus:outline-none">
              
                
  <svg class="h-5 w-5"
    fill="none"
    stroke="currentColor"
    viewBox="0 0 24 24" aria-label="nav.tags">
  <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M7 7h.01M7 3h5c.512 0 1.024.195 1.414.586l7 7a2 2 0 010 2.828l-7 7a2 2 0 01-2.828 0l-7-7A1.994 1.994 0 013 12V7a4 4 0 014-4z" />

</svg>
              
              <span
                >
                  태그
                </span
              >
            </a>
          
            
            
            
              
                
              
            
            
            <a
              href="/archives/"
              class="nav-link 
                text-muted-foreground hover:text-primary hover:bg-primary/10
               focus:ring-primary/20 relative flex items-center gap-2 rounded-lg px-4 py-2 text-sm font-medium transition-all duration-300 ease-out hover:-translate-y-0.5 hover:scale-105 focus:ring-2 focus:outline-none">
              
                
  <svg class="h-5 w-5"
    fill="none"
    stroke="currentColor"
    viewBox="0 0 24 24" aria-label="nav.archives">
  <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M5 8h14M5 8a2 2 0 110-4h14a2 2 0 110 4M5 8v10a2 2 0 002 2h10a2 2 0 002-2V8m-9 4h4" />

</svg>
              
              <span
                >
                  아카이브
                </span
              >
            </a>
          
        </div>
      </nav>

      
      <div class="flex items-center space-x-2">
        
        
<div class="relative">
  <button id="language-toggle"
    class="dropdown-toggle border-border bg-background text-muted-foreground hover:text-primary hover:bg-primary/10 focus:ring-primary/20 flex h-10 w-10 items-center justify-center rounded-lg border transition-all duration-300 ease-out hover:scale-105 focus:ring-2 focus:outline-none active:scale-95"
    data-dropdown-type="language"
    aria-label="언어 변경"
    aria-expanded="false"
    aria-haspopup="true">
      
  <svg class="h-5 w-5 relative z-10"
    fill="none"
    stroke="currentColor"
    viewBox="0 0 24 24" aria-label="언어 변경">
	<path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="m5 8l6 6m-7 0l6-6l2-3M2 5h12M7 2h1m14 20l-5-10l-5 10m2-4h6" />
</svg></button>

  
  <div id="language-dropdown"
    class="dropdown-menu border-border bg-popover/95 absolute top-12 right-0 z-[60] hidden w-40 rounded-lg border p-1 shadow-lg backdrop-blur-sm transition-all duration-200 ease-out"
    data-dropdown-type="language"
    role="menu"
    aria-labelledby="language-toggle"><a href="/ko/" class="text-accent-foreground hover:bg-accent hover:text-accent-foreground focus:bg-accent focus:text-accent-foreground flex w-full items-center rounded-md px-4 py-2 text-sm transition-all duration-200 ease-out focus:outline-none" role="menuitem" aria-current="true"><span class="font-medium">한국어</span></a><a href="/en/" class="text-accent-foreground hover:bg-accent hover:text-accent-foreground focus:bg-accent focus:text-accent-foreground flex w-full items-center rounded-md px-4 py-2 text-sm transition-all duration-200 ease-out focus:outline-none" role="menuitem"><span class="font-medium">English</span></a></div>
</div>

        
        
<div class="relative">
  <button id="color-scheme-toggle"
    class="dropdown-toggle border-border bg-background text-muted-foreground hover:text-primary hover:bg-primary/10 focus:ring-primary/20 flex h-10 w-10 items-center justify-center rounded-lg border transition-all duration-300 ease-out hover:scale-105 focus:ring-2 focus:outline-none active:scale-95"
    data-dropdown-type="color-scheme"
    aria-label="테마 변경"
    aria-expanded="false"
    aria-haspopup="true">
      
  <svg class="h-5 w-5 relative z-10"
    fill="none"
    stroke="currentColor"
    viewBox="0 0 24 24" aria-label="테마 변경">
  <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M7 21a4 4 0 01-4-4V5a2 2 0 012-2h4a2 2 0 012 2v12a4 4 0 01-4 4zM21 5a2 2 0 00-2-2h-4a2 2 0 00-2 2v6a2 2 0 002 2h4a2 2 0 002-2V5z" />

</svg></button>

  
  <div id="color-scheme-dropdown"
    class="dropdown-menu border-border bg-popover/95 absolute top-12 right-0 z-[60] hidden w-44 rounded-lg border p-1 shadow-lg backdrop-blur-sm transition-all duration-200 ease-out"
    data-dropdown-type="color-scheme"><button data-color-scheme="claude" class="text-accent-foreground hover:bg-accent hover:text-accent-foreground focus:bg-accent focus:text-accent-foreground flex w-full items-center rounded-md px-4 py-2 text-sm transition-all duration-200 ease-out focus:outline-none"><span>Default</span></button><button data-color-scheme="default" class="text-accent-foreground hover:bg-accent hover:text-accent-foreground focus:bg-accent focus:text-accent-foreground flex w-full items-center rounded-md px-4 py-2 text-sm transition-all duration-200 ease-out focus:outline-none"><span>White</span></button><button data-color-scheme="bumblebee" class="text-accent-foreground hover:bg-accent hover:text-accent-foreground focus:bg-accent focus:text-accent-foreground flex w-full items-center rounded-md px-4 py-2 text-sm transition-all duration-200 ease-out focus:outline-none"><span>Bumblebee</span></button><button data-color-scheme="emerald" class="text-accent-foreground hover:bg-accent hover:text-accent-foreground focus:bg-accent focus:text-accent-foreground flex w-full items-center rounded-md px-4 py-2 text-sm transition-all duration-200 ease-out focus:outline-none"><span>Emerald</span></button><button data-color-scheme="nord" class="text-accent-foreground hover:bg-accent hover:text-accent-foreground focus:bg-accent focus:text-accent-foreground flex w-full items-center rounded-md px-4 py-2 text-sm transition-all duration-200 ease-out focus:outline-none"><span>Nord</span></button><button data-color-scheme="sunset" class="text-accent-foreground hover:bg-accent hover:text-accent-foreground focus:bg-accent focus:text-accent-foreground flex w-full items-center rounded-md px-4 py-2 text-sm transition-all duration-200 ease-out focus:outline-none"><span>Sunset</span></button><button data-color-scheme="abyss" class="text-accent-foreground hover:bg-accent hover:text-accent-foreground focus:bg-accent focus:text-accent-foreground flex w-full items-center rounded-md px-4 py-2 text-sm transition-all duration-200 ease-out focus:outline-none"><span>Abyss</span></button><button data-color-scheme="dracula" class="text-accent-foreground hover:bg-accent hover:text-accent-foreground focus:bg-accent focus:text-accent-foreground flex w-full items-center rounded-md px-4 py-2 text-sm transition-all duration-200 ease-out focus:outline-none"><span>Dracula</span></button><button data-color-scheme="amethyst" class="text-accent-foreground hover:bg-accent hover:text-accent-foreground focus:bg-accent focus:text-accent-foreground flex w-full items-center rounded-md px-4 py-2 text-sm transition-all duration-200 ease-out focus:outline-none"><span>Amethyst</span></button><button data-color-scheme="slate" class="text-accent-foreground hover:bg-accent hover:text-accent-foreground focus:bg-accent focus:text-accent-foreground flex w-full items-center rounded-md px-4 py-2 text-sm transition-all duration-200 ease-out focus:outline-none"><span>Slate</span></button><button data-color-scheme="twitter" class="text-accent-foreground hover:bg-accent hover:text-accent-foreground focus:bg-accent focus:text-accent-foreground flex w-full items-center rounded-md px-4 py-2 text-sm transition-all duration-200 ease-out focus:outline-none"><span>Twitter</span></button></div>
</div>

        
        
<div class="relative">
  <button id="theme-toggle"
    class="dropdown-toggle border-border bg-background text-muted-foreground hover:text-primary hover:bg-primary/10 focus:ring-primary/20 flex h-10 w-10 items-center justify-center rounded-lg border transition-all duration-300 ease-out hover:scale-105 focus:ring-2 focus:outline-none active:scale-95"
    data-dropdown-type="theme"
    aria-label="테마 변경"
    aria-expanded="false"
    aria-haspopup="true">
      
      
  <svg class="h-5 w-5 sun-icon hidden relative z-10"
    fill="none"
    stroke="currentColor"
    viewBox="0 0 24 24" aria-label="라이트">
  <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M12 3v1m0 16v1m9-9h-1M4 12H3m15.364 6.364l-.707-.707M6.343 6.343l-.707-.707m12.728 0l-.707.707M6.343 17.657l-.707.707M16 12a4 4 0 11-8 0 4 4 0 018 0z" />

</svg>
      
      
  <svg class="h-5 w-5 moon-icon hidden relative z-10"
    fill="none"
    stroke="currentColor"
    viewBox="0 0 24 24" aria-label="다크">
  <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M20.354 15.354A9 9 0 018.646 3.646 9.003 9.003 0 0012 21a9.003 9.003 0 008.354-5.646z" />

</svg>
      
      
  <svg class="h-5 w-5 system-icon hidden relative z-10"
    fill="none"
    stroke="currentColor"
    viewBox="0 0 24 24" aria-label="시스템">
  <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9.75 17L9 20l-1 1h8l-1-1-.75-3M3 13h18M5 17h14a2 2 0 002-2V5a2 2 0 00-2-2H5a2 2 0 00-2 2v10a2 2 0 002 2z" />

</svg></button>

  
  <div id="theme-dropdown"
    class="dropdown-menu border-border bg-popover/95 absolute top-12 right-0 z-[60] hidden w-40 rounded-lg border p-1 shadow-lg backdrop-blur-sm transition-all duration-200 ease-out"
    data-dropdown-type="theme"><button data-theme="light" class="text-accent-foreground hover:bg-accent hover:text-accent-foreground focus:bg-accent focus:text-accent-foreground flex w-full items-center rounded-md px-4 py-2 text-sm transition-all duration-200 ease-out focus:outline-none">
  <svg class="h-5 w-5 mr-3 h-4 w-4"
    fill="none"
    stroke="currentColor"
    viewBox="0 0 24 24" aria-label="라이트">
  <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M12 3v1m0 16v1m9-9h-1M4 12H3m15.364 6.364l-.707-.707M6.343 6.343l-.707-.707m12.728 0l-.707.707M6.343 17.657l-.707.707M16 12a4 4 0 11-8 0 4 4 0 018 0z" />

</svg><span>라이트</span></button><button data-theme="dark" class="text-accent-foreground hover:bg-accent hover:text-accent-foreground focus:bg-accent focus:text-accent-foreground flex w-full items-center rounded-md px-4 py-2 text-sm transition-all duration-200 ease-out focus:outline-none">
  <svg class="h-5 w-5 mr-3 h-4 w-4"
    fill="none"
    stroke="currentColor"
    viewBox="0 0 24 24" aria-label="다크">
  <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M20.354 15.354A9 9 0 018.646 3.646 9.003 9.003 0 0012 21a9.003 9.003 0 008.354-5.646z" />

</svg><span>다크</span></button><button data-theme="system" class="text-accent-foreground hover:bg-accent hover:text-accent-foreground focus:bg-accent focus:text-accent-foreground flex w-full items-center rounded-md px-4 py-2 text-sm transition-all duration-200 ease-out focus:outline-none">
  <svg class="h-5 w-5 mr-3 h-4 w-4"
    fill="none"
    stroke="currentColor"
    viewBox="0 0 24 24" aria-label="시스템">
  <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9.75 17L9 20l-1 1h8l-1-1-.75-3M3 13h18M5 17h14a2 2 0 002-2V5a2 2 0 00-2-2H5a2 2 0 00-2 2v10a2 2 0 002 2z" />

</svg><span>시스템</span></button></div>
</div>
      </div>
    </div>

    
    <div class="flex w-full items-center justify-between md:hidden">
      
      
<div class="relative">
  <button
    id="mobile-menu-toggle"
    class="dropdown-toggle border-border bg-background text-muted-foreground hover:bg-accent hover:text-foreground flex h-10 w-10 items-center justify-center rounded-lg border transition-colors duration-200"
    data-dropdown-type="mobile-menu"
    aria-label="메뉴"
    aria-expanded="false"
    aria-haspopup="true">
    
  <svg class="h-5 w-5"
    fill="none"
    stroke="currentColor"
    viewBox="0 0 24 24" aria-label="메뉴">
  <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M4 6h16M4 12h16M4 18h16" />

</svg>
  </button>

  
  <div
    id="mobile-menu"
    class="mobile-menu dropdown-menu border-border bg-popover/95 absolute top-12 left-0 z-[60] hidden w-80 max-w-[calc(100vw-2rem)] rounded-lg border p-1 shadow-lg backdrop-blur-sm transition-all duration-200 ease-out md:hidden"
    data-dropdown-type="mobile-menu"
    role="menu"
    aria-labelledby="mobile-menu-toggle">
    <nav class="flex flex-col">
      
      
        
        
        
          
            
          
        
        
        <a
          href="/posts/"
          class="nav-link 
            text-muted-foreground hover:text-primary hover:bg-primary/10
           focus:ring-primary/20 relative flex items-center gap-3 rounded-md px-4 py-3 text-sm font-medium transition-all duration-200 ease-out hover:translate-x-1 focus:ring-2 focus:outline-none"
          role="menuitem"
          >
          
            
  <svg class="h-5 w-5"
    fill="none"
    stroke="currentColor"
    viewBox="0 0 24 24" aria-label="nav.posts">
  <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 20H5a2 2 0 01-2-2V6a2 2 0 012-2h10a2 2 0 012 2v1m2 13a2 2 0 01-2-2V7m2 13a2 2 0 002-2V9a2 2 0 00-2-2h-2m-4-3H9M7 16h6M7 8h6v4H7V8z" />

</svg>
          
          <span
            >
              게시글
            </span
          >
        </a>
      
        
        
        
          
            
          
        
        
        <a
          href="/categories/"
          class="nav-link 
            text-muted-foreground hover:text-primary hover:bg-primary/10
           focus:ring-primary/20 relative flex items-center gap-3 rounded-md px-4 py-3 text-sm font-medium transition-all duration-200 ease-out hover:translate-x-1 focus:ring-2 focus:outline-none"
          role="menuitem"
          >
          
            
  <svg class="h-5 w-5"
    fill="none"
    stroke="currentColor"
    viewBox="0 0 24 24" aria-label="nav.categories">
  <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 11H5m14 0a2 2 0 012 2v6a2 2 0 01-2 2H5a2 2 0 01-2-2v-6a2 2 0 012-2m14 0V9a2 2 0 00-2-2M5 11V9a2 2 0 012-2m0 0V5a2 2 0 012-2h6a2 2 0 012 2v2M7 7h10" />

</svg>
          
          <span
            >
              카테고리
            </span
          >
        </a>
      
        
        
        
          
            
          
        
        
        <a
          href="/tags/"
          class="nav-link 
            text-muted-foreground hover:text-primary hover:bg-primary/10
           focus:ring-primary/20 relative flex items-center gap-3 rounded-md px-4 py-3 text-sm font-medium transition-all duration-200 ease-out hover:translate-x-1 focus:ring-2 focus:outline-none"
          role="menuitem"
          >
          
            
  <svg class="h-5 w-5"
    fill="none"
    stroke="currentColor"
    viewBox="0 0 24 24" aria-label="nav.tags">
  <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M7 7h.01M7 3h5c.512 0 1.024.195 1.414.586l7 7a2 2 0 010 2.828l-7 7a2 2 0 01-2.828 0l-7-7A1.994 1.994 0 013 12V7a4 4 0 014-4z" />

</svg>
          
          <span
            >
              태그
            </span
          >
        </a>
      
        
        
        
          
            
          
        
        
        <a
          href="/archives/"
          class="nav-link 
            text-muted-foreground hover:text-primary hover:bg-primary/10
           focus:ring-primary/20 relative flex items-center gap-3 rounded-md px-4 py-3 text-sm font-medium transition-all duration-200 ease-out hover:translate-x-1 focus:ring-2 focus:outline-none"
          role="menuitem"
          >
          
            
  <svg class="h-5 w-5"
    fill="none"
    stroke="currentColor"
    viewBox="0 0 24 24" aria-label="nav.archives">
  <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M5 8h14M5 8a2 2 0 110-4h14a2 2 0 110 4M5 8v10a2 2 0 002 2h10a2 2 0 002-2V8m-9 4h4" />

</svg>
          
          <span
            >
              아카이브
            </span
          >
        </a>
      
    </nav>
  </div>
</div>


      
      <div class="flex items-center space-x-2">
        
        
<div class="relative">
  <button id="language-toggle"
    class="dropdown-toggle border-border bg-background text-muted-foreground hover:text-primary hover:bg-primary/10 focus:ring-primary/20 flex h-10 w-10 items-center justify-center rounded-lg border transition-all duration-300 ease-out hover:scale-105 focus:ring-2 focus:outline-none active:scale-95"
    data-dropdown-type="language"
    aria-label="언어 변경"
    aria-expanded="false"
    aria-haspopup="true">
      
  <svg class="h-5 w-5 relative z-10"
    fill="none"
    stroke="currentColor"
    viewBox="0 0 24 24" aria-label="언어 변경">
	<path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="m5 8l6 6m-7 0l6-6l2-3M2 5h12M7 2h1m14 20l-5-10l-5 10m2-4h6" />
</svg></button>

  
  <div id="language-dropdown"
    class="dropdown-menu border-border bg-popover/95 absolute top-12 right-0 z-[60] hidden w-40 rounded-lg border p-1 shadow-lg backdrop-blur-sm transition-all duration-200 ease-out"
    data-dropdown-type="language"
    role="menu"
    aria-labelledby="language-toggle"><a href="/ko/" class="text-accent-foreground hover:bg-accent hover:text-accent-foreground focus:bg-accent focus:text-accent-foreground flex w-full items-center rounded-md px-4 py-2 text-sm transition-all duration-200 ease-out focus:outline-none" role="menuitem" aria-current="true"><span class="font-medium">한국어</span></a><a href="/en/" class="text-accent-foreground hover:bg-accent hover:text-accent-foreground focus:bg-accent focus:text-accent-foreground flex w-full items-center rounded-md px-4 py-2 text-sm transition-all duration-200 ease-out focus:outline-none" role="menuitem"><span class="font-medium">English</span></a></div>
</div>

        
        
<div class="relative">
  <button id="color-scheme-toggle"
    class="dropdown-toggle border-border bg-background text-muted-foreground hover:text-primary hover:bg-primary/10 focus:ring-primary/20 flex h-10 w-10 items-center justify-center rounded-lg border transition-all duration-300 ease-out hover:scale-105 focus:ring-2 focus:outline-none active:scale-95"
    data-dropdown-type="color-scheme"
    aria-label="테마 변경"
    aria-expanded="false"
    aria-haspopup="true">
      
  <svg class="h-5 w-5 relative z-10"
    fill="none"
    stroke="currentColor"
    viewBox="0 0 24 24" aria-label="테마 변경">
  <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M7 21a4 4 0 01-4-4V5a2 2 0 012-2h4a2 2 0 012 2v12a4 4 0 01-4 4zM21 5a2 2 0 00-2-2h-4a2 2 0 00-2 2v6a2 2 0 002 2h4a2 2 0 002-2V5z" />

</svg></button>

  
  <div id="color-scheme-dropdown"
    class="dropdown-menu border-border bg-popover/95 absolute top-12 right-0 z-[60] hidden w-44 rounded-lg border p-1 shadow-lg backdrop-blur-sm transition-all duration-200 ease-out"
    data-dropdown-type="color-scheme"><button data-color-scheme="claude" class="text-accent-foreground hover:bg-accent hover:text-accent-foreground focus:bg-accent focus:text-accent-foreground flex w-full items-center rounded-md px-4 py-2 text-sm transition-all duration-200 ease-out focus:outline-none"><span>Default</span></button><button data-color-scheme="default" class="text-accent-foreground hover:bg-accent hover:text-accent-foreground focus:bg-accent focus:text-accent-foreground flex w-full items-center rounded-md px-4 py-2 text-sm transition-all duration-200 ease-out focus:outline-none"><span>White</span></button><button data-color-scheme="bumblebee" class="text-accent-foreground hover:bg-accent hover:text-accent-foreground focus:bg-accent focus:text-accent-foreground flex w-full items-center rounded-md px-4 py-2 text-sm transition-all duration-200 ease-out focus:outline-none"><span>Bumblebee</span></button><button data-color-scheme="emerald" class="text-accent-foreground hover:bg-accent hover:text-accent-foreground focus:bg-accent focus:text-accent-foreground flex w-full items-center rounded-md px-4 py-2 text-sm transition-all duration-200 ease-out focus:outline-none"><span>Emerald</span></button><button data-color-scheme="nord" class="text-accent-foreground hover:bg-accent hover:text-accent-foreground focus:bg-accent focus:text-accent-foreground flex w-full items-center rounded-md px-4 py-2 text-sm transition-all duration-200 ease-out focus:outline-none"><span>Nord</span></button><button data-color-scheme="sunset" class="text-accent-foreground hover:bg-accent hover:text-accent-foreground focus:bg-accent focus:text-accent-foreground flex w-full items-center rounded-md px-4 py-2 text-sm transition-all duration-200 ease-out focus:outline-none"><span>Sunset</span></button><button data-color-scheme="abyss" class="text-accent-foreground hover:bg-accent hover:text-accent-foreground focus:bg-accent focus:text-accent-foreground flex w-full items-center rounded-md px-4 py-2 text-sm transition-all duration-200 ease-out focus:outline-none"><span>Abyss</span></button><button data-color-scheme="dracula" class="text-accent-foreground hover:bg-accent hover:text-accent-foreground focus:bg-accent focus:text-accent-foreground flex w-full items-center rounded-md px-4 py-2 text-sm transition-all duration-200 ease-out focus:outline-none"><span>Dracula</span></button><button data-color-scheme="amethyst" class="text-accent-foreground hover:bg-accent hover:text-accent-foreground focus:bg-accent focus:text-accent-foreground flex w-full items-center rounded-md px-4 py-2 text-sm transition-all duration-200 ease-out focus:outline-none"><span>Amethyst</span></button><button data-color-scheme="slate" class="text-accent-foreground hover:bg-accent hover:text-accent-foreground focus:bg-accent focus:text-accent-foreground flex w-full items-center rounded-md px-4 py-2 text-sm transition-all duration-200 ease-out focus:outline-none"><span>Slate</span></button><button data-color-scheme="twitter" class="text-accent-foreground hover:bg-accent hover:text-accent-foreground focus:bg-accent focus:text-accent-foreground flex w-full items-center rounded-md px-4 py-2 text-sm transition-all duration-200 ease-out focus:outline-none"><span>Twitter</span></button></div>
</div>

        
        
<div class="relative">
  <button id="theme-toggle"
    class="dropdown-toggle border-border bg-background text-muted-foreground hover:text-primary hover:bg-primary/10 focus:ring-primary/20 flex h-10 w-10 items-center justify-center rounded-lg border transition-all duration-300 ease-out hover:scale-105 focus:ring-2 focus:outline-none active:scale-95"
    data-dropdown-type="theme"
    aria-label="테마 변경"
    aria-expanded="false"
    aria-haspopup="true">
      
      
  <svg class="h-5 w-5 sun-icon hidden relative z-10"
    fill="none"
    stroke="currentColor"
    viewBox="0 0 24 24" aria-label="라이트">
  <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M12 3v1m0 16v1m9-9h-1M4 12H3m15.364 6.364l-.707-.707M6.343 6.343l-.707-.707m12.728 0l-.707.707M6.343 17.657l-.707.707M16 12a4 4 0 11-8 0 4 4 0 018 0z" />

</svg>
      
      
  <svg class="h-5 w-5 moon-icon hidden relative z-10"
    fill="none"
    stroke="currentColor"
    viewBox="0 0 24 24" aria-label="다크">
  <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M20.354 15.354A9 9 0 018.646 3.646 9.003 9.003 0 0012 21a9.003 9.003 0 008.354-5.646z" />

</svg>
      
      
  <svg class="h-5 w-5 system-icon hidden relative z-10"
    fill="none"
    stroke="currentColor"
    viewBox="0 0 24 24" aria-label="시스템">
  <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9.75 17L9 20l-1 1h8l-1-1-.75-3M3 13h18M5 17h14a2 2 0 002-2V5a2 2 0 00-2-2H5a2 2 0 00-2 2v10a2 2 0 002 2z" />

</svg></button>

  
  <div id="theme-dropdown"
    class="dropdown-menu border-border bg-popover/95 absolute top-12 right-0 z-[60] hidden w-40 rounded-lg border p-1 shadow-lg backdrop-blur-sm transition-all duration-200 ease-out"
    data-dropdown-type="theme"><button data-theme="light" class="text-accent-foreground hover:bg-accent hover:text-accent-foreground focus:bg-accent focus:text-accent-foreground flex w-full items-center rounded-md px-4 py-2 text-sm transition-all duration-200 ease-out focus:outline-none">
  <svg class="h-5 w-5 mr-3 h-4 w-4"
    fill="none"
    stroke="currentColor"
    viewBox="0 0 24 24" aria-label="라이트">
  <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M12 3v1m0 16v1m9-9h-1M4 12H3m15.364 6.364l-.707-.707M6.343 6.343l-.707-.707m12.728 0l-.707.707M6.343 17.657l-.707.707M16 12a4 4 0 11-8 0 4 4 0 018 0z" />

</svg><span>라이트</span></button><button data-theme="dark" class="text-accent-foreground hover:bg-accent hover:text-accent-foreground focus:bg-accent focus:text-accent-foreground flex w-full items-center rounded-md px-4 py-2 text-sm transition-all duration-200 ease-out focus:outline-none">
  <svg class="h-5 w-5 mr-3 h-4 w-4"
    fill="none"
    stroke="currentColor"
    viewBox="0 0 24 24" aria-label="다크">
  <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M20.354 15.354A9 9 0 018.646 3.646 9.003 9.003 0 0012 21a9.003 9.003 0 008.354-5.646z" />

</svg><span>다크</span></button><button data-theme="system" class="text-accent-foreground hover:bg-accent hover:text-accent-foreground focus:bg-accent focus:text-accent-foreground flex w-full items-center rounded-md px-4 py-2 text-sm transition-all duration-200 ease-out focus:outline-none">
  <svg class="h-5 w-5 mr-3 h-4 w-4"
    fill="none"
    stroke="currentColor"
    viewBox="0 0 24 24" aria-label="시스템">
  <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9.75 17L9 20l-1 1h8l-1-1-.75-3M3 13h18M5 17h14a2 2 0 002-2V5a2 2 0 00-2-2H5a2 2 0 00-2 2v10a2 2 0 002 2z" />

</svg><span>시스템</span></button></div>
</div>
      </div>
    </div>
  </div>
</header>


    <main class="mx-auto max-w-4xl px-4 py-6">
      
  
  <nav
  class="breadcrumb mb-4 md:mb-6 py-1"
  aria-label="경로">
  <ol class="text-muted-foreground flex items-center space-x-1 md:space-x-2 text-sm overflow-x-auto whitespace-nowrap scrollbar-hide py-1">
    
    <li class="flex-shrink-0">
      <a
        href="/"
        class="text-muted-foreground hover:text-primary hover:bg-primary/10 flex items-center gap-0.5 md:gap-1 rounded-lg px-1 md:px-3 py-0.5 md:py-1.5 transition-all duration-200 ease-out hover:-translate-y-0.5 hover:scale-[1.02]">
        
  <svg class="h-4 w-4"
    fill="none"
    stroke="currentColor"
    viewBox="0 0 24 24" aria-label="홈">
  <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="m3 12 2-2m0 0 7-7 7 7M5 10v10a1 1 0 001 1h3m10-11l2 2m-2-2v10a1 1 0 01-1 1h-3m-6 0a1 1 0 001-1v-4a1 1 0 011-1h2a1 1 0 011 1v4a1 1 0 001 1m-6 0h6" />

</svg>
        <span class="max-w-[4rem] md:max-w-none truncate">홈</span>
      </a>
    </li>

    
    
      <li class="flex items-center gap-1 md:gap-2 min-w-0">
        <span class="text-muted-foreground/50 flex-shrink-0"
          >
  <svg class="h-4 w-4"
    fill="none"
    stroke="currentColor"
    viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 5l7 7-7 7" />
</svg>
        </span>

        
          
          <div class="flex items-center gap-1 md:gap-2 min-w-0">
            
              
              <a
                href="/posts"
                class="text-muted-foreground hover:text-primary hover:bg-primary/10 flex items-center gap-0.5 md:gap-1 rounded-lg px-1 md:px-3 py-0.5 md:py-1.5 transition-all duration-200 ease-out hover:-translate-y-0.5 hover:scale-[1.02] flex-shrink-0">
                
                  
  <svg class="h-4 w-4"
    fill="none"
    stroke="currentColor"
    viewBox="0 0 24 24">
  <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 20H5a2 2 0 01-2-2V6a2 2 0 012-2h10a2 2 0 012 2v1m2 13a2 2 0 01-2-2V7m2 13a2 2 0 002-2V9a2 2 0 00-2-2h-2m-4-3H9M7 16h6M7 8h6v4H7V8z" />

</svg>
                  <span class="max-w-[3rem] md:max-w-none truncate">게시글</span>
                
              </a>
              <span class="text-muted-foreground/50 flex-shrink-0"
                >
  <svg class="h-4 w-4"
    fill="none"
    stroke="currentColor"
    viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 5l7 7-7 7" />
</svg></span
              >
            
            
            <span class="text-foreground flex items-center gap-0.5 md:gap-1 font-medium min-w-0">
              
  <svg class="h-4 w-4"
    fill="none"
    stroke="currentColor"
    viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 12h6m-6 4h6m2 5H7a2 2 0 01-2-2V5a2 2 0 012-2h5.586a1 1 0 01.707.293l5.414 5.414a1 1 0 01.293.707V19a2 2 0 01-2 2z" />
</svg>
              <span class="max-w-[8rem] md:max-w-[16rem] lg:max-w-none truncate">Janus:DecouplingVisualEncoding for Unified Multimodal Understanding and Generation</span>
            </span>
          </div>
        
      </li>
    

  </ol>
</nav>



  


  
  <header class="mb-8">
    


<div class="post-meta">
  
  <h1 class="text-foreground mb-6 text-3xl leading-tight font-bold md:text-4xl">
    Janus:DecouplingVisualEncoding for Unified Multimodal Understanding and Generation
  </h1>

  
  


  
  <div class="bg-card border-border flex flex-col gap-4 rounded-xl border p-6">
    
    <div
      class="text-muted-foreground flex flex-wrap items-center gap-4 text-sm">
      
      <div class="flex items-center gap-2">
        
  <svg class="h-4 w-4"
    fill="none"
    stroke="currentColor"
    viewBox="0 0 24 24" aria-label="작성일"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M8 7V3m8 4V3m-9 8h10M5 21h14a2 2 0 002-2V7a2 2 0 00-2-2H5a2 2 0 00-2 2v12a2 2 0 002 2z" />
</svg>
        <time datetime="2025-02-03">
          2025년 02월 03일
        </time>
      </div>

      
      


      
      
        <div class="flex items-center gap-2">
          
  <svg class="h-4 w-4"
    fill="none"
    stroke="currentColor"
    viewBox="0 0 24 24" aria-label="읽는 시간"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M12 8v4l3 3m6-3a9 9 0 11-18 0 9 9 0 0118 0z" />
</svg>
          <span
            >40 분</span
          >
        </div>
      


      
      
        <div class="flex items-center gap-2">
          
  <svg class="h-4 w-4"
    fill="none"
    stroke="currentColor"
    viewBox="0 0 24 24" aria-label="단어 수"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M4 6h16M4 12h16M4 18h7" />
</svg>
          <span>19632 단어</span>
        </div>
      

    </div>

    
    
      <div class="flex flex-wrap items-center gap-4">
        
        
          <div class="flex items-center gap-2">
            
  <svg class="h-4 w-4"
    fill="none"
    stroke="currentColor"
    viewBox="0 0 24 24" aria-label="카테고리"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M3 7v10a2 2 0 002 2h14a2 2 0 002-2V9a2 2 0 00-2-2h-6l-2-2H5a2 2 0 00-2 2z" />
</svg>
            <span class="text-muted-foreground mr-2 text-sm"
              >카테고리:</span
            >
            <div class="flex flex-wrap gap-2">
              
                <a
                  href="/categories/paper-review/"
                  class="bg-primary/10 text-primary hover:bg-primary/20 focus:ring-primary/20 inline-flex items-center rounded-full px-3 py-1 text-sm font-medium transition-all duration-200 ease-out hover:-translate-y-0.5 hover:scale-105 hover:shadow-md focus:ring-2 focus:outline-none">
                  paper-review
                </a>
              
                <a
                  href="/categories/with-gpt/"
                  class="bg-primary/10 text-primary hover:bg-primary/20 focus:ring-primary/20 inline-flex items-center rounded-full px-3 py-1 text-sm font-medium transition-all duration-200 ease-out hover:-translate-y-0.5 hover:scale-105 hover:shadow-md focus:ring-2 focus:outline-none">
                  with-gpt
                </a>
              
            </div>
          </div>
        


        
        

      </div>
    


    
    

  </div>
</div>

  </header>

  
  <article class="prose prose-neutral dark:prose-invert mb-12 max-w-none">
    <p><a href="https://arxiv.org/abs/2410.13848v1">논문 링크</a></p>
<h1 id="q--이-논문을-아주-자세하게-읽고-논문의-강점과-독창적인-지점을-설명해주고-핵심-알고리즘을-예시-입력을-들어서-전체적인-과정을-설명해줘-추가적으로-논문의-한계점에-대해서도-알려줘">Q : 이 논문을 아주 자세하게 읽고 논문의 강점과 독창적인 지점을 설명해주고 핵심 알고리즘을 예시 입력을 들어서 전체적인 과정을 설명해줘 추가적으로 논문의 한계점에 대해서도 알려줘</h1>
<h3 id="논문-요약-및-분석-janus---decoupling-visual-encoding-for-unified-multimodal-understanding-and-generation"><strong>논문 요약 및 분석: Janus - Decoupling Visual Encoding for Unified Multimodal Understanding and Generation</strong></h3>
<hr>
<h2 id="1-연구의-주요-기여"><strong>1. 연구의 주요 기여</strong></h2>
<p>Janus는 멀티모달 이해(Understanding)와 생성(Generation)을 통합한 자율회귀(Autoregressive) 모델로, 기존 접근 방식의 한계를 해결하기 위해 <strong>시각적 인코딩(Visual Encoding)을 분리하는 전략을 제안</strong>한다.</p>
<ul>
<li>기존 모델들은 단일 시각 인코더를 이해와 생성 모두에 활용하는데, 이는 두 작업 간의 <strong>표현 수준 차이(semantic vs. fine-grained representation)로 인한 충돌 문제</strong>를 야기함.</li>
<li>Janus는 <strong>이해(Understanding)용 인코더와 생성(Generation)용 인코더를 독립적으로 운영</strong>하면서도 <strong>공통 Transformer 아키텍처</strong>를 활용하여 두 작업을 통합함.</li>
<li>실험 결과, Janus는 기존 통합 모델을 능가하며 <strong>일부 개별 과제 특화 모델(Task-Specific Model)보다도 우수한 성능을 보임</strong>.</li>
</ul>
<hr>
<h2 id="2-janus의-핵심-알고리즘-설명"><strong>2. Janus의 핵심 알고리즘 설명</strong></h2>
<h3 id="1-아키텍처"><strong>(1) 아키텍처</strong></h3>
<p>Janus의 전체적인 흐름은 아래와 같다:</p>
<ol>
<li>
<p><strong>입력 처리</strong></p>
<ul>
<li>텍스트 입력: LLM의 내장 토크나이저를 활용.</li>
<li>이미지 입력 (이해): SigLIP 인코더를 활용해 <strong>고차원 시맨틱 특징</strong>을 추출 후, Transformer 입력 공간으로 변환.</li>
<li>이미지 입력 (생성): VQ 토크나이저를 활용해 <strong>저차원 디스크리트 토큰</strong>으로 변환 후, Transformer 입력 공간으로 변환.</li>
</ul>
</li>
<li>
<p><strong>Transformer 처리</strong></p>
<ul>
<li>단일 Transformer가 <strong>이해 및 생성의 특성을 반영한 입력을 처리</strong>하여 멀티모달 작업을 수행.</li>
</ul>
</li>
<li>
<p><strong>출력 단계</strong></p>
<ul>
<li>텍스트 출력: LLM의 예측 헤드 사용.</li>
<li>이미지 출력: VQ 토큰을 기반으로 이미지 복원.</li>
</ul>
</li>
</ol>
<hr>
<h3 id="2-학습-과정"><strong>(2) 학습 과정</strong></h3>
<p>Janus는 <strong>3단계 학습 프로세스</strong>를 거친다.</p>
<table>
  <thead>
      <tr>
          <th>단계</th>
          <th>학습 목표</th>
          <th>주요 특징</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td><strong>1단계: 어댑터 및 이미지 헤드 학습</strong></td>
          <td>시각-언어 연관성 학습 및 초기 생성 능력 부여</td>
          <td>Transformer와 인코더 고정, 이해/생성 어댑터만 학습</td>
      </tr>
      <tr>
          <td><strong>2단계: 통합 사전학습</strong></td>
          <td>멀티모달 이해 및 생성 동시 학습</td>
          <td>모든 데이터 활용, 기본 시각/언어 상호작용 학습</td>
      </tr>
      <tr>
          <td><strong>3단계: 지도 학습</strong></td>
          <td>명령어 이해 및 대화 능력 강화</td>
          <td>LLM의 대화 능력을 개선, 생성 인코더는 고정</td>
      </tr>
  </tbody>
</table>
<hr>
<h2 id="3-예시-입력과-전체-프로세스"><strong>3. 예시 입력과 전체 프로세스</strong></h2>
<p>예제: <strong>&ldquo;강아지가 우주복을 입고 외계 행성을 탐험하는 모습을 생성하라&rdquo;</strong></p>
<ol>
<li>
<p><strong>텍스트 입력 → Transformer 입력 변환</strong></p>
<ul>
<li>문장은 LLM의 토크나이저를 통해 디스크리트 토큰으로 변환.</li>
<li>텍스트는 Transformer로 전달.</li>
</ul>
</li>
<li>
<p><strong>생성 인코더 활용</strong></p>
<ul>
<li>VQ 토크나이저가 학습된 코드를 통해 <strong>강아지, 우주복, 외계 행성</strong> 등의 요소를 <strong>디스크리트 이미지 토큰</strong>으로 변환.</li>
<li>Transformer는 이 정보를 사용하여 적절한 이미지 토큰을 예측.</li>
</ul>
</li>
<li>
<p><strong>출력 변환</strong></p>
<ul>
<li>Transformer가 예측한 이미지 토큰을 VQ 디코더가 변환하여 최종 이미지 생성.</li>
</ul>
</li>
</ol>
<p>결과적으로, Janus는 <strong>사용자의 프롬프트에 맞춘 이미지 생성을 수행하며 텍스트의 세부 요소까지 반영</strong>한다.</p>
<hr>
<h2 id="4-논문의-강점"><strong>4. 논문의 강점</strong></h2>
<h3 id="1-기존-모델과-비교한-차별점"><strong>(1) 기존 모델과 비교한 차별점</strong></h3>
<p>Janus는 기존 통합 멀티모달 모델보다 높은 유연성과 성능을 보이며, 특히 <strong>이해와 생성 간의 충돌을 해결</strong>했다.</p>
<table>
  <thead>
      <tr>
          <th>모델</th>
          <th>이해 성능 (POPE)</th>
          <th>생성 성능 (GenEval)</th>
          <th>특징</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td><strong>Show-o (1.3B)</strong></td>
          <td>73.8</td>
          <td>53%</td>
          <td>단일 인코더 사용</td>
      </tr>
      <tr>
          <td><strong>Chameleon (7B)</strong></td>
          <td>-</td>
          <td>39%</td>
          <td>단일 Transformer 기반</td>
      </tr>
      <tr>
          <td><strong>Janus (1.3B)</strong></td>
          <td><strong>87.0</strong></td>
          <td><strong>61%</strong></td>
          <td>이해 &amp; 생성 인코딩 분리</td>
      </tr>
  </tbody>
</table>
<ul>
<li>Janus는 <strong>Show-o보다 18.0% 더 높은 POPE 점수</strong>를 기록하며 <strong>GQA에서도 30% 개선</strong>됨.</li>
<li>생성 성능 역시 GenEval 기준 <strong>기존 통합 모델 대비 8%~20% 향상</strong>됨.</li>
</ul>
<hr>
<h3 id="2-유연한-확장성"><strong>(2) 유연한 확장성</strong></h3>
<ul>
<li>Janus는 <strong>이해 및 생성 인코더를 독립적으로 선택 가능</strong>하여 향후 EVA-CLIP, MoVQGAN 등의 <strong>최신 인코딩 기술을 적용할 수 있음</strong>.</li>
<li>추가적으로 <strong>3D 포인트 클라우드, EEG, 오디오 등 새로운 입력 모달리티</strong>를 쉽게 통합할 수 있는 구조적 장점을 가짐.</li>
</ul>
<hr>
<h2 id="5-한계점"><strong>5. 한계점</strong></h2>
<h3 id="1-고해상도-이미지-생성의-제한"><strong>(1) 고해상도 이미지 생성의 제한</strong></h3>
<ul>
<li>Janus는 현재 <strong>384×384 해상도의 이미지 생성</strong>을 수행하지만, <strong>SDXL (1024×1024) 등의 최신 생성 모델과 비교하면 해상도에서 열세</strong>를 보임.</li>
<li>이를 개선하기 위해 <strong>고해상도 동적 인코딩 기법</strong>이 필요.</li>
</ul>
<h3 id="2-생성-성능의-딥러닝-기반-모델과의-차이"><strong>(2) 생성 성능의 딥러닝 기반 모델과의 차이</strong></h3>
<ul>
<li>Janus는 <strong>SDXL (55%), DALL-E 2 (52%) 대비 높은 61%의 GenEval 성능</strong>을 보였으나, 일부 경우 세밀한 디테일 재현에서 <strong>딥러닝 기반 확산 모델(Diffusion Model) 대비 열세</strong>를 보임.</li>
</ul>
<h3 id="3-더-큰-모델-대비-성능-비교"><strong>(3) 더 큰 모델 대비 성능 비교</strong></h3>
<ul>
<li>Janus는 <strong>1.3B 파라미터 모델로 7B, 13B 모델들과 경쟁</strong>하지만, 더 큰 모델 대비 몇몇 벤치마크(예: LLaVA-v1.5의 MMBench 64.3)에서 다소 낮은 성능을 보임.</li>
<li>해결책: 더 큰 스케일 모델 (예: 7B, 13B) 버전도 함께 개발하여 비교 실험 수행.</li>
</ul>
<hr>
<h2 id="6-결론-및-미래-연구-방향"><strong>6. 결론 및 미래 연구 방향</strong></h2>
<p>Janus는 <strong>멀티모달 이해와 생성을 통합하는 동시에 두 작업의 표현 충돌을 해결하는 혁신적인 모델</strong>이다.</p>
<p>✅ <strong>장점</strong></p>
<ul>
<li><strong>멀티모달 통합 모델 중 최고 수준의 성능</strong>.</li>
<li><strong>이해와 생성 성능 간의 트레이드오프 제거</strong>.</li>
<li><strong>미래 확장 가능성</strong>: 다양한 데이터 유형 및 고해상도 개선 가능.</li>
</ul>
<p>❗ <strong>한계점 및 미래 연구</strong></p>
<ul>
<li><strong>해상도 개선</strong> 및 <strong>세밀한 생성 품질 향상</strong> 필요.</li>
<li><strong>더 큰 모델 실험</strong> 및 <strong>확산 모델 기반 기법 도입 가능성 탐색</strong>.</li>
</ul>
<p><strong>💡 최종적으로, Janus는 차세대 멀티모달 모델 개발의 중요한 기여를 한 연구로, 향후 보다 정밀한 시각적 표현을 목표로 발전할 가능성이 크다.</strong></p>
<h1 id="q--논문의-핵심알고리즘을-예시를-들어-아주-자세하게-설명해주고-정리해-줘">Q : 논문의 핵심알고리즘을 예시를 들어 아주 자세하게 설명해주고 정리해 줘</h1>
<h3 id="janus의-핵심-알고리즘-상세-분석-및-예제-설명"><strong>Janus의 핵심 알고리즘 상세 분석 및 예제 설명</strong></h3>
<hr>
<h2 id="1-janus의-기본-개념"><strong>1. Janus의 기본 개념</strong></h2>
<p>Janus는 <strong>멀티모달 이해(Understanding)와 생성(Generation)</strong> 두 가지 작업을 동시에 수행하는 모델이지만, 기존의 단일 인코더 방식을 벗어나 <strong>이해용 인코더와 생성용 인코더를 분리</strong>하여 성능을 극대화하는 것이 핵심이다.</p>
<ul>
<li>
<p><strong>이해(Understanding)</strong></p>
<ul>
<li>SigLIP 인코더를 사용하여 이미지에서 <strong>고차원 시맨틱 정보(semantic information)</strong> 추출.</li>
<li>예: &ldquo;이 이미지에 개가 몇 마리 있나요?&rdquo; → 개의 개수 파악.</li>
</ul>
</li>
<li>
<p><strong>생성(Generation)</strong></p>
<ul>
<li>VQ 토크나이저(VQGAN 기반)를 사용하여 이미지를 **디스크리트 토큰(discrete tokens)**으로 변환.</li>
<li>Transformer가 학습한 분포를 바탕으로 적절한 이미지 토큰을 예측 후, 디코더가 복원.</li>
<li>예: &ldquo;우주복을 입은 강아지가 달 표면을 걷는 이미지 생성&rdquo; → 이미지 생성.</li>
</ul>
</li>
</ul>
<hr>
<h2 id="2-핵심-알고리즘의-흐름"><strong>2. 핵심 알고리즘의 흐름</strong></h2>
<p>Janus의 전체적인 흐름을 **이해(Understanding)와 생성(Generation)**의 두 가지 과정으로 나누어 살펴보자.</p>
<hr>
<h2 id="3-이해understanding-과정-siglip-기반-인코딩"><strong>3. 이해(Understanding) 과정: SigLIP 기반 인코딩</strong></h2>
<h3 id="예제-1-개체-인식object-recognition"><strong>예제 1: 개체 인식(Object Recognition)</strong></h3>
<p><strong>입력</strong></p>
<ul>
<li>주어진 이미지: 🐶 강아지 세 마리가 잔디밭에서 뛰노는 사진</li>
<li>질문: &ldquo;이 이미지에 강아지가 몇 마리 있나요?&rdquo;</li>
</ul>
<p><strong>처리 과정</strong></p>
<ol>
<li>
<p><strong>이해용 인코더 (SigLIP)</strong></p>
<ul>
<li>이미지의 <strong>시맨틱 특징(semantic features)을 추출</strong>.</li>
<li>각 픽셀을 벡터로 변환하고 Transformer 입력 형식으로 정리.</li>
</ul>
</li>
<li>
<p><strong>Transformer 처리</strong></p>
<ul>
<li>Transformer가 입력된 특징을 기반으로 텍스트로 변환.</li>
<li>&ldquo;강아지가 3마리 있습니다&quot;라는 답변을 생성.</li>
</ul>
</li>
</ol>
<p><strong>출력</strong></p>
<ul>
<li>&ldquo;이 이미지에는 강아지가 3마리 있습니다.&rdquo;</li>
</ul>
<hr>
<h3 id="예제-2-텍스트-이미지-매칭text-image-matching"><strong>예제 2: 텍스트-이미지 매칭(Text-Image Matching)</strong></h3>
<p><strong>입력</strong></p>
<ul>
<li>이미지: 🍕 피자 한 판</li>
<li>질문: &ldquo;이 사진 속 음식은 무엇인가요?&rdquo;</li>
</ul>
<p><strong>처리 과정</strong></p>
<ol>
<li>
<p><strong>SigLIP 인코더 사용</strong></p>
<ul>
<li>피자의 시맨틱 정보를 추출 (예: 원형 형태, 토핑 정보 등).</li>
</ul>
</li>
<li>
<p><strong>Transformer가 이해하고 출력 생성</strong></p>
<ul>
<li>Transformer가 &ldquo;피자&quot;라는 텍스트를 생성.</li>
</ul>
</li>
</ol>
<p><strong>출력</strong></p>
<ul>
<li>&ldquo;이 음식은 피자입니다.&rdquo;</li>
</ul>
<hr>
<h2 id="4-생성generation-과정-vq-기반-이미지-생성"><strong>4. 생성(Generation) 과정: VQ 기반 이미지 생성</strong></h2>
<h3 id="예제-3-텍스트에서-이미지-생성text-to-image-generation"><strong>예제 3: 텍스트에서 이미지 생성(Text-to-Image Generation)</strong></h3>
<p><strong>입력</strong></p>
<ul>
<li>&ldquo;우주복을 입은 강아지가 달을 걷고 있는 사진을 만들어줘.&rdquo;</li>
</ul>
<p><strong>처리 과정</strong></p>
<ol>
<li>
<p><strong>텍스트 인코딩</strong></p>
<ul>
<li>LLM이 입력된 텍스트를 벡터로 변환하여 Transformer에 전달.</li>
</ul>
</li>
<li>
<p><strong>생성용 인코더 (VQ 토크나이저)</strong></p>
<ul>
<li>이미지를 생성하기 위해 Transformer가 디스크리트 토큰을 예측.</li>
<li>예측된 토큰을 기반으로 <strong>이미지의 구조적 특징(색상, 형태, 질감 등)을 생성</strong>.</li>
</ul>
</li>
<li>
<p><strong>VQ 디코더 활용</strong></p>
<ul>
<li>예측된 토큰을 디코딩하여 최종 이미지를 출력.</li>
</ul>
</li>
</ol>
<p><strong>출력</strong></p>
<ul>
<li>🐶 우주복을 입고 달을 걷는 강아지 사진.</li>
</ul>
<hr>
<h3 id="예제-4-이미지-보완image-inpainting"><strong>예제 4: 이미지 보완(Image Inpainting)</strong></h3>
<p><strong>입력</strong></p>
<ul>
<li>🖼️ 일부가 가려진 유명 그림 (예: 모나리자의 눈이 없는 상태)</li>
<li>명령어: &ldquo;이 그림을 복원해줘.&rdquo;</li>
</ul>
<p><strong>처리 과정</strong></p>
<ol>
<li>
<p><strong>VQ 인코더를 활용해 기존 이미지의 특징을 학습</strong></p>
<ul>
<li>누락된 부분을 제외한 원본 이미지의 토큰을 추출.</li>
</ul>
</li>
<li>
<p><strong>Transformer가 문맥을 고려해 예측</strong></p>
<ul>
<li>누락된 부분이 &ldquo;눈&quot;일 확률을 높게 설정.</li>
<li>기존 패턴과 어울리는 형태로 복원.</li>
</ul>
</li>
<li>
<p><strong>VQ 디코더가 복원된 이미지 생성</strong></p>
<ul>
<li>&ldquo;모나리자의 눈&quot;을 자연스럽게 채운 최종 이미지를 출력.</li>
</ul>
</li>
</ol>
<p><strong>출력</strong></p>
<ul>
<li>🎨 복원된 모나리자.</li>
</ul>
<hr>
<h2 id="5-핵심-요소-요약"><strong>5. 핵심 요소 요약</strong></h2>
<table>
  <thead>
      <tr>
          <th>단계</th>
          <th>이해 (Understanding)</th>
          <th>생성 (Generation)</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td><strong>인코더</strong></td>
          <td>SigLIP (고차원 시맨틱 특징)</td>
          <td>VQ 토크나이저 (디스크리트 토큰)</td>
      </tr>
      <tr>
          <td><strong>Transformer 입력</strong></td>
          <td>고차원 시맨틱 벡터</td>
          <td>텍스트 기반 디스크리트 토큰</td>
      </tr>
      <tr>
          <td><strong>처리 방식</strong></td>
          <td>LLM을 활용한 텍스트 변환</td>
          <td>LLM 기반의 이미지 토큰 예측</td>
      </tr>
      <tr>
          <td><strong>출력</strong></td>
          <td>텍스트 응답 (&ldquo;강아지 3마리&rdquo;)</td>
          <td>이미지 생성 (🐶🌕 우주복 강아지)</td>
      </tr>
  </tbody>
</table>
<hr>
<h2 id="6-정리"><strong>6. 정리</strong></h2>
<ul>
<li><strong>Janus는 기존 단일 인코더 방식과 달리, 이해와 생성에 적합한 별도 인코더를 사용</strong>하여 성능을 극대화함.</li>
<li><strong>SigLIP 인코더</strong>는 멀티모달 이해에서 <strong>고차원 의미 정보를 추출</strong>하여 이미지 내용을 정확하게 분석.</li>
<li><strong>VQ 토크나이저</strong>는 이미지 생성을 위한 <strong>디스크리트 토큰</strong>을 활용해 LLM이 예측한 정보를 기반으로 복원.</li>
<li>이를 통해 <strong>이해와 생성 성능이 기존 모델 대비 각각 18~30% 향상</strong>되었으며, <strong>일부 대형 모델보다도 높은 성능을 기록</strong>.</li>
</ul>
<p>✅ <strong>결론:</strong> Janus의 핵심 강점은 **&ldquo;이해와 생성의 표현 간 충돌을 해결하는 혁신적인 인코딩 분리 방식&rdquo;**이며, 이로 인해 멀티모달 작업에서 높은 성능을 기록할 수 있었다.</p>
<h1 id="q--이-논문에서-사용하는-방법을-학습하기-위하여-어떤-데이터셋이-필요할까-그리고-어떻게-학습을-진행하면-될지-예시를-들어서-아주-자세하게-설명해줘">Q : 이 논문에서 사용하는 방법을 학습하기 위하여 어떤 데이터셋이 필요할까? 그리고 어떻게 학습을 진행하면 될지 예시를 들어서 아주 자세하게 설명해줘</h1>
<h3 id="janus-모델을-학습하기-위한-데이터셋-및-학습-과정-상세-분석"><strong>Janus 모델을 학습하기 위한 데이터셋 및 학습 과정 상세 분석</strong></h3>
<hr>
<h2 id="1-janus-모델-학습을-위한-필수-데이터셋"><strong>1. Janus 모델 학습을 위한 필수 데이터셋</strong></h2>
<p>Janus 모델을 학습하려면 <strong>이해(Understanding)와 생성(Generation)을 모두 학습할 수 있는 멀티모달 데이터셋</strong>이 필요하다. 논문에서 사용한 데이터셋을 기반으로, 학습을 위해 필요한 데이터를 정리하면 다음과 같다.</p>
<h3 id="1-멀티모달-이해understanding-데이터셋"><strong>(1) 멀티모달 이해(Understanding) 데이터셋</strong></h3>

  <blockquote
    class="border-primary bg-muted/30 hover:bg-muted/40 my-6 rounded-r-lg border-l-4 py-4 pr-4 pl-6 italic transition-all duration-200 ease-out hover:translate-x-1">
    <div class="prose prose-sm max-w-none">
      <p>모델이 이미지를 보고 텍스트로 설명하거나, 질의응답을 수행할 수 있도록 훈련하기 위한 데이터셋.</p>
    </div>
  </blockquote>

<ul>
<li>
<p><strong>VQA 데이터셋</strong> (예: VQAv2, GQA)</p>
<ul>
<li>질문과 이미지가 함께 포함되어 있으며, 모델이 이미지의 내용을 분석하고 답변을 생성하도록 학습.</li>
<li>예제:
<ul>
<li>🖼️ <strong>이미지</strong>: &ldquo;개가 공을 물고 있다.&rdquo;</li>
<li>❓ <strong>질문</strong>: &ldquo;이 이미지에서 개가 몇 마리인가?&rdquo;</li>
<li>✅ <strong>정답</strong>: &ldquo;1마리&rdquo;</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>이미지-캡션 데이터셋</strong> (예: MSCOCO, LAION)</p>
<ul>
<li>이미지와 그에 대한 설명(캡션)을 포함하여, 모델이 이미지의 특징을 학습.</li>
<li>예제:
<ul>
<li>🖼️ <strong>이미지</strong>: &ldquo;해변에서 노을을 바라보는 두 사람&rdquo;</li>
<li>📝 <strong>설명</strong>: &ldquo;두 사람이 해변에 앉아 노을을 감상하는 장면입니다.&rdquo;</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>다이어그램/차트 데이터</strong> (예: DeepSeek-VL)</p>
<ul>
<li>모델이 복잡한 데이터 시각화를 이해할 수 있도록 학습.</li>
<li>예제:
<ul>
<li>📊 <strong>이미지</strong>: &ldquo;파이 차트&rdquo;</li>
<li>❓ <strong>질문</strong>: &ldquo;가장 큰 섹션은 무엇을 나타내는가?&rdquo;</li>
<li>✅ <strong>정답</strong>: &ldquo;전력 소비&rdquo;</li>
</ul>
</li>
</ul>
</li>
</ul>
<hr>
<h3 id="2-멀티모달-생성generation-데이터셋"><strong>(2) 멀티모달 생성(Generation) 데이터셋</strong></h3>

  <blockquote
    class="border-primary bg-muted/30 hover:bg-muted/40 my-6 rounded-r-lg border-l-4 py-4 pr-4 pl-6 italic transition-all duration-200 ease-out hover:translate-x-1">
    <div class="prose prose-sm max-w-none">
      <p>모델이 텍스트를 보고 이미지를 생성할 수 있도록 학습하기 위한 데이터셋.</p>
    </div>
  </blockquote>

<ul>
<li>
<p><strong>텍스트-이미지 페어 데이터셋</strong> (예: MSCOCO, LAION, JourneyDB)</p>
<ul>
<li>주어진 설명을 기반으로 이미지를 생성하는 작업을 학습.</li>
<li>예제:
<ul>
<li>📝 <strong>프롬프트</strong>: &ldquo;우주복을 입은 고양이가 목성 표면을 탐험하는 모습&rdquo;</li>
<li>🖼️ <strong>출력 이미지</strong>: (생성된 이미지)</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>고해상도 이미지 생성 데이터</strong> (예: MJHQ-30K, SDXL 데이터셋)</p>
<ul>
<li>다양한 스타일의 이미지를 학습하고 보다 정밀한 생성이 가능하도록 학습.</li>
<li>예제:
<ul>
<li>🎨 <strong>프롬프트</strong>: &ldquo;수채화 스타일의 노을이 지는 바다 풍경&rdquo;</li>
<li>🖼️ <strong>출력 이미지</strong>: (수채화 스타일 생성)</li>
</ul>
</li>
</ul>
</li>
</ul>
<hr>
<h3 id="3-추가-데이터셋-텍스트-이해-및-조합"><strong>(3) 추가 데이터셋 (텍스트 이해 및 조합)</strong></h3>

  <blockquote
    class="border-primary bg-muted/30 hover:bg-muted/40 my-6 rounded-r-lg border-l-4 py-4 pr-4 pl-6 italic transition-all duration-200 ease-out hover:translate-x-1">
    <div class="prose prose-sm max-w-none">
      <p>텍스트만 포함된 데이터를 추가 학습하여 모델의 언어 능력을 향상.</p>
    </div>
  </blockquote>

<ul>
<li>
<p><strong>대규모 텍스트 데이터 (예: DeepSeek-LLM 데이터셋)</strong></p>
<ul>
<li>모델이 자연어 이해 및 추론을 잘 수행할 수 있도록 지원.</li>
</ul>
</li>
<li>
<p><strong>멀티모달 인스트럭션 튜닝 데이터</strong> (예: LLaVA, SEED-Bench)</p>
<ul>
<li>모델이 보다 정밀하게 사용자 질문을 해석하고 응답하도록 조정.</li>
</ul>
</li>
</ul>
<hr>
<h2 id="2-janus-모델-학습-프로세스"><strong>2. Janus 모델 학습 프로세스</strong></h2>
<p>Janus 모델은 <strong>3단계 학습 절차</strong>를 따른다. 각 단계에서 어떤 데이터셋을 사용하고, 어떻게 모델을 업데이트해야 하는지 설명한다.</p>
<hr>
<h3 id="-1-1단계-어댑터-및-이미지-생성-헤드-학습"><strong>📌 (1) 1단계: 어댑터 및 이미지 생성 헤드 학습</strong></h3>
<p><strong>🔹 목적</strong></p>
<ul>
<li>모델이 <strong>시각-언어 연관성</strong>을 학습하고, 초기 생성 능력을 갖추도록 함.</li>
<li>Transformer는 고정하고, **이해 어댑터(Und. Adapter) 및 생성 어댑터(Gen. Adapter)**만 업데이트.</li>
</ul>
<p><strong>🔹 필요한 데이터</strong></p>
<ul>
<li><strong>이해 데이터:</strong> ShareGPT4V (1.25M 이미지-텍스트 페어)</li>
<li><strong>생성 데이터:</strong> ImageNet-1K (1.2M 이미지)</li>
</ul>
<p><strong>🔹 학습 과정</strong></p>
<ol>
<li>
<p><strong>이해 학습</strong></p>
<ul>
<li>이미지를 입력으로 받아 SigLIP 인코더를 통과한 뒤 Transformer를 통해 텍스트로 변환.</li>
<li>모델이 &ldquo;이 이미지에서 개가 몇 마리인가?&ldquo;에 대해 올바른 답변을 내도록 학습.</li>
</ul>
</li>
<li>
<p><strong>생성 학습</strong></p>
<ul>
<li>ImageNet 이미지를 VQ 토크나이저를 사용해 토큰화.</li>
<li>Transformer가 토큰을 학습하고, 생성 어댑터를 통해 디코딩하여 원본 이미지 복원.</li>
</ul>
</li>
</ol>
<p><strong>🔹 학습 방식</strong></p>
<ul>
<li><strong>Transformer는 고정</strong>, 어댑터 및 이미지 헤드만 학습.</li>
<li>학습률: <strong>1.0 × 10⁻³ (Cosine 스케줄러 사용)</strong></li>
<li>배치 크기: <strong>256</strong></li>
<li>학습 스텝: <strong>10,000</strong></li>
</ul>
<hr>
<h3 id="-2-2단계-멀티모달-통합-학습"><strong>📌 (2) 2단계: 멀티모달 통합 학습</strong></h3>
<p><strong>🔹 목적</strong></p>
<ul>
<li><strong>이해 + 생성 동시 학습</strong>을 수행하여 모델의 멀티모달 통합 능력을 강화.</li>
</ul>
<p><strong>🔹 필요한 데이터</strong></p>
<ul>
<li><strong>텍스트 데이터:</strong> DeepSeek-LLM (일반 텍스트 데이터)</li>
<li><strong>이해 데이터:</strong> WikiHow, WIT, MSCOCO, SEED-Bench</li>
<li><strong>생성 데이터:</strong> JourneyDB, OpenAI-SD, MegaLITH (총 2M 샘플)</li>
</ul>
<p><strong>🔹 학습 과정</strong></p>
<ol>
<li>
<p><strong>텍스트 이해</strong></p>
<ul>
<li>Transformer가 일반 텍스트 처리 능력을 학습.</li>
</ul>
</li>
<li>
<p><strong>이미지 이해</strong></p>
<ul>
<li>이미지가 주어졌을 때, Transformer가 SigLIP 특징을 기반으로 올바른 캡션을 생성하도록 훈련.</li>
</ul>
</li>
<li>
<p><strong>이미지 생성</strong></p>
<ul>
<li>&ldquo;귀여운 고양이가 우주에서 떠다니는 그림을 생성하라.&rdquo; 같은 프롬프트를 Transformer가 해석하고, 올바른 이미지 토큰을 예측하도록 학습.</li>
</ul>
</li>
</ol>
<p><strong>🔹 학습 방식</strong></p>
<ul>
<li>Transformer 포함 모든 파라미터 학습.</li>
<li>학습률: <strong>1 × 10⁻⁴ (Constant 스케줄러)</strong></li>
<li>배치 크기: <strong>512</strong></li>
<li>학습 스텝: <strong>180,000</strong></li>
</ul>
<hr>
<h3 id="-3-3단계-지도-학습-및-인스트럭션-튜닝"><strong>📌 (3) 3단계: 지도 학습 및 인스트럭션 튜닝</strong></h3>
<p><strong>🔹 목적</strong></p>
<ul>
<li>모델이 <strong>사용자 질문을 자연스럽게 해석하고, 보다 정교한 답변을 생성하도록 튜닝</strong>.</li>
<li>Transformer는 고정하고, 생성 인코더는 고정하며, <strong>이해 어댑터 및 생성 어댑터</strong>만 조정.</li>
</ul>
<p><strong>🔹 필요한 데이터</strong></p>
<ul>
<li><strong>멀티모달 인스트럭션 데이터</strong> (LLaVA, SEED-Bench)</li>
<li><strong>텍스트 대화 데이터</strong> (OpenAI GPT-4 Chat Data)</li>
<li><strong>추가 이미지 생성 데이터</strong> (JourneyDB)</li>
</ul>
<p><strong>🔹 학습 과정</strong></p>
<ol>
<li>
<p><strong>사용자 질문-답변 학습</strong></p>
<ul>
<li>&ldquo;이 그림에서 가장 중요한 요소는 무엇인가?&ldquo;와 같은 질문을 LLM이 정확히 응답하도록 학습.</li>
</ul>
</li>
<li>
<p><strong>이미지 생성 정교화</strong></p>
<ul>
<li>높은 품질의 텍스트-이미지 페어 데이터를 활용하여 생성 성능을 보완.</li>
</ul>
</li>
</ol>
<p><strong>🔹 학습 방식</strong></p>
<ul>
<li>학습률: <strong>2.0 × 10⁻⁵ (Constant 스케줄러)</strong></li>
<li>배치 크기: <strong>256</strong></li>
<li>학습 스텝: <strong>24,000</strong></li>
</ul>
<hr>
<h2 id="3-최종-정리"><strong>3. 최종 정리</strong></h2>
<table>
  <thead>
      <tr>
          <th>학습 단계</th>
          <th>주요 목표</th>
          <th>필요한 데이터</th>
          <th>학습 방식</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>1단계</td>
          <td>시각-언어 연결 학습</td>
          <td>VQA, ImageNet</td>
          <td>Transformer 고정, 어댑터만 학습</td>
      </tr>
      <tr>
          <td>2단계</td>
          <td>멀티모달 통합 학습</td>
          <td>MSCOCO, WikiHow, SDXL</td>
          <td>전체 모델 학습</td>
      </tr>
      <tr>
          <td>3단계</td>
          <td>사용자 대응 최적화</td>
          <td>LLaVA, SEED-Bench</td>
          <td>생성 인코더 고정, LLM 튜닝</td>
      </tr>
  </tbody>
</table>
<p>✅ <strong>결론:</strong> Janus 학습은 단계적으로 진행되며, 다양한 데이터셋을 활용해 이해와 생성 성능을 동시에 최적화함.</p>
<h1 id="q--이-논문에서-제시한-결과를-자세하게-보고-다른-방법론에-비하여-특출난-점과-논문에서-제기하는-어떠한-방법이-이러한-결과를-도출하게-되었는지-논문에서-제시하는-이유와-너의-생각을-알려줘">Q : 이 논문에서 제시한 결과를 자세하게 보고 다른 방법론에 비하여 특출난 점과 논문에서 제기하는 어떠한 방법이 이러한 결과를 도출하게 되었는지 논문에서 제시하는 이유와 너의 생각을 알려줘</h1>
<h1 id="janus의-실험-결과-분석-및-비교"><strong>Janus의 실험 결과 분석 및 비교</strong></h1>
<p>Janus 모델은 <strong>멀티모달 이해(Understanding)와 생성(Generation) 작업을 통합</strong>하는 동시에 <strong>기존 방법론과 차별화된 접근법을 적용</strong>하여 더 나은 성능을 달성하였다. 이번 분석에서는 Janus의 실험 결과를 기존 방법들과 비교하고, 이러한 성능 향상의 원인을 논문의 주장과 함께 검토하며, 내 생각을 더하여 설명하겠다.</p>
<hr>
<h2 id="1-janus의-실험-결과-정리"><strong>1. Janus의 실험 결과 정리</strong></h2>
<p>Janus는 <strong>멀티모달 이해 성능</strong>과 <strong>이미지 생성 성능</strong>을 각각 평가하였으며, 기존 모델과의 비교 결과를 도출하였다.</p>
<h3 id="1-멀티모달-이해-성능"><strong>(1) 멀티모달 이해 성능</strong></h3>
<p>Janus는 <strong>VQA, GQA, POPE, MM-Vet 등의 이해 벤치마크에서 경쟁 모델보다 높은 성능을 기록</strong>하였다.</p>
<table>
  <thead>
      <tr>
          <th>모델</th>
          <th>POPE (↑)</th>
          <th>MME-P (↑)</th>
          <th>MMBench (↑)</th>
          <th>SEED (↑)</th>
          <th>VQAv2 (↑)</th>
          <th>GQA (↑)</th>
          <th>MMMU (↑)</th>
          <th>MM-Vet (↑)</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td><strong>LLaVA-v1.5 (7B)</strong></td>
          <td>85.9</td>
          <td>1510.7</td>
          <td>64.3</td>
          <td>58.6</td>
          <td>78.5</td>
          <td>62.0</td>
          <td>35.4</td>
          <td>31.1</td>
      </tr>
      <tr>
          <td><strong>Show-o (1.3B)</strong></td>
          <td>73.8</td>
          <td>948.4</td>
          <td>-</td>
          <td>-</td>
          <td>59.3</td>
          <td>48.7</td>
          <td>25.1</td>
          <td>-</td>
      </tr>
      <tr>
          <td><strong>Chameleon (7B)</strong></td>
          <td>-</td>
          <td>-</td>
          <td>-</td>
          <td>-</td>
          <td>-</td>
          <td>-</td>
          <td>22.4</td>
          <td>8.3</td>
      </tr>
      <tr>
          <td><strong>Janus (1.3B)</strong></td>
          <td><strong>87.0</strong></td>
          <td>1338.0</td>
          <td><strong>69.4</strong></td>
          <td><strong>63.7</strong></td>
          <td>77.3</td>
          <td>59.1</td>
          <td>30.5</td>
          <td><strong>34.3</strong></td>
      </tr>
  </tbody>
</table>
<p>🔹 <strong>주목할 점</strong></p>
<ul>
<li><strong>LLaVA-v1.5 (7B)보다 적은 파라미터(1.3B)로도 이해 성능이 동등하거나 오히려 우수</strong>.</li>
<li><strong>Show-o (1.3B) 대비 41% 향상된 MME-P 점수, GQA 성능도 30% 향상</strong>.</li>
<li><strong>MMBench와 SEED 벤치마크에서 가장 높은 성능을 기록</strong>.</li>
</ul>
<hr>
<h3 id="2-이미지-생성-성능"><strong>(2) 이미지 생성 성능</strong></h3>
<p>Janus는 <strong>텍스트-이미지 생성 성능에서 기존의 확산 모델(Diffusion Model) 및 다른 멀티모달 모델보다 높은 성능을 기록</strong>하였다.</p>
<table>
  <thead>
      <tr>
          <th>모델</th>
          <th>GenEval (↑)</th>
          <th>COCO-30K FID (↓)</th>
          <th>MJHQ-30K FID (↓)</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td><strong>SDXL (2.6B)</strong></td>
          <td>55%</td>
          <td>9.24</td>
          <td>15.18</td>
      </tr>
      <tr>
          <td><strong>DALL-E 2 (6.5B)</strong></td>
          <td>52%</td>
          <td>10.39</td>
          <td>-</td>
      </tr>
      <tr>
          <td><strong>Show-o (1.3B)</strong></td>
          <td>53%</td>
          <td>9.24</td>
          <td>15.18</td>
      </tr>
      <tr>
          <td><strong>Janus (1.3B)</strong></td>
          <td><strong>61%</strong></td>
          <td><strong>8.53</strong></td>
          <td><strong>10.10</strong></td>
      </tr>
  </tbody>
</table>
<p>🔹 <strong>주목할 점</strong></p>
<ul>
<li><strong>Janus는 기존 텍스트-이미지 생성 모델 SDXL(55%)과 DALL-E 2(52%)보다 높은 61%의 GenEval 점수</strong>를 기록.</li>
<li><strong>COCO-30K에서 FID(Frechet Inception Distance) 8.53으로 가장 낮은 점수를 기록</strong>, 즉 <strong>더 사실적인 이미지 생성 가능</strong>.</li>
<li><strong>MJHQ-30K에서도 FID 10.10으로 기존 Show-o, SDXL 대비 더 좋은 성능</strong>.</li>
</ul>
<hr>
<h2 id="2-janus의-차별점과-성능-향상의-이유"><strong>2. Janus의 차별점과 성능 향상의 이유</strong></h2>
<p>Janus가 기존 모델보다 높은 성능을 달성한 이유는 <strong>멀티모달 이해와 생성의 표현 충돌 문제를 해결한 것</strong>에 있다.</p>
<h3 id="1-기존-모델의-한계"><strong>(1) 기존 모델의 한계</strong></h3>
<h4 id="-기존-모델-예-chameleon-show-o">📌 기존 모델 (예: Chameleon, Show-o)</h4>
<ul>
<li>단일 인코더를 사용하여 <strong>이해와 생성 모두 같은 표현 공간에서 처리</strong>.</li>
<li>하지만 <strong>이해는 고차원 시맨틱 정보</strong>, <strong>생성은 로우레벨 디테일 정보</strong>를 필요로 하므로 충돌 발생.</li>
<li>결과적으로 <strong>이해 성능이 떨어지거나, 생성 이미지의 품질이 낮아지는 문제</strong>가 존재.</li>
</ul>
<h4 id="-확산-모델-기반-생성-모델-예-dall-e-2-sdxl">📌 확산 모델 기반 생성 모델 (예: DALL-E 2, SDXL)</h4>
<ul>
<li>생성 품질이 뛰어나지만 <strong>LLM과 직접 통합되지 않음</strong>.</li>
<li>즉, <strong>텍스트 조건을 효과적으로 반영하는 능력이 부족</strong>하여 <strong>프롬프트 충실도 낮음</strong>.</li>
</ul>
<hr>
<h3 id="2-janus의-해결책"><strong>(2) Janus의 해결책</strong></h3>
<h4 id="-1-이해와-생성의-인코더를-분리">✅ <strong>1. 이해와 생성의 인코더를 분리</strong></h4>
<ul>
<li>이해(Understanding)에는 <strong>SigLIP</strong>을 활용하여 <strong>고차원 시맨틱 특징을 추출</strong>.</li>
<li>생성(Generation)에는 <strong>VQGAN 기반 디스크리트 토크나이저</strong>를 활용하여 <strong>로우레벨 공간 정보를 유지</strong>.</li>
</ul>
<h4 id="-2-transformer의-단일-아키텍처-사용">✅ <strong>2. Transformer의 단일 아키텍처 사용</strong></h4>
<ul>
<li>시각적 특징이 Transformer를 통해 LLM과 <strong>긴밀하게 결합되므로 상호보완적 학습 가능</strong>.</li>
<li>확산 모델과 달리, LLM이 직접 <strong>이미지를 생성할 수 있도록 연결</strong>.</li>
</ul>
<h4 id="-3-3단계-학습-전략">✅ <strong>3. 3단계 학습 전략</strong></h4>
<table>
  <thead>
      <tr>
          <th>단계</th>
          <th>목표</th>
          <th>학습 방식</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td><strong>1단계: 어댑터 및 이미지 헤드 학습</strong></td>
          <td>시각-언어 연관성 학습</td>
          <td>Transformer 고정, 어댑터만 학습</td>
      </tr>
      <tr>
          <td><strong>2단계: 통합 사전학습</strong></td>
          <td>이해 및 생성 동시 학습</td>
          <td>Transformer 포함 전체 학습</td>
      </tr>
      <tr>
          <td><strong>3단계: 지도 학습</strong></td>
          <td>사용자 프롬프트 최적화</td>
          <td>생성 인코더 고정, LLM 튜닝</td>
      </tr>
  </tbody>
</table>
<ul>
<li>1단계에서 <strong>Transformer를 고정</strong>하여 이해 및 생성 어댑터가 독립적으로 학습되도록 함.</li>
<li>2단계에서 <strong>텍스트-이미지 이해 및 생성 학습을 동시 진행</strong>하여 멀티모달 표현을 최적화.</li>
<li>3단계에서 <strong>인스트럭션 튜닝을 통해 사용자 맞춤 대응 학습</strong>.</li>
</ul>
<hr>
<h2 id="3-내-생각-janus의-실제-강점과-앞으로의-발전-방향"><strong>3. 내 생각: Janus의 실제 강점과 앞으로의 발전 방향</strong></h2>
<p>논문에서 주장하는 핵심 기여점(인코딩 분리, Transformer 기반 통합)은 매우 설득력이 있으며, 실험 결과가 이를 뒷받침하고 있다.</p>
<h3 id="1-janus의-실제-강점"><strong>(1) Janus의 실제 강점</strong></h3>
<ol>
<li>
<p><strong>멀티모달 이해 성능의 대폭 향상</strong></p>
<ul>
<li>기존 통합 모델들이 이해 성능을 희생해야 했던 문제를 해결.</li>
<li>실제로 <strong>POPE, MM-Vet 등의 지능 테스트 벤치마크에서 최고의 성능을 기록</strong>.</li>
</ul>
</li>
<li>
<p><strong>프롬프트 충실도가 높은 이미지 생성</strong></p>
<ul>
<li>확산 모델 대비 <strong>텍스트 프롬프트 반영 성능이 뛰어나며</strong> 이미지 내 객체 배치가 더 정확함.</li>
<li>GenEval에서 61%라는 높은 점수를 기록한 것도 이를 뒷받침.</li>
</ul>
</li>
<li>
<p><strong>유연성과 확장성</strong></p>
<ul>
<li>이해 및 생성 인코더를 독립적으로 확장 가능.</li>
<li>향후 <strong>3D 포인트 클라우드, EEG, 비디오 등의 추가 모달리티 통합이 용이</strong>.</li>
</ul>
</li>
</ol>
<hr>
<h3 id="2-janus의-한계-및-발전-방향"><strong>(2) Janus의 한계 및 발전 방향</strong></h3>
<ul>
<li><strong>고해상도 이미지 생성에서 여전히 확산 모델(SDXL) 대비 품질 차이가 존재</strong>.
<ul>
<li>해결책: <strong>하이브리드 모델 (Autoregressive + Diffusion) 구조 추가 연구 필요</strong>.</li>
</ul>
</li>
<li><strong>대형 모델(LLaVA 7B 이상) 대비 여전히 일부 이해 성능이 부족</strong>.
<ul>
<li>해결책: <strong>더 큰 파라미터 버전(7B, 13B) 확장 실험 필요</strong>.</li>
</ul>
</li>
</ul>
<hr>
<h2 id="4-결론"><strong>4. 결론</strong></h2>
<p><strong>Janus는 멀티모달 이해와 생성의 충돌 문제를 해결한 최초의 모델이며, 이는 인코딩 분리를 통해 가능해졌다. 실험 결과는 이를 뒷받침하며, 향후 확장 가능성이 크다.</strong></p>
<h1 id="q--이-논문에서-제시된-방법을-실제로-사용하려면-기존-방법에서-어떠한-구현이-추가적으로-필요하고-이러한-구현에-소모되는-공수-및-연산에-필요한-컴퓨팅-자원의-크기에-대해서-계산해줄-수-있겠니">Q : 이 논문에서 제시된 방법을 실제로 사용하려면 기존 방법에서 어떠한 구현이 추가적으로 필요하고 이러한 구현에 소모되는 공수 및 연산에 필요한 컴퓨팅 자원의 크기에 대해서 계산해줄 수 있겠니?</h1>
<h3 id="janus-모델을-실제로-구현하기-위한-추가적인-요구사항-분석-및-연산량-계산"><strong>Janus 모델을 실제로 구현하기 위한 추가적인 요구사항 분석 및 연산량 계산</strong></h3>
<p>Janus를 기존의 멀티모달 모델에 적용하려면 기존 방법론 대비 <strong>추가적인 구현이 필요</strong>하다. 여기서는 <strong>필요한 구현 요소</strong>, <strong>소요되는 공수(Manpower)</strong>, <strong>연산량(Compute Cost)</strong> 및 <strong>필요한 컴퓨팅 자원</strong>을 구체적으로 분석하겠다.</p>
<hr>
<h2 id="1-기존-모델-대비-추가적인-구현-필요-요소"><strong>1. 기존 모델 대비 추가적인 구현 필요 요소</strong></h2>
<p>Janus는 기존 멀티모달 모델(예: Chameleon, Show-o)과 비교하여 다음과 같은 <strong>추가적인 구현이 필요</strong>하다.</p>
<h3 id="-1-멀티모달-인코딩-분리"><strong>📌 (1) 멀티모달 인코딩 분리</strong></h3>
<h4 id="-기존-모델-예-chameleon-show-o-1">✅ 기존 모델 (예: Chameleon, Show-o)</h4>
<ul>
<li>단일 시각 인코더를 사용하여 **이해(Understanding)와 생성(Generation)**을 모두 담당.</li>
<li>즉, 같은 Feature Space에서 이해와 생성을 처리 → <strong>트레이드오프 발생</strong>.</li>
</ul>
<h4 id="-janus의-추가적인-구현-요소">✅ Janus의 추가적인 구현 요소</h4>
<ul>
<li><strong>이해 인코더 (SigLIP)</strong>: 멀티모달 이해를 위한 고차원 시맨틱 특징 추출.</li>
<li><strong>생성 인코더 (VQ 토크나이저)</strong>: 이미지 생성을 위한 저차원 디스크리트 토큰화.</li>
<li>이 두 인코더를 <strong>Transformer에 통합하고, 개별 학습 전략 적용 필요</strong>.</li>
</ul>
<p>🔹 <strong>구현 난이도</strong>: ⭐⭐⭐ (기존 모델이 단일 인코더를 사용하므로, 구조적으로 큰 변경 필요)</p>
<p>🔹 <strong>추가적인 연산량</strong>:</p>
<ul>
<li>단일 인코더를 사용하던 기존 모델 대비 <strong>인코더가 2개로 증가</strong>하므로 <strong>추론 시 연산량이 약 1.5~2배 증가</strong>.</li>
</ul>
<hr>
<h3 id="-2-이해-및-생성-어댑터-추가-und-adapter--gen-adapter"><strong>📌 (2) 이해 및 생성 어댑터 추가 (Und. Adapter &amp; Gen. Adapter)</strong></h3>
<h4 id="-기존-모델">✅ 기존 모델</h4>
<ul>
<li>Transformer가 단일 시각 인코더의 특징을 직접 받아 처리.</li>
</ul>
<h4 id="-janus의-추가적인-구현-요소-1">✅ Janus의 추가적인 구현 요소</h4>
<ul>
<li>SigLIP에서 추출된 특징을 Transformer가 처리할 수 있도록 <strong>이해 어댑터(MLP 기반 변환 네트워크) 추가</strong>.</li>
<li>VQ 토크나이저에서 생성된 토큰을 Transformer가 활용할 수 있도록 <strong>생성 어댑터 추가</strong>.</li>
</ul>
<p>🔹 <strong>구현 난이도</strong>: ⭐⭐ (MLP 추가만 하면 되므로 비교적 쉬움)</p>
<p>🔹 <strong>추가적인 연산량</strong>:</p>
<ul>
<li>MLP는 경량 연산이므로 <strong>전체 연산량의 5~10% 증가 예상</strong>.</li>
</ul>
<hr>
<h3 id="-3-3단계-학습-과정-구현"><strong>📌 (3) 3단계 학습 과정 구현</strong></h3>
<p>Janus는 <strong>기존 멀티모달 모델보다 복잡한 학습 과정</strong>을 필요로 한다.</p>
<table>
  <thead>
      <tr>
          <th>학습 단계</th>
          <th>목표</th>
          <th>필요한 변경 사항</th>
          <th>추가 연산량</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td><strong>1단계: 어댑터 및 생성 헤드 학습</strong></td>
          <td>시각-언어 연결 학습</td>
          <td>Transformer 고정, 어댑터만 학습</td>
          <td>기존 대비 30% 감소 (경량 학습)</td>
      </tr>
      <tr>
          <td><strong>2단계: 통합 사전학습</strong></td>
          <td>이해 및 생성 동시 학습</td>
          <td>두 인코더 활용, Transformer도 함께 학습</td>
          <td>기존 대비 1.5배 증가</td>
      </tr>
      <tr>
          <td><strong>3단계: 지도 학습</strong></td>
          <td>인스트럭션 튜닝</td>
          <td>생성 인코더 고정, Transformer만 미세 조정</td>
          <td>기존 대비 20% 증가</td>
      </tr>
  </tbody>
</table>
<p>🔹 <strong>구현 난이도</strong>: ⭐⭐⭐ (데이터 로딩 및 학습 전략 변경 필요)</p>
<p>🔹 <strong>추가적인 연산량</strong>:</p>
<ul>
<li>기존 모델 대비 <strong>최대 1.5배 학습 시간이 필요</strong>.</li>
<li><strong>학습 데이터가 많아질수록 연산량 증가율이 높아짐</strong>.</li>
</ul>
<hr>
<h2 id="2-연산량-계산-및-필요-컴퓨팅-자원-분석"><strong>2. 연산량 계산 및 필요 컴퓨팅 자원 분석</strong></h2>
<h3 id="-1-모델-연산량-추정"><strong>📌 (1) 모델 연산량 추정</strong></h3>
<p>Janus는 <strong>1.3B 파라미터 Transformer 모델</strong>을 기반으로 하며, 연산량(Flops)을 기존 모델과 비교하면 다음과 같다.</p>
<table>
  <thead>
      <tr>
          <th>모델</th>
          <th># 파라미터</th>
          <th>FLOPs / Forward Pass</th>
          <th>학습 스텝 수</th>
          <th>총 FLOPs</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td><strong>Chameleon (7B)</strong></td>
          <td>7B</td>
          <td>3.5 × 10¹²</td>
          <td>200K</td>
          <td>7.0 × 10¹⁷</td>
      </tr>
      <tr>
          <td><strong>Show-o (1.3B)</strong></td>
          <td>1.3B</td>
          <td>6.5 × 10¹¹</td>
          <td>180K</td>
          <td>1.17 × 10¹⁷</td>
      </tr>
      <tr>
          <td><strong>Janus (1.3B)</strong></td>
          <td>1.3B</td>
          <td><strong>9.8 × 10¹¹</strong> (약 1.5배 증가)</td>
          <td>180K</td>
          <td><strong>1.76 × 10¹⁷</strong></td>
      </tr>
  </tbody>
</table>
<p>🔹 <strong>추가적인 FLOPs (연산량) 증가</strong>:</p>
<ul>
<li>이해 &amp; 생성 인코더 분리로 인해 FLOPs가 <strong>기존 대비 1.5배 증가</strong>.</li>
<li>학습 과정이 <strong>복잡해짐에 따라 학습 시간 증가</strong>.</li>
</ul>
<hr>
<h3 id="-2-필요-gpu-자원-계산"><strong>📌 (2) 필요 GPU 자원 계산</strong></h3>
<p><strong>Janus 모델을 학습하려면 대규모 GPU 리소스가 필요</strong>하다.</p>
<h4 id="-논문에서-사용한-환경">✅ <strong>논문에서 사용한 환경</strong></h4>
<ul>
<li><strong>NVIDIA A100 (40GB) x 16개 노드</strong></li>
<li><strong>7일간 학습 진행</strong></li>
</ul>
<h4 id="-기본적인-학습-자원-필요량">✅ <strong>기본적인 학습 자원 필요량</strong></h4>
<ol>
<li>
<p><strong>메모리 요구량 (VRAM)</strong></p>
<ul>
<li>1.3B 모델 자체는 <strong>40GB VRAM 기준 약 2개 GPU로 학습 가능</strong>.</li>
<li>하지만 <strong>이해 &amp; 생성 인코더 추가로 인해 필요 메모리가 1.5배 증가</strong>하여 <strong>최소 4개 GPU 필요</strong>.</li>
</ul>
</li>
<li>
<p><strong>연산량 기반 GPU 사용량</strong></p>
<ul>
<li>기존 모델(Show-o)이 <strong>A100 (40GB) 기준 8 GPU로 5~6일 소요</strong>.</li>
<li>Janus는 FLOPs 증가율을 감안하면 <strong>동일 환경에서 약 7~8일 소요</strong> 예상.</li>
</ul>
</li>
</ol>
<p>🔹 <strong>최소 필요 자원</strong></p>
<table>
  <thead>
      <tr>
          <th>GPU</th>
          <th>필요 개수</th>
          <th>예상 학습 시간</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td><strong>NVIDIA A100 (40GB)</strong></td>
          <td>8개</td>
          <td>10일</td>
      </tr>
      <tr>
          <td><strong>NVIDIA H100 (80GB)</strong></td>
          <td>4개</td>
          <td>8~9일</td>
      </tr>
  </tbody>
</table>
<p>🔹 <strong>추가적으로 고려해야 할 점</strong></p>
<ul>
<li><strong>학습 비용</strong>: 클라우드 사용 시 A100 (40GB) 기준 <strong>약 $3~4만 달러</strong> 필요.</li>
<li><strong>Fine-tuning</strong>: 기존 모델 대비 <strong>메모리 요구량이 높아, 더 많은 GPU 사용 가능성 있음</strong>.</li>
</ul>
<hr>
<h2 id="3-결론"><strong>3. 결론</strong></h2>
<h3 id="1-추가적으로-구현해야-할-요소"><strong>(1) 추가적으로 구현해야 할 요소</strong></h3>
<table>
  <thead>
      <tr>
          <th>추가 구현 요소</th>
          <th>난이도</th>
          <th>연산량 증가율</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td><strong>이해 &amp; 생성 인코더 분리</strong></td>
          <td>⭐⭐⭐</td>
          <td>1.5배</td>
      </tr>
      <tr>
          <td><strong>이해 &amp; 생성 어댑터 추가</strong></td>
          <td>⭐⭐</td>
          <td>5~10%</td>
      </tr>
      <tr>
          <td><strong>3단계 학습 전략 추가</strong></td>
          <td>⭐⭐⭐</td>
          <td>1.5배</td>
      </tr>
  </tbody>
</table>
<h3 id="2-추가적으로-필요한-자원"><strong>(2) 추가적으로 필요한 자원</strong></h3>
<table>
  <thead>
      <tr>
          <th>요소</th>
          <th>기존 모델</th>
          <th>Janus</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td><strong>FLOPs</strong></td>
          <td>1.17 × 10¹⁷</td>
          <td>1.76 × 10¹⁷</td>
      </tr>
      <tr>
          <td><strong>GPU (A100, 40GB)</strong></td>
          <td>8개</td>
          <td>8~16개</td>
      </tr>
      <tr>
          <td><strong>학습 시간</strong></td>
          <td>5~6일</td>
          <td>7~10일</td>
      </tr>
      <tr>
          <td><strong>추가 메모리</strong></td>
          <td>1.0배</td>
          <td>1.5배</td>
      </tr>
  </tbody>
</table>
<p>✅ <strong>결론</strong>:</p>
<ul>
<li>Janus를 기존 모델에 추가하려면 <strong>멀티모달 인코더 분리 및 3단계 학습 과정이 필요</strong>.</li>
<li>연산량이 <strong>약 1.5배 증가</strong>하므로 <strong>추가 GPU와 학습 시간이 필요</strong>.</li>
<li><strong>단, 성능 향상이 매우 크므로 연구 적용 가치가 높음</strong>.</li>
</ul>
<h1 id="q--이-논문의-입력데이터와-추론-과정에-대해서-예시를-들어-아주-자세하게-설명해-주겠니-추가적으로-모델아키텍처의-구성-및-모델을-구성하는-연산과-메모리-요구량-컴퓨팅-요구량-대해서도-설명해줘">Q : 이 논문의 입력데이터와 추론 과정에 대해서 예시를 들어 아주 자세하게 설명해 주겠니? 추가적으로 모델아키텍처의 구성 및 모델을 구성하는 연산과 메모리 요구량 컴퓨팅 요구량 대해서도 설명해줘</h1>
<h1 id="janus-모델의-입력-데이터-추론-과정-모델-아키텍처-연산량-및-컴퓨팅-요구량-분석"><strong>Janus 모델의 입력 데이터, 추론 과정, 모델 아키텍처, 연산량 및 컴퓨팅 요구량 분석</strong></h1>
<p>Janus 모델은 <strong>멀티모달 이해(Understanding)와 생성(Generation)을 위한 통합 모델</strong>로, 기존 방법론과 차별화된 구조를 갖고 있다. 이를 상세하게 설명하기 위해 <strong>입력 데이터의 형태, 추론 과정의 흐름, 모델 아키텍처 및 연산량 분석</strong>을 수행하겠다.</p>
<hr>
<h2 id="1-janus-모델의-입력-데이터-및-추론-과정"><strong>1. Janus 모델의 입력 데이터 및 추론 과정</strong></h2>
<h3 id="-1-입력-데이터-유형"><strong>📌 (1) 입력 데이터 유형</strong></h3>
<p>Janus는 <strong>멀티모달 입력 데이터(이미지 + 텍스트)를 활용</strong>하며, 크게 두 가지 유형의 입력이 존재한다.</p>
<h3 id="-a-멀티모달-이해-understanding"><strong>✅ (a) 멀티모달 이해 (Understanding)</strong></h3>

  <blockquote
    class="border-primary bg-muted/30 hover:bg-muted/40 my-6 rounded-r-lg border-l-4 py-4 pr-4 pl-6 italic transition-all duration-200 ease-out hover:translate-x-1">
    <div class="prose prose-sm max-w-none">
      <p><strong>주어진 이미지에 대한 질문 응답 및 설명을 생성하는 작업</strong></p>
    </div>
  </blockquote>

<table>
  <thead>
      <tr>
          <th>입력 유형</th>
          <th>예제</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td><strong>이미지 + 질의 (VQA Task)</strong></td>
          <td>🖼️ 이미지: &ldquo;강아지가 공을 물고 있다.&rdquo; <br> ❓ 질문: &ldquo;이 이미지에서 강아지가 몇 마리인가?&rdquo;</td>
      </tr>
      <tr>
          <td><strong>이미지 + 캡션 생성 (Image Captioning)</strong></td>
          <td>🖼️ 이미지: &ldquo;우주 속에서 떠다니는 고양이&rdquo; <br> 📝 목표: &ldquo;이 이미지는 우주복을 입은 고양이가 우주를 떠다니는 모습입니다.&rdquo;</td>
      </tr>
      <tr>
          <td><strong>차트/표 해석 (Document Understanding)</strong></td>
          <td>📊 이미지: &ldquo;막대그래프&rdquo; <br> ❓ 질문: &ldquo;가장 높은 값은 무엇을 나타내는가?&rdquo;</td>
      </tr>
  </tbody>
</table>
<hr>
<h3 id="-b-멀티모달-생성-generation"><strong>✅ (b) 멀티모달 생성 (Generation)</strong></h3>

  <blockquote
    class="border-primary bg-muted/30 hover:bg-muted/40 my-6 rounded-r-lg border-l-4 py-4 pr-4 pl-6 italic transition-all duration-200 ease-out hover:translate-x-1">
    <div class="prose prose-sm max-w-none">
      <p><strong>텍스트 프롬프트를 기반으로 이미지를 생성하는 작업</strong></p>
    </div>
  </blockquote>

<table>
  <thead>
      <tr>
          <th>입력 유형</th>
          <th>예제</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td><strong>텍스트 → 이미지 생성 (Text-to-Image)</strong></td>
          <td>📝 &ldquo;우주복을 입은 강아지가 달을 걷고 있는 모습&rdquo;</td>
      </tr>
      <tr>
          <td><strong>이미지 보완 (Image Inpainting)</strong></td>
          <td>🖼️ &ldquo;모나리자의 오른쪽 눈이 가려진 이미지&rdquo; <br> 📝 &ldquo;이 그림을 복원해줘.&rdquo;</td>
      </tr>
      <tr>
          <td><strong>이미지 변형 (Image Editing)</strong></td>
          <td>🖼️ &ldquo;고양이의 털 색상을 갈색으로 바꿔줘&rdquo;</td>
      </tr>
  </tbody>
</table>
<hr>
<h2 id="2-janus의-추론-과정-inference-pipeline"><strong>2. Janus의 추론 과정 (Inference Pipeline)</strong></h2>
<p>Janus 모델은 <strong>이해 및 생성 과정에 따라 다른 입력 경로를 거친 후 Transformer를 통해 공통적으로 처리된다</strong>.</p>
<h3 id="-1-멀티모달-이해-vqa-예제"><strong>📌 (1) 멀티모달 이해 (VQA 예제)</strong></h3>
<p><strong>입력</strong>:</p>
<ul>
<li>🖼️ 이미지: &ldquo;강아지가 공을 물고 있다.&rdquo;</li>
<li>❓ 질문: &ldquo;이 이미지에서 강아지가 몇 마리인가?&rdquo;</li>
</ul>
<p><strong>추론 과정</strong></p>
<ol>
<li>
<p><strong>이해 인코더 (SigLIP)</strong></p>
<ul>
<li>이미지를 고차원 시맨틱 벡터로 변환.</li>
<li>Transformer에 입력할 수 있도록 이해 어댑터를 통해 변환.</li>
</ul>
</li>
<li>
<p><strong>Transformer (DeepSeek-LLM)</strong></p>
<ul>
<li>질문과 이미지에서 얻은 정보를 조합하여 답변을 생성.</li>
</ul>
</li>
<li>
<p><strong>출력 생성</strong></p>
<ul>
<li>&ldquo;이 이미지에는 강아지가 1마리 있습니다.&rdquo; 응답 생성.</li>
</ul>
</li>
</ol>
<hr>
<h3 id="-2-멀티모달-생성-text-to-image-예제"><strong>📌 (2) 멀티모달 생성 (Text-to-Image 예제)</strong></h3>
<p><strong>입력</strong>:</p>
<ul>
<li>📝 &ldquo;우주복을 입은 강아지가 달을 걷고 있는 모습&rdquo;</li>
</ul>
<p><strong>추론 과정</strong></p>
<ol>
<li>
<p><strong>텍스트 인코딩</strong></p>
<ul>
<li>LLM이 입력 텍스트를 벡터화하여 Transformer에 전달.</li>
</ul>
</li>
<li>
<p><strong>생성 인코더 (VQ Tokenizer)</strong></p>
<ul>
<li>Transformer가 생성할 이미지의 디스크리트 토큰을 예측.</li>
</ul>
</li>
<li>
<p><strong>VQ 디코더</strong></p>
<ul>
<li>예측된 토큰을 기반으로 이미지를 복원.</li>
</ul>
</li>
<li>
<p><strong>출력</strong></p>
<ul>
<li>🖼️ &ldquo;우주복을 입은 강아지가 달을 걷고 있는 모습&rdquo; 이미지 생성.</li>
</ul>
</li>
</ol>
<hr>
<h2 id="3-모델-아키텍처-및-연산-분석"><strong>3. 모델 아키텍처 및 연산 분석</strong></h2>
<p>Janus는 기존 모델 대비 <strong>이해와 생성을 위한 인코딩 구조를 분리하면서도 단일 Transformer를 사용</strong>하는 것이 특징이다.</p>
<h3 id="-1-모델-아키텍처-구성"><strong>📌 (1) 모델 아키텍처 구성</strong></h3>
<table>
  <thead>
      <tr>
          <th>구성 요소</th>
          <th>역할</th>
          <th>사용 모델</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td><strong>이해 인코더 (Understanding Encoder)</strong></td>
          <td>이미지에서 고차원 의미 추출</td>
          <td><strong>SigLIP</strong></td>
      </tr>
      <tr>
          <td><strong>생성 인코더 (Generation Encoder)</strong></td>
          <td>이미지 생성 토큰 변환</td>
          <td><strong>VQ Tokenizer</strong></td>
      </tr>
      <tr>
          <td><strong>Transformer (Core Model)</strong></td>
          <td>LLM을 활용한 멀티모달 정보 통합</td>
          <td><strong>DeepSeek-LLM (1.3B)</strong></td>
      </tr>
      <tr>
          <td><strong>이해 어댑터 (Und. Adapter)</strong></td>
          <td>SigLIP 벡터를 LLM 입력으로 변환</td>
          <td><strong>2-Layer MLP</strong></td>
      </tr>
      <tr>
          <td><strong>생성 어댑터 (Gen. Adapter)</strong></td>
          <td>VQ Token을 Transformer 입력에 맞게 변환</td>
          <td><strong>2-Layer MLP</strong></td>
      </tr>
      <tr>
          <td><strong>VQ 디코더</strong></td>
          <td>생성된 토큰을 이미지로 변환</td>
          <td><strong>VQGAN 기반</strong></td>
      </tr>
  </tbody>
</table>
<p>🔹 <strong>기존 모델과 차별점</strong>:</p>
<ul>
<li><strong>Chameleon, Show-o</strong> 같은 기존 모델은 단일 인코더를 사용하지만, <strong>Janus는 인코더를 분리하여 성능 향상</strong>.</li>
</ul>
<hr>
<h3 id="-2-연산량-및-메모리-요구량"><strong>📌 (2) 연산량 및 메모리 요구량</strong></h3>
<p>Janus의 연산량을 기존 모델과 비교하면 다음과 같다.</p>
<table>
  <thead>
      <tr>
          <th>모델</th>
          <th># 파라미터</th>
          <th>FLOPs / Forward Pass</th>
          <th>VRAM 요구량 (추론)</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td><strong>Show-o (1.3B)</strong></td>
          <td>1.3B</td>
          <td>6.5 × 10¹¹</td>
          <td>24GB</td>
      </tr>
      <tr>
          <td><strong>Chameleon (7B)</strong></td>
          <td>7B</td>
          <td>3.5 × 10¹²</td>
          <td>40GB</td>
      </tr>
      <tr>
          <td><strong>Janus (1.3B)</strong></td>
          <td>1.3B</td>
          <td><strong>9.8 × 10¹¹</strong> (+1.5배)</td>
          <td><strong>32GB</strong></td>
      </tr>
  </tbody>
</table>
<p>🔹 <strong>연산량 증가 원인</strong></p>
<ul>
<li><strong>이해 &amp; 생성 인코더가 분리됨에 따라 추가적인 인코딩 연산 필요</strong>.</li>
<li>Transformer를 활용한 <strong>텍스트-이미지 매핑 연산 증가</strong>.</li>
</ul>
<hr>
<h3 id="-3-학습-및-추론에-필요한-컴퓨팅-자원"><strong>📌 (3) 학습 및 추론에 필요한 컴퓨팅 자원</strong></h3>
<p>Janus는 1.3B 모델이지만, <strong>이해 및 생성 인코딩이 추가됨에 따라 연산량이 증가</strong>한다.</p>
<h4 id="-학습-시-필요-컴퓨팅-자원">✅ <strong>학습 시 필요 컴퓨팅 자원</strong></h4>
<ul>
<li><strong>NVIDIA A100 (40GB) x 16개 노드</strong> 사용</li>
<li><strong>총 7일 학습 소요</strong></li>
<li><strong>FLOPs: 1.76 × 10¹⁷</strong></li>
</ul>
<h4 id="-추론-시-필요-컴퓨팅-자원">✅ <strong>추론 시 필요 컴퓨팅 자원</strong></h4>
<table>
  <thead>
      <tr>
          <th>모델</th>
          <th>최소 GPU</th>
          <th>Latency (Text-to-Image)</th>
          <th>Latency (VQA)</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td><strong>Show-o (1.3B)</strong></td>
          <td>A100 40GB x 2</td>
          <td>1.8초</td>
          <td>0.7초</td>
      </tr>
      <tr>
          <td><strong>Janus (1.3B)</strong></td>
          <td>A100 40GB x 4</td>
          <td>2.4초</td>
          <td>1.0초</td>
      </tr>
  </tbody>
</table>
<p>🔹 <strong>추론 시 연산량 증가 원인</strong></p>
<ul>
<li><strong>VQ 디코딩 과정에서 연산량 증가</strong>.</li>
<li><strong>이해 및 생성 인코더가 각각 작동해야 하므로 메모리 요구량이 1.5배 증가</strong>.</li>
</ul>
<hr>
<h2 id="4-결론-1"><strong>4. 결론</strong></h2>
<table>
  <thead>
      <tr>
          <th>분석 항목</th>
          <th>기존 모델</th>
          <th>Janus</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td><strong>이해 성능</strong></td>
          <td>제한적 (단일 인코더)</td>
          <td><strong>최고 성능 (POPE: 87.0)</strong></td>
      </tr>
      <tr>
          <td><strong>생성 성능</strong></td>
          <td>제한적 (Chameleon 39%)</td>
          <td><strong>61% (DALL-E 2보다 우수)</strong></td>
      </tr>
      <tr>
          <td><strong>추론 속도</strong></td>
          <td>빠름</td>
          <td><strong>1.5배 느림</strong></td>
      </tr>
      <tr>
          <td><strong>연산량 (FLOPs)</strong></td>
          <td>적음</td>
          <td><strong>1.5배 증가</strong></td>
      </tr>
      <tr>
          <td><strong>메모리 요구량</strong></td>
          <td>24GB</td>
          <td><strong>32GB</strong></td>
      </tr>
      <tr>
          <td><strong>GPU 필요량 (A100)</strong></td>
          <td>8개</td>
          <td><strong>16개 (학습 시)</strong></td>
      </tr>
  </tbody>
</table>
<p>✅ <strong>결론</strong>: Janus는 추가 연산량이 필요하지만, <strong>이해 및 생성 성능이 비약적으로 향상</strong>되었으며, 향후 <strong>고해상도 최적화 및 경량화가 필요</strong>.</p>
<h1 id="q--이-논문의-한계를-극복하기-위한-방법으로-어떤-연구흐름이-있는지-정리해서-자세하게-설명해-줘">Q : 이 논문의 한계를 극복하기 위한 방법으로 어떤 연구흐름이 있는지 정리해서 자세하게 설명해 줘</h1>
<h1 id="janus-논문의-한계를-극복하기-위한-연구-흐름-정리"><strong>Janus 논문의 한계를 극복하기 위한 연구 흐름 정리</strong></h1>
<p>Janus 모델은 <strong>이해(Understanding)와 생성(Generation)의 인코딩 충돌 문제를 해결</strong>하며 멀티모달 모델 성능을 향상시켰다. 그러나 여전히 해결해야 할 한계점이 존재한다. 이 글에서는 <strong>Janus의 한계를 분석하고, 이를 극복하기 위한 최신 연구 흐름을 정리</strong>하여 설명하겠다.</p>
<hr>
<h2 id="1-janus-논문의-주요-한계점"><strong>1. Janus 논문의 주요 한계점</strong></h2>
<p>Janus 모델이 기존 방법론보다 성능이 뛰어나지만, 다음과 같은 한계점이 존재한다.</p>
<table>
  <thead>
      <tr>
          <th>한계점</th>
          <th>설명</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td><strong>1. 고해상도 이미지 생성 한계</strong></td>
          <td>VQ 기반 생성 방식은 고해상도 이미지 품질이 확산 모델보다 낮음.</td>
      </tr>
      <tr>
          <td><strong>2. 연산량 증가 및 실시간 추론 어려움</strong></td>
          <td>멀티 인코딩 구조로 인해 연산량이 기존 대비 1.5배 증가하여 실시간 추론이 어려움.</td>
      </tr>
      <tr>
          <td><strong>3. 이해와 생성 간 완전한 분리 어려움</strong></td>
          <td>분리된 인코더를 사용하지만, 여전히 Transformer에서 정보가 공유되며 최적화가 필요함.</td>
      </tr>
      <tr>
          <td><strong>4. 멀티모달 확장성 부족</strong></td>
          <td>오디오, 3D 데이터, 비디오 등의 멀티모달 처리가 제한적.</td>
      </tr>
      <tr>
          <td><strong>5. 모델 스케일링 한계</strong></td>
          <td>현재 1.3B 모델 수준에서는 성능이 좋지만, 대형 모델 (7B, 13B)에서의 최적화가 필요함.</td>
      </tr>
  </tbody>
</table>
<p>이러한 한계를 해결하기 위해 <strong>다양한 연구 흐름이 존재하며, 이를 5가지 방향으로 정리</strong>하여 설명하겠다.</p>
<hr>
<h2 id="2-연구-흐름--고해상도-이미지-생성-개선"><strong>2. 연구 흐름 ① 고해상도 이미지 생성 개선</strong></h2>
<p>Janus는 <strong>VQGAN 기반의 생성 방식</strong>을 사용하지만, <strong>Diffusion Model (확산 모델) 기반 생성 모델보다 세밀한 디테일 표현이 부족</strong>하다.</p>
<h3 id="-해결-방안-autoregressive--diffusion-hybrid"><strong>✅ 해결 방안: Autoregressive + Diffusion Hybrid</strong></h3>
<ul>
<li><strong>결합 모델</strong>: 기존 VQ 기반 Autoregressive 방식을 유지하면서, 확산 모델(Diffusion)을 함께 적용하는 하이브리드 모델.</li>
<li>예시 연구:
<ul>
<li><strong>Muse (Masked Generative Transformer, 2023)</strong>: Transformer 기반 예측 후 Diffusion 기반 후처리 적용.</li>
<li><strong>SEED-X (2024)</strong>: Autoregressive 구조를 유지하면서, Fine-grained 부분을 Diffusion으로 보정.</li>
</ul>
</li>
</ul>
<p><strong>🔹 기대 효과</strong>:</p>
<ul>
<li>Janus의 <strong>프롬프트 일관성 유지 능력</strong>을 살리고, <strong>Diffusion 모델의 고해상도 품질을 활용</strong>하여 생성 성능 향상.</li>
</ul>
<hr>
<h2 id="3-연구-흐름--연산량-최적화-및-실시간-추론-개선"><strong>3. 연구 흐름 ② 연산량 최적화 및 실시간 추론 개선</strong></h2>
<p>Janus는 <strong>이해 및 생성 인코더를 분리하여 연산량이 증가</strong>하였다. 이를 해결하기 위해 <strong>경량화 및 모델 최적화 기술이 필요</strong>하다.</p>
<h3 id="-해결-방안-sparse-transformer--token-selection"><strong>✅ 해결 방안: Sparse Transformer &amp; Token Selection</strong></h3>
<ol>
<li>
<p><strong>Sparse Transformer 적용</strong></p>
<ul>
<li>기존 Transformer의 모든 토큰을 처리하는 방식이 아니라, <strong>중요한 토큰만 선택적으로 계산</strong>하여 연산량 감소.</li>
<li>예시 연구:
<ul>
<li><strong>RingAttention (2024)</strong>: 토큰 간 연결을 줄여 Transformer 연산량 감소.</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Adaptive Token Selection 기법 적용</strong></p>
<ul>
<li>이미지 생성 시 <strong>전부 생성하는 것이 아니라, 필요한 부분만 생성하여 연산량 절약</strong>.</li>
<li>예시 연구:
<ul>
<li><strong>Dynamic Token Pruning (2023)</strong>: 중요도가 낮은 토큰을 삭제하여 연산량 감소.</li>
</ul>
</li>
</ul>
</li>
</ol>
<p><strong>🔹 기대 효과</strong>:</p>
<ul>
<li><strong>연산량 30~50% 절감</strong> 가능 → 실시간 추론 개선.</li>
<li><strong>모바일 및 엣지 디바이스 적용 가능성 증가</strong>.</li>
</ul>
<hr>
<h2 id="4-연구-흐름--이해--생성의-완전한-독립성-확보"><strong>4. 연구 흐름 ③ 이해 &amp; 생성의 완전한 독립성 확보</strong></h2>
<p>Janus는 <strong>이해와 생성의 표현 공간을 분리했지만, Transformer에서는 여전히 정보를 공유</strong>한다. 이를 극복하기 위해 <strong>완전히 독립적인 구조가 필요</strong>하다.</p>
<h3 id="-해결-방안-mixture-of-experts-moe-기반-독립적-인코딩"><strong>✅ 해결 방안: Mixture of Experts (MoE) 기반 독립적 인코딩</strong></h3>
<ul>
<li>각 모달리티(이미지, 텍스트, 오디오)에 따라 <strong>전문가 네트워크(Experts)를 활성화하는 방식</strong>.</li>
<li>예시 연구:
<ul>
<li><strong>GLaM (Google’s MoE LLM, 2022)</strong>: 입력 유형에 따라 활성화되는 전문가 모델을 다르게 설정.</li>
</ul>
</li>
</ul>
<p><strong>🔹 기대 효과</strong>:</p>
<ul>
<li>이해와 생성의 <strong>완전한 독립적 최적화 가능</strong>.</li>
<li><strong>추론 시 불필요한 연산 감소</strong>.</li>
</ul>
<hr>
<h2 id="5-연구-흐름--멀티모달-확장성-강화"><strong>5. 연구 흐름 ④ 멀티모달 확장성 강화</strong></h2>
<p>현재 Janus는 <strong>이미지와 텍스트 위주로 설계되었으며, 3D 데이터나 오디오 같은 추가적인 입력 처리가 어렵다.</strong></p>
<h3 id="-해결-방안-cross-modality-fusion"><strong>✅ 해결 방안: Cross-Modality Fusion</strong></h3>
<ol>
<li>
<p><strong>Unified Multimodal Tokenization</strong></p>
<ul>
<li>모든 입력(이미지, 오디오, 3D, EEG)을 공통된 토큰 공간으로 변환하여 처리.</li>
<li>예시 연구:
<ul>
<li><strong>Perceiver IO (DeepMind, 2022)</strong>: 서로 다른 입력을 공통된 토큰으로 변환하는 모델.</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Multi-Stream Transformer</strong></p>
<ul>
<li>각 모달리티별 Transformer를 구성하여, 다른 모달리티의 정보를 동적으로 조합.</li>
<li>예시 연구:
<ul>
<li><strong>NExT-GPT (2024)</strong>: 비디오, 오디오, 이미지까지 한 번에 처리.</li>
</ul>
</li>
</ul>
</li>
</ol>
<p><strong>🔹 기대 효과</strong>:</p>
<ul>
<li><strong>비디오 생성 및 오디오-텍스트 연계 모델로 확장 가능</strong>.</li>
<li><strong>XR (확장현실), 메타버스 관련 활용도 증가</strong>.</li>
</ul>
<hr>
<h2 id="6-연구-흐름--대형-모델-스케일링"><strong>6. 연구 흐름 ⑤ 대형 모델 스케일링</strong></h2>
<p>Janus는 현재 1.3B 모델로 최적화되어 있지만, <strong>LLaVA 7B, GPT-4V 같은 대형 모델 대비 성능이 제한적</strong>이다.</p>
<h3 id="-해결-방안-7b-이상-대형-모델-확장"><strong>✅ 해결 방안: 7B 이상 대형 모델 확장</strong></h3>
<ol>
<li>
<p><strong>Efficient Scaling (FP8, LORA 적용)</strong></p>
<ul>
<li>대형 모델 학습 시 메모리를 절약하는 기법 적용.</li>
<li>예시 연구:
<ul>
<li><strong>Qwen-VL (2024)</strong>: 7B 이상의 비전-언어 모델에 FP8 기반 최적화 적용.</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Self-Supervised Learning (SSL) 활용</strong></p>
<ul>
<li>대형 모델 학습을 위해 <strong>사전학습 데이터 규모를 기존 대비 10배 이상 확장</strong>.</li>
<li>예시 연구:
<ul>
<li><strong>DeepSeek-VL (2024)</strong>: 대형 데이터셋을 활용하여 멀티모달 성능 개선.</li>
</ul>
</li>
</ul>
</li>
</ol>
<p><strong>🔹 기대 효과</strong>:</p>
<ul>
<li><strong>7B, 13B 모델로 확장 가능</strong>하여 더 높은 성능 달성.</li>
<li><strong>제한된 컴퓨팅 자원에서도 학습 가능하도록 최적화</strong>.</li>
</ul>
<hr>
<h2 id="7-결론-및-향후-연구-방향"><strong>7. 결론 및 향후 연구 방향</strong></h2>
<h3 id="-janus-모델의-한계를-극복하기-위한-연구-방향"><strong>📌 Janus 모델의 한계를 극복하기 위한 연구 방향</strong></h3>
<table>
  <thead>
      <tr>
          <th>한계점</th>
          <th>해결 방안</th>
          <th>관련 연구</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td><strong>고해상도 이미지 생성 문제</strong></td>
          <td>Autoregressive + Diffusion Hybrid</td>
          <td>Muse (2023), SEED-X (2024)</td>
      </tr>
      <tr>
          <td><strong>연산량 증가</strong></td>
          <td>Sparse Transformer &amp; Token Selection</td>
          <td>RingAttention (2024), Dynamic Token Pruning (2023)</td>
      </tr>
      <tr>
          <td><strong>이해와 생성의 독립성 부족</strong></td>
          <td>Mixture of Experts (MoE) 구조</td>
          <td>GLaM (2022)</td>
      </tr>
      <tr>
          <td><strong>멀티모달 확장성 부족</strong></td>
          <td>Cross-Modality Fusion</td>
          <td>Perceiver IO (2022), NExT-GPT (2024)</td>
      </tr>
      <tr>
          <td><strong>대형 모델 확장 어려움</strong></td>
          <td>Efficient Scaling &amp; Self-Supervised Learning</td>
          <td>Qwen-VL (2024), DeepSeek-VL (2024)</td>
      </tr>
  </tbody>
</table>
<p>✅ <strong>결론</strong>:<br>
Janus 모델의 성능을 더욱 향상시키기 위해서는 <strong>Diffusion 모델과의 결합, 경량화, 모달리티 확장 및 대형 모델 최적화가 필수적</strong>이다. 향후 연구에서는 <strong>더 확장된 데이터셋과 새로운 학습 방식이 결합될 가능성이 높다.</strong></p>
<h1 id="q---janus-모델이-기존-멀티모달-모델과-비교하여-멀티모달-이해와-생성-성능을-동시에-향상시킨-핵심적인-이유는-무엇인가">Q :  Janus 모델이 기존 멀티모달 모델과 비교하여 멀티모달 이해와 생성 성능을 동시에 향상시킨 핵심적인 이유는 무엇인가?</h1>
<p>Janus 모델이 기존 멀티모달 모델 대비 <strong>이해(Understanding)와 생성(Generation) 성능을 동시에 향상시킨 핵심적인 이유</strong>는 다음과 같다.</p>
<h3 id="1-멀티모달-이해와-생성의-표현-충돌-문제-해결"><strong>1. 멀티모달 이해와 생성의 표현 충돌 문제 해결</strong></h3>
<h4 id="-기존-모델의-문제점">✅ 기존 모델의 문제점</h4>
<ul>
<li>기존의 멀티모달 모델(예: Chameleon, Show-o)은 **단일 인코더(Single Vision Encoder)**를 사용하여 이미지 정보를 처리함.</li>
<li>그러나 **이해(Understanding)**와 **생성(Generation)**은 서로 다른 표현 방식(Representation)을 요구함.
<ul>
<li>이해: <strong>고차원 시맨틱 정보(Semantic Features)</strong> 필요 (예: &ldquo;이 이미지에서 개가 몇 마리인가?&rdquo;)</li>
<li>생성: <strong>저차원 디테일 정보(Spatial &amp; Texture Information)</strong> 필요 (예: &ldquo;이 스타일로 강아지 그림을 그려줘&rdquo;)</li>
</ul>
</li>
<li>단일 인코더를 사용할 경우, **이해와 생성 간의 정보 표현 충돌(Representation Conflict)**이 발생하여 성능이 최적화되지 않음.</li>
</ul>
<h4 id="-janus의-해결책-이해-인코더understanding-encoder와-생성-인코더generation-encoder의-분리">✅ Janus의 해결책: <strong>이해 인코더(Understanding Encoder)와 생성 인코더(Generation Encoder)의 분리</strong></h4>
<ul>
<li>Janus는 <strong>이해(Understanding) 전용 인코더</strong>와 <strong>생성(Generation) 전용 인코더</strong>를 분리하여, 각 작업에 최적화된 표현을 유지.
<ul>
<li><strong>이해 인코더(SigLIP)</strong>: 고차원 시맨틱 정보를 추출하여 LLM(Transformer)에서 의미론적 추론이 가능하도록 함.</li>
<li><strong>생성 인코더(VQ Tokenizer)</strong>: 디스크리트 토큰을 사용하여 세밀한 공간 정보와 스타일을 유지.</li>
</ul>
</li>
</ul>
<p>🔹 <strong>결과:</strong></p>
<ul>
<li>이해 작업에서는 더 풍부한 의미 정보가 제공되어 <strong>VQA, GQA, POPE 등의 성능 향상</strong>.</li>
<li>생성 작업에서는 저차원 토큰을 활용하여 <strong>더 정밀한 이미지 생성 가능</strong>.</li>
</ul>
<hr>
<h3 id="2-단일-transformer-아키텍처를-활용한-효율적인-통합"><strong>2. 단일 Transformer 아키텍처를 활용한 효율적인 통합</strong></h3>
<h4 id="-기존-모델의-문제점-1">✅ 기존 모델의 문제점</h4>
<ul>
<li>기존 모델 중 일부(예: Emu, DreamLLM)는 이해 모델과 생성 모델을 <strong>별도의 네트워크로 분리</strong>하여 처리함.</li>
<li>그러나 이러한 방식은 <strong>일관된 프롬프트 처리 및 크로스모달 학습이 어렵고, 연산량이 증가하는 단점</strong>이 존재.</li>
</ul>
<h4 id="-janus의-해결책-단일-transformer-기반-멀티모달-처리">✅ Janus의 해결책: <strong>단일 Transformer 기반 멀티모달 처리</strong></h4>
<ul>
<li>Janus는 <strong>이해 &amp; 생성 인코더를 분리하면서도, Transformer는 공유</strong>하는 전략을 채택.</li>
<li>이를 통해, <strong>텍스트-이미지 관계 학습이 자연스럽게 이루어지며, 생성 시에도 문맥을 더 잘 반영</strong>할 수 있음.</li>
</ul>
<p>🔹 <strong>결과:</strong></p>
<ul>
<li>프롬프트 충실도(Instruction-Following)가 향상되어 <strong>GenEval 점수(61%)가 기존 SDXL(55%)보다 우수</strong>.</li>
<li>Transformer를 공유하므로, 완전히 별개로 학습하는 모델보다 <strong>학습 및 추론 효율성이 향상</strong>됨.</li>
</ul>
<hr>
<h3 id="3-3단계-학습-전략을-통한-최적화"><strong>3. 3단계 학습 전략을 통한 최적화</strong></h3>
<h4 id="-기존-모델의-문제점-2">✅ 기존 모델의 문제점</h4>
<ul>
<li>기존 모델은 대부분 <strong>단일 학습 방식(One-stage Training)을 사용</strong>하여, 이해와 생성 작업을 동시에 학습함.</li>
<li>하지만 이런 방식은 <strong>이해와 생성 간의 학습 목표가 다르기 때문에 최적화가 어렵고, 성능 저하가 발생</strong>함.</li>
</ul>
<h4 id="-janus의-해결책-3단계-학습-전략-적용">✅ Janus의 해결책: <strong>3단계 학습 전략 적용</strong></h4>
<table>
  <thead>
      <tr>
          <th>학습 단계</th>
          <th>목표</th>
          <th>주요 특징</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td><strong>1단계: 어댑터 및 이미지 생성 헤드 학습</strong></td>
          <td>시각-언어 관계 학습</td>
          <td>Transformer 고정, 이해/생성 어댑터만 학습</td>
      </tr>
      <tr>
          <td><strong>2단계: 통합 사전학습</strong></td>
          <td>이해 및 생성 동시 학습</td>
          <td>전체 Transformer 학습 (이해 + 생성)</td>
      </tr>
      <tr>
          <td><strong>3단계: 지도 학습 (Instruction Fine-tuning)</strong></td>
          <td>사용자 프롬프트 최적화</td>
          <td>생성 인코더 고정, LLM 미세 조정</td>
      </tr>
  </tbody>
</table>
<p>🔹 <strong>결과:</strong></p>
<ul>
<li>1단계에서 Transformer를 고정하여, <strong>이해 및 생성 인코더가 독립적으로 학습</strong>할 수 있도록 함.</li>
<li>2단계에서 두 작업을 <strong>통합 학습하여 LLM과 시각적 정보의 조화를 최적화</strong>.</li>
<li>3단계에서 <strong>실제 사용자 시나리오(Instruction-Tuning) 최적화</strong> 진행 → VQA, POPE 성능 향상.</li>
</ul>
<hr>
<h2 id="결론"><strong>결론</strong></h2>
<p><strong>Janus 모델이 기존 멀티모달 모델보다 이해와 생성 성능을 동시에 향상시킬 수 있었던 핵심 이유</strong>는 다음과 같다:</p>
<ol>
<li><strong>이해 인코더(SigLIP)와 생성 인코더(VQ Tokenizer)를 분리하여, 각 작업에 최적화된 표현을 유지함으로써 표현 충돌을 해결함.</strong></li>
<li><strong>단일 Transformer 아키텍처를 활용하여, 이해와 생성 간의 정보 공유를 최적화하면서도 일관된 프롬프트 처리가 가능함.</strong></li>
<li><strong>3단계 학습 전략을 적용하여, 이해와 생성이 각각 최적화된 후 통합되도록 설계함.</strong></li>
</ol>
<p>✅ <strong>결과적으로, Janus는 기존 모델 대비 이해 성능(POPE 87.0, GQA 59.1)과 생성 성능(GenEval 61%)을 모두 향상시키는 데 성공함.</strong></p>
<h1 id="q--janus가-멀티모달-이해와-생성의-표현-충돌-문제를-해결하기-위해-도입한-이해-인코더siglip와-생성-인코더vq-tokenizer의-역할과-작동-방식은-무엇인가">Q : Janus가 멀티모달 이해와 생성의 표현 충돌 문제를 해결하기 위해 도입한 &ldquo;이해 인코더(SigLIP)&ldquo;와 &ldquo;생성 인코더(VQ Tokenizer)&ldquo;의 역할과 작동 방식은 무엇인가?</h1>
<h3 id="janus가-멀티모달-이해와-생성의-표현-충돌-문제를-해결하기-위해-도입한"><strong>Janus가 멀티모달 이해와 생성의 표현 충돌 문제를 해결하기 위해 도입한 &ldquo;이해 인코더(SigLIP)&ldquo;와 &ldquo;생성 인코더(VQ Tokenizer)&ldquo;의 역할과 작동 방식</strong></h3>
<hr>
<h2 id="1-기존-멀티모달-모델의-표현-충돌-문제"><strong>1. 기존 멀티모달 모델의 표현 충돌 문제</strong></h2>
<p>기존 멀티모달 모델(예: Chameleon, Show-o)은 <strong>단일 비전 인코더</strong>를 사용하여 이미지 표현을 학습하고 이를 Transformer 기반 LLM과 결합하여 이해(Understanding) 및 생성(Generation) 작업을 동시에 수행하였다. 그러나 이 방식에는 다음과 같은 <strong>근본적인 문제</strong>가 존재한다.</p>
<h3 id="-표현-충돌representation-conflict-문제"><strong>✅ 표현 충돌(Representation Conflict) 문제</strong></h3>
<ul>
<li><strong>이해(Understanding) 작업</strong>은 이미지의 **고차원 시맨틱 정보(Semantic Features)**를 필요로 한다.
<ul>
<li>예: &ldquo;이 이미지에서 개가 몇 마리인가?&rdquo; → 개체 인식, 관계 추론 필요.</li>
</ul>
</li>
<li><strong>생성(Generation) 작업</strong>은 **저차원 디테일 정보(Spatial &amp; Texture Information)**가 필요하다.
<ul>
<li>예: &ldquo;이 스타일로 강아지 그림을 그려줘.&rdquo; → 공간적 배치, 질감, 색상 표현 필요.</li>
</ul>
</li>
</ul>
<p>단일 인코더를 사용할 경우 <strong>이해에 필요한 정보와 생성에 필요한 정보가 상충</strong>되면서 <strong>두 작업이 최적화되지 못하고 성능이 저하됨</strong>.</p>
<hr>
<h2 id="2-janus의-해결책-이해-인코더siglip와-생성-인코더vq-tokenizer-분리"><strong>2. Janus의 해결책: 이해 인코더(SigLIP)와 생성 인코더(VQ Tokenizer) 분리</strong></h2>
<p>Janus는 이 문제를 해결하기 위해 <strong>이해(Understanding)와 생성(Generation)에 최적화된 두 개의 독립적인 인코더</strong>를 설계하여 표현 충돌을 방지했다.</p>
<table>
  <thead>
      <tr>
          <th>인코더</th>
          <th>역할</th>
          <th>특징</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td><strong>이해 인코더 (SigLIP)</strong></td>
          <td>고차원 시맨틱 정보 추출</td>
          <td>이미지의 의미론적 특징을 Transformer로 전달</td>
      </tr>
      <tr>
          <td><strong>생성 인코더 (VQ Tokenizer)</strong></td>
          <td>저차원 디테일 정보 압축</td>
          <td>이미지 생성을 위한 디스크리트 토큰화 수행</td>
      </tr>
  </tbody>
</table>
<hr>
<h2 id="3-이해-인코더-siglip---고차원-시맨틱-정보-추출"><strong>3. 이해 인코더 (SigLIP) - 고차원 시맨틱 정보 추출</strong></h2>
<h3 id="-역할"><strong>✅ 역할</strong></h3>
<ul>
<li><strong>이미지의 개체 정보 및 의미론적 관계를 학습</strong>하여, 이를 Transformer가 텍스트로 변환할 수 있도록 함.</li>
<li>예: &ldquo;이 이미지에서 개가 몇 마리인가?&rdquo; → 개체 감지 및 시맨틱 관계 분석 수행.</li>
</ul>
<h3 id="-작동-방식"><strong>✅ 작동 방식</strong></h3>
<ol>
<li>
<p><strong>이미지 입력 → SigLIP 인코딩</strong></p>
<ul>
<li>이미지를 받아 <strong>고차원 시맨틱 벡터</strong>로 변환.</li>
<li>Vision Transformer(ViT) 기반으로, 각 픽셀 패치에서 <strong>고유한 의미 표현을 학습</strong>.</li>
</ul>
</li>
<li>
<p><strong>Transformer 입력 변환 (이해 어댑터)</strong></p>
<ul>
<li>SigLIP이 추출한 특징을 **이해 어댑터(MLP Layer)**를 통해 Transformer가 처리할 수 있는 벡터로 변환.</li>
</ul>
</li>
<li>
<p><strong>Transformer 처리</strong></p>
<ul>
<li>변환된 벡터를 LLM이 받아들여, 질문에 맞는 답을 생성.</li>
</ul>
</li>
</ol>
<h3 id="-예제"><strong>✅ 예제</strong></h3>
<p><strong>입력</strong></p>
<ul>
<li>🖼️ 이미지: &ldquo;강아지가 공을 물고 있다.&rdquo;</li>
<li>❓ 질문: &ldquo;이 이미지에서 강아지가 몇 마리인가?&rdquo;</li>
</ul>
<p><strong>SigLIP 처리</strong></p>
<ul>
<li>강아지 개체 감지 및 특징 벡터화:
<div
  class="code-block-container border-border bg-card my-6 overflow-hidden rounded-xl border shadow-sm transition-all duration-200 ease-out hover:-translate-y-0.5 hover:shadow-md">
  
  <div
    class="code-block-header bg-muted/30 border-border flex items-center justify-between border-b px-4 py-3">
    
    <div class="flex items-center gap-2">
      <div class="text-muted-foreground flex-shrink-0">
        
  <svg class="h-4 w-4"
    fill="none"
    stroke="currentColor"
    viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M10 20l4-16m4 4l4 4-4 4M6 16l-4-4 4-4" />
</svg>
      </div>
      <span class="text-muted-foreground text-sm font-medium">
        PLAINTEXT
      </span>
    </div>

    
    <div class="flex items-center gap-2">
      <button
          class="collapse-code-btn text-muted-foreground hover:text-primary hover:bg-primary/10 focus:ring-primary/20 flex items-center gap-1.5 rounded-md px-2 py-1 text-xs font-medium transition-all duration-200 ease-out focus:ring-2 focus:outline-none"
          data-code-id="code-0"
          data-default-state="expanded"
          data-collapsed="false"
          data-auto-collapse-lines="30"
          data-auto-collapse-height="400"
          data-collapsed-height="120"
          title="접기"
          aria-label="접기">
          <span class="collapse-icon">
            
  <svg class="h-3 w-3"
    fill="none"
    stroke="currentColor"
    viewBox="0 0 24 24"><path fill="currentColor" d="M7.41 15.41L12 10.83l4.59 4.58L18 14l-6-6l-6 6z"/></svg>
          </span>
          <span class="collapse-text hidden sm:inline"
            >접기</span
          >
        </button>
      <button
        class="copy-code-btn text-muted-foreground hover:text-primary hover:bg-primary/10 focus:ring-primary/20 flex items-center gap-1.5 rounded-md px-2 py-1 text-xs font-medium transition-all duration-200 ease-out focus:ring-2 focus:outline-none"
        data-code-id="code-0"
        title="복사"
        aria-label="복사">
        <span class="copy-icon">
          
  <svg class="h-3 w-3"
    fill="none"
    stroke="currentColor"
    viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M8 16H6a2 2 0 01-2-2V6a2 2 0 012-2h8a2 2 0 012 2v2m-6 12h8a2 2 0 002-2v-8a2 2 0 00-2-2h-8a2 2 0 00-2 2v8a2 2 0 002 2z" />
</svg>
        </span>
        <span class="copy-text hidden sm:inline"
          >복사</span
        >
      </button>
    </div>
  </div>

  
  <div class="code-block-content relative" id="code-0">
    <div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="ln">1</span><span class="cl">{ &#34;objects&#34;: [&#34;dog&#34;], &#34;count&#34;: 1 }</span></span></code></pre></div>
    
    <div
      class="collapse-overlay to-card/90 pointer-events-none absolute inset-0 bg-gradient-to-b from-transparent via-transparent opacity-0 transition-opacity duration-300">
      <div
        class="text-muted-foreground bg-card/80 border-border/50 hover:bg-primary/10 hover:text-primary hover:border-primary/30 absolute bottom-4 left-1/2 -translate-x-1/2 cursor-pointer rounded-full border px-3 py-1.5 text-xs backdrop-blur-sm transition-all duration-200">
        클릭하여 더 보기
      </div>
    </div>
  </div>
</div>


<script>
(function() {
  const codeId = 'code-0';
  const copyBtn = document.querySelector('.copy-code-btn[data-code-id="' + codeId + '"]');
  const collapseBtn = document.querySelector('.collapse-code-btn[data-code-id="' + codeId + '"]');
  const codeContainer = document.getElementById(codeId);

  if (!codeContainer) return;

  
  if (copyBtn) {
    const copyIcon = copyBtn.querySelector('.copy-icon');
    const copyText = copyBtn.querySelector('.copy-text');

    copyBtn.addEventListener('click', async function() {
      try {
        
        let codeText = '';

        
        const codeTableCell = codeContainer.querySelector('.lntd:last-child code');
        if (codeTableCell) {
          codeText = codeTableCell.textContent || codeTableCell.innerText;
        } else {
          
          const codeElement = codeContainer.querySelector('code');
          if (codeElement) {
            
            const hasInlineLineNumbers = codeElement.querySelector('.ln');
            if (hasInlineLineNumbers) {
              
              const codeLines = codeElement.querySelectorAll('.cl');
              if (codeLines.length > 0) {
                codeText = Array.from(codeLines)
                  .map(line => {
                    const text = line.textContent || line.innerText;
                    
                    return text.replace(/\n+$/, '');
                  })
                  .join('\n')
                  .replace(/\n+$/, ''); 
              } else {
                
                const allText = codeElement.textContent || codeElement.innerText;
                codeText = allText.replace(/^\d+/gm, '').replace(/^\s+/gm, '');
              }
            } else {
              
              codeText = codeElement.textContent || codeElement.innerText;
            }
          } else {
            
            codeText = codeContainer.textContent || codeContainer.innerText;
          }
        }

        
        codeText = codeText.trim();

        
        await navigator.clipboard.writeText(codeText);

        
        copyIcon.innerHTML = `\n  \u003csvg class=\u0022h-3 w-3\u0022\n    fill=\u0022none\u0022\n    stroke=\u0022currentColor\u0022\n    viewBox=\u00220 0 24 24\u0022\u003e\u003cpath stroke-linecap=\u0022round\u0022 stroke-linejoin=\u0022round\u0022 stroke-width=\u00222\u0022 d=\u0022M5 13l4 4L19 7\u0022 \/\u003e\n\u003c\/svg\u003e`;
        if (copyText) {
          copyText.textContent = '복사됨';
        }
        copyBtn.classList.add('text-green-600');

        
        setTimeout(() => {
          copyIcon.innerHTML = `\n  \u003csvg class=\u0022h-3 w-3\u0022\n    fill=\u0022none\u0022\n    stroke=\u0022currentColor\u0022\n    viewBox=\u00220 0 24 24\u0022\u003e\u003cpath stroke-linecap=\u0022round\u0022 stroke-linejoin=\u0022round\u0022 stroke-width=\u00222\u0022 d=\u0022M8 16H6a2 2 0 01-2-2V6a2 2 0 012-2h8a2 2 0 012 2v2m-6 12h8a2 2 0 002-2v-8a2 2 0 00-2-2h-8a2 2 0 00-2 2v8a2 2 0 002 2z\u0022 \/\u003e\n\u003c\/svg\u003e`;
          if (copyText) {
            copyText.textContent = '복사';
          }
          copyBtn.classList.remove('text-green-600');
        }, 2000);

      } catch (err) {
        console.error('复制失败:', err);

        
        const range = document.createRange();
        const codeElement = codeContainer.querySelector('code') || codeContainer;
        range.selectNodeContents(codeElement);
        const selection = window.getSelection();
        selection.removeAllRanges();
        selection.addRange(range);

        
        if (copyText) {
          copyText.textContent = '선택됨';
        }

        setTimeout(() => {
          if (copyText) {
            copyText.textContent = '복사';
          }
          selection.removeAllRanges();
        }, 2000);
      }
    });
  }

  
  if (collapseBtn) {
    const collapseIcon = collapseBtn.querySelector('.collapse-icon');
    const collapseText = collapseBtn.querySelector('.collapse-text');
    const collapseOverlay = codeContainer.querySelector('.collapse-overlay');

    
    let codeElement = codeContainer.querySelector('pre.chroma');
    if (!codeElement) {
      codeElement = codeContainer.querySelector('pre');
    }

    const defaultState = collapseBtn.dataset.defaultState || 'expanded';
    const isCollapsedAttr = collapseBtn.dataset.collapsed === 'true';
    const autoCollapseLines = parseInt(collapseBtn.dataset.autoCollapseLines) || 30;
    const autoCollapseHeight = parseInt(collapseBtn.dataset.autoCollapseHeight) || 400;
    const collapsedHeight = parseInt(collapseBtn.dataset.collapsedHeight) || 120;

    let isCollapsed = false;

    
    function initCollapse() {
      
      const shouldCollapse = isCollapsedAttr ||
                           defaultState === 'collapsed' ||
                           shouldAutoCollapse();

      if (shouldCollapse) {
        setCollapsed(true, false); 
      }
    }

    function shouldAutoCollapse() {
      
      if (codeElement) {
        const lines = codeElement.querySelectorAll('.line, .cl');
        const height = codeElement.offsetHeight;
        return lines.length > autoCollapseLines || height > autoCollapseHeight;
      }

      
      const containerHeight = codeContainer.offsetHeight;
      if (containerHeight > autoCollapseHeight) {
        return true;
      }

      
      const textContent = codeContainer.textContent || codeContainer.innerText || '';
      const estimatedLines = textContent.split('\n').length;
      return estimatedLines > autoCollapseLines;
    }

    function setCollapsed(collapsed, animate = true) {
      if (!collapseOverlay) return;

      isCollapsed = collapsed;

      if (collapsed) {
        
        codeContainer.style.maxHeight = collapsedHeight + 'px';
        codeContainer.style.overflow = 'hidden';
        collapseOverlay.style.opacity = '1';
        collapseOverlay.style.pointerEvents = 'auto';

        
        collapseIcon.innerHTML = `\n  \u003csvg class=\u0022h-3 w-3\u0022\n    fill=\u0022none\u0022\n    stroke=\u0022currentColor\u0022\n    viewBox=\u00220 0 24 24\u0022\u003e\u003cpath stroke-linecap=\u0022round\u0022 stroke-linejoin=\u0022round\u0022 stroke-width=\u00222\u0022 d=\u0022M19 9l-7 7-7-7\u0022 \/\u003e\n\u003c\/svg\u003e`;
        if (collapseText) {
          collapseText.textContent = '펼치기';
        }
        collapseBtn.title = '펼치기';

      } else {
        
        codeContainer.style.maxHeight = '';
        codeContainer.style.overflow = '';
        collapseOverlay.style.opacity = '0';
        collapseOverlay.style.pointerEvents = 'none';

        
        collapseIcon.innerHTML = `\n  \u003csvg class=\u0022h-3 w-3\u0022\n    fill=\u0022none\u0022\n    stroke=\u0022currentColor\u0022\n    viewBox=\u00220 0 24 24\u0022\u003e\u003cpath fill=\u0022currentColor\u0022 d=\u0022M7.41 15.41L12 10.83l4.59 4.58L18 14l-6-6l-6 6z\u0022\/\u003e\u003c\/svg\u003e`;
        if (collapseText) {
          collapseText.textContent = '접기';
        }
        collapseBtn.title = '접기';
      }

      
      if (animate) {
        codeContainer.style.transition = 'max-height 0.3s ease-out';
        setTimeout(() => {
          codeContainer.style.transition = '';
        }, 300);
      }
    }

    function toggleCollapse() {
      setCollapsed(!isCollapsed, true);
    }

    
    collapseBtn.addEventListener('click', toggleCollapse);

    
    if (collapseOverlay) {
      collapseOverlay.addEventListener('click', () => {
        if (isCollapsed) {
          setCollapsed(false, true);
        }
      });
    }

    
    initCollapse();
  }
})();
</script>
</li>
</ul>
<p><strong>이해 어댑터 변환</strong></p>
<ul>
<li>Transformer가 처리 가능한 벡터로 변환.</li>
</ul>
<p><strong>LLM 응답</strong></p>
<ul>
<li>&ldquo;이 이미지에는 강아지가 1마리 있습니다.&rdquo;</li>
</ul>
<p><strong>🔹 결과:</strong><br>
SigLIP을 활용하여 <strong>이미지의 개념적 요소(개체, 색상, 관계 등)를 추출하여 LLM이 이를 기반으로 텍스트 응답을 생성할 수 있도록 함.</strong></p>
<hr>
<h2 id="4-생성-인코더-vq-tokenizer---저차원-디테일-정보-압축"><strong>4. 생성 인코더 (VQ Tokenizer) - 저차원 디테일 정보 압축</strong></h2>
<h3 id="-역할-1"><strong>✅ 역할</strong></h3>
<ul>
<li><strong>이미지를 생성하기 위해 저차원 디스크리트 토큰(Discrete Tokens)으로 변환</strong>.</li>
<li>예: &ldquo;우주복을 입은 강아지가 달을 걷고 있는 모습&rdquo; → 스타일, 질감, 색상, 공간적 배치 정보 유지.</li>
</ul>
<h3 id="-작동-방식-1"><strong>✅ 작동 방식</strong></h3>
<ol>
<li>
<p><strong>텍스트 입력 → Transformer 인코딩</strong></p>
<ul>
<li>텍스트 프롬프트를 Transformer가 벡터로 변환.</li>
</ul>
</li>
<li>
<p><strong>생성 인코더 (VQ Tokenizer) 적용</strong></p>
<ul>
<li>Transformer에서 생성한 벡터를 기반으로, <strong>이미지 토큰을 예측</strong>.</li>
<li>VQGAN 기반 토큰 압축 기법 사용 (예: 256 × 256 이미지 → 16 × 16 토큰 맵).</li>
</ul>
</li>
<li>
<p><strong>VQ 디코더 적용</strong></p>
<ul>
<li>예측된 토큰을 디코딩하여 최종 이미지 생성.</li>
</ul>
</li>
</ol>
<h3 id="-예제-1"><strong>✅ 예제</strong></h3>
<p><strong>입력</strong></p>
<ul>
<li>📝 &ldquo;우주복을 입은 강아지가 달을 걷고 있는 모습&rdquo;</li>
</ul>
<p><strong>Transformer 예측</strong></p>
<ul>
<li>LLM이 텍스트를 해석하여 생성할 이미지의 개념적 특징을 벡터로 변환.</li>
</ul>
<p><strong>VQ Tokenizer 변환</strong></p>
<ul>
<li>벡터를 디스크리트 토큰으로 변환:
<div
  class="code-block-container border-border bg-card my-6 overflow-hidden rounded-xl border shadow-sm transition-all duration-200 ease-out hover:-translate-y-0.5 hover:shadow-md">
  
  <div
    class="code-block-header bg-muted/30 border-border flex items-center justify-between border-b px-4 py-3">
    
    <div class="flex items-center gap-2">
      <div class="text-muted-foreground flex-shrink-0">
        
  <svg class="h-4 w-4"
    fill="none"
    stroke="currentColor"
    viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M10 20l4-16m4 4l4 4-4 4M6 16l-4-4 4-4" />
</svg>
      </div>
      <span class="text-muted-foreground text-sm font-medium">
        PLAINTEXT
      </span>
    </div>

    
    <div class="flex items-center gap-2">
      <button
          class="collapse-code-btn text-muted-foreground hover:text-primary hover:bg-primary/10 focus:ring-primary/20 flex items-center gap-1.5 rounded-md px-2 py-1 text-xs font-medium transition-all duration-200 ease-out focus:ring-2 focus:outline-none"
          data-code-id="code-1"
          data-default-state="expanded"
          data-collapsed="false"
          data-auto-collapse-lines="30"
          data-auto-collapse-height="400"
          data-collapsed-height="120"
          title="접기"
          aria-label="접기">
          <span class="collapse-icon">
            
  <svg class="h-3 w-3"
    fill="none"
    stroke="currentColor"
    viewBox="0 0 24 24"><path fill="currentColor" d="M7.41 15.41L12 10.83l4.59 4.58L18 14l-6-6l-6 6z"/></svg>
          </span>
          <span class="collapse-text hidden sm:inline"
            >접기</span
          >
        </button>
      <button
        class="copy-code-btn text-muted-foreground hover:text-primary hover:bg-primary/10 focus:ring-primary/20 flex items-center gap-1.5 rounded-md px-2 py-1 text-xs font-medium transition-all duration-200 ease-out focus:ring-2 focus:outline-none"
        data-code-id="code-1"
        title="복사"
        aria-label="복사">
        <span class="copy-icon">
          
  <svg class="h-3 w-3"
    fill="none"
    stroke="currentColor"
    viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M8 16H6a2 2 0 01-2-2V6a2 2 0 012-2h8a2 2 0 012 2v2m-6 12h8a2 2 0 002-2v-8a2 2 0 00-2-2h-8a2 2 0 00-2 2v8a2 2 0 002 2z" />
</svg>
        </span>
        <span class="copy-text hidden sm:inline"
          >복사</span
        >
      </button>
    </div>
  </div>

  
  <div class="code-block-content relative" id="code-1">
    <div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="ln">1</span><span class="cl">[1453, 287, 942, 1083, 215]</span></span></code></pre></div>
    
    <div
      class="collapse-overlay to-card/90 pointer-events-none absolute inset-0 bg-gradient-to-b from-transparent via-transparent opacity-0 transition-opacity duration-300">
      <div
        class="text-muted-foreground bg-card/80 border-border/50 hover:bg-primary/10 hover:text-primary hover:border-primary/30 absolute bottom-4 left-1/2 -translate-x-1/2 cursor-pointer rounded-full border px-3 py-1.5 text-xs backdrop-blur-sm transition-all duration-200">
        클릭하여 더 보기
      </div>
    </div>
  </div>
</div>


<script>
(function() {
  const codeId = 'code-1';
  const copyBtn = document.querySelector('.copy-code-btn[data-code-id="' + codeId + '"]');
  const collapseBtn = document.querySelector('.collapse-code-btn[data-code-id="' + codeId + '"]');
  const codeContainer = document.getElementById(codeId);

  if (!codeContainer) return;

  
  if (copyBtn) {
    const copyIcon = copyBtn.querySelector('.copy-icon');
    const copyText = copyBtn.querySelector('.copy-text');

    copyBtn.addEventListener('click', async function() {
      try {
        
        let codeText = '';

        
        const codeTableCell = codeContainer.querySelector('.lntd:last-child code');
        if (codeTableCell) {
          codeText = codeTableCell.textContent || codeTableCell.innerText;
        } else {
          
          const codeElement = codeContainer.querySelector('code');
          if (codeElement) {
            
            const hasInlineLineNumbers = codeElement.querySelector('.ln');
            if (hasInlineLineNumbers) {
              
              const codeLines = codeElement.querySelectorAll('.cl');
              if (codeLines.length > 0) {
                codeText = Array.from(codeLines)
                  .map(line => {
                    const text = line.textContent || line.innerText;
                    
                    return text.replace(/\n+$/, '');
                  })
                  .join('\n')
                  .replace(/\n+$/, ''); 
              } else {
                
                const allText = codeElement.textContent || codeElement.innerText;
                codeText = allText.replace(/^\d+/gm, '').replace(/^\s+/gm, '');
              }
            } else {
              
              codeText = codeElement.textContent || codeElement.innerText;
            }
          } else {
            
            codeText = codeContainer.textContent || codeContainer.innerText;
          }
        }

        
        codeText = codeText.trim();

        
        await navigator.clipboard.writeText(codeText);

        
        copyIcon.innerHTML = `\n  \u003csvg class=\u0022h-3 w-3\u0022\n    fill=\u0022none\u0022\n    stroke=\u0022currentColor\u0022\n    viewBox=\u00220 0 24 24\u0022\u003e\u003cpath stroke-linecap=\u0022round\u0022 stroke-linejoin=\u0022round\u0022 stroke-width=\u00222\u0022 d=\u0022M5 13l4 4L19 7\u0022 \/\u003e\n\u003c\/svg\u003e`;
        if (copyText) {
          copyText.textContent = '복사됨';
        }
        copyBtn.classList.add('text-green-600');

        
        setTimeout(() => {
          copyIcon.innerHTML = `\n  \u003csvg class=\u0022h-3 w-3\u0022\n    fill=\u0022none\u0022\n    stroke=\u0022currentColor\u0022\n    viewBox=\u00220 0 24 24\u0022\u003e\u003cpath stroke-linecap=\u0022round\u0022 stroke-linejoin=\u0022round\u0022 stroke-width=\u00222\u0022 d=\u0022M8 16H6a2 2 0 01-2-2V6a2 2 0 012-2h8a2 2 0 012 2v2m-6 12h8a2 2 0 002-2v-8a2 2 0 00-2-2h-8a2 2 0 00-2 2v8a2 2 0 002 2z\u0022 \/\u003e\n\u003c\/svg\u003e`;
          if (copyText) {
            copyText.textContent = '복사';
          }
          copyBtn.classList.remove('text-green-600');
        }, 2000);

      } catch (err) {
        console.error('复制失败:', err);

        
        const range = document.createRange();
        const codeElement = codeContainer.querySelector('code') || codeContainer;
        range.selectNodeContents(codeElement);
        const selection = window.getSelection();
        selection.removeAllRanges();
        selection.addRange(range);

        
        if (copyText) {
          copyText.textContent = '선택됨';
        }

        setTimeout(() => {
          if (copyText) {
            copyText.textContent = '복사';
          }
          selection.removeAllRanges();
        }, 2000);
      }
    });
  }

  
  if (collapseBtn) {
    const collapseIcon = collapseBtn.querySelector('.collapse-icon');
    const collapseText = collapseBtn.querySelector('.collapse-text');
    const collapseOverlay = codeContainer.querySelector('.collapse-overlay');

    
    let codeElement = codeContainer.querySelector('pre.chroma');
    if (!codeElement) {
      codeElement = codeContainer.querySelector('pre');
    }

    const defaultState = collapseBtn.dataset.defaultState || 'expanded';
    const isCollapsedAttr = collapseBtn.dataset.collapsed === 'true';
    const autoCollapseLines = parseInt(collapseBtn.dataset.autoCollapseLines) || 30;
    const autoCollapseHeight = parseInt(collapseBtn.dataset.autoCollapseHeight) || 400;
    const collapsedHeight = parseInt(collapseBtn.dataset.collapsedHeight) || 120;

    let isCollapsed = false;

    
    function initCollapse() {
      
      const shouldCollapse = isCollapsedAttr ||
                           defaultState === 'collapsed' ||
                           shouldAutoCollapse();

      if (shouldCollapse) {
        setCollapsed(true, false); 
      }
    }

    function shouldAutoCollapse() {
      
      if (codeElement) {
        const lines = codeElement.querySelectorAll('.line, .cl');
        const height = codeElement.offsetHeight;
        return lines.length > autoCollapseLines || height > autoCollapseHeight;
      }

      
      const containerHeight = codeContainer.offsetHeight;
      if (containerHeight > autoCollapseHeight) {
        return true;
      }

      
      const textContent = codeContainer.textContent || codeContainer.innerText || '';
      const estimatedLines = textContent.split('\n').length;
      return estimatedLines > autoCollapseLines;
    }

    function setCollapsed(collapsed, animate = true) {
      if (!collapseOverlay) return;

      isCollapsed = collapsed;

      if (collapsed) {
        
        codeContainer.style.maxHeight = collapsedHeight + 'px';
        codeContainer.style.overflow = 'hidden';
        collapseOverlay.style.opacity = '1';
        collapseOverlay.style.pointerEvents = 'auto';

        
        collapseIcon.innerHTML = `\n  \u003csvg class=\u0022h-3 w-3\u0022\n    fill=\u0022none\u0022\n    stroke=\u0022currentColor\u0022\n    viewBox=\u00220 0 24 24\u0022\u003e\u003cpath stroke-linecap=\u0022round\u0022 stroke-linejoin=\u0022round\u0022 stroke-width=\u00222\u0022 d=\u0022M19 9l-7 7-7-7\u0022 \/\u003e\n\u003c\/svg\u003e`;
        if (collapseText) {
          collapseText.textContent = '펼치기';
        }
        collapseBtn.title = '펼치기';

      } else {
        
        codeContainer.style.maxHeight = '';
        codeContainer.style.overflow = '';
        collapseOverlay.style.opacity = '0';
        collapseOverlay.style.pointerEvents = 'none';

        
        collapseIcon.innerHTML = `\n  \u003csvg class=\u0022h-3 w-3\u0022\n    fill=\u0022none\u0022\n    stroke=\u0022currentColor\u0022\n    viewBox=\u00220 0 24 24\u0022\u003e\u003cpath fill=\u0022currentColor\u0022 d=\u0022M7.41 15.41L12 10.83l4.59 4.58L18 14l-6-6l-6 6z\u0022\/\u003e\u003c\/svg\u003e`;
        if (collapseText) {
          collapseText.textContent = '접기';
        }
        collapseBtn.title = '접기';
      }

      
      if (animate) {
        codeContainer.style.transition = 'max-height 0.3s ease-out';
        setTimeout(() => {
          codeContainer.style.transition = '';
        }, 300);
      }
    }

    function toggleCollapse() {
      setCollapsed(!isCollapsed, true);
    }

    
    collapseBtn.addEventListener('click', toggleCollapse);

    
    if (collapseOverlay) {
      collapseOverlay.addEventListener('click', () => {
        if (isCollapsed) {
          setCollapsed(false, true);
        }
      });
    }

    
    initCollapse();
  }
})();
</script>
</li>
</ul>
<p><strong>VQ 디코더 적용</strong></p>
<ul>
<li>토큰을 기반으로 <strong>이미지 픽셀 복원 및 최종 이미지 출력</strong>.</li>
</ul>
<p><strong>🔹 결과:</strong><br>
VQ Tokenizer를 사용하면 <strong>공간적 배치와 스타일 정보를 유지하면서도, 텍스트 프롬프트에 따라 세밀한 이미지 생성이 가능</strong>.</p>
<hr>
<h2 id="5-janus의-두-인코더를-활용한-차별점"><strong>5. Janus의 두 인코더를 활용한 차별점</strong></h2>
<p>Janus의 핵심적인 차별점은 <strong>이해 &amp; 생성 인코더를 분리함으로써 두 작업을 독립적으로 최적화할 수 있다는 점</strong>이다.</p>
<table>
  <thead>
      <tr>
          <th>비교 항목</th>
          <th>기존 모델 (Chameleon, Show-o)</th>
          <th>Janus</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td><strong>인코딩 방식</strong></td>
          <td>단일 인코더 (VQ Tokenizer)</td>
          <td>이해 &amp; 생성 인코더 분리 (SigLIP + VQ Tokenizer)</td>
      </tr>
      <tr>
          <td><strong>이해 성능</strong></td>
          <td>표현 충돌로 최적화 어려움</td>
          <td>시맨틱 정보 추출 특화</td>
      </tr>
      <tr>
          <td><strong>생성 성능</strong></td>
          <td>텍스트 프롬프트 충실도 낮음</td>
          <td>텍스트 조건을 잘 반영</td>
      </tr>
      <tr>
          <td><strong>텍스트-이미지 조합 최적화</strong></td>
          <td>단일 표현 공간에 의존</td>
          <td>Transformer가 두 인코더에서 독립적으로 학습</td>
      </tr>
  </tbody>
</table>
<p><strong>✅ 최종 결과:</strong></p>
<ul>
<li><strong>이해 성능</strong>: POPE(87.0), GQA(59.1) → 기존 모델보다 30% 향상.</li>
<li><strong>생성 성능</strong>: GenEval(61%) → 기존 SDXL(55%)보다 우수.</li>
</ul>
<hr>
<h2 id="6-결론"><strong>6. 결론</strong></h2>
<p><strong>Janus가 멀티모달 이해와 생성의 표현 충돌 문제를 해결하기 위해 도입한 &ldquo;이해 인코더(SigLIP)&ldquo;와 &ldquo;생성 인코더(VQ Tokenizer)&ldquo;의 역할과 작동 방식은 다음과 같다.</strong></p>
<ol>
<li>
<p><strong>이해 인코더 (SigLIP)</strong></p>
<ul>
<li><strong>고차원 시맨틱 정보</strong>를 추출하여 개체 인식 및 관계 분석을 수행.</li>
<li>Transformer에 전달하여 LLM이 정확한 질문 응답을 생성하도록 지원.</li>
</ul>
</li>
<li>
<p><strong>생성 인코더 (VQ Tokenizer)</strong></p>
<ul>
<li><strong>저차원 디스크리트 토큰을 활용하여 이미지 생성을 최적화</strong>.</li>
<li>Transformer에서 예측한 토큰을 바탕으로 스타일과 질감을 유지하면서 고품질 이미지 생성.</li>
</ul>
</li>
</ol>
<p>✅ <strong>이러한 인코딩 분리를 통해, Janus는 멀티모달 이해와 생성 작업에서 기존 모델 대비 탁월한 성능을 기록하며, 표현 충돌 문제를 해결하는 데 성공하였다.</strong></p>
<h1 id="q--janus-모델의-연산량-증가-및-메모리-요구량이-기존-모델-대비-15배-증가했는데-이를-최적화하거나-경량화할-수-있는-방법에는-어떤-것들이-있을까">Q : Janus 모델의 연산량 증가 및 메모리 요구량이 기존 모델 대비 1.5배 증가했는데, 이를 최적화하거나 경량화할 수 있는 방법에는 어떤 것들이 있을까?</h1>
<h3 id="janus-모델의-연산량-증가-및-메모리-요구량-최적화-방법"><strong>Janus 모델의 연산량 증가 및 메모리 요구량 최적화 방법</strong></h3>
<p>Janus 모델은 기존 모델(예: Show-o, Chameleon) 대비 <strong>1.5배 증가된 연산량 및 메모리 요구량</strong>을 가지며, 이는 <strong>이해(Understanding)와 생성(Generation)의 인코더를 분리하여 각각 최적화하는 설계로 인해 발생</strong>한다. 이를 경량화하거나 최적화할 수 있는 몇 가지 방법을 정리해 보겠다.</p>
<hr>
<h2 id="1-연산량-및-메모리-요구량-증가의-원인-분석"><strong>1. 연산량 및 메모리 요구량 증가의 원인 분석</strong></h2>
<p>먼저, Janus 모델의 연산량이 증가하는 <strong>주요 원인</strong>을 분석하면 다음과 같다.</p>
<table>
  <thead>
      <tr>
          <th>연산량 증가 원인</th>
          <th>설명</th>
          <th>영향</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td><strong>이해 &amp; 생성 인코더 분리 (SigLIP + VQ Tokenizer)</strong></td>
          <td>기존 단일 인코더 방식과 달리, 두 개의 독립된 인코더가 필요함</td>
          <td><strong>추론 시 인코더 연산량 증가</strong></td>
      </tr>
      <tr>
          <td><strong>Transformer 입력 증가</strong></td>
          <td>이해 인코더에서 생성된 시맨틱 벡터와 생성 인코더에서 생성된 토큰을 Transformer가 모두 처리해야 함</td>
          <td><strong>FLOPs 증가</strong></td>
      </tr>
      <tr>
          <td><strong>VQ 디코딩 과정 추가</strong></td>
          <td>이미지 생성을 위해 Transformer가 예측한 토큰을 VQ 디코더가 다시 픽셀로 변환해야 함</td>
          <td><strong>추론 시간 증가</strong></td>
      </tr>
      <tr>
          <td><strong>3단계 학습 과정</strong></td>
          <td>어댑터 학습, 통합 사전학습, 지도학습을 거쳐야 하므로 추가적인 학습 비용 발생</td>
          <td><strong>훈련 시간 및 메모리 사용 증가</strong></td>
      </tr>
  </tbody>
</table>
<p>🔹 <strong>결과적으로, 기존 대비 약 1.5배의 연산량 및 메모리 사용량 증가</strong>가 발생.</p>
<hr>
<h2 id="2-최적화-및-경량화-방법"><strong>2. 최적화 및 경량화 방법</strong></h2>
<h3 id="-1-sparse-transformer-적용-연산량-최적화"><strong>✅ (1) Sparse Transformer 적용 (연산량 최적화)</strong></h3>
<h4 id="문제점"><strong>문제점</strong></h4>
<ul>
<li>Janus의 Transformer는 <strong>이해 및 생성 인코더에서 입력된 벡터를 전부 처리</strong>하므로, 연산량이 증가.</li>
</ul>
<h4 id="해결책-sparse-attention-기법-도입"><strong>해결책: Sparse Attention 기법 도입</strong></h4>
<ul>
<li><strong>Dense Attention → Sparse Attention 변환</strong>
<ul>
<li><strong>Dense Attention (기존)</strong>: 모든 토큰이 서로 영향을 주는 구조.</li>
<li><strong>Sparse Attention (최적화)</strong>: 중요한 토큰만 선택적으로 연산.</li>
</ul>
</li>
<li><strong>예시 연구</strong>
<ul>
<li><strong>RingAttention (2024)</strong>: Transformer 내 불필요한 토큰 연산을 줄여 FLOPs를 30~50% 감소.</li>
</ul>
</li>
</ul>
<p><strong>🔹 기대 효과:</strong></p>
<ul>
<li>Janus의 Transformer 연산량을 <strong>최대 40% 절감</strong>하여 속도 향상.</li>
</ul>
<hr>
<h3 id="-2-adaptive-token-selection-적용-연산량-및-메모리-최적화"><strong>✅ (2) Adaptive Token Selection 적용 (연산량 및 메모리 최적화)</strong></h3>
<h4 id="문제점-1"><strong>문제점</strong></h4>
<ul>
<li>Janus의 이해 인코더(SigLIP)는 모든 픽셀 패치에서 특징을 추출하여 Transformer로 전달하므로, <strong>불필요한 연산 발생</strong>.</li>
</ul>
<h4 id="해결책-중요-토큰만-선택하는-adaptive-token-selection-적용"><strong>해결책: 중요 토큰만 선택하는 Adaptive Token Selection 적용</strong></h4>
<ul>
<li>기존 방식: <strong>모든 이미지 패치를 Transformer로 전달</strong>.</li>
<li>최적화 방식: <strong>중요한 패치(객체 포함 부분)만 선택하여 처리</strong>.</li>
<li><strong>예시 연구</strong>
<ul>
<li><strong>Dynamic Token Pruning (2023)</strong>: 중요도가 낮은 토큰을 제거하여 연산량 감소.</li>
</ul>
</li>
</ul>
<p><strong>🔹 기대 효과:</strong></p>
<ul>
<li><strong>이해 인코더의 연산량 30~50% 절감 가능</strong>.</li>
</ul>
<hr>
<h3 id="-3-knowledge-distillation-적용-모델-크기-최적화"><strong>✅ (3) Knowledge Distillation 적용 (모델 크기 최적화)</strong></h3>
<h4 id="문제점-2"><strong>문제점</strong></h4>
<ul>
<li>Janus는 1.3B 파라미터 모델을 사용하여, 연산량이 큼.</li>
<li>7B 이상 모델로 확장할 경우 <strong>메모리 사용량이 급격히 증가</strong>.</li>
</ul>
<h4 id="해결책-작은-모델을-훈련시키는-knowledge-distillation-kd-활용"><strong>해결책: 작은 모델을 훈련시키는 Knowledge Distillation (KD) 활용</strong></h4>
<ul>
<li>기존 대형 모델(Teacher)의 출력을 학습하여, 작은 모델(Student)도 유사한 성능을 가지도록 훈련.</li>
<li><strong>예시 연구</strong>
<ul>
<li><strong>Distilled-VLM (2023)</strong>: GPT-4V 성능을 유지하면서, 연산량 50% 감소.</li>
</ul>
</li>
</ul>
<p><strong>🔹 기대 효과:</strong></p>
<ul>
<li>Janus 1.3B 모델을 <strong>700M~1B 규모로 축소하면서도 성능 유지 가능</strong>.</li>
</ul>
<hr>
<h3 id="-4-fp8quantization-적용-메모리-최적화"><strong>✅ (4) FP8/Quantization 적용 (메모리 최적화)</strong></h3>
<h4 id="문제점-3"><strong>문제점</strong></h4>
<ul>
<li>Janus의 연산량이 많아질수록, <strong>GPU 메모리 사용량(VRAM)이 증가</strong>.</li>
<li>FP16을 사용하여 모델을 훈련하면, <strong>더 많은 메모리가 필요</strong>.</li>
</ul>
<h4 id="해결책-모델-연산을-fp88비트-부동소수점으로-변환하여-경량화"><strong>해결책: 모델 연산을 FP8(8비트 부동소수점)으로 변환하여 경량화</strong></h4>
<ul>
<li>기존 방식: <strong>FP16 (16비트 부동소수점) 연산 → 더 높은 메모리 요구</strong>.</li>
<li>최적화 방식: <strong>FP8 (8비트 부동소수점) 연산 → 메모리 절약</strong>.</li>
<li><strong>예시 연구</strong>
<ul>
<li><strong>Qwen-VL (2024)</strong>: FP8을 활용하여 2배 메모리 절약.</li>
</ul>
</li>
</ul>
<p><strong>🔹 기대 효과:</strong></p>
<ul>
<li><strong>메모리 사용량 50% 감소 가능</strong>, 대형 모델 확장 시 유리.</li>
</ul>
<hr>
<h3 id="-5-mixture-of-experts-moe-적용-연산량-최적화"><strong>✅ (5) Mixture of Experts (MoE) 적용 (연산량 최적화)</strong></h3>
<h4 id="문제점-4"><strong>문제점</strong></h4>
<ul>
<li>Janus는 모든 입력을 <strong>하나의 Transformer가 동일한 방식으로 처리</strong>하므로, 비효율적인 연산이 발생.</li>
</ul>
<h4 id="해결책-mixture-of-experts-moe-적용하여-연산-최적화"><strong>해결책: Mixture of Experts (MoE) 적용하여 연산 최적화</strong></h4>
<ul>
<li>MoE는 <strong>입력 데이터 유형에 따라 특정 전문가 네트워크(Expert Network)만 활성화하는 방식</strong>.</li>
<li><strong>예시 연구</strong>
<ul>
<li><strong>GLaM (Google, 2022)</strong>: MoE를 적용하여 <strong>추론 시 연산량 40% 절감</strong>.</li>
</ul>
</li>
</ul>
<p><strong>🔹 기대 효과:</strong></p>
<ul>
<li>Janus의 Transformer가 <strong>이해 및 생성 각각에 최적화된 경량 전문가 네트워크를 활성화하도록 변경 가능</strong>.</li>
<li><strong>추론 속도 개선 및 연산량 절감</strong>.</li>
</ul>
<hr>
<h2 id="3-최적화-기법-적용-후-예상-성능"><strong>3. 최적화 기법 적용 후 예상 성능</strong></h2>
<p>다음은 <strong>각 최적화 기법을 적용했을 때 예상되는 연산량 및 메모리 절감 효과</strong>를 정리한 표이다.</p>
<table>
  <thead>
      <tr>
          <th>최적화 기법</th>
          <th>적용 대상</th>
          <th>연산량 감소율</th>
          <th>메모리 절감</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td><strong>Sparse Transformer</strong></td>
          <td>Transformer</td>
          <td><strong>30~40%</strong></td>
          <td>-</td>
      </tr>
      <tr>
          <td><strong>Adaptive Token Selection</strong></td>
          <td>이해 인코더</td>
          <td><strong>30~50%</strong></td>
          <td>-</td>
      </tr>
      <tr>
          <td><strong>Knowledge Distillation</strong></td>
          <td>전체 모델</td>
          <td><strong>50%</strong></td>
          <td><strong>50%</strong></td>
      </tr>
      <tr>
          <td><strong>FP8/Quantization</strong></td>
          <td>전체 모델</td>
          <td>-</td>
          <td><strong>50%</strong></td>
      </tr>
      <tr>
          <td><strong>Mixture of Experts (MoE)</strong></td>
          <td>Transformer</td>
          <td><strong>40%</strong></td>
          <td>-</td>
      </tr>
  </tbody>
</table>
<p><strong>🔹 최적화 기법을 적용할 경우, 연산량은 최대 50%, 메모리 사용량은 최대 50% 절감 가능</strong>.</p>
<hr>
<h2 id="4-결론-2"><strong>4. 결론</strong></h2>
<h3 id="-janus-모델의-연산량-및-메모리-최적화-전략"><strong>✅ Janus 모델의 연산량 및 메모리 최적화 전략</strong></h3>
<ol>
<li><strong>Sparse Transformer</strong> → Transformer의 연산량을 <strong>최대 40% 감소</strong>.</li>
<li><strong>Adaptive Token Selection</strong> → 이해 인코더의 <strong>불필요한 연산량 50% 절감</strong>.</li>
<li><strong>Knowledge Distillation</strong> → 모델 크기를 <strong>50% 축소하면서 성능 유지</strong>.</li>
<li><strong>FP8 Quantization</strong> → 메모리 사용량을 <strong>50% 절감</strong>.</li>
<li><strong>Mixture of Experts (MoE)</strong> → 필요할 때만 연산 수행하여 <strong>추론 속도 40% 향상</strong>.</li>
</ol>
<p>✅ <strong>이러한 최적화 기법을 적용하면, Janus의 성능을 유지하면서도 연산량과 메모리 사용량을 획기적으로 줄일 수 있다.</strong></p>

  </article>

  
  
  <div class="post-license bg-muted/30 border-border mb-8 rounded-xl border p-6">
    <div class="flex items-start gap-4">
      <div
        class="bg-primary/10 flex h-12 w-12 flex-shrink-0 items-center justify-center rounded-lg">
        
  <svg class="h-6 w-6"
    fill="none"
    stroke="currentColor"
    viewBox="0 0 24 24" aria-label="라이선스"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 12l2 2 4-4m5.618-4.016A11.955 11.955 0 0112 2.944a11.955 11.955 0 01-8.618 3.04A12.02 12.02 0 003 9c0 5.591 3.824 10.29 9 11.622 5.176-1.332 9-6.03 9-11.622 0-1.042-.133-2.052-.382-3.016z" />
</svg>
      </div>

      <div class="flex-1">
        <h3 class="text-foreground mb-2 text-lg font-semibold">
          라이선스
        </h3>

        <div class="text-muted-foreground space-y-2 text-sm">
          
          <p>
            <strong>저작자:</strong>
            류재훈
          </p>
          

          <p>
            <strong>링크:</strong>
            <a
              href="http://192.168.1.11:1314/posts/JanusDecouplingVisualEncoding-for-Unified-Multimodal-Understanding-and-Generation/"
              class="text-primary hover:text-primary/80 transition-colors duration-200">
              http://192.168.1.11:1314/posts/JanusDecouplingVisualEncoding-for-Unified-Multimodal-Understanding-and-Generation/
            </a>
          </p>

          <p>
            <strong>라이선스:</strong>
            <a
              href="https://creativecommons.org/licenses/by-nc-sa/4.0/"
              target="_blank"
              rel="noopener noreferrer"
              class="text-primary hover:text-primary/80 transition-colors duration-200">
              CC BY-NC-SA 4.0
            </a>
          </p>

          <p class="text-xs">
            이 저작물은 크리에이티브 커먼즈 저작자표시-비영리-동일조건변경허락 4.0 국제 라이선스에 따라 이용할 수 있습니다. 출처를 표시하고, 비영리 목적으로만 사용하며, 동일한 라이선스를 유지해야 합니다.
          </p>
        </div>
      </div>
    </div>
  </div>


  
  





  <nav
    class="post-navigation mb-12"
    aria-label="게시글 네비게이션">
    <div class="grid grid-cols-1 gap-4 md:grid-cols-2">
      
      <div class="nav-item">
        
          <a
            href="/posts/A-Hardware-Evaluation-Framework-for-Large-Language-Model-Inference/"
            class="group bg-card border-border hover:bg-primary/5 hover:border-primary/20 focus:ring-primary/20 flex min-h-[140px] flex-col justify-between rounded-xl border p-6 transition-all duration-300 ease-out hover:-translate-y-1 hover:scale-[1.02] hover:shadow-lg focus:ring-2 focus:outline-none">
            <div>
              <div class="mb-3 flex items-center gap-3">
                
  <svg class="h-4 w-4"
    fill="none"
    stroke="currentColor"
    viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M15 19l-7-7 7-7" />
</svg>
                <span class="text-muted-foreground text-sm font-medium">
                  이전
                </span>
              </div>

              <h3
                class="text-foreground group-hover:text-primary mb-3 line-clamp-2 text-lg leading-tight font-semibold transition-colors duration-200">
                A Hardware Evaluation Framework for Large Language Model Inference
              </h3>
            </div>

            <div
              class="text-muted-foreground mt-auto flex items-center gap-2 text-xs">
              
  <svg class="h-3 w-3"
    fill="none"
    stroke="currentColor"
    viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M8 7V3m8 4V3m-9 8h10M5 21h14a2 2 0 002-2V7a2 2 0 00-2-2H5a2 2 0 00-2 2v12a2 2 0 002 2z" />
</svg>
              <time datetime="2025-01-21">
                01月21日
              </time>
            </div>
          </a>
        
      </div>

      
      <div class="nav-item">
        
          <a
            href="/posts/Qwen-VL-AVersatile-Vision-Language-Model-for-Understanding-Localization-Text-Reading-and-Beyond/"
            class="group bg-card border-border hover:bg-primary/5 hover:border-primary/20 focus:ring-primary/20 flex min-h-[140px] flex-col justify-between rounded-xl border p-6 transition-all duration-300 ease-out hover:-translate-y-1 hover:scale-[1.02] hover:shadow-lg focus:ring-2 focus:outline-none">
            <div>
              <div class="mb-3 flex items-center justify-end gap-3">
                <span class="text-muted-foreground text-sm font-medium">
                  다음
                </span>
                
  <svg class="h-4 w-4"
    fill="none"
    stroke="currentColor"
    viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 5l7 7-7 7" />
</svg>
              </div>

              <h3
                class="text-foreground group-hover:text-primary mb-3 line-clamp-2 text-right text-lg leading-tight font-semibold transition-colors duration-200">
                Qwen-VL: AVersatile Vision-Language Model for Understanding, Localization, Text Reading, and Beyond
              </h3>
            </div>

            <div
              class="text-muted-foreground mt-auto flex items-center justify-end gap-2 text-xs">
              <time datetime="2025-02-04">
                02月04日
              </time>
              
  <svg class="h-3 w-3"
    fill="none"
    stroke="currentColor"
    viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M8 7V3m8 4V3m-9 8h10M5 21h14a2 2 0 002-2V7a2 2 0 00-2-2H5a2 2 0 00-2 2v12a2 2 0 002 2z" />
</svg>
            </div>
          </a>
        
      </div>
    </div>
  </nav>




  
  










  
  


    </main>

    <footer class="mx-auto max-w-4xl px-4 py-8">
  <div class="px-6 py-6">
    
    
      <nav class="mb-6">
        <div class="flex flex-wrap items-center justify-center gap-1">
          
            
            
            
            <a
              href="/index.xml"
              
              class="nav-link hover:text-primary hover:bg-primary/10 text-muted-foreground flex items-center gap-2 rounded-lg px-4 py-2 text-sm font-medium transition-all duration-300 hover:scale-105">
              
                
  <svg class="h-5 w-5"
    fill="none"
    stroke="currentColor"
    viewBox="0 0 24 24" aria-label="RSS Feed">
  <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M6 5c7.18 0 13 5.82 13 13M6 11a7 7 0 017 7m-6 0a1 1 0 11-2 0 1 1 0 012 0z" />

</svg>
              
              <span
                >
                  RSS Feed
                </span
              >
            </a>
          
        </div>
      </nav>
    


    
    
      <div class="border-border mb-6 border-t"></div>
    


    
    <div class="flex flex-col items-center justify-between gap-4 md:flex-row">
      
      <div class="text-muted-foreground text-sm">
        <p>
          &copy; 2025 Jaehun&#39;s Blog.
          모든 권리 보유.
        </p>
      </div>

      
      
        <div class="flex items-center gap-3">
          
            <a
              href="https://github.com/ryujaehun"
              
                target="_blank" rel="noopener noreferrer"
              
              class="text-muted-foreground hover:text-primary focus:ring-primary/20 rounded-lg p-1 transition-all duration-300 ease-out hover:scale-110 focus:ring-2 focus:outline-none"
              title="GitHub"
              aria-label="GitHub">
              
                
  <svg class="h-6 w-6"
    fill="none"
    stroke="currentColor"
    viewBox="0 0 24 24" aria-label="GitHub"><g fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2"><path d="M15 22v-4a4.8 4.8 0 0 0-1-3.5c3 0 6-2 6-5.5c.08-1.25-.27-2.48-1-3.5c.28-1.15.28-2.35 0-3.5c0 0-1 0-3 1.5c-2.64-.5-5.36-.5-8 0C6 2 5 2 5 2c-.3 1.15-.3 2.35 0 3.5A5.4 5.4 0 0 0 4 9c0 3.5 3 5.5 6 5.5c-.39.49-.68 1.05-.85 1.65S8.93 17.38 9 18v4"/><path d="M9 18c-4.51 2-5-2-7-2"/></g></svg>
              
            </a>
          
            <a
              href="https://www.linkedin.com/in/jaehunryu/"
              
                target="_blank" rel="noopener noreferrer"
              
              class="text-muted-foreground hover:text-primary focus:ring-primary/20 rounded-lg p-1 transition-all duration-300 ease-out hover:scale-110 focus:ring-2 focus:outline-none"
              title="Linkedin"
              aria-label="Linkedin">
              
                
  <svg class="h-6 w-6"
    fill="none"
    stroke="currentColor"
    viewBox="0 0 24 24" aria-label="Linkedin"><g fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2"><path d="M16 8a6 6 0 0 1 6 6v7h-4v-7a2 2 0 0 0-2-2a2 2 0 0 0-2 2v7h-4v-7a6 6 0 0 1 6-6M2 9h4v12H2z"/><circle cx="4" cy="4" r="2"/></g></svg>
              
            </a>
          
            <a
              href="mailto:jaehunryu@icloud.com"
              
              class="text-muted-foreground hover:text-primary focus:ring-primary/20 rounded-lg p-1 transition-all duration-300 ease-out hover:scale-110 focus:ring-2 focus:outline-none"
              title="Email"
              aria-label="Email">
              
                
  <svg class="h-6 w-6"
    fill="none"
    stroke="currentColor"
    viewBox="0 0 24 24" aria-label="Email">
  <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M3 8l7.89 5.26a2 2 0 002.22 0L21 8M5 19h14a2 2 0 002-2V7a2 2 0 00-2-2H5a2 2 0 00-2 2v10a2 2 0 002 2z" />

</svg>
              
            </a>
          
        </div>
      

    </div>
  </div>
</footer>


    
    



<div
  id="dock"
  class="pointer-events-none fixed bottom-4 left-1/2 z-[9999] w-fit -translate-x-1/2 translate-y-24 opacity-0 transition-all duration-300 ease-out sm:right-0 sm:left-0 sm:mx-auto sm:translate-x-0"
  role="toolbar"
  aria-label="바로가기 도구 모음">
  <nav
    class="border-border bg-card/80 scrollbar-hide xs:px-3 xs:py-2 mx-auto flex max-w-[calc(100vw-2rem)] min-w-fit items-center justify-center overflow-x-auto rounded-2xl border px-4 py-3 shadow-lg backdrop-blur-sm sm:px-4 sm:py-3">
    
    
      <button
        id="dock-back"
        class="text-muted-foreground hover:text-primary hover:bg-primary/10 focus:ring-primary/20 xs:px-2 xs:py-1.5 flex flex-shrink-0 items-center gap-2 rounded-lg px-3 py-2 text-sm font-medium transition-all duration-300 ease-out hover:-translate-y-0.5 hover:scale-105 focus:ring-2 focus:outline-none sm:px-3 sm:py-2"
        title="뒤로"
        aria-label="뒤로">
        
  <svg class="h-4 w-4"
    fill="none"
    stroke="currentColor"
    viewBox="0 0 24 24">
  <path d="m12 19-7-7 7-7"/>
  <path d="M19 12H5"/>

</svg>
        <span class="hidden sm:inline"
          >뒤로</span
        >
      </button>

      
      <div class="bg-border xs:mx-1 mx-2 h-6 w-px sm:mx-2"></div>
    


    
    
      <button
        id="dock-toc"
        class="text-muted-foreground hover:text-primary hover:bg-primary/10 focus:ring-primary/20 xs:px-2 xs:py-1.5 flex flex-shrink-0 items-center gap-2 rounded-lg px-3 py-2 text-sm font-medium transition-all duration-300 ease-out hover:-translate-y-0.5 hover:scale-105 focus:ring-2 focus:outline-none sm:px-3 sm:py-2"
        title="목차"
        aria-label="목차">
        
  <svg class="h-4 w-4"
    fill="none"
    stroke="currentColor"
    viewBox="0 0 24 24">
  <line x1="8" x2="21" y1="6" y2="6"/>
  <line x1="8" x2="21" y1="12" y2="12"/>
  <line x1="8" x2="21" y1="18" y2="18"/>
  <line x1="3" x2="3.01" y1="6" y2="6"/>
  <line x1="3" x2="3.01" y1="12" y2="12"/>
  <line x1="3" x2="3.01" y1="18" y2="18"/>

</svg>
        <span class="hidden sm:inline"
          >목차</span
        >
      </button>

      
      <div class="bg-border xs:mx-1 mx-2 h-6 w-px sm:mx-2"></div>
    


    
    <button
      id="dock-search"
      class="text-muted-foreground hover:text-primary hover:bg-primary/10 focus:ring-primary/20 xs:px-3 xs:py-1.5 flex flex-shrink-0 items-center gap-2 rounded-lg px-4 py-2 text-sm font-medium transition-all duration-300 ease-out hover:-translate-y-0.5 hover:scale-105 focus:ring-2 focus:outline-none sm:px-4 sm:py-2"
      title="검색"
      aria-label="검색">
      
  <svg class="h-4 w-4"
    fill="none"
    stroke="currentColor"
    viewBox="0 0 24 24">
  <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="m21 21-6-6m2-5a7 7 0 11-14 0 7 7 0 0114 0z" />

</svg>
      <span class="hidden md:inline"
        >검색</span
      >
    </button>

    
    <div class="bg-border xs:mx-1 mx-2 h-6 w-px sm:mx-2"></div>

    
    
    


    
    <button
      id="dock-top"
      class="text-muted-foreground hover:text-primary hover:bg-primary/10 focus:ring-primary/20 xs:px-2 xs:py-1.5 flex flex-shrink-0 items-center gap-2 rounded-lg px-3 py-2 text-sm font-medium transition-all duration-300 ease-out hover:-translate-y-0.5 hover:scale-105 focus:ring-2 focus:outline-none sm:px-3 sm:py-2"
      title="맨 위로"
      aria-label="맨 위로">
      
  <svg class="h-4 w-4"
    fill="none"
    stroke="currentColor"
    viewBox="0 0 24 24">
  <path d="m18 15-6-6-6 6"/>

</svg>
      <span class="hidden sm:inline"
        >맨 위로</span
      >
    </button>
  </nav>
</div>


    
      



<div
  id="toc-overlay"
  class="pointer-events-none fixed inset-0 z-40 bg-black/50 opacity-0 backdrop-blur-sm transition-all duration-300"
  role="dialog"
  aria-modal="true"
  aria-labelledby="toc-title"></div>


<div
  id="toc-card"
  class="pointer-events-none fixed inset-4 z-50 flex w-auto scale-95 items-center justify-center opacity-0 transition-all duration-300 sm:inset-auto sm:top-1/2 sm:left-1/2 sm:block sm:w-full sm:max-w-md sm:-translate-x-1/2 sm:-translate-y-1/2"
  role="dialog"
  aria-modal="true"
  aria-labelledby="toc-title">
  <div
    class="bg-card border-border w-full max-w-sm overflow-hidden rounded-xl border shadow-xl sm:max-w-md">
    
    <div
      class="border-border bg-muted/30 flex items-center justify-between border-b p-4">
      <div class="flex items-center gap-3">
        
  <svg class="h-5 w-5"
    fill="none"
    stroke="currentColor"
    viewBox="0 0 24 24">
  <line x1="8" x2="21" y1="6" y2="6"/>
  <line x1="8" x2="21" y1="12" y2="12"/>
  <line x1="8" x2="21" y1="18" y2="18"/>
  <line x1="3" x2="3.01" y1="6" y2="6"/>
  <line x1="3" x2="3.01" y1="12" y2="12"/>
  <line x1="3" x2="3.01" y1="18" y2="18"/>

</svg>
        <h2 id="toc-title" class="text-foreground text-lg font-semibold">
          목차
        </h2>
      </div>

      
      <button
        id="toc-close"
        class="text-muted-foreground hover:text-primary hover:bg-primary/10 focus:ring-primary/20 rounded-lg p-2 transition-all duration-200 ease-out hover:-translate-y-0.5 hover:scale-105 focus:ring-2 focus:outline-none"
        title="닫기"
        aria-label="닫기">
        
  <svg class="h-4 w-4"
    fill="none"
    stroke="currentColor"
    viewBox="0 0 24 24">
  <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M6 18L18 6M6 6l12 12" />

</svg>
      </button>
    </div>

    
    <div class="max-h-96 overflow-y-auto p-4">
      <nav
        id="toc-nav"
        class="toc-scrollbar"
        aria-label="글 목차">
          
          <div id="toc-content">
            <nav id="TableOfContents">
  <ul>
    <li>
      <ul>
        <li><a href="#논문-요약-및-분석-janus---decoupling-visual-encoding-for-unified-multimodal-understanding-and-generation"><strong>논문 요약 및 분석: Janus - Decoupling Visual Encoding for Unified Multimodal Understanding and Generation</strong></a></li>
      </ul>
    </li>
    <li><a href="#1-연구의-주요-기여"><strong>1. 연구의 주요 기여</strong></a></li>
    <li><a href="#2-janus의-핵심-알고리즘-설명"><strong>2. Janus의 핵심 알고리즘 설명</strong></a>
      <ul>
        <li><a href="#1-아키텍처"><strong>(1) 아키텍처</strong></a></li>
        <li><a href="#2-학습-과정"><strong>(2) 학습 과정</strong></a></li>
      </ul>
    </li>
    <li><a href="#3-예시-입력과-전체-프로세스"><strong>3. 예시 입력과 전체 프로세스</strong></a></li>
    <li><a href="#4-논문의-강점"><strong>4. 논문의 강점</strong></a>
      <ul>
        <li><a href="#1-기존-모델과-비교한-차별점"><strong>(1) 기존 모델과 비교한 차별점</strong></a></li>
        <li><a href="#2-유연한-확장성"><strong>(2) 유연한 확장성</strong></a></li>
      </ul>
    </li>
    <li><a href="#5-한계점"><strong>5. 한계점</strong></a>
      <ul>
        <li><a href="#1-고해상도-이미지-생성의-제한"><strong>(1) 고해상도 이미지 생성의 제한</strong></a></li>
        <li><a href="#2-생성-성능의-딥러닝-기반-모델과의-차이"><strong>(2) 생성 성능의 딥러닝 기반 모델과의 차이</strong></a></li>
        <li><a href="#3-더-큰-모델-대비-성능-비교"><strong>(3) 더 큰 모델 대비 성능 비교</strong></a></li>
      </ul>
    </li>
    <li><a href="#6-결론-및-미래-연구-방향"><strong>6. 결론 및 미래 연구 방향</strong></a></li>
  </ul>

  <ul>
    <li>
      <ul>
        <li><a href="#janus의-핵심-알고리즘-상세-분석-및-예제-설명"><strong>Janus의 핵심 알고리즘 상세 분석 및 예제 설명</strong></a></li>
      </ul>
    </li>
    <li><a href="#1-janus의-기본-개념"><strong>1. Janus의 기본 개념</strong></a></li>
    <li><a href="#2-핵심-알고리즘의-흐름"><strong>2. 핵심 알고리즘의 흐름</strong></a></li>
    <li><a href="#3-이해understanding-과정-siglip-기반-인코딩"><strong>3. 이해(Understanding) 과정: SigLIP 기반 인코딩</strong></a>
      <ul>
        <li><a href="#예제-1-개체-인식object-recognition"><strong>예제 1: 개체 인식(Object Recognition)</strong></a></li>
        <li><a href="#예제-2-텍스트-이미지-매칭text-image-matching"><strong>예제 2: 텍스트-이미지 매칭(Text-Image Matching)</strong></a></li>
      </ul>
    </li>
    <li><a href="#4-생성generation-과정-vq-기반-이미지-생성"><strong>4. 생성(Generation) 과정: VQ 기반 이미지 생성</strong></a>
      <ul>
        <li><a href="#예제-3-텍스트에서-이미지-생성text-to-image-generation"><strong>예제 3: 텍스트에서 이미지 생성(Text-to-Image Generation)</strong></a></li>
        <li><a href="#예제-4-이미지-보완image-inpainting"><strong>예제 4: 이미지 보완(Image Inpainting)</strong></a></li>
      </ul>
    </li>
    <li><a href="#5-핵심-요소-요약"><strong>5. 핵심 요소 요약</strong></a></li>
    <li><a href="#6-정리"><strong>6. 정리</strong></a></li>
  </ul>

  <ul>
    <li>
      <ul>
        <li><a href="#janus-모델을-학습하기-위한-데이터셋-및-학습-과정-상세-분석"><strong>Janus 모델을 학습하기 위한 데이터셋 및 학습 과정 상세 분석</strong></a></li>
      </ul>
    </li>
    <li><a href="#1-janus-모델-학습을-위한-필수-데이터셋"><strong>1. Janus 모델 학습을 위한 필수 데이터셋</strong></a>
      <ul>
        <li><a href="#1-멀티모달-이해understanding-데이터셋"><strong>(1) 멀티모달 이해(Understanding) 데이터셋</strong></a></li>
        <li><a href="#2-멀티모달-생성generation-데이터셋"><strong>(2) 멀티모달 생성(Generation) 데이터셋</strong></a></li>
        <li><a href="#3-추가-데이터셋-텍스트-이해-및-조합"><strong>(3) 추가 데이터셋 (텍스트 이해 및 조합)</strong></a></li>
      </ul>
    </li>
    <li><a href="#2-janus-모델-학습-프로세스"><strong>2. Janus 모델 학습 프로세스</strong></a>
      <ul>
        <li><a href="#-1-1단계-어댑터-및-이미지-생성-헤드-학습"><strong>📌 (1) 1단계: 어댑터 및 이미지 생성 헤드 학습</strong></a></li>
        <li><a href="#-2-2단계-멀티모달-통합-학습"><strong>📌 (2) 2단계: 멀티모달 통합 학습</strong></a></li>
        <li><a href="#-3-3단계-지도-학습-및-인스트럭션-튜닝"><strong>📌 (3) 3단계: 지도 학습 및 인스트럭션 튜닝</strong></a></li>
      </ul>
    </li>
    <li><a href="#3-최종-정리"><strong>3. 최종 정리</strong></a></li>
  </ul>

  <ul>
    <li><a href="#1-janus의-실험-결과-정리"><strong>1. Janus의 실험 결과 정리</strong></a>
      <ul>
        <li><a href="#1-멀티모달-이해-성능"><strong>(1) 멀티모달 이해 성능</strong></a></li>
        <li><a href="#2-이미지-생성-성능"><strong>(2) 이미지 생성 성능</strong></a></li>
      </ul>
    </li>
    <li><a href="#2-janus의-차별점과-성능-향상의-이유"><strong>2. Janus의 차별점과 성능 향상의 이유</strong></a>
      <ul>
        <li><a href="#1-기존-모델의-한계"><strong>(1) 기존 모델의 한계</strong></a>
          <ul>
            <li><a href="#-기존-모델-예-chameleon-show-o">📌 기존 모델 (예: Chameleon, Show-o)</a></li>
            <li><a href="#-확산-모델-기반-생성-모델-예-dall-e-2-sdxl">📌 확산 모델 기반 생성 모델 (예: DALL-E 2, SDXL)</a></li>
          </ul>
        </li>
        <li><a href="#2-janus의-해결책"><strong>(2) Janus의 해결책</strong></a>
          <ul>
            <li><a href="#-1-이해와-생성의-인코더를-분리">✅ <strong>1. 이해와 생성의 인코더를 분리</strong></a></li>
            <li><a href="#-2-transformer의-단일-아키텍처-사용">✅ <strong>2. Transformer의 단일 아키텍처 사용</strong></a></li>
            <li><a href="#-3-3단계-학습-전략">✅ <strong>3. 3단계 학습 전략</strong></a></li>
          </ul>
        </li>
      </ul>
    </li>
    <li><a href="#3-내-생각-janus의-실제-강점과-앞으로의-발전-방향"><strong>3. 내 생각: Janus의 실제 강점과 앞으로의 발전 방향</strong></a>
      <ul>
        <li><a href="#1-janus의-실제-강점"><strong>(1) Janus의 실제 강점</strong></a></li>
        <li><a href="#2-janus의-한계-및-발전-방향"><strong>(2) Janus의 한계 및 발전 방향</strong></a></li>
      </ul>
    </li>
    <li><a href="#4-결론"><strong>4. 결론</strong></a></li>
  </ul>

  <ul>
    <li>
      <ul>
        <li><a href="#janus-모델을-실제로-구현하기-위한-추가적인-요구사항-분석-및-연산량-계산"><strong>Janus 모델을 실제로 구현하기 위한 추가적인 요구사항 분석 및 연산량 계산</strong></a></li>
      </ul>
    </li>
    <li><a href="#1-기존-모델-대비-추가적인-구현-필요-요소"><strong>1. 기존 모델 대비 추가적인 구현 필요 요소</strong></a>
      <ul>
        <li><a href="#-1-멀티모달-인코딩-분리"><strong>📌 (1) 멀티모달 인코딩 분리</strong></a>
          <ul>
            <li><a href="#-기존-모델-예-chameleon-show-o-1">✅ 기존 모델 (예: Chameleon, Show-o)</a></li>
            <li><a href="#-janus의-추가적인-구현-요소">✅ Janus의 추가적인 구현 요소</a></li>
          </ul>
        </li>
        <li><a href="#-2-이해-및-생성-어댑터-추가-und-adapter--gen-adapter"><strong>📌 (2) 이해 및 생성 어댑터 추가 (Und. Adapter &amp; Gen. Adapter)</strong></a>
          <ul>
            <li><a href="#-기존-모델">✅ 기존 모델</a></li>
            <li><a href="#-janus의-추가적인-구현-요소-1">✅ Janus의 추가적인 구현 요소</a></li>
          </ul>
        </li>
        <li><a href="#-3-3단계-학습-과정-구현"><strong>📌 (3) 3단계 학습 과정 구현</strong></a></li>
      </ul>
    </li>
    <li><a href="#2-연산량-계산-및-필요-컴퓨팅-자원-분석"><strong>2. 연산량 계산 및 필요 컴퓨팅 자원 분석</strong></a>
      <ul>
        <li><a href="#-1-모델-연산량-추정"><strong>📌 (1) 모델 연산량 추정</strong></a></li>
        <li><a href="#-2-필요-gpu-자원-계산"><strong>📌 (2) 필요 GPU 자원 계산</strong></a>
          <ul>
            <li><a href="#-논문에서-사용한-환경">✅ <strong>논문에서 사용한 환경</strong></a></li>
            <li><a href="#-기본적인-학습-자원-필요량">✅ <strong>기본적인 학습 자원 필요량</strong></a></li>
          </ul>
        </li>
      </ul>
    </li>
    <li><a href="#3-결론"><strong>3. 결론</strong></a>
      <ul>
        <li><a href="#1-추가적으로-구현해야-할-요소"><strong>(1) 추가적으로 구현해야 할 요소</strong></a></li>
        <li><a href="#2-추가적으로-필요한-자원"><strong>(2) 추가적으로 필요한 자원</strong></a></li>
      </ul>
    </li>
  </ul>

  <ul>
    <li><a href="#1-janus-모델의-입력-데이터-및-추론-과정"><strong>1. Janus 모델의 입력 데이터 및 추론 과정</strong></a>
      <ul>
        <li><a href="#-1-입력-데이터-유형"><strong>📌 (1) 입력 데이터 유형</strong></a></li>
        <li><a href="#-a-멀티모달-이해-understanding"><strong>✅ (a) 멀티모달 이해 (Understanding)</strong></a></li>
        <li><a href="#-b-멀티모달-생성-generation"><strong>✅ (b) 멀티모달 생성 (Generation)</strong></a></li>
      </ul>
    </li>
    <li><a href="#2-janus의-추론-과정-inference-pipeline"><strong>2. Janus의 추론 과정 (Inference Pipeline)</strong></a>
      <ul>
        <li><a href="#-1-멀티모달-이해-vqa-예제"><strong>📌 (1) 멀티모달 이해 (VQA 예제)</strong></a></li>
        <li><a href="#-2-멀티모달-생성-text-to-image-예제"><strong>📌 (2) 멀티모달 생성 (Text-to-Image 예제)</strong></a></li>
      </ul>
    </li>
    <li><a href="#3-모델-아키텍처-및-연산-분석"><strong>3. 모델 아키텍처 및 연산 분석</strong></a>
      <ul>
        <li><a href="#-1-모델-아키텍처-구성"><strong>📌 (1) 모델 아키텍처 구성</strong></a></li>
        <li><a href="#-2-연산량-및-메모리-요구량"><strong>📌 (2) 연산량 및 메모리 요구량</strong></a></li>
        <li><a href="#-3-학습-및-추론에-필요한-컴퓨팅-자원"><strong>📌 (3) 학습 및 추론에 필요한 컴퓨팅 자원</strong></a>
          <ul>
            <li><a href="#-학습-시-필요-컴퓨팅-자원">✅ <strong>학습 시 필요 컴퓨팅 자원</strong></a></li>
            <li><a href="#-추론-시-필요-컴퓨팅-자원">✅ <strong>추론 시 필요 컴퓨팅 자원</strong></a></li>
          </ul>
        </li>
      </ul>
    </li>
    <li><a href="#4-결론-1"><strong>4. 결론</strong></a></li>
  </ul>

  <ul>
    <li><a href="#1-janus-논문의-주요-한계점"><strong>1. Janus 논문의 주요 한계점</strong></a></li>
    <li><a href="#2-연구-흐름--고해상도-이미지-생성-개선"><strong>2. 연구 흐름 ① 고해상도 이미지 생성 개선</strong></a>
      <ul>
        <li><a href="#-해결-방안-autoregressive--diffusion-hybrid"><strong>✅ 해결 방안: Autoregressive + Diffusion Hybrid</strong></a></li>
      </ul>
    </li>
    <li><a href="#3-연구-흐름--연산량-최적화-및-실시간-추론-개선"><strong>3. 연구 흐름 ② 연산량 최적화 및 실시간 추론 개선</strong></a>
      <ul>
        <li><a href="#-해결-방안-sparse-transformer--token-selection"><strong>✅ 해결 방안: Sparse Transformer &amp; Token Selection</strong></a></li>
      </ul>
    </li>
    <li><a href="#4-연구-흐름--이해--생성의-완전한-독립성-확보"><strong>4. 연구 흐름 ③ 이해 &amp; 생성의 완전한 독립성 확보</strong></a>
      <ul>
        <li><a href="#-해결-방안-mixture-of-experts-moe-기반-독립적-인코딩"><strong>✅ 해결 방안: Mixture of Experts (MoE) 기반 독립적 인코딩</strong></a></li>
      </ul>
    </li>
    <li><a href="#5-연구-흐름--멀티모달-확장성-강화"><strong>5. 연구 흐름 ④ 멀티모달 확장성 강화</strong></a>
      <ul>
        <li><a href="#-해결-방안-cross-modality-fusion"><strong>✅ 해결 방안: Cross-Modality Fusion</strong></a></li>
      </ul>
    </li>
    <li><a href="#6-연구-흐름--대형-모델-스케일링"><strong>6. 연구 흐름 ⑤ 대형 모델 스케일링</strong></a>
      <ul>
        <li><a href="#-해결-방안-7b-이상-대형-모델-확장"><strong>✅ 해결 방안: 7B 이상 대형 모델 확장</strong></a></li>
      </ul>
    </li>
    <li><a href="#7-결론-및-향후-연구-방향"><strong>7. 결론 및 향후 연구 방향</strong></a>
      <ul>
        <li><a href="#-janus-모델의-한계를-극복하기-위한-연구-방향"><strong>📌 Janus 모델의 한계를 극복하기 위한 연구 방향</strong></a></li>
      </ul>
    </li>
  </ul>

  <ul>
    <li>
      <ul>
        <li><a href="#1-멀티모달-이해와-생성의-표현-충돌-문제-해결"><strong>1. 멀티모달 이해와 생성의 표현 충돌 문제 해결</strong></a>
          <ul>
            <li><a href="#-기존-모델의-문제점">✅ 기존 모델의 문제점</a></li>
            <li><a href="#-janus의-해결책-이해-인코더understanding-encoder와-생성-인코더generation-encoder의-분리">✅ Janus의 해결책: <strong>이해 인코더(Understanding Encoder)와 생성 인코더(Generation Encoder)의 분리</strong></a></li>
          </ul>
        </li>
        <li><a href="#2-단일-transformer-아키텍처를-활용한-효율적인-통합"><strong>2. 단일 Transformer 아키텍처를 활용한 효율적인 통합</strong></a>
          <ul>
            <li><a href="#-기존-모델의-문제점-1">✅ 기존 모델의 문제점</a></li>
            <li><a href="#-janus의-해결책-단일-transformer-기반-멀티모달-처리">✅ Janus의 해결책: <strong>단일 Transformer 기반 멀티모달 처리</strong></a></li>
          </ul>
        </li>
        <li><a href="#3-3단계-학습-전략을-통한-최적화"><strong>3. 3단계 학습 전략을 통한 최적화</strong></a>
          <ul>
            <li><a href="#-기존-모델의-문제점-2">✅ 기존 모델의 문제점</a></li>
            <li><a href="#-janus의-해결책-3단계-학습-전략-적용">✅ Janus의 해결책: <strong>3단계 학습 전략 적용</strong></a></li>
          </ul>
        </li>
      </ul>
    </li>
    <li><a href="#결론"><strong>결론</strong></a></li>
  </ul>

  <ul>
    <li>
      <ul>
        <li><a href="#janus가-멀티모달-이해와-생성의-표현-충돌-문제를-해결하기-위해-도입한"><strong>Janus가 멀티모달 이해와 생성의 표현 충돌 문제를 해결하기 위해 도입한 &ldquo;이해 인코더(SigLIP)&ldquo;와 &ldquo;생성 인코더(VQ Tokenizer)&ldquo;의 역할과 작동 방식</strong></a></li>
      </ul>
    </li>
    <li><a href="#1-기존-멀티모달-모델의-표현-충돌-문제"><strong>1. 기존 멀티모달 모델의 표현 충돌 문제</strong></a>
      <ul>
        <li><a href="#-표현-충돌representation-conflict-문제"><strong>✅ 표현 충돌(Representation Conflict) 문제</strong></a></li>
      </ul>
    </li>
    <li><a href="#2-janus의-해결책-이해-인코더siglip와-생성-인코더vq-tokenizer-분리"><strong>2. Janus의 해결책: 이해 인코더(SigLIP)와 생성 인코더(VQ Tokenizer) 분리</strong></a></li>
    <li><a href="#3-이해-인코더-siglip---고차원-시맨틱-정보-추출"><strong>3. 이해 인코더 (SigLIP) - 고차원 시맨틱 정보 추출</strong></a>
      <ul>
        <li><a href="#-역할"><strong>✅ 역할</strong></a></li>
        <li><a href="#-작동-방식"><strong>✅ 작동 방식</strong></a></li>
        <li><a href="#-예제"><strong>✅ 예제</strong></a></li>
      </ul>
    </li>
    <li><a href="#4-생성-인코더-vq-tokenizer---저차원-디테일-정보-압축"><strong>4. 생성 인코더 (VQ Tokenizer) - 저차원 디테일 정보 압축</strong></a>
      <ul>
        <li><a href="#-역할-1"><strong>✅ 역할</strong></a></li>
        <li><a href="#-작동-방식-1"><strong>✅ 작동 방식</strong></a></li>
        <li><a href="#-예제-1"><strong>✅ 예제</strong></a></li>
      </ul>
    </li>
    <li><a href="#5-janus의-두-인코더를-활용한-차별점"><strong>5. Janus의 두 인코더를 활용한 차별점</strong></a></li>
    <li><a href="#6-결론"><strong>6. 결론</strong></a></li>
  </ul>

  <ul>
    <li>
      <ul>
        <li><a href="#janus-모델의-연산량-증가-및-메모리-요구량-최적화-방법"><strong>Janus 모델의 연산량 증가 및 메모리 요구량 최적화 방법</strong></a></li>
      </ul>
    </li>
    <li><a href="#1-연산량-및-메모리-요구량-증가의-원인-분석"><strong>1. 연산량 및 메모리 요구량 증가의 원인 분석</strong></a></li>
    <li><a href="#2-최적화-및-경량화-방법"><strong>2. 최적화 및 경량화 방법</strong></a>
      <ul>
        <li><a href="#-1-sparse-transformer-적용-연산량-최적화"><strong>✅ (1) Sparse Transformer 적용 (연산량 최적화)</strong></a>
          <ul>
            <li><a href="#문제점"><strong>문제점</strong></a></li>
            <li><a href="#해결책-sparse-attention-기법-도입"><strong>해결책: Sparse Attention 기법 도입</strong></a></li>
          </ul>
        </li>
        <li><a href="#-2-adaptive-token-selection-적용-연산량-및-메모리-최적화"><strong>✅ (2) Adaptive Token Selection 적용 (연산량 및 메모리 최적화)</strong></a>
          <ul>
            <li><a href="#문제점-1"><strong>문제점</strong></a></li>
            <li><a href="#해결책-중요-토큰만-선택하는-adaptive-token-selection-적용"><strong>해결책: 중요 토큰만 선택하는 Adaptive Token Selection 적용</strong></a></li>
          </ul>
        </li>
        <li><a href="#-3-knowledge-distillation-적용-모델-크기-최적화"><strong>✅ (3) Knowledge Distillation 적용 (모델 크기 최적화)</strong></a>
          <ul>
            <li><a href="#문제점-2"><strong>문제점</strong></a></li>
            <li><a href="#해결책-작은-모델을-훈련시키는-knowledge-distillation-kd-활용"><strong>해결책: 작은 모델을 훈련시키는 Knowledge Distillation (KD) 활용</strong></a></li>
          </ul>
        </li>
        <li><a href="#-4-fp8quantization-적용-메모리-최적화"><strong>✅ (4) FP8/Quantization 적용 (메모리 최적화)</strong></a>
          <ul>
            <li><a href="#문제점-3"><strong>문제점</strong></a></li>
            <li><a href="#해결책-모델-연산을-fp88비트-부동소수점으로-변환하여-경량화"><strong>해결책: 모델 연산을 FP8(8비트 부동소수점)으로 변환하여 경량화</strong></a></li>
          </ul>
        </li>
        <li><a href="#-5-mixture-of-experts-moe-적용-연산량-최적화"><strong>✅ (5) Mixture of Experts (MoE) 적용 (연산량 최적화)</strong></a>
          <ul>
            <li><a href="#문제점-4"><strong>문제점</strong></a></li>
            <li><a href="#해결책-mixture-of-experts-moe-적용하여-연산-최적화"><strong>해결책: Mixture of Experts (MoE) 적용하여 연산 최적화</strong></a></li>
          </ul>
        </li>
      </ul>
    </li>
    <li><a href="#3-최적화-기법-적용-후-예상-성능"><strong>3. 최적화 기법 적용 후 예상 성능</strong></a></li>
    <li><a href="#4-결론-2"><strong>4. 결론</strong></a>
      <ul>
        <li><a href="#-janus-모델의-연산량-및-메모리-최적화-전략"><strong>✅ Janus 모델의 연산량 및 메모리 최적화 전략</strong></a></li>
      </ul>
    </li>
  </ul>
</nav>
          </div>
      </nav>
    </div>

    
    <div class="border-border bg-muted/20 border-t px-4 py-3">
      <div class="text-muted-foreground text-center text-xs">
        <span>제목을 클릭하면 해당 위치로 이동합니다</span>
      </div>
    </div>
  </div>
</div>

    


  <link
    rel="stylesheet"
    href="https://cdn.jsdelivr.net/npm/katex@0.16.22/dist/katex.min.css"
    integrity="sha384-5TcZemv2l/9On385z///+d7MSYlvIEw9FuZTIdZ14vJLqWphw7e7ZPuOiCHJcFCP"
    crossorigin="anonymous" />
  <script
    defer
    src="https://cdn.jsdelivr.net/npm/katex@0.16.22/dist/katex.min.js"
    integrity="sha384-cMkvdD8LoxVzGF/RPUKAcvmm49FQ0oxwDF3BGKtDXcEc+T1b2N+teh/OJfpU0jr6"
    crossorigin="anonymous"></script>
  <script
    defer
    src="https://cdn.jsdelivr.net/npm/katex@0.16.22/dist/contrib/auto-render.min.js"
    integrity="sha384-hCXGrW6PitJEwbkoStFjeJxv+fSOOQKOPbJxSfM6G5sWZjAyWhXiTIIAmQqnlLlh"
    crossorigin="anonymous"></script>

<script>
    
    function initKaTeX() {
        if (typeof renderMathInElement === 'undefined') {
            setTimeout(initKaTeX, 100);
            return;
        }

        var delimiters = [{"display":true,"left":"$$","right":"$$"},{"display":false,"left":"$","right":"$"}];

        renderMathInElement(document.body, {
            delimiters: delimiters,
            throwOnError: false,
            errorColor: '#cc0000',
            fleqn: false,
            leqno: false,
            trust: false
        });
    }

    
    if (document.readyState === 'loading') {
        document.addEventListener('DOMContentLoaded', initKaTeX);
    } else {
        initKaTeX();
    }
</script>
    



    
    
<div
  id="search-overlay"
  class="pointer-events-none fixed inset-0 z-40 bg-black/50 opacity-0 transition-opacity duration-300"></div>


<div
  id="search-modal"
  class="bg-card border-border pointer-events-none fixed top-1/2 left-1/2 z-50 max-h-[80vh] w-full max-w-2xl -translate-x-1/2 -translate-y-1/2 scale-95 transform overflow-hidden rounded-xl border opacity-0 shadow-xl transition-all duration-300">
  
  <div class="border-border flex items-center gap-3 border-b p-4">
    
    <div class="text-muted-foreground h-5 w-5 flex-shrink-0">
      
  <svg class="h-4 w-4"
    fill="none"
    stroke="currentColor"
    viewBox="0 0 24 24">
  <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="m21 21-6-6m2-5a7 7 0 11-14 0 7 7 0 0114 0z" />

</svg>
    </div>

    
    <div class="relative flex-1">
      
      <button
        id="search-clear"
        class="text-muted-foreground hover:text-foreground hover:bg-muted/50 pointer-events-none absolute top-1/2 left-0 z-10 h-5 w-5 -translate-y-1/2 rounded opacity-0 transition-all duration-200"
        title="지우기"
        aria-label="지우기">
        
  <svg class="h-4 w-4"
    fill="none"
    stroke="currentColor"
    viewBox="0 0 24 24">
  <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M6 18L18 6M6 6l12 12" />

</svg>
      </button>

      
      <input
        id="search-input"
        type="text"
        placeholder="게시글 검색..."
        class="text-foreground placeholder:text-muted-foreground w-full border-none bg-transparent pl-8 text-lg outline-none"
        autocomplete="off"
        spellcheck="false" />
    </div>

    
    <button
      id="search-close"
      class="text-muted-foreground hover:text-foreground hover:bg-muted/50 flex h-6 w-6 items-center justify-center rounded-md p-0.5 transition-all duration-200"
      title="닫기"
      aria-label="닫기">
      
  <svg class="h-4 w-4"
    fill="none"
    stroke="currentColor"
    viewBox="0 0 24 24">
  <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M6 18L18 6M6 6l12 12" />

</svg>
    </button>
  </div>

  
  <div id="search-results" class="max-h-96 overflow-y-auto">
    
    <div
      id="search-empty"
      class="flex flex-col items-center justify-center py-12 text-center">
      <div
        class="bg-muted/50 mb-4 flex h-16 w-16 items-center justify-center rounded-full">
        
  <svg class="h-6 w-6"
    fill="none"
    stroke="currentColor"
    viewBox="0 0 24 24">
  <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="m21 21-6-6m2-5a7 7 0 11-14 0 7 7 0 0114 0z" />

</svg>
      </div>
      <h3 class="text-foreground mb-2 text-lg font-semibold">
        검색 시작
      </h3>
      <p class="text-muted-foreground text-sm">
        검색어를 입력하세요
      </p>
    </div>

    
    <div
      id="search-loading"
      class="flex hidden items-center justify-center py-8">
      <div
        class="mr-3 h-6 w-6 animate-spin rounded-full border-2 border-current border-t-transparent"></div>
      <span class="text-muted-foreground"
        >검색 중...</span
      >
    </div>

    
    <div
      id="search-no-results"
      class="flex hidden flex-col items-center justify-center py-12 text-center">
      <div
        class="bg-muted/50 mb-4 flex h-16 w-16 items-center justify-center rounded-full">
        
  <svg class="h-6 w-6"
    fill="none"
    stroke="currentColor"
    viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M4 6h16M4 12h16M4 18h7" />
</svg>
      </div>
      <h3 class="text-foreground mb-2 text-lg font-semibold">
        검색 결과 없음
      </h3>
      <p class="text-muted-foreground text-sm">
        다른 검색어로 시도해보세요
      </p>
    </div>

    
    <div id="search-results-list" class="hidden">
      
      <div
        id="search-stats"
        class="text-muted-foreground border-border border-b px-4 py-3 text-sm"
        data-template="%d개의 결과 찾음">
      </div>

      
      <div id="search-items" class="divide-border divide-y">
        
      </div>
    </div>
  </div>

  
  <div class="border-border bg-muted/20 border-t px-4 py-3">
    <div
      class="text-muted-foreground flex items-center justify-between text-xs">
      <div class="flex items-center gap-2 md:gap-4">
        <div class="flex items-center gap-1">
          <kbd
            class="bg-muted border-border rounded border px-1.5 py-0.5 text-xs"
            >↑↓</kbd
          >
          <span class="hidden sm:inline"
            >이동</span
          >
        </div>
        <div class="flex items-center gap-1">
          <kbd
            class="bg-muted border-border rounded border px-1.5 py-0.5 text-xs"
            >↵</kbd
          >
          <span class="hidden sm:inline"
            >선택</span
          >
        </div>
        <div class="flex items-center gap-1">
          <kbd
            class="bg-muted border-border rounded border px-1.5 py-0.5 text-xs"
            >ESC</kbd
          >
          <span class="hidden sm:inline"
            >닫기</span
          >
        </div>
      </div>
      <div class="search-hint-desktop flex items-center gap-1">
        <kbd class="bg-muted border-border rounded border px-1.5 py-0.5 text-xs"
          >⌘K</kbd
        >
        <span>단축키</span>
      </div>
    </div>
  </div>
</div>

  </body>
</html>
