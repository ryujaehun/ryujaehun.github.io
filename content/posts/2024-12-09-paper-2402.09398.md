---
categories:
- paper-review
- with-gpt
- LLM-Inference
date: "2024-12-09"
title: 'Get More with LESS: Synthesizing Recurrence with KV Cache Compression for
  Efficient LLM Inference'
---

[논문 링크](https://arxiv.org/abs/2402.09398)

# Q : 이 논문을 아주 자세하게 읽고 논문의 강점과 독창적인 지점을 설명해주고 핵심 알고리즘을 예시 입력을 들어서 전체적인 과정을 설명해줘 추가적으로 논문의 한계점에 대해서도 알려줘



논문 제목은 **"Get More with LESS: Synthesizing Recurrence with KV Cache Compression for Efficient LLM Inference"**입니다. 논문에서 제안된 LESS(Low-rank Embedding Sidekick with Sparse policy)는 대형 언어 모델(LLM)의 키-값(KV) 캐시 메모리 병목 문제를 해결하기 위해 Sparse(희소) 정책과 Low-rank(저차원) 캐시를 결합한 새로운 방법론입니다. 이제 논문의 주요 강점과 독창성, 알고리즘, 한계점을 자세히 설명하겠습니다.

---

### 논문의 주요 강점과 독창성
1. **효율적 메모리 사용**:
   - KV 캐시 메모리를 희소 정책으로 줄이면서도 성능 손실을 보완하는 Low-rank 캐시를 통합하여 캐시 메모리 크기를 일정하게 유지합니다.
   - 저차원 캐시(Low-rank state)는 시퀀스 길이에 상관없이 일정한 메모리를 사용합니다.

2. **희소 정책과 저차원 구조의 결합**:
   - 기존 희소 정책은 중요한 토큰만 선택하여 캐시에 유지하지만, 정보 손실 문제를 겪습니다.
   - LESS는 Low-rank 캐시를 통해 삭제된 정보의 잔차(residual)를 학습하여 성능 저하를 크게 줄입니다.

3. **간단한 통합 및 확장 가능성**:
   - 기존 모델의 구조를 크게 변경하지 않고, 각 어텐션 계층에 작은 MLP를 추가하는 방식으로 구현됩니다.
   - 희소 정책과 결합해도 높은 성능을 유지하며, 다양한 모델(Llama 2, Falcon 등)과 작업(요약, 분류 등)에서 유연하게 작동합니다.

4. **학습 및 추론 효율성**:
   - 학습은 어텐션 계층별로 독립적으로 수행되어 계산 비용이 낮고, 추론 시간 동안도 일관성을 유지합니다.

---

### 핵심 알고리즘
LESS의 알고리즘은 크게 두 단계로 나뉩니다: **어텐션 계산**과 **캐시 업데이트**.

#### 1. 어텐션 계산
- 기존 어텐션 출력 \( a \)는 희소 정책에 의해 일부 정보가 삭제된 \( a_{\text{sparse}} \)를 기반으로 계산됩니다.
- LESS는 이 잔차(residual)를 보완하기 위해 저차원 캐시 \( H_t \)와 \( z_t \)를 활용합니다.
- 어텐션 계산은 다음과 같이 이루어집니다:
  \[
  \hat{a}_t = \frac{\phi(q_t)H_t + \exp(q_tK_{C,t}^\top)V_{C,t}}{\phi(q_t)z_t^\top + \exp(q_tK_{C,t}^\top)\mathbf{1}}
  \]
  여기서 \( \phi \)와 \( \psi \)는 저차원 임베딩을 위한 커널 함수입니다.

#### 2. 캐시 업데이트
- 희소 정책에 의해 삭제된 KV 쌍은 저차원 캐시에 통합됩니다:
  \[
  H_{t+1} = H_t + \sum_{(k, v) \in D_t} \psi(k)^\top v, \quad z_{t+1} = z_t + \sum_{(k, v) \in D_t} \psi(k)
  \]
- 이 과정에서 삭제된 정보는 \( H_t \)와 \( z_t \)에 추가적으로 통합되어 추후 복원 가능합니다.

#### 예시 입력을 사용한 과정 설명:
1. 입력 토큰: "The quick brown fox jumps over the lazy dog".
2. 희소 정책: 중요하지 않은 토큰("over", "lazy")은 삭제됩니다.
3. 삭제된 토큰의 정보는 \( H_t \)와 \( z_t \)에 통합되어 잔차로 관리됩니다.
4. 추론 시 삭제된 토큰의 정보를 활용해 원래의 어텐션 맵을 복원합니다.

---

### 논문의 한계점
1. **완벽한 성능 복원 어려움**:
   - 희소 정책과 결합하여 높은 성능을 유지하지만, 완전한 캐시(full cache)와 동일한 수준의 성능을 항상 보장하지는 못합니다.

2. **복잡한 커널 설계**:
   - 저차원 상태를 생성하는 커널 함수의 설계가 모델 및 작업에 따라 조정이 필요하며, 일반적인 규칙은 제시되지 않았습니다.

3. **장기적 정보 손실 가능성**:
   - 시퀀스 길이가 길어질수록 희소 정책에 의해 삭제된 정보의 비율이 증가하며, 이는 저차원 캐시에서도 완벽히 보완하기 어렵습니다.

4. **제한된 검증 데이터**:
   - 주요 실험은 WikiText, CNN/DailyMail 등에서 수행되었으며, 더 다양한 도메인에 대한 검증이 필요합니다.

---

이 논문은 LLM의 실제 배포 환경에서 중요한 메모리 효율성과 성능을 동시에 고려한 독창적인 방법론을 제안하며, 다양한 분야에서의 적용 가능성을 엿보게 합니다. 추가적으로 궁금한 사항이 있으면 알려주세요!

# Q : 논문의 핵심알고리즘을 예시를 들어 아주 자세하게 설명해주고 정리해 줘



논문 제목은 **"Get More with LESS: Synthesizing Recurrence with KV Cache Compression for Efficient LLM Inference"**입니다. 논문에서 제안된 LESS(Low-rank Embedding Sidekick with Sparse policy)는 대형 언어 모델(LLM)의 키-값(KV) 캐시 메모리 병목 문제를 해결하기 위해 Sparse(희소) 정책과 Low-rank(저차원) 캐시를 결합한 새로운 방법론입니다. 이제 논문의 주요 강점과 독창성, 알고리즘, 한계점을 자세히 설명하겠습니다.

---

### 논문의 주요 강점과 독창성
1. **효율적 메모리 사용**:
   - KV 캐시 메모리를 희소 정책으로 줄이면서도 성능 손실을 보완하는 Low-rank 캐시를 통합하여 캐시 메모리 크기를 일정하게 유지합니다.
   - 저차원 캐시(Low-rank state)는 시퀀스 길이에 상관없이 일정한 메모리를 사용합니다.

2. **희소 정책과 저차원 구조의 결합**:
   - 기존 희소 정책은 중요한 토큰만 선택하여 캐시에 유지하지만, 정보 손실 문제를 겪습니다.
   - LESS는 Low-rank 캐시를 통해 삭제된 정보의 잔차(residual)를 학습하여 성능 저하를 크게 줄입니다.

3. **간단한 통합 및 확장 가능성**:
   - 기존 모델의 구조를 크게 변경하지 않고, 각 어텐션 계층에 작은 MLP를 추가하는 방식으로 구현됩니다.
   - 희소 정책과 결합해도 높은 성능을 유지하며, 다양한 모델(Llama 2, Falcon 등)과 작업(요약, 분류 등)에서 유연하게 작동합니다.

4. **학습 및 추론 효율성**:
   - 학습은 어텐션 계층별로 독립적으로 수행되어 계산 비용이 낮고, 추론 시간 동안도 일관성을 유지합니다.

---

### 핵심 알고리즘
LESS의 알고리즘은 크게 두 단계로 나뉩니다: **어텐션 계산**과 **캐시 업데이트**.

#### 1. 어텐션 계산
- 기존 어텐션 출력 \( a \)는 희소 정책에 의해 일부 정보가 삭제된 \( a_{\text{sparse}} \)를 기반으로 계산됩니다.
- LESS는 이 잔차(residual)를 보완하기 위해 저차원 캐시 \( H_t \)와 \( z_t \)를 활용합니다.
- 어텐션 계산은 다음과 같이 이루어집니다:
  \[
  \hat{a}_t = \frac{\phi(q_t)H_t + \exp(q_tK_{C,t}^\top)V_{C,t}}{\phi(q_t)z_t^\top + \exp(q_tK_{C,t}^\top)\mathbf{1}}
  \]
  여기서 \( \phi \)와 \( \psi \)는 저차원 임베딩을 위한 커널 함수입니다.

#### 2. 캐시 업데이트
- 희소 정책에 의해 삭제된 KV 쌍은 저차원 캐시에 통합됩니다:
  \[
  H_{t+1} = H_t + \sum_{(k, v) \in D_t} \psi(k)^\top v, \quad z_{t+1} = z_t + \sum_{(k, v) \in D_t} \psi(k)
  \]
- 이 과정에서 삭제된 정보는 \( H_t \)와 \( z_t \)에 추가적으로 통합되어 추후 복원 가능합니다.

#### 예시 입력을 사용한 과정 설명:
1. 입력 토큰: "The quick brown fox jumps over the lazy dog".
2. 희소 정책: 중요하지 않은 토큰("over", "lazy")은 삭제됩니다.
3. 삭제된 토큰의 정보는 \( H_t \)와 \( z_t \)에 통합되어 잔차로 관리됩니다.
4. 추론 시 삭제된 토큰의 정보를 활용해 원래의 어텐션 맵을 복원합니다.

---

### 논문의 한계점
1. **완벽한 성능 복원 어려움**:
   - 희소 정책과 결합하여 높은 성능을 유지하지만, 완전한 캐시(full cache)와 동일한 수준의 성능을 항상 보장하지는 못합니다.

2. **복잡한 커널 설계**:
   - 저차원 상태를 생성하는 커널 함수의 설계가 모델 및 작업에 따라 조정이 필요하며, 일반적인 규칙은 제시되지 않았습니다.

3. **장기적 정보 손실 가능성**:
   - 시퀀스 길이가 길어질수록 희소 정책에 의해 삭제된 정보의 비율이 증가하며, 이는 저차원 캐시에서도 완벽히 보완하기 어렵습니다.

4. **제한된 검증 데이터**:
   - 주요 실험은 WikiText, CNN/DailyMail 등에서 수행되었으며, 더 다양한 도메인에 대한 검증이 필요합니다.

---

이 논문은 LLM의 실제 배포 환경에서 중요한 메모리 효율성과 성능을 동시에 고려한 독창적인 방법론을 제안하며, 다양한 분야에서의 적용 가능성을 엿보게 합니다. 추가적으로 궁금한 사항이 있으면 알려주세요!

# Q : 이 논문에서 사용하는 방법을 학습하기 위하여 어떤 데이터셋이 필요할까? 그리고 어떻게 학습을 진행하면 될지 예시를 들어서 아주 자세하게 설명해줘



### 학습에 필요한 데이터셋
논문에서 LESS를 학습하는 데 필요한 데이터셋은 **언어 모델의 어텐션 매커니즘을 평가할 수 있는 대규모 텍스트 데이터셋**입니다. 논문에서는 아래와 같은 데이터셋을 활용합니다:

1. **WikiText (WikiText-103)**:
   - 대규모 텍스트 데이터셋으로, 언어 모델의 학습 및 평가에 적합합니다.
   - LESS는 문장 내에서 어텐션이 어떻게 작동하는지 학습하기 위해, 해당 데이터셋에서 생성된 쿼리, 키, 값(QKV)을 사용합니다.

2. **PG-19**:
   - 긴 문맥을 포함한 데이터셋으로, 긴 시퀀스에서 모델의 성능을 평가하기 적합합니다.
   - LESS는 긴 문맥의 경우 삭제된 KV 페어에서 잔차 정보를 복구하는 방법을 학습할 수 있습니다.

3. **C4 (Colossal Clean Crawled Corpus)**:
   - 웹에서 수집된 다양한 텍스트 데이터로, 사전 학습과 어텐션 기반 학습에 활용됩니다.
   - 다양한 문맥과 주제에 대해 학습할 수 있는 기회를 제공합니다.

---

### 학습 방법과 과정

#### 1. **데이터 준비**
   - 데이터셋에서 샘플링하여 입력 시퀀스를 생성합니다.
     - 예를 들어, WikiText에서 임의로 문장을 선택해 시퀀스를 구성합니다.
   - 각 시퀀스는 모델로 전달되어 쿼리(\( q \)), 키(\( k \)), 값(\( v \))의 형태로 변환됩니다.

#### 2. **희소 정책(Sparse Policy) 설정**
   - 희소 정책은 KV 캐시에서 일부 토큰을 제거하는 방식을 정의합니다.
     - **H2O 정책**: 중요도가 높은 토큰(heavy-hitter)과 가장 최근의 토큰을 캐시에 유지합니다.
     - **Λ-Masking 정책**: 첫 번째 몇 개의 토큰과 마지막 몇 개의 토큰만 캐시에 남깁니다.
   - 희소 정책에 따라 캐시에 남는 KV 페어와 삭제되는 KV 페어를 구분합니다.

#### 3. **저차원 캐시(Low-rank Cache) 초기화**
   - 초기 저차원 상태는 모두 0으로 설정됩니다:
     \[
     H_0 = 0_{R \times D}, \quad z_0 = 0_{1 \times R}
     \]

#### 4. **잔차 학습 (Residual Learning)**
   - 삭제된 KV 페어(\( D_t \))의 정보를 잔차로 학습합니다.
   - 손실 함수는 어텐션 레이어의 출력과 희소 정책에 따른 어텐션 출력 간의 차이를 최소화합니다:
     \[
     L = \| A - \hat{A} \|_2^2
     \]
     여기서 \( A \)는 원래 어텐션 출력, \( \hat{A} \)는 LESS를 포함한 어텐션 출력입니다.

---

### 학습 과정 예시

1. **초기 단계**:
   - 데이터셋에서 512개 문장을 샘플링해 시퀀스를 구성합니다.
   - 각 시퀀스에서 쿼리, 키, 값(\( q, k, v \))를 계산합니다.
   - 희소 정책(H2O 등)을 적용해 삭제된 KV 페어(\( D_t \))와 유지된 KV 페어를 분리합니다.

2. **LESS 적용**:
   - 삭제된 KV 페어를 기반으로 저차원 캐시 \( H_t, z_t \)를 업데이트합니다:
     \[
     H_{t+1} = H_t + \sum_{(k, v) \in D_t} \psi(k)^\top v, \quad z_{t+1} = z_t + \sum_{(k, v) \in D_t} \psi(k)
     \]
   - 업데이트된 \( H_t, z_t \)를 사용해 어텐션 출력 \( \hat{A}_t \)를 계산합니다.

3. **손실 계산 및 역전파**:
   - 원래 어텐션 출력 \( A_t \)와 \( \hat{A}_t \) 간의 차이를 손실로 계산합니다.
   - 손실에 대해 역전파를 수행하여 \( \phi \)와 \( \psi \)의 파라미터를 업데이트합니다.

4. **반복 학습**:
   - 위 과정을 여러 시퀀스에 대해 반복하며 모델의 저차원 캐시가 잔차를 잘 학습하도록 만듭니다.
   - 다양한 희소 정책과 입력 시퀀스를 실험하여 일반화를 도모합니다.

---

### 학습 설정 요약
- **학습 목표**: 저차원 캐시가 삭제된 정보를 효과적으로 복구하도록 학습.
- **입력 데이터**: WikiText, PG-19, C4와 같은 대규모 텍스트 데이터.
- **손실 함수**: 어텐션 출력의 차이를 최소화하는 \( \ell_2 \) 손실.
- **하이퍼파라미터**:
  - 학습률: \( 0.001 \) (Adam Optimizer 사용)
  - 저차원 캐시 크기: \( R = 8 \)
  - 드롭아웃: \( 0.3 \)

---

### 구현 가이드라인
- **병렬화**: 각 어텐션 계층을 독립적으로 학습해 병렬 처리를 극대화합니다.
- **모델 초기화**: 희소 정책 기반의 모델 성능을 초기값으로 활용합니다.
- **학습 시간 단축**: 각 어텐션 계층을 독립적으로 학습하므로, 여러 GPU를 사용해 병렬 학습을 진행합니다.

이와 같은 과정을 따라 LESS를 학습시키면, 다양한 희소 정책에서 성능을 보완할 수 있습니다. 추가적으로 구현과 관련된 질문이 있으면 알려주세요!

# Q : 이 논문에서 제시한 결과를 자세하게 보고 다른 방법론에 비하여 특출난 점과 논문에서 제기하는 어떠한 방법이 이러한 결과를 도출하게 되었는지 논문에서 제시하는 이유와 너의 생각을 알려줘



### 논문에서 제시한 결과와 분석

논문은 LESS가 다양한 LLM 작업에서 캐시 메모리를 효율적으로 사용하면서도 성능 저하를 최소화한다는 점을 입증합니다. 결과는 크게 **언어 모델링**, **문서 요약**, **추론 속도 및 메모리 사용**의 세 가지로 나뉩니다.

---

#### 1. **언어 모델링**
- 평가 데이터셋: **WikiText** 및 **PG-19**
- 주요 결과:
  - 희소 정책(H2O)과 LESS를 결합한 경우, 기존 희소 정책만 사용한 경우보다 언어 모델의 단어 당 perplexity가 평균 20% 이상 감소했습니다.
  - 특히, **WikiText**에서 FULL 캐시 성능과 비교해 희소 정책 단독 사용 시 큰 성능 저하가 발생했으나, LESS는 성능 격차를 크게 줄였습니다.

**LESS의 특출난 점**:
- 단순히 더 많은 KV 페어를 저장하는 것보다, 삭제된 정보를 잔차로 복원하는 방식이 훨씬 효과적입니다.
- 논문에서는 저차원 캐시가 삭제된 토큰의 정보를 적절히 압축하여, 희소 정책으로 인한 성능 손실을 보완하는 데 중요한 역할을 한다고 주장합니다.

**핵심 기여 방법**:
- 저차원 상태 \( H_t \)와 \( z_t \)를 활용하여 삭제된 정보의 잔차를 복구합니다.
- \( H_t \)와 \( z_t \)는 시퀀스 길이에 독립적인 일정한 메모리 크기를 사용해 효율적입니다.

**내 생각**:
- 이 접근법은 단순히 추가적인 캐시 메모리를 사용하는 것이 아니라, 삭제된 정보의 중요도를 반영해 압축하는 방식입니다. 이는 기존의 단순한 희소 정책이나 FULL 캐시 대비 효율성과 성능의 균형을 잘 맞춘 것으로 보입니다.

---

#### 2. **문서 요약**
- 평가 데이터셋: **CNN/DailyMail**, **XSum**, **MultiNews**
- 주요 결과:
  - LESS는 희소 정책(H2O)과 결합하여 요약 품질을 개선했습니다.
  - 예를 들어, CNN/DailyMail에서 ROUGE-1 점수 기준으로 H2O 단독 대비 약 2~5점 향상되었습니다.
  - XSum에서는 FULL 캐시와 유사한 수준의 요약 품질을 달성했습니다.

**LESS의 특출난 점**:
- 요약 작업에서 삭제된 토큰이 나중에 중요한 정보를 포함할 가능성이 큽니다. LESS는 이러한 토큰 정보를 복원함으로써 긴 문맥에서 높은 성능을 유지합니다.
- FULL 캐시에 가까운 결과를 적은 메모리로 달성합니다.

**핵심 기여 방법**:
- 삭제된 KV 페어의 정보를 잔차 형태로 저차원 캐시에 저장하고, 다음 디코딩 단계에서 이를 활용하여 어텐션 출력에 반영합니다.
- 단순히 최근 토큰을 저장하는 방식이 아닌, 잔차를 학습한 점이 성능 향상의 주요 원인입니다.

**내 생각**:
- 요약 작업은 삭제된 정보의 복원이 특히 중요한 도메인입니다. LESS가 FULL 캐시 성능에 근접한 점은, 단순히 희소 정책을 사용하는 기존 방식보다 훨씬 세밀한 정보 활용이 가능하다는 점을 보여줍니다.

---

#### 3. **추론 속도 및 메모리 사용**
- 평가 환경: NVIDIA A100 GPU, Llama 2 7B, 13B 모델
- 주요 결과:
  - LESS는 FULL 캐시 대비 추론 속도를 1.1~1.3배 향상시키고, 메모리 사용량을 크게 줄였습니다.
  - 동일한 메모리 조건에서 LESS는 H2O 대비 약간 더 많은 계산 비용이 발생하지만, 성능 개선 효과는 훨씬 큽니다.

**LESS의 특출난 점**:
- 희소 정책 기반으로 작동하면서도, 추가적인 \( H_t, z_t \) 상태를 유지하여 정보 복원을 가능하게 합니다.
- FULL 캐시 대비 메모리 사용량을 최대 40% 이상 줄이면서도 성능 손실을 최소화합니다.

**핵심 기여 방법**:
- 저차원 캐시는 시퀀스 길이에 무관하게 일정한 메모리를 유지하므로, 긴 시퀀스에서도 FULL 캐시 대비 메모리 사용량을 줄입니다.
- 메모리 효율성을 기반으로 추론 속도를 높입니다.

**내 생각**:
- 메모리 사용량과 추론 속도는 실제 LLM 배포 시 매우 중요한 요소입니다. LESS는 이 두 가지 요소를 효과적으로 최적화하며, 실질적인 응용 가능성이 높아 보입니다.

---

### LESS의 결과를 도출한 방법론적 기여

1. **희소 정책과 저차원 상태 결합**:
   - LESS는 희소 정책의 단점(삭제된 토큰 정보 손실)을 보완하기 위해 저차원 캐시를 도입했습니다.
   - 단순히 저장 공간을 늘리는 대신, 삭제된 정보를 잔차로 압축 및 복원하는 구조가 주요한 기여입니다.

2. **손실 함수 기반 학습**:
   - 어텐션 출력과 복원된 출력 간의 잔차를 최소화하는 방식으로 학습을 진행하여, 삭제된 정보를 효과적으로 활용할 수 있습니다.

3. **일정한 메모리 크기 유지**:
   - 시퀀스 길이에 무관한 일정한 크기의 저차원 캐시를 사용하여 메모리 사용량을 효율적으로 제어했습니다.

---

### 결론 및 나의 생각

LESS는 **희소 정책의 단점을 보완하며, FULL 캐시에 가까운 성능을 달성하는 효율적인 방법론**입니다. 특히 저차원 캐시를 도입한 방식은 기존의 단순한 희소 정책 대비 독창적이며, 메모리 효율성을 고려한 점에서 큰 강점을 보입니다.

- **특출난 점**: 잔차 학습 및 복원을 통해 삭제된 정보를 효과적으로 보완.
- **개선점**: LONG 시퀀스에서의 정보 손실을 더 세밀하게 처리할 방법이 필요하며, 다양한 희소 정책과의 결합 성능 검증이 추가될 수 있습니다.

LESS는 실제 LLM 배포 환경에서 매우 유용한 방법으로 보이며, 추가 실험을 통해 더욱 폭넓은 도메인에 적용 가능할 것입니다.



# Q : 이 논문의 입력데이터와 추론 과정에 대해서 예시를 들어 아주 자세하게 설명해 주겠니? 추가적으로 모델아키텍처의 구성 및 모델을 구성하는 연산과 메모리 요구량 컴퓨팅 요구량 대해서도 설명해줘



### 입력 데이터와 추론 과정

논문에서 LESS를 적용하는 추론 과정과 입력 데이터를 아래와 같이 예시를 들어 설명하겠습니다.

---

### **1. 입력 데이터**
#### 입력 데이터 특징:
- **형식**: 텍스트 시퀀스 (예: 문장, 문단 등)
- **구성**: 입력 텍스트는 모델에서 쿼리(\(q\)), 키(\(k\)), 값(\(v\))로 변환됩니다.
- 데이터셋: WikiText, PG-19, CNN/DailyMail 등 다양한 자연어 텍스트 데이터셋.

#### 예시 입력:
```
입력 문장: "The quick brown fox jumps over the lazy dog."
```

- 각 단어가 토큰화되고, 모델 내부에서 임베딩 벡터로 변환됩니다.
- 입력 시퀀스의 길이는 \(T = 9\) (9개의 단어로 구성).

---

### **2. 추론 과정**
#### (1) **기본 추론 흐름**
1. **쿼리, 키, 값 계산**:
   - 입력 시퀀스는 \(q_t, k_t, v_t\)의 쿼리-키-값 페어로 변환됩니다.
   - 각 시점 \(t\)에서 \(q_t = f(x_t)\), \(k_t = g(x_t)\), \(v_t = h(x_t)\)로 모델 임베딩 계층에서 계산됩니다.

2. **희소 정책 적용**:
   - 희소 정책(H2O, Λ-masking 등)을 사용하여 중요하지 않은 KV 페어는 삭제되고, 중요한 KV 페어만 캐시에 유지됩니다.
   - 예: \(T = 9\)에서 첫 번째와 마지막 두 개의 단어만 캐시에 유지.
     ```
     유지된 KV 페어: ("The", "dog")
     삭제된 KV 페어: ("quick", "brown", ..., "lazy")
     ```

3. **잔차 복구(Residual Recovery)**:
   - 삭제된 KV 페어의 정보를 저차원 캐시 \(H_t\)와 \(z_t\)에 통합하여 저장.
   - 저차원 캐시의 업데이트:
     \[
     H_{t+1} = H_t + \sum_{(k, v) \in D_t} \psi(k)^\top v, \quad z_{t+1} = z_t + \sum_{(k, v) \in D_t} \psi(k)
     \]
   - 잔차 복구된 정보를 활용하여 어텐션 계산에 포함.

4. **최종 출력 계산**:
   - 어텐션 출력 \(\hat{a}_t\)는 다음과 같이 계산됩니다:
     \[
     \hat{a}_t = \frac{\phi(q_t)H_t + \exp(q_tK_{C,t}^\top)V_{C,t}}{\phi(q_t)z_t^\top + \exp(q_tK_{C,t}^\top)\mathbf{1}}
     \]
   - 여기서 \(K_{C,t}\), \(V_{C,t}\)는 희소 정책에 따라 유지된 KV 페어입니다.

#### (2) **구체적 예시**
1. 입력 문장:
   ```
   "The quick brown fox jumps over the lazy dog."
   ```

2. 각 단어의 쿼리(\(q\)), 키(\(k\)), 값(\(v\)) 계산:
   - \(q_t, k_t, v_t\)는 입력 임베딩 계층에서 계산.

3. 희소 정책 적용:
   - 유지된 토큰: "The", "dog"
   - 삭제된 토큰: "quick", "brown", "fox", "jumps", "over", "lazy"

4. 잔차 복구:
   - 삭제된 토큰의 정보를 \(H_t\), \(z_t\)에 저장.

5. 어텐션 계산:
   - 유지된 KV 페어와 저차원 캐시를 결합하여 출력 \(\hat{a}_t\)를 생성.

---

#### 프롬프트모델 아키텍처 구성

#### 1. 주요 구성 요소
1. **Transformer 아키텍처**:
   - 모델의 기반은 Transformer이며, 어텐션 계층, FFN 계층, 레이어 정규화로 구성.

2. **LESS 통합**:
   - 기존 어텐션 계층에 다음을 추가:
     - 저차원 캐시 \((H_t, z_t)\)를 계산하기 위한 MLP.
     - \(H_t, z_t\) 업데이트를 위한 수식 추가.

3. **희소 정책 결합**:
   - 기존 희소 정책(H2O, Λ-masking 등)과 저차원 캐시가 결합된 어텐션 구조.

#### 2. LESS의 연산 흐름
- 기본 Transformer 연산 + 추가적인 \(H_t, z_t\) 계산 및 업데이트.

---

### 메모리 요구량 및 컴퓨팅 요구량

#### 1. **메모리 요구량**
- 기존 Transformer 대비 추가 메모리:
  - 저차원 캐시 \(H_t \in \mathbb{R}^{R \times D}\), \(z_t \in \mathbb{R}^{1 \times R}\)
  - \(R\): 저차원 크기, \(D\): 임베딩 차원
  - \(R = 8\), \(D = 512\)로 설정 시, 추가 메모리는 KV 페어 4개를 저장하는 것과 유사.

- 결과:
  - 기존 KV 캐시와 비교해 메모리 사용량 감소:
    - 예: FULL 캐시(모든 \(k, v\) 저장) 대비 약 40% 메모리 절약.

#### 2. **컴퓨팅 요구량**
- 추가 연산:
  - 저차원 캐시 계산:
    \[
    H_{t+1} = H_t + \sum_{(k, v) \in D_t} \psi(k)^\top v
    \]
  - 저차원 캐시를 활용한 어텐션 출력 계산:
    \[
    \hat{a}_t = \frac{\phi(q_t)H_t + \exp(q_tK_{C,t}^\top)V_{C,t}}{\phi(q_t)z_t^\top + \exp(q_tK_{C,t}^\top)\mathbf{1}}
    \]

- 결과:
  - FULL 캐시 대비 연산량 감소.
  - 희소 정책만 사용한 경우와 비교해 연산량 증가(잔차 계산 추가)하나, 성능 향상으로 상쇄.

---

### 결론
LESS는 기존 Transformer 모델에 저차원 캐시를 추가하여 **효율적인 메모리 관리**와 **높은 성능 복원**을 동시에 달성합니다. 특히, 입력 데이터에서 삭제된 정보를 효과적으로 복원하며, 실용적인 메모리 요구량과 계산량으로 LLM 배포에 적합한 솔루션을 제공합니다.

# Q : 이 논문의 한계를 극복하기 위한 방법으로 어떤 연구흐름이 있는지 정리해서 자세하게 설명해 줘



논문에서 제기한 한계를 극복하기 위해 발전시킬 수 있는 연구 흐름과 접근 방식을 아래와 같이 정리하겠습니다.

---

### **1. 논문의 주요 한계**
#### A. **FULL 캐시와의 성능 격차**
- LESS는 희소 정책과 저차원 캐시를 결합하여 성능을 개선했지만, FULL 캐시 대비 성능 저하가 여전히 존재합니다.
- 특정 작업(예: 언어 모델링)에서는 삭제된 정보의 복원이 완벽하지 않아 성능이 제한됩니다.

#### B. **희소 정책에 대한 의존성**
- LESS는 희소 정책(H2O, Λ-masking 등)에 따라 작동하며, 희소 정책의 선택이 성능에 큰 영향을 미칩니다.
- 모든 유형의 작업과 모델에 최적화된 단일 희소 정책이 존재하지 않기 때문에, 특정 작업에서 성능이 저하될 가능성이 있습니다.

#### C. **긴 시퀀스 처리의 한계**
- 저차원 캐시의 메모리 사용량은 일정하지만, 매우 긴 시퀀스에서는 삭제된 정보가 누적되어 복원이 어려울 수 있습니다.
- 특히, 긴 문맥을 요구하는 작업(예: 법률 문서 요약)에서 성능 저하 가능성이 존재합니다.

#### D. **잔차 표현의 제한**
- 잔차를 복원하기 위해 사용하는 저차원 캐시(\(H_t, z_t\))의 차원이 작아 복원 가능한 정보의 표현력에 한계가 있을 수 있습니다.
- 삭제된 정보의 복잡성이 증가할수록 성능이 제한될 가능성이 있습니다.

---

### **2. 한계를 극복하기 위한 연구 흐름**

#### A. **FULL 캐시와 성능 격차 해소**
1. **동적 잔차 표현 학습**:
   - 잔차 복원을 위한 저차원 캐시의 구조를 동적으로 학습하도록 설계.
   - 모델이 삭제된 정보의 복잡도에 따라 잔차의 표현력을 자동으로 조정할 수 있게끔 확장.
   - 예시:
     - Transformer 계층별로 서로 다른 크기의 \(H_t, z_t\)를 사용하여 계층별 정보 복잡도에 적응.

2. **가변 저차원 캐시**:
   - 저차원 캐시의 크기(\(R\))를 고정하지 않고 작업의 복잡도나 시퀀스 길이에 따라 동적으로 조정.
   - 긴 시퀀스에서는 캐시 크기를 증가시켜 잔차 복원을 강화.

---

#### B. **희소 정책 개선**
1. **작업별 최적화된 희소 정책 개발**:
   - 작업별로 가장 효과적인 희소 정책을 자동으로 학습하는 알고리즘 개발.
   - 예: 강화학습(RL)을 활용해 각 작업에 맞는 최적의 토큰 선택 규칙 학습.

2. **복합 희소 정책 설계**:
   - 단일 정책에 의존하지 않고, 여러 희소 정책(H2O, Λ-masking 등)을 결합하여 복합적인 정보 유지.
   - 각 시퀀스에 대해 다양한 희소 정책을 적용하고, 결과를 가중 평균하거나 앙상블 방식으로 결합.

---

#### C. **긴 시퀀스 처리 능력 강화**
1. **다단계 캐시 구조**:
   - 짧은 시퀀스는 기존 방식대로 처리하고, 긴 시퀀스는 다단계로 나눠 처리.
   - 예: 전체 시퀀스를 여러 구간으로 나누고 각 구간에 대해 별도의 저차원 캐시를 생성한 뒤, 구간 간 정보를 통합.

2. **시퀀스 축약(Summarization) 기법 통합**:
   - 긴 시퀀스의 중요 정보를 축약하는 기법을 통합하여 캐시에 저장.
   - 예: 삭제된 정보를 단순히 복구하는 대신, 삭제된 토큰들에서 중요한 정보를 요약해 저장.

---

#### D. **잔차 표현의 강화**
1. **다중 저차원 캐시 사용**:
   - 단일 \(H_t, z_t\) 대신 여러 개의 저차원 캐시를 병렬로 사용하여 정보 표현력 증가.
   - 각 캐시가 다른 유형의 정보를 복원하도록 설계.

2. **어텐션 메커니즘 통합**:
   - 잔차 계산에 어텐션 메커니즘을 통합하여 삭제된 KV 페어의 상호작용을 더 효과적으로 모델링.
   - 예: \(H_t\)를 업데이트할 때, 삭제된 KV 페어 간의 유사성을 고려한 어텐션 가중치를 부여.

---

#### E. **메모리와 계산 효율성 향상**
1. **경량화 커널 설계**:
   - 잔차를 계산하는 커널(\(\phi, \psi\))을 더 경량화하여 계산 효율성을 높임.
   - 예: 커널 계산을 위한 MLP 크기를 줄이거나, 선형 변환 기반의 단순화된 구조 도입.

2. **하드웨어 최적화**:
   - GPU/TPU 등에서 병렬화와 데이터 로드 효율성을 강화하기 위한 LESS 알고리즘 최적화.
   - 예: CUDA 커널을 활용한 희소 정책의 효율적 구현.

---

### **3. 제안된 연구 흐름의 기대 효과**
- **FULL 캐시 성능에 근접**:
  - 동적 잔차 표현 및 다중 캐시 사용으로 삭제된 정보의 복원력을 강화.
- **긴 시퀀스에서도 높은 성능 유지**:
  - 다단계 캐시 구조 및 시퀀스 축약 기법으로 긴 문맥에서의 성능 저하 문제 해결.
- **작업 범용성 증가**:
  - 복합 희소 정책과 작업별 최적화로 다양한 도메인 및 작업에 적합한 성능 발휘.
- **효율성 극대화**:
  - 경량화 커널과 하드웨어 최적화로 실질적인 추론 속도 및 메모리 사용량 개선.

---

### **결론**
LESS의 한계를 극복하기 위해서는 **동적 잔차 표현 학습**, **복합 희소 정책 설계**, **긴 시퀀스 처리 강화**, 그리고 **효율적인 연산 구조 설계**가 필요합니다. 이러한 연구 흐름은 LLM의 실제 응용 가능성을 더욱 높이고, LESS를 보다 강력하고 범용적인 솔루션으로 발전시킬 것입니다.