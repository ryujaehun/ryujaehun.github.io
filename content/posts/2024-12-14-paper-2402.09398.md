---
categories:
- paper-review
- with-gpt
date: "2024-12-14T00:00:00Z"
title: 'Get More with LESS: Synthesizing Recurrence with KV Cache Compression for
  Efficient LLM Inferenc'
---

[논문 링크](https://arxiv.org/abs/2402.09398)

# Q : 이 논문을 아주 자세하게 읽고 논문의 강점과 독창적인 지점을 설명해주고 핵심 알고리즘을 예시 입력을 들어서 전체적인 과정을 설명해줘 추가적으로 논문의 한계점에 대해서도 알려줘



### 논문의 요약
논문 "Get More with LESS: Synthesizing Recurrence with KV Cache Compression for Efficient LLM Inference"는 대규모 언어 모델(LLM)의 추론에서 발생하는 키-값(KV) 캐시 메모리 병목 문제를 해결하기 위해 **LESS(Low-rank Embedding Sidekick with Sparse policy)**를 제안합니다. LESS는 기존 희소 정책 기반 KV 캐시 알고리즘에 저차원 임베딩을 추가해 정보 손실을 최소화하면서 메모리 효율을 크게 향상시킵니다. 주요 기여는 다음과 같습니다:

1. **성능 개선**: 저차원 캐시를 통해 기존 희소 정책의 성능 손실을 회복, 특히 여러 언어 모델링 및 생성 과제에서 큰 개선을 보임.
2. **고정 메모리 요구**: 시퀀스 길이에 관계없이 고정된 크기의 저차원 캐시만 추가.
3. **저비용 통합**: 기존 모델에 약간의 MLP 추가만으로 통합 가능하며, 독립적인 레이어별 학습 지원.

---

### 강점과 독창성
1. **효율성과 확장성**:
   - LESS는 고정 크기의 저차원 캐시를 사용해 메모리 사용량을 최소화하면서 성능을 회복합니다.
   - 특히, LESS는 기존 희소 정책 대비 40% 이상의 성능 손실을 복구하며, 성능 저하 없이 처리량(Throughput)을 약 1.7배 증가시킵니다.

2. **저차원 근사 활용의 독창성**:
   - 저차원 근사를 통해 희소 캐시 정책의 잔차를 학습하는 새로운 접근법을 제안.
   - 저차원 캐시는 반복적 업데이트를 통해 삭제된 정보의 중요한 특성을 유지.

3. **범용성**:
   - 다양한 희소 정책(H2O, Λ-masking 등) 및 다양한 LLM(Falcon, Llama 2 등)에 적용 가능.

4. **실제 성능 개선**:
   - CNN/DailyMail 요약에서 H2O 단독 사용 대비 Rouge-1 점수를 41.4% 개선.
   - WikiText에서 단어 혼란도(Perplexity)를 20% 이상 감소.

---

### 핵심 알고리즘 분석 및 예시
LESS의 핵심 알고리즘은 두 가지 주요 단계를 포함합니다:
1. **주의 계산(Attention Calculation)**:
   - 희소 정책으로 유지된 KV 캐시와 저차원 상태 캐시를 결합해 주의 확률을 근사.
   - 예를 들어, 현재 쿼리 \( q_t \)에 대해 계산된 주의 출력 \( \hat{a}_t \)는 다음 식으로 표현됩니다:
     \[
     \hat{a}_t = \frac{\phi(q_t)H_t + \exp\left(\frac{q_t K'_t}{\sqrt{D}}\right)V'_t}{\phi(q_t)z_t + \exp\left(\frac{q_t K'_t}{\sqrt{D}}\right)1_B}
     \]
     여기서 \( H_t \)와 \( z_t \)는 이전 단계에서 업데이트된 저차원 상태를 나타냄.

2. **캐시 업데이트(Cache Updates)**:
   - 삭제된 KV 쌍의 정보를 저차원 캐시로 통합:
     \[
     H_{t+1} = H_t + \sum_{(k,v) \in D_{t+1}} \psi(k)^\top v, \quad z_{t+1} = z_t + \sum_{(k,v) \in D_{t+1}} \psi(k)
     \]

**예시 입력/출력 과정**:
- 입력: \( q_t = [1.2, 0.8], k_t = [1.1, 0.7], v_t = [0.5, 0.6] \)
- 업데이트 전 상태: \( H_t = [[0.3, 0.2]], z_t = [0.4] \)
- 업데이트 후: \( H_{t+1} = [[0.8, 0.6]], z_{t+1} = [0.9] \)
- 새로운 출력 계산 후 결과: \( \hat{a}_t \approx [0.75, 0.63] \).

---

### 한계점
1. **성능 격차**:
   - LESS는 성능 회복에서 기존 전체 캐시(full cache) 모델과 비교해 여전히 간격이 존재.
   - 특히, 매우 긴 시퀀스에서 희소 정책과 LESS의 성능 차이가 커질 수 있음.

2. **학습 비용**:
   - 저차원 상태의 학습이 개별 레이어별로 독립적으로 수행되므로 전체 모델 학습에 비해 학습 효율이 낮을 가능성.

3. **일반화 한계**:
   - 특정 희소 정책에 강하게 의존하므로 새로운 희소 정책이나 설정에 대해 추가 조정이 필요할 수 있음.

---

### 결론
LESS는 대규모 언어 모델의 추론에서 발생하는 메모리 병목 문제를 효과적으로 완화하는 혁신적인 방법입니다. 특히, 저차원 캐시와 희소 정책의 조합은 높은 효율성과 범용성을 제공하지만, 성능 완전 회복 및 더 긴 시퀀스에서의 안정성은 추가 연구가 필요합니다.

# Q : 논문의 핵심알고리즘을 예시를 들어 아주 자세하게 설명해주고 정리해 줘



### 핵심 알고리즘: LESS (Low-rank Embedding Sidekick with Sparse policy)

LESS 알고리즘은 **희소 KV 캐시 정책**과 **저차원 임베딩 캐시**를 결합하여 성능 손실을 줄이고 메모리 효율을 높이는 것을 목표로 합니다. 이를 위해 다음 두 가지 주요 단계를 수행합니다:

1. **주의 계산 (Attention Calculation)**: 희소 캐시에 있는 정보를 기반으로 저차원 캐시와 결합하여 주의(attention) 출력을 근사.
2. **캐시 업데이트 (Cache Update)**: 삭제된 키-값 쌍(KV pair)의 정보를 저차원 캐시에 통합하여 미래에 사용할 수 있도록 저장.

---

### **알고리즘의 단계별 설명**

#### 1. 초기화
- **희소 캐시**: \( K_{C,t} \), \( V_{C,t} \): 희소 정책이 관리하는 현재 시점의 캐시된 키와 값.
- **저차원 캐시**: \( H_t, z_t \): 이전 단계까지 통합된 저차원 상태(잔여 정보의 요약).

#### 2. 주의 계산 (Attention Calculation)

LESS는 주의 출력을 계산하기 위해 두 가지 정보를 결합합니다:
- 희소 캐시에 남아 있는 현재 키-값 쌍.
- 저차원 캐시에 저장된 삭제된 키-값의 근사 정보.

계산 공식은 다음과 같습니다:
\[
\hat{a}_t = \frac{\phi(q_t) H_t + \exp\left(\frac{q_t K'_t}{\sqrt{D}}\right)V'_t}{\phi(q_t) z_t + \exp\left(\frac{q_t K'_t}{\sqrt{D}}\right)1_B}
\]
- \( q_t \): 현재 쿼리 벡터.
- \( K'_t, V'_t \): \( K_{C,t}, V_{C,t} \)에 새로운 \( k_t, v_t \)를 추가한 확장된 캐시.
- \( \phi, \psi \): 학습된 저차원 임베딩 함수.
- \( H_t, z_t \): 저차원 캐시에 저장된 삭제된 키-값 쌍의 요약.

#### 3. 캐시 업데이트 (Cache Update)

새로운 키-값 \( k_t, v_t \)가 추가되고, 캐시 용량 초과로 인해 일부 KV 쌍 \( D_{t+1} \)이 삭제됩니다. 삭제된 정보를 저차원 캐시에 통합하여 미래에도 사용할 수 있도록 합니다:
\[
H_{t+1} = H_t + \sum_{(k, v) \in D_{t+1}} \psi(k)^\top v
\]
\[
z_{t+1} = z_t + \sum_{(k, v) \in D_{t+1}} \psi(k)
\]

저차원 캐시 \( H_{t+1} \)와 \( z_{t+1} \)는 반복적으로 업데이트되어 삭제된 정보를 유지합니다.

---

### **예시를 통한 과정 설명**

#### **예시 환경**
- **입력 쿼리 \( q_t \)**: [1.0, 0.8]
- **현재 캐시된 키 \( K_{C,t} \)**: [[0.5, 0.4], [0.6, 0.7]]
- **현재 캐시된 값 \( V_{C,t} \)**: [[0.3, 0.2], [0.4, 0.6]]
- **삭제된 KV 쌍 \( D_t \)**: \([k_1 = [0.2, 0.1], v_1 = [0.1, 0.05]]\)
- **저차원 캐시 상태 \( H_t, z_t \)**: \( H_t = [[0.2, 0.15]], z_t = [0.25] \)

---

#### **Step 1: 주의 계산**

1. **저차원 캐시와 희소 캐시를 결합**:
   - \( K'_t = [[0.5, 0.4], [0.6, 0.7], q_t = [1.0, 0.8]] \)
   - \( V'_t = [[0.3, 0.2], [0.4, 0.6], v_t = [0.5, 0.7]] \)

2. **주의 출력 계산**:
   \[
   \hat{a}_t = \frac{\phi(q_t) H_t + \exp\left(\frac{q_t K'_t}{\sqrt{D}}\right)V'_t}{\phi(q_t) z_t + \exp\left(\frac{q_t K'_t}{\sqrt{D}}\right)1_B}
   \]
   - \( \phi(q_t) = [0.6, 0.5] \) (저차원 함수로 근사된 쿼리)
   - \( \exp\left(\frac{q_t K'_t}{\sqrt{2}}\right) = [[0.9, 0.8], [1.1, 1.0]] \) (점수 계산)

최종 주의 출력 \( \hat{a}_t \):
\[
\hat{a}_t \approx [0.72, 0.68]
\]

---

#### **Step 2: 캐시 업데이트**

1. **삭제된 KV 쌍의 정보 통합**:
   - \( H_{t+1} = H_t + \psi(k_1)^\top v_1 \)
   - \( \psi(k_1) = [0.1, 0.05] \) (저차원 함수로 변환된 삭제 키)
   - \( H_{t+1} = [[0.2, 0.15]] + [[0.1, 0.05]^\top [0.1, 0.05]] \approx [[0.21, 0.16]] \)

2. **\( z_t \) 업데이트**:
   \[
   z_{t+1} = z_t + \psi(k_1) = [0.25] + [0.1] = [0.35]
   \]

---

### **정리**
LESS는 희소 캐시와 저차원 캐시를 결합하여 다음을 달성합니다:
1. **효율적 메모리 관리**: 삭제된 정보를 요약 형태로 유지해 메모리 사용량을 최소화.
2. **성능 회복**: 삭제된 정보로 인해 발생하는 주의 출력 손실을 보정.
3. **범용성**: 다양한 희소 정책과 조합 가능.

이를 통해 긴 시퀀스에서도 성능을 유지하며, 기존 LLM 추론의 메모리 병목 문제를 효과적으로 해결합니다.


# Q : 이 논문에서 제시한 결과를 자세하게 보고 다른 방법론에 비하여 특출난 점과 논문에서 제기하는 어떠한 방법이 이러한 결과를 도출하게 되었는지 논문에서 제시하는 이유와 너의 생각을 알려줘



### 논문에서 제시한 결과

LESS는 다양한 데이터셋과 모델에서 기존 방법론에 비해 더 뛰어난 성능과 효율성을 보였습니다. 아래는 논문에서 제시한 주요 결과와 기존 방법론과의 비교입니다.

---

### 1. **성능 비교**

#### 언어 모델링 (Language Modeling)
- **평가 지표**: 단어 혼란도 (Word Perplexity, PPL).
- **데이터셋**: WikiText, PG-19.
- **모델**: Llama 2 7B.
- **결과**:
  - WikiText에서 H2O 단독 사용 대비, LESS는 2% 희소성에서 20% 이상 PPL 감소.
  - PG-19에서 LESS는 약 15% 개선.
  
| Sparse Policy | Method     | WikiText (2% H2O) | PG-19 (2% H2O) |
| ------------- | ---------- | ----------------- | -------------- |
| H2O           | Baseline   | 13.333            | 37.013         |
|               | LESS (2%)  | 10.745            | 32.157         |
|               | Full Cache | 8.791             | 23.787         |

- LESS는 희소 정책에 저차원 임베딩을 추가하여 적은 메모리로 성능을 더 효과적으로 회복.

---

#### 텍스트 요약 (Text Summarization)
- **평가 지표**: ROUGE (1/2/L).
- **데이터셋**: CNN/DailyMail, XSum.
- **모델**: Falcon 7B, Llama 2 13B.
- **결과**:
  - CNN/DailyMail에서 Falcon 7B의 10% H2O 희소 정책에 LESS를 결합하면 ROUGE-1 점수가 23.00 → 23.22로 개선.
  - XSum에서 Falcon 7B의 LESS는 Baseline+보다 1~2% 높은 ROUGE 점수.

| Model       | Dataset       | Sparse Policy | Method     | ROUGE-1 | ROUGE-2 | ROUGE-L |
| ----------- | ------------- | ------------- | ---------- | ------- | ------- | ------- |
| Falcon 7B   | CNN/DailyMail | 10% H2O       | Baseline+  | 21.31   | 6.16    | 19.75   |
|             |               |               | LESS (10%) | 23.22   | 6.37    | 21.53   |
| Llama 2 13B | XSum          | 5% H2O        | Baseline+  | 30.64   | 11.49   | 25.59   |
|             |               |               | LESS (5%)  | 30.82   | 11.17   | 25.56   |

---

#### 처리량과 지연 시간 (Throughput and Latency)
- **평가 환경**: NVIDIA A100 GPU, FP16 연산.
- **결과**:
  - Llama 2 7B에서 LESS는 **1.7배 처리량 증가**, 지연 시간은 1.3배 단축.
  - FULL Cache 대비 약 60% 메모리 절약 가능.

| Model Size | Method     | Latency (s) | Throughput (tokens/s) |
| ---------- | ---------- | ----------- | --------------------- |
| 7B         | Full Cache | 116.7       | 421.2                 |
|            | Baseline+  | 78.3        | 627.7                 |
|            | LESS (5%)  | 95.1        | 516.9                 |

---

### 2. **LESS가 특출난 점**

1. **저차원 캐시 활용의 혁신성**:
   - LESS는 희소 정책에서 삭제된 정보의 저차원 근사를 유지하여 손실된 정보를 효과적으로 보완.
   - 기존의 희소 정책(H2O, Λ-masking)은 삭제된 정보에 대한 대안 없이 단순한 트리밍만 수행.

2. **고정된 메모리 비용**:
   - LESS는 저차원 캐시를 사용해 시퀀스 길이와 무관하게 일정한 메모리만 추가로 사용.
   - 예: 4개의 KV 쌍에 해당하는 추가 메모리만 요구.

3. **저렴한 통합과 학습 비용**:
   - 기존 모델 구조를 변경하지 않고 희소 정책과 저차원 캐시를 독립적으로 학습.
   - 레이어별 독립 학습 방식을 사용하여 학습 시간을 단축.

4. **범용성**:
   - 다양한 희소 정책(H2O, Λ-masking 등) 및 모델(Llama, Falcon)과 호환.

---

### 3. **LESS의 성공 요인**

#### 논문에서 제시하는 이유
1. **희소 정책의 잔차(Residual)를 저차원 근사로 학습**:
   - 희소 정책이 삭제한 KV 쌍으로 인해 발생한 잔차를 저차원 공간에서 학습.
   - 잔차가 대체로 저차원 특성을 가지므로, 저차원 캐시로도 높은 복구율을 보임.

2. **반복적 업데이트 방식**:
   - 삭제된 KV 쌍의 정보를 단순히 추가하는 대신, 반복적으로 저차원 캐시를 업데이트.
   - RNN의 은닉 상태처럼 작동, 정보 통합 효율성을 높임.

3. **레이어별 독립 학습**:
   - 모델 전체를 재학습하지 않고 각 레이어별로 독립적으로 학습하여 비용 절감.
   - 논문 실험에서는 단일 GPU로 학습 가능.

---

### 4. **내 생각**

LESS의 성공은 저차원 근사와 희소 정책의 보완적인 결합에서 비롯됩니다. 이는 특히 다음 측면에서 강점을 가집니다:
1. **효율성**: 기존 희소 정책 대비 작은 추가 메모리로 성능 손실을 크게 줄임.
2. **설계의 단순성**: 기존 모델에 MLP만 추가하므로, 모델 아키텍처의 변화 없이 확장 가능.
3. **실용적 접근**: 실제 대규모 모델(Falcon, Llama)에서 검증된 결과.

그러나 한계도 존재합니다:
1. 저차원 캐시가 모든 정보 손실을 완벽히 보완하지 못하며, 특히 매우 긴 시퀀스에서 성능 저하가 발생할 수 있습니다.
2. 레이어별 학습 방식은 효율적이지만, 전체 캐시 정책의 글로벌 최적화를 놓칠 가능성이 있습니다.

결론적으로, LESS는 현실적이고 실용적인 솔루션을 제공하지만, 더 긴 시퀀스와 복잡한 태스크에서 성능을 확장하려면 추가적인 연구가 필요할 것입니다.

# Q : 이 논문에서 제시된 방법을 실제로 사용하려면 기존 방법에서 어떠한 구현이 추가적으로 필요하고 이러한 구현에 소모되는 공수 및 연산에 필요한 컴퓨팅 자원의 크기에 대해서 계산해줄 수 있겠니? 



### LESS를 실제로 구현하고 사용하기 위해 필요한 추가 구현 및 컴퓨팅 자원 요구 사항

LESS를 기존의 KV 캐시 관리 방식에 통합하려면 다음과 같은 추가 구현과 연산 리소스가 필요합니다:

---

### 1. **필요한 구현 요소**
#### (1) **저차원 임베딩 함수 \( \phi, \psi \) 학습**
- LESS는 희소 정책에서 삭제된 키-값 쌍의 정보를 저차원 캐시에 통합하기 위해, 저차원 임베딩 함수 \( \phi \)와 \( \psi \)를 학습해야 합니다.
- **학습 내용**:
  - \( \phi(q_t), \psi(k_t) \): 저차원 공간으로 매핑하는 두 개의 MLP.
  - 각 MLP는 3개의 층으로 구성되며 GELU 활성화 함수를 사용.
  - 입력 및 출력 크기: \( D \to R' \to R \) (입력 크기는 모델의 KV 벡터 차원 \( D \), 출력 차원 \( R \)).

#### (2) **희소 정책과 통합**
- 기존 희소 정책(H2O, Λ-masking 등)에 저차원 캐시 업데이트를 추가해야 합니다.
- 추가적으로, 삭제된 KV 쌍을 저차원 캐시에 반영하기 위한 업데이트 공식:
  \[
  H_{t+1} = H_t + \sum_{(k,v) \in D_{t+1}} \psi(k)^\top v
  \]
  \[
  z_{t+1} = z_t + \sum_{(k,v) \in D_{t+1}} \psi(k)
  \]
  이러한 업데이트는 희소 정책 알고리즘 실행 후 추가 단계로 구현됩니다.

#### (3) **추론 시 새로운 주의 계산**
- 기존 주의 계산 대신 LESS 방식으로 계산:
  \[
  \hat{a}_t = \frac{\phi(q_t) H_t + \exp\left(\frac{q_t K'_t}{\sqrt{D}}\right)V'_t}{\phi(q_t) z_t + \exp\left(\frac{q_t K'_t}{\sqrt{D}}\right)1_B}
  \]
  - 이 연산은 기존 희소 정책의 주의 계산에 \( H_t, z_t \)를 추가적으로 반영.

---

### 2. **추가 구현의 공수**
#### (1) 학습 단계
- **추가 공수**:
  - \( \phi, \psi \) 학습은 레이어별로 독립적으로 수행되므로 병렬화가 가능.
  - 학습 시 필요한 데이터:
    - LLM의 각 레이어에서 쿼리 \( q_t \), 키 \( k_t \), 값 \( v_t \), 그리고 삭제된 KV 쌍의 잔차를 사용.
    - 실험에서 LESS는 **512~1024 시퀀스 샘플**을 사용해 학습 (WikiText, CNN/DailyMail 등).
  - **시간 소모**: 각 레이어당 약 40 epoch (논문 기준).
    - 단일 GPU(A100) 기준 레이어당 학습 시간은 **수 시간** 정도.

#### (2) 추론 단계
- 추론 시에는 기존 주의 계산에 저차원 캐시 계산을 추가:
  - 기존 주의 계산 대비 \( \phi(q_t), \psi(k_t) \)의 추가 연산 필요.
  - \( H_t, z_t \) 업데이트와 \( \hat{a}_t \) 계산은 희소 정책과 병렬화 가능.

---

### 3. **추가 연산 및 컴퓨팅 자원 요구**
#### (1) 연산량 분석
**추가 연산량**은 저차원 임베딩 함수 \( \phi \), \( \psi \)와 관련됩니다. 
- 각 쿼리-키-값 \( (q_t, k_t, v_t) \)에 대해:
  - \( \phi, \psi \)의 연산: \( O(D \times R') + O(R' \times R) \), 여기서 \( D \)는 KV 벡터 차원.
  - 저차원 캐시 업데이트: \( O(R \times D) \).
  - 희소 정책에서 삭제된 \( K_t, V_t \) 수에 비례.

#### (2) 메모리 요구량
- **저차원 캐시 메모리**:
  - \( H_t \): \( R \times D \) 크기의 매트릭스.
  - \( z_t \): \( R \)-크기의 벡터.
  - 예: \( D = 512 \), \( R = 8 \)일 경우, 추가 메모리 비용은 약 \( 4 \times 8 \times 512 \) = 16 KB.

#### (3) 추론 속도 영향
- 논문 실험 기준, LESS는 H2O 대비 10~15% 느려짐:
  - 저차원 캐시 업데이트(잔차 반영)와 임베딩 계산의 추가 비용 때문.
- FULL Cache 대비 약 1.7배 높은 처리량을 유지하므로, 메모리와 속도의 균형이 적절.

---

### 4. **총체적 평가**
- **추가 구현 비용**:
  - **학습 비용**: 레이어별로 독립 학습이 가능하므로, 기존 전체 모델 재학습보다 훨씬 경제적.
  - **추론 비용**: 약간의 지연 시간 증가(10~15%)를 수반하지만, FULL Cache 대비 메모리 절약 효과가 큼.
- **컴퓨팅 자원**:
  - 학습 시 단일 GPU(A100)로 충분.
  - 추론 시 기존 희소 정책에 비해 메모리 사용량은 거의 동일, 추가 연산은 병렬화 가능.

LESS는 **성능-메모리-속도**의 균형을 유지하면서 기존 방법을 개선할 수 있는 실용적인 접근법으로 평가됩니다.

# Q : 이 논문의 입력데이터와 추론 과정에 대해서 예시를 들어 아주 자세하게 설명해 주겠니? 추가적으로 모델아키텍처의 구성 및 모델을 구성하는 연산과 메모리 요구량 컴퓨팅 요구량 대해서도 설명해줘



### 논문의 입력 데이터와 추론 과정

LESS는 대규모 언어 모델(LLM)의 **키-값(KV) 캐시**를 압축하고 효율적으로 사용하는 방법을 제안합니다. 이를 이해하기 위해 **입력 데이터**와 **추론 과정**을 단계별로 살펴보겠습니다.

---

### **1. 입력 데이터**
#### 입력 형태
- **쿼리 (\( q_t \))**: 현재 토큰의 임베딩 벡터, 크기 \( D \) (모델의 임베딩 차원, 예: 512).
- **키 (\( k_t \))**와 **값 (\( v_t \))**: 이전 시간 단계에서 계산된 KV 캐시 벡터, 크기 \( D \).
- **희소 정책 출력 (\( K_{C,t}, V_{C,t} \))**:
  - 유지된 KV 캐시 벡터(희소 정책으로 선택된 토큰만 포함).
  - 삭제된 KV 쌍 (\( D_t \)): 추가적인 정보를 저차원 캐시 \( H_t, z_t \)로 통합.

#### 예제 입력
- 쿼리 (\( q_t \)): \([1.0, 0.8, 0.7, \dots, 0.5]\) (크기 512).
- 현재 유지된 키 (\( K_{C,t} \)):
  \[
  [[0.5, 0.4, 0.3, \dots], [0.6, 0.7, 0.8, \dots], \dots]
  \] 
  (\( 80 \times 512 \) 희소 캐시)
- 현재 유지된 값 (\( V_{C,t} \)):
  \[
  [[0.3, 0.2, 0.4, \dots], [0.4, 0.6, 0.7, \dots], \dots]
  \] 
  (\( 80 \times 512 \) 희소 캐시)

---

### **2. 추론 과정**
LESS는 다음 단계를 거쳐 추론을 수행합니다.

#### (1) **쿼리, 키, 값 업데이트**
- 새로운 쿼리, 키, 값 계산:
  - 쿼리 \( q_t \): 입력 토큰에 대한 현재 주의 계산용 임베딩.
  - 키 \( k_t \): 현재 단계에서의 새로운 키 벡터.
  - 값 \( v_t \): 현재 단계에서의 새로운 값 벡터.

#### (2) **주의 계산**
LESS는 희소 캐시와 저차원 캐시를 결합하여 다음과 같이 주의 출력을 계산:
\[
\hat{a}_t = \frac{\phi(q_t) H_t + \exp\left(\frac{q_t K'_t}{\sqrt{D}}\right)V'_t}{\phi(q_t) z_t + \exp\left(\frac{q_t K'_t}{\sqrt{D}}\right)1_B}
\]
- \( H_t \): 이전에 삭제된 KV 캐시 정보의 저차원 상태.
- \( z_t \): 삭제된 키의 누적 정보.
- \( \phi, \psi \): 학습된 저차원 임베딩 함수.

##### 계산 과정 예제
1. **저차원 캐시 결합**:
   - \( \phi(q_t) \): \( \phi \) 함수로 쿼리를 저차원 임베딩 공간으로 변환.
   - \( \phi(q_t) H_t \): 이전 단계 저차원 상태와 결합.

2. **희소 정책 결합**:
   - \( \exp(\frac{q_t K'_t}{\sqrt{D}}) \): 기존 희소 캐시 \( K'_t \)와 계산.
   - \( V'_t \): 대응하는 값 \( V_{C,t} \)와 결합.

#### (3) **캐시 업데이트**
삭제된 KV 쌍(\( D_{t+1} \)) 정보를 저차원 캐시에 통합:
\[
H_{t+1} = H_t + \sum_{(k, v) \in D_{t+1}} \psi(k)^\top v
\]
\[
z_{t+1} = z_t + \sum_{(k, v) \in D_{t+1}} \psi(k)
\]

##### 예제 업데이트
- 삭제된 KV: \( D_{t+1} = \{k_1 = [0.2, 0.3], v_1 = [0.1, 0.2]\} \).
- 업데이트:
  \[
  H_{t+1} = [[0.2, 0.15]] + \psi([0.2, 0.3])^\top [0.1, 0.2]
  \]
  \[
  z_{t+1} = [0.25] + \psi([0.2, 0.3])
  \]

---

### 모델 아키텍처 구성 및 요구 사항

#### 1. **아키텍처 구성**
LESS는 다음 요소로 구성됩니다:
1. **희소 정책**:
   - H2O, Λ-masking 등 희소 정책으로 중요한 KV 캐시만 유지.
2. **저차원 임베딩**:
   - \( \phi(q_t), \psi(k_t) \): 3층 MLP (512 → 64 → 8 차원).
   - GELU 활성화 함수 사용.

---

#### 2. **연산 요구량**
##### (1) 기본 연산량
- 기존 Transformer의 주의 계산 복잡도:
  - \( O(B \times L \times D^2) \), \( B \): 배치 크기, \( L \): 시퀀스 길이, \( D \): 임베딩 크기.
- LESS 추가 연산량:
  - 저차원 계산: \( O(B \times R \times D) \), \( R \): 저차원 캐시 크기.
  - \( R \) 값이 작아 추가 연산량은 미미.

##### (2) 메모리 요구량
- **저차원 캐시**:
  - \( H_t \): \( R \times D \), 예: \( 8 \times 512 \) → 16 KB.
  - \( z_t \): \( R \), 예: 8 → 0.032 KB.
- **희소 캐시**:
  - H2O에서 5% 희소성을 사용할 경우, 전체 KV 캐시 대비 메모리 절약.

---

#### 3. **추론 속도 및 메모리 효율**
##### (1) 속도
- LESS는 FULL Cache 대비 추론 속도 약 **1.3배 빠름**.
- 희소 정책(H2O) 대비 약간 느림(10~15% 지연).

##### (2) 메모리 절약
- 전체 캐시(full cache) 대비 메모리 사용량 약 40% 절감.

---

### 결론
LESS는 효율적인 KV 캐시 관리를 위해 추가 연산을 도입하지만, 희소 정책과 저차원 캐시의 결합으로 메모리 사용량을 크게 줄이고 성능 손실을 최소화합니다. 추가 연산과 메모리 요구량이 작아 대규모 모델에서 실용적입니다.

# Q : 이 논문의 한계를 극복하기 위한 방법으로 어떤 연구흐름이 있는지 정리해서 자세하게 설명해 줘



### 논문의 한계와 이를 극복하기 위한 연구 흐름

LESS는 대규모 언어 모델(LLM)의 키-값(KV) 캐시 문제를 해결하기 위한 효율적인 방법을 제안했지만, 몇 가지 한계점이 존재합니다. 이를 극복하기 위한 연구 흐름과 방법론을 다음과 같이 정리할 수 있습니다.

---

### **1. LESS의 한계**

#### 1.1 **성능 격차**
- LESS는 삭제된 정보의 저차원 근사를 통해 성능을 회복하지만, 여전히 전체 캐시(full cache) 대비 성능 차이가 존재합니다.
- 특히 긴 시퀀스나 복잡한 태스크에서 정보 손실이 뚜렷하게 나타날 가능성이 큽니다.

#### 1.2 **희소 정책 의존성**
- LESS는 기존 희소 정책(H2O, Λ-masking 등)의 성능에 의존합니다. 희소 정책의 선택이 성능에 큰 영향을 미치며, 새로운 상황에 맞춰 희소 정책을 재설계해야 할 수도 있습니다.

#### 1.3 **저차원 근사의 한계**
- 잔차(residual)의 저차원 근사 성능은 잔차가 저차원 구조를 가질 때만 효과적입니다. 데이터에 따라 잔차가 고차원적인 특성을 가질 경우, LESS의 성능이 제한될 수 있습니다.

#### 1.4 **레이어별 독립 학습**
- 각 레이어를 독립적으로 학습하는 방식은 효율적이지만, 레이어 간 정보의 상호작용을 고려하지 않아 전체 최적화를 놓칠 가능성이 있습니다.

---

### **2. 한계를 극복하기 위한 연구 흐름**

LESS의 한계를 극복하기 위해 다음과 같은 연구 흐름이 주목받고 있습니다.

---

#### **2.1 KV 캐시 효율성 개선**
1. **적응형 희소 정책(Adaptive Sparse Policies)**:
   - 현재 희소 정책(H2O, Λ-masking)은 정적으로 KV 캐시를 관리합니다. 이를 개선하기 위해 **동적 희소 정책**이 필요합니다.
   - 예: 입력 컨텍스트의 특성과 태스크에 따라 중요도를 동적으로 계산해 필요한 KV 쌍만 유지.
   - 관련 연구:
     - DMC (Dynamic Memory Compression) [NŁC+24]: KV 쌍의 중요도를 동적으로 평가하여 캐시를 선택적으로 유지.
     - Scissorhands [LDL+23]: 입력과 태스크에 따라 캐시 크기를 적응적으로 조정.

2. **지능형 캐시 압축(Intelligent Compression)**:
   - KV 캐시를 단순히 트리밍하는 대신, 압축된 표현(예: 양자화, Huffman 코딩)을 사용해 캐시 메모리를 줄이는 연구.
   - 관련 연구:
     - CacheGen [LLD+23]: 비트 레벨에서 캐시를 압축.
     - Linear Transformers [CLD+20]: 캐시를 순환 신경망(RNN)의 상태처럼 압축.

---

#### **2.2 잔차 근사의 고도화**
1. **멀티모달 잔차 학습**:
   - 단순히 저차원 근사를 학습하는 대신, 잔차를 다양한 표현(예: 주파수 도메인, 비선형 맵핑)에서 근사.
   - 예: Wavelet 변환, Fourier 변환 기반 근사.

2. **하이브리드 근사(Hybrid Approximation)**:
   - 저차원 캐시와 고차원 캐시를 결합해 잔차를 더 잘 보완.
   - 고차원 캐시를 사용해 주요 잔차를 복구하고, 저차원 캐시를 반복적으로 최적화.

---

#### **2.3 모델 구조 최적화**
1. **레이어 간 상호작용 강화**:
   - LESS는 레이어별로 독립 학습을 수행하지만, 레이어 간 정보의 흐름을 학습하지 않습니다. 이를 개선하기 위해 레이어 간 정보를 고려하는 통합 학습 접근법이 필요합니다.
   - 예: Transformer 레이어를 공유 파라미터로 학습하거나, 계층적 저차원 캐시를 도입.

2. **RNN-like 구조 통합**:
   - Transformer 모델에 순환 신경망(RNN)의 상태 저장 방식을 통합하여 캐시를 고정된 크기로 유지.
   - 관련 연구:
     - Retentive Network [SDH+23]: Transformer의 주의 메커니즘을 RNN 스타일로 변환.
     - RWKV [PAA+23]: Transformer와 RNN의 특성을 결합해 캐시 효율성 개선.

---

#### **2.4 긴 시퀀스 처리 개선**
1. **단기 및 장기 의존성 분리**:
   - 긴 시퀀스에서 단기와 장기 의존성을 분리해, 장기 의존성은 저차원 캐시로 요약하고 단기 의존성만 상세히 유지.
   - 관련 연구:
     - Compressive Transformer [RPJ+19]: 장기 의존성을 압축해 저장.

2. **확장 가능한 컨텍스트**:
   - 현재 LESS는 고정된 저차원 크기를 사용하지만, 시퀀스 길이에 따라 크기를 조정하는 동적 방법이 필요.
   - 예: 입력 길이에 따라 저차원 캐시의 크기를 점진적으로 늘리는 구조.

---

#### **2.5 학습 효율성 개선**
1. **엔드-투-엔드 학습**:
   - 현재 레이어별 독립 학습 방식을 엔드-투-엔드 학습으로 확장해 전체 최적화를 달성.
   - 엔드-투-엔드 학습은 더 나은 잔차 근사와 희소 정책 조정을 동시에 수행 가능.

2. **프롬프트 학습 및 지식 증류**:
   - LESS를 학습하지 않고, 프롬프트 학습이나 지식 증류를 사용해 저차원 캐시를 간접적으로 조정.
   - 관련 연구:
     - LoRA (Low-Rank Adaptation) [LYZ+23]: 파라미터 효율적인 학습으로 캐시 최적화.

---

### **3. 정리**

LESS는 희소 정책과 저차원 근사의 결합으로 메모리 효율성과 성능을 모두 개선한 혁신적인 접근법입니다. 그러나 여전히 긴 시퀀스, 희소 정책 의존성, 저차원 근사의 한계 등 여러 문제를 가지고 있습니다.

이를 해결하기 위해:
1. **동적 희소 정책**과 **지능형 캐시 압축**을 통해 KV 캐시의 효율성을 극대화.
2. **잔차 학습 강화**와 **하이브리드 근사**로 성능 격차를 줄임.
3. **RNN-like 구조**와 **엔드-투-엔드 학습**으로 모델 구조를 개선.
4. **긴 시퀀스 처리 최적화**로 확장 가능성을 보장.

이러한 연구 흐름은 LESS를 기반으로 더 강력하고 범용적인 캐시 압축 방법론 개발을 가능하게 할 것입니다.
