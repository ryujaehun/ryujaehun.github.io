---
categories:
- paper-review
- with-gpt
date: "2024-11-06T00:00:00Z"
tags: null
title: CDMPP:ADevice-Model Agnostic Framework for Latency Prediction of Tensor Programs
---


논문 : https://i.cs.hku.hk/~cwu/papers/hphu-eurosys24.pdf


아래글은 Scholar GPT와 대화를 나눈 내용입니다.

# Q : 논문의 핵심 내용과 강점, 알고리즘 설명, 그리고 한계점

 

### 논문의 강점 및 독창성

1. **장치 및 모델 독립적 지연 예측**: 이 논문은 다양한 장치와 DNN 모델에 대해 지연 시간을 예측할 수 있는 **CDMPP (Cross-Device and Cross-Model Performance Prediction)** 프레임워크를 제안합니다. 기존 방법들이 특정 장치나 모델에 대한 성능 예측에 국한된 반면, CDMPP는 다양한 DNN 모델과 장치에서 작동하도록 설계된 점에서 독창적입니다.

2. **Compact AST 및 순서 기반 위치 인코딩**: CDMPP는 텐서 프로그램의 내부 구조를 효과적으로 캡처하는 **Compact Abstract Syntax Trees (ASTs)**와 **순서 기반 위치 인코딩**을 도입하여 효율적인 학습을 가능하게 합니다. 이를 통해 모델은 다중 장치와 모델에서 성능을 예측하는 데 필요한 데이터 표현을 보다 간결하게 학습할 수 있습니다.

3. **도메인 불변 표현 학습**: CDMPP는 도메인 간 차이를 최소화하기 위해 도메인 불변 표현(domain-invariant representations)을 학습하는데, 이를 통해 다양한 DNN 모델과 장치 간 분포 이동을 극복하고 일반화 성능을 향상시킵니다. 이를 위한 **CMD 기반 정규화 항**을 추가하여, 다수의 장치와 모델에 걸쳐 효율적인 예측을 가능하게 합니다.

### 핵심 알고리즘 및 예시 설명

CDMPP의 핵심 알고리즘은 텐서 프로그램을 표현하는 Compact AST를 사용하여 장치 및 모델 불변 표현을 학습하고, 이를 통해 지연 시간을 예측하는 것입니다.

#### 예시: BERT 모델을 A100 GPU와 T4 GPU에서 실행할 때 지연 시간 예측

1. **Compact AST 생성**: BERT 모델의 특정 텐서 프로그램(예: Convolution 연산)을 Compact AST로 표현합니다. 각 AST는 연산 및 메모리 접근 패턴, 루프 정보 등을 포함하여 단순화된 형태로 변환됩니다. 예를 들어, AST는 루프와 계산 노드를 포함하며, Compact AST는 이러한 정보를 일정한 구조로 표현해줍니다.

2. **순서 기반 위치 인코딩 적용**: Compact AST의 각 노드 위치는 순서 기반 위치 인코딩을 통해 고유한 벡터로 변환됩니다. 이를 통해 모델은 AST 구조 내에서 각 연산의 상대적 위치 정보를 학습하게 됩니다.

3. **장치 독립적 및 장치 종속적 특징 결합**: Compact AST에서 추출된 장치 독립적 특징과 장치 관련 정보(예: GPU 클럭 속도, 메모리 대역폭)를 결합하여 텐서 프로그램의 성능 예측에 필요한 전체 입력을 구성합니다.

4. **도메인 불변 학습 및 지연 시간 예측**: CDMPP는 학습 중 CMD 기반 정규화를 통해 BERT와 같은 모델이 T4 GPU에서 실행될 때의 지연 시간과 A100 GPU에서의 지연 시간 간 차이를 최소화하도록 훈련됩니다. 이 과정을 통해 학습된 모델은 새로운 장치나 DNN 모델에서도 높은 정확도로 지연 시간을 예측할 수 있습니다.

### 한계점

1. **다양한 텐서 프로그램의 일반화 한계**: CDMPP는 다양한 텐서 프로그램을 일반화하도록 설계되었지만, 특정 연산자나 DNN 모델에서 생소한 연산의 성능을 예측하는 데는 한계가 있을 수 있습니다.

2. **프로파일링 비용**: CDMPP는 목표 장치에 대해 대표적인 샘플을 선택해 학습하지만, 새로운 장치에 대한 프로파일링 비용이 완전히 해결된 것은 아닙니다.

3. **상대적 성능 예측과의 호환성 문제**: CDMPP는 절대적인 지연 시간 예측에 중점을 두고 있어 상대적 성능 비교가 중요한 응용 분야에서는 추가적인 조정이 필요할 수 있습니다.

CDMPP는 다양한 장치와 모델에서 지연 시간을 효과적으로 예측하는 점에서 혁신적이며, DNN 성능 최적화 및 장치 선택에 중요한 기여를 할 수 있는 프레임워크입니다【41†source】.


# Q : Compact AST는 어떤 형태를 띄고 있는지 예시를 들어줄 수 있을까? 그리고 AST에 독립적 특징과 장치 관련 정보가 결합이 되더라도 해당 모델의 프로그래밍 모델과 구조적인 특성이 반영되지 않으면 GPU/DSP/CPU와 같은 각기 다른 모델에 대한 성능을 예측하기힘들것 같은데 어떻게 생각하니?

 

Compact AST는 기존의 AST(Abstract Syntax Tree) 구조에서 **불필요한 노드를 제거하고 계산 관련 노드와 메모리 접근 정보를 유지**하는 방식으로 간소화된 형태입니다. Compact AST는 일반적인 AST와 달리 **루프와 계산 표현 정보만 포함**하여 보다 간결하게 텐서 프로그램의 구조를 캡처하며, 주로 루프 정보(루프 횟수, 벡터화, 병렬화 여부 등)와 계산 유형, 메모리 접근 패턴이 반영됩니다.

### Compact AST의 예시

예를 들어, CNN 모델의 **Convolution 연산**이 있다고 가정하겠습니다. 이 연산을 일반적인 AST와 Compact AST로 표현하면 다음과 같습니다:

#### 일반적인 AST 예시 (Convolution 연산)
```
root
├── Loop(n)
│   ├── Loop(o)
│   │   ├── Loop(h)
│   │   │   ├── Loop(w)
│   │   │   │   └── Computation: Conv[n, o, h, w]
│   │   │   └── Memory Access: Inp[n, i, h, w], Weight[o, i, r, c]
```

#### Compact AST 예시 (간소화된 형태)
Compact AST는 루프와 계산 노드를 유지하며, 각 노드는 계산 연산과 메모리 접근 정보를 요약하여 표현합니다.
```
Compact AST
├── Loop(n)
│   ├── Loop(o)
│   │   ├── Loop(h)
│   │   │   ├── Loop(w)
│   │   │   └── Computation Vector: [Conv, Inp, Weight]
│   └── Loop Information: {vectorized, unrolled, parallelized}
```

위와 같이 Compact AST는 전체 구조를 요약하여 각 계산 노드에 대한 정보와 루프 특성을 유지하며, 불필요한 비계산 노드를 제외해 가벼운 구조를 갖추고 있습니다.

### Compact AST의 한계와 해결 방안

Compact AST와 장치 종속적 특징이 결합되더라도, **각기 다른 프로세싱 아키텍처(GPU, DSP, CPU 등)의 구조적 특성**이 반영되지 않으면 성능 예측이 제한될 수 있습니다. 예를 들어 GPU는 병렬 연산에 최적화된 반면, CPU는 순차적 처리가 더 효율적일 수 있으며, DSP는 특정 연산에 특화되어 있을 수 있습니다.

CDMPP는 이러한 문제를 다음과 같은 방법으로 해결하고 있습니다:

1. **장치 종속적 특징 추가**: Compact AST는 장치 독립적인 텐서 프로그램 구조만을 반영하기 때문에, CDMPP는 **클럭 속도, 메모리 대역폭, FLOPS, 캐시 크기 등 각 장치의 특징**을 추가로 결합하여 장치 간 차이를 학습하도록 합니다. 이러한 장치 관련 정보를 Compact AST와 결합하여, 장치에 따라 변동될 수 있는 성능을 보다 정확히 반영하려고 합니다.

2. **도메인 불변 표현 학습**: CDMPP는 다양한 DNN 모델과 장치에서 성능 예측이 가능하도록 **CMD 기반 정규화**를 통해 장치별 차이를 학습하여 도메인 간 분포 차이를 줄입니다. 즉, 장치와 모델에 독립적인 공통 표현을 학습하여 성능 예측에서 일반화 성능을 높이는 것입니다.

3. **장치별 학습 샘플링 및 미세 조정(Fine-tuning)**: 새로운 장치에 대해 성능 예측 정확도를 높이기 위해, CDMPP는 특정 장치에 대한 **대표 샘플을 사용하여 미세 조정**을 수행합니다. 이를 통해 특정 장치에 최적화된 성능을 보장하면서도 새로운 아키텍처에 대한 확장성을 제공합니다.

결론적으로, Compact AST와 장치 관련 정보의 결합으로 인해 CDMPP는 다양한 장치의 구조적 특성을 반영할 수 있으며, 장치별 학습을 통해 추가적인 조정이 가능합니다.