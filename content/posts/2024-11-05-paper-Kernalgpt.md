---
categories:
- paper-review
- with-gpt
date: "2024-11-05T00:00:00Z"
tags: null
title: KernelGPT Enhanced Kernel Fuzzing via Large Language Models
---


논문 : https://arxiv.org/abs/2401.00563


아래글은 Scholar GPT와 대화를 나눈 내용입니다.

# Q : 논문의 핵심 내용과 강점, 알고리즘 설명, 그리고 한계점

# Answer

**KernelGPT** 논문은 운영체제 커널에서의 결함 탐지를 위해 **대형 언어 모델(LLM)**을 활용한 자동화된 시스템 호출(specification) 생성 방법을 제안합니다. 기존의 커널 퍼징 도구 Syzkaller의 제약을 해결하기 위해 LLM을 활용하여 Syzkaller가 필요로 하는 system call의 사양을 자동으로 생성, 검증, 수정하는 방식을 도입했습니다. 이를 통해 기존의 수작업 기반 방식보다 더 높은 커버리지와 효율적인 퍼징을 달성할 수 있습니다.

### 논문의 강점과 독창적인 지점

1. **LLM을 통한 자동화된 사양 생성**:
   - 기존에는 Syzkaller와 같은 퍼징 도구에 필요한 system call 사양을 수작업으로 작성해야 했으며, 이는 많은 시간과 전문 지식을 요구했습니다. KernelGPT는 LLM을 활용해 커널 코드로부터 자동으로 system call 사양을 생성함으로써 이러한 수작업 과정을 크게 줄였습니다.

2. **반복적 학습 및 수정 기법**:
   - KernelGPT는 사양을 자동으로 생성한 후, Syzkaller를 통해 퍼징을 실행하면서 발생하는 오류를 LLM으로 재분석하여 사양을 수정합니다. 이 반복적 접근법을 통해 높은 정확도의 사양을 생성하고, 새로운 버그를 탐지할 수 있습니다.

3. **기존 기술과의 차별성**:
   - 기존 퍼징 연구는 주로 정적 분석이나 심볼릭 실행을 통해 시스템 호출 사양을 추론했으나, KernelGPT는 LLM을 사용하여 사양 생성 및 수정의 자동화를 가능하게 합니다. 특히, Syzkaller와의 통합을 통해 LLM의 사양 생성 기능을 퍼징 프레임워크에 적용한 첫 사례입니다【43†source】.

### 핵심 알고리즘과 예시

KernelGPT의 접근 방식은 **드라이버 탐지 → 사양 생성 → 사양 검증 및 수정**의 3단계로 구성됩니다.

1. **드라이버 탐지**:
   - 커널 코드에서 장치 드라이버의 operation 핸들러 위치를 LLM이 추론하여, 장치 이름과 초기화 사양을 추출합니다. 예를 들어, `dm_ctl_ioctl`과 같은 ioctl 핸들러를 찾아 해당 장치 이름을 확인합니다.

2. **사양 생성**:
   - LLM을 사용하여 system call 사양을 생성합니다. 예를 들어, 커널 코드에서 `dm_ctl_ioctl` 핸들러의 명령어와 매개변수 타입을 추론하고, LLM이 이를 Syzkaller가 인식할 수 있는 형태로 변환합니다. 필요한 경우, LLM이 누락된 정보를 "UNKNOWN"으로 표시하고, KernelGPT가 이를 수집해 반복적으로 분석합니다.

3. **사양 검증 및 수정**:
   - Syzkaller와의 통합을 통해 사양을 검증하고, 오류 메시지를 LLM으로 전송하여 수정을 제안받습니다. 예를 들어, `vfio_pci_hot_reset_info`에서 배열 길이 지정 오류가 발생하면, Syzkaller가 이를 감지하고 LLM을 통해 올바른 형식으로 수정합니다.

### 한계점

1. **LLM의 한계**:
   - 커널 코드가 너무 길거나 복잡할 경우, LLM의 문맥 길이 한계로 인해 코드 분석 정확도가 낮아질 수 있습니다. 이로 인해 일부 사양을 정확하게 생성하지 못할 수 있습니다.

2. **복잡한 초기화 단계**:
   - 특정 장치 드라이버는 복잡한 초기화 과정을 필요로 하는데, LLM이 이를 정확하게 추론하지 못하면 사양 생성의 정확도가 떨어질 수 있습니다.

3. **LLM에 대한 높은 의존도**:
   - 사양 생성 및 수정을 모두 LLM에 의존하므로, 모델의 성능에 따라 결과가 좌우됩니다. LLM의 개선 없이 사양의 품질을 계속 유지하거나 향상하기 어려울 수 있습니다【43†source】.

KernelGPT는 Syzkaller 퍼징의 커버리지를 높이고, 자동화된 사양 생성의 가능성을 열었으며, 향후 LLM을 활용한 다양한 커널 퍼징 연구로 확장 가능성이 높습니다.


# Q : LLM을 통한 접근 방법이 LLM에 많은것을 의존하는것 같은데 예를 들어 이 논문에서 얻은 인사이트를 가지고 deep learning compiler TVM의 IR인 TIR에 대하여 fuzzing을 진행한다고 할때 어떤 insight를 얻을 수 있을까?

 

이 논문에서 제안하는 **LLM 기반의 자동화된 사양 생성과 검증 방법**을 TVM의 중간 표현(Intermediate Representation, IR)인 TIR에 대한 퍼징에 적용하면, 다음과 같은 인사이트를 얻을 수 있습니다.

### 1. **자동화된 TIR 사양 생성**

   - KernelGPT가 Syzkaller에 필요한 system call 사양을 LLM을 통해 자동 생성한 것처럼, **TIR에 대한 사양**도 LLM을 통해 생성할 수 있습니다. TVM에서 TIR은 저수준에서의 최적화가 많이 적용되며, **복잡한 연산 구조와 메모리 접근 패턴**을 포함하기 때문에 정확한 사양 작성이 어려울 수 있습니다.
   - LLM을 활용하면 TIR 내의 **연산 패턴, 메모리 접근, 데이터 배치** 등의 특징을 추출하여, 퍼징에 필요한 사양을 자동으로 생성하고, 이를 통해 다양한 코드 조합을 자동으로 테스트할 수 있습니다. 예를 들어, TIR의 `for` 루프, `if` 조건문, 메모리 로드 및 저장 연산 등의 구조적 패턴을 사양으로 정의하는 데 도움을 줄 수 있습니다.

### 2. **LLM을 통한 반복적 학습과 TIR 사양 개선**

   - KernelGPT가 Syzkaller와의 상호작용을 통해 system call 사양을 지속적으로 개선한 것처럼, TIR 퍼징에서도 **LLM을 통해 검증 및 수정 작업을 반복**하며 사양을 개선할 수 있습니다.
   - TIR의 복잡한 연산으로 인해 퍼징 과정에서 발생하는 오류를 감지하고, LLM이 이를 분석해 TIR 사양을 수정 및 보완할 수 있습니다. 예를 들어, TIR에서 불완전하게 정의된 연산이나 메모리 접근 오류가 발생하면, LLM이 이러한 오류를 학습하고 보완된 사양을 생성하여, **보다 정확한 사양을 기반으로 퍼징**할 수 있습니다.

### 3. **TIR의 특성에 맞춘 동적 퍼징 전략 수립**

   - TIR은 특정 하드웨어 아키텍처에 맞춰 최적화된 코드 생성을 목표로 하므로, 다양한 하드웨어 상의 **IR 코드 실행을 통한 최적화 테스트**가 중요합니다. KernelGPT의 LLM 접근 방식을 통해 TIR의 **특정 하드웨어 특성**에 맞춘 테스트 케이스를 자동 생성하고, 이를 통해 다양한 아키텍처에서 발생할 수 있는 오류를 탐지할 수 있습니다.
   - 예를 들어, 특정 하드웨어에서 발생할 수 있는 메모리 오버플로우, 정렬 미스매치와 같은 이슈를 사전에 TIR의 사양에 반영하여 퍼징할 수 있습니다.

### 4. **고품질 TIR 코드 생성과 LLM 기반 사양 검증**

   - KernelGPT가 사양의 질을 높이기 위해 LLM을 통한 사양 검증을 진행한 것처럼, TIR 퍼징에서도 **LLM을 사용해 생성된 TIR 코드의 품질을 검증**할 수 있습니다. 퍼징 중 발견된 오류를 기반으로 LLM이 반복적으로 코드를 수정하고 재학습하여, TVM이 최적의 성능을 낼 수 있도록 돕는 고품질 TIR 사양을 도출할 수 있습니다.
   - 이와 같은 접근 방식은 TVM의 컴파일러 최적화 수준을 높이는 데 도움이 될 뿐 아니라, **컴파일러 안정성 향상**에도 기여할 수 있습니다.

### 5. **편향 문제와 다양성 증진**

   - KernelGPT의 OSS-INSTRUCT는 데이터 편향을 줄이고 현실성을 높이기 위해 다양한 코드 패턴을 학습하도록 설계되었습니다. 마찬가지로, TIR 퍼징에서도 특정 연산 패턴에 치우치지 않고 **다양한 코드 구조와 연산 방식을 테스트**하는 것이 중요합니다.
   - 이를 위해 LLM이 TIR의 다양한 연산과 최적화 패턴을 학습하도록 하고, 실제 배포 환경에서 발생할 수 있는 다양한 TIR 코드를 자동으로 생성하여 편향된 데이터 학습을 방지할 수 있습니다.

### 요약

KernelGPT의 LLM 기반 사양 생성 및 수정 접근 방식은 TIR 퍼징에 다음과 같은 인사이트를 제공할 수 있습니다:
- **자동화된 TIR 사양 생성**을 통해 수작업을 줄이고, **LLM을 통한 반복적 학습 및 수정**으로 TIR 사양을 지속적으로 개선할 수 있습니다.
- 다양한 하드웨어에 맞춘 동적 퍼징과, 고품질 코드 생성을 통해 TVM의 컴파일러 최적화와 안정성을 향상시킬 수 있습니다.
- 데이터 편향을 줄이고 다양성을 증진하여, 실제 사용 환경에 맞는 TIR 퍼징 테스트를 수행할 수 있습니다.

이러한 접근 방식을 통해 LLM 기반의 TIR 퍼징은 TVM 컴파일러의 최적화 품질을 높이고, 새로운 아키텍처에 대한 호환성 검증을 자동화할 수 있는 강력한 도구가 될 것입니다.