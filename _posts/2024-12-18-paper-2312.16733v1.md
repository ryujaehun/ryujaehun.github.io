---
title: "SuperServe: Fine-Grained Inference Serving for Unpredictable Workloads"
date: 2024-12-18
categories:
 - paper-review
 - with-gpt
---

{% capture time %}{{ content | reading_time }}{% endcapture %}
   <p>이 포스트를 읽는데 약 {{ time }} {% if time == '1' %}분{% else %}분{% endif %} 이 소요될 수 있습니다.</p>

[논문 링크](https://arxiv.org/abs/2312.16733v1)

# Q : 이 논문을 아주 자세하게 읽고 논문의 강점과 독창적인 지점을 설명해주고 핵심 알고리즘을 예시 입력을 들어서 전체적인 과정을 설명해줘 추가적으로 논문의 한계점에 대해서도 알려줘



### 논문 요약 및 분석

---

#### **논문의 강점**
1. **문제 정의의 명확성**: 예측 불가능하고 폭발적인 워크로드 하에서 ML 추론 시스템이 지연(SLO)을 만족하면서 높은 정확도를 유지해야 하는 문제를 효과적으로 다룸.
2. **독창적인 접근 방식 - SubNetAct**:
   - **SubNetAct**는 SuperNet을 활용하여 메모리 효율성과 지연 최소화를 동시에 달성.
   - SuperNet 내에서 **LayerSelect**, **SubnetNorm**, **WeightSlice** 연산자를 사용해 모델 스위칭 대신 즉각적인 서브넷 활성화 구현.
3. **유연성과 실용성**:
   - SlackFit이라는 스케줄링 정책을 제안하여 서비스 로드에 맞춰 실시간으로 정확도와 지연 간의 균형을 조정.
   - 다양한 실제 데이터셋(Microsoft Azure Functions) 및 합성 데이터로 실험을 통해 성능 검증.
4. **실질적인 성과**:
   - 경쟁 시스템 대비 4.67% 높은 정확도를 유지하며 동일한 SLO 달성률을 제공.
   - 같은 정확도에서 2.85배 더 높은 SLO 달성률 달성.

---

#### **핵심 알고리즘: SubNetAct와 SlackFit**

**SubNetAct의 주요 작동 과정**:
- **입력 예시**:
  - 요청: 이미지 분류, SLO = 30ms.
  - 서브넷 후보: 정확도 73%-80%, 추론 시간 10-50ms.
- **과정**:
  1. **LayerSelect**: 요청의 SLO에 맞춰 서브넷의 깊이를 동적으로 선택. 예: 깊이=3 레이어.
  2. **SubnetNorm**: 각 서브넷의 정규화 통계를 별도로 관리하여 정확도 저하 방지.
  3. **WeightSlice**: 필요한 채널만 선택하여 메모리와 계산량 감소.

**SlackFit 스케줄링 정책**:
- **작동 방식**:
  1. 요청의 남은 시간(slack)을 계산.
  2. SLO를 만족하면서 가장 높은 정확도를 제공하는 서브넷과 배치 크기를 선택.
  3. 높은 부하 시 더 작은 정확도의 모델과 큰 배치를 선택해 처리량 증가.
- **결과**: 정확도와 처리량의 동적 균형 유지.

---

#### **한계점**
1. **제약된 실험 환경**:
   - 실험은 RTX 2080Ti GPU에서 수행되어 최신 하드웨어에서의 일반화가 불확실.
   - 더 다양한 실제 시나리오에서 검증 필요.
2. **SuperNet 학습 비용**:
   - SuperNet 학습 과정이 일반적으로 비용이 많이 들고, 특정 작업에만 최적화 가능.
3. **정책의 일반화**:
   - SlackFit이 모든 워크로드에서 최적의 선택을 보장하지 않으며, 급격히 변화하는 트래픽에서는 한계가 있을 수 있음.

---

#### **결론**

이 논문은 ML 추론 시스템의 지연 및 정확도 트레이드오프를 동적으로 해결하는 데 있어 중요한 기여를 했습니다. SubNetAct와 SlackFit의 조합은 성능 최적화와 유연성을 제공하지만, 실험 환경과 학습 비용에서 현실적인 제약이 있습니다. 이를 보완하기 위해 다양한 하드웨어와 시나리오에서 추가적인 검증이 필요합니다.

# Q : 논문의 핵심알고리즘을 예시를 들어 아주 자세하게 설명해주고 정리해 줘



### 핵심 알고리즘: SubNetAct와 SlackFit

---

### **SubNetAct: 즉각적인 모델 활성화 기법**

SubNetAct는 SuperNet 기반의 서브넷을 즉각적으로 활성화하여 메모리 사용을 최적화하고 지연(Latency)을 줄이는 혁신적인 기법입니다. 이 알고리즘은 아래와 같은 세 가지 주요 연산자를 활용합니다: **LayerSelect**, **SubnetNorm**, **WeightSlice**.

#### **예시 상황**
- 입력: 이미지 분류 요청
- 서비스 레벨 목표(SLO): 30ms
- SuperNet에 포함된 서브넷들:
  - 서브넷 1: 정확도 73%, 추론 시간 10ms
  - 서브넷 2: 정확도 76%, 추론 시간 20ms
  - 서브넷 3: 정확도 80%, 추론 시간 50ms

#### **1. LayerSelect 연산자**
- **역할**: 요청의 SLO에 따라 서브넷의 깊이를 동적으로 결정.
- **작동 방식**:
  1. 요청이 30ms의 SLO를 요구한다고 가정.
  2. SuperNet의 서브넷 후보들 중 추론 시간이 30ms 이하인 서브넷 1과 서브넷 2가 후보로 선택됨.
  3. LayerSelect 연산자는 서브넷의 레이어를 활성화하거나 비활성화하여 최적의 레이어 깊이를 설정.
- **결과**: 서브넷 2(정확도 76%)가 선택됨.

#### **2. SubnetNorm 연산자**
- **역할**: 서브넷의 활성화된 레이어에 적합한 정규화 통계를 제공하여 정확도를 보장.
- **작동 방식**:
  1. 서브넷 2를 활성화한 후 Batch Normalization 레이어가 적절한 평균(mean)과 분산(variance) 값을 필요로 함.
  2. SubnetNorm은 SuperNet 학습 과정에서 미리 계산된 서브넷별 통계 데이터를 로드하여 적용.
- **결과**: 정규화 오류 없이 서브넷 2의 정확도 76% 유지.

#### **3. WeightSlice 연산자**
- **역할**: 추론 시 서브넷의 레이어에서 필요한 채널만 선택하여 메모리와 계산 비용 감소.
- **작동 방식**:
  1. 서브넷 2의 레이어 중 Expand Ratio(레이어 확장 비율)가 0.5로 설정.
  2. WeightSlice는 레이어의 입력/출력 채널에서 절반만 활성화.
  3. 활성화된 가중치만 사용해 계산을 수행.
- **결과**: 메모리 사용량 감소와 더불어 20ms 내에 서브넷 2의 추론 완료.

---

### **SlackFit: 온라인 스케줄링 정책**

SlackFit은 SubNetAct를 활용하여 요청의 남은 시간(slack)에 기반한 효율적인 서브넷과 배치 크기 조합을 선택하는 정책입니다.

#### **예시 상황**
- 요청 도착 시간: `t=0`
- 요청의 SLO: `30ms`
- 현재 대기열:
  - 요청 1: 남은 slack = 25ms
  - 요청 2: 남은 slack = 10ms
  - 요청 3: 남은 slack = 5ms

#### **작동 과정**
1. **Slack 계산**:
   - 각 요청의 남은 slack을 계산: `SLO - (현재 시간 - 도착 시간)`.

2. **서브넷 선택**:
   - SlackFit은 남은 slack이 가장 적은 요청(여기서는 요청 3)을 기준으로 최적의 서브넷을 선택.
   - 요청 3의 남은 slack = 5ms, 따라서 서브넷 1(추론 시간 10ms)은 제외되고, 서브넷 2(추론 시간 20ms)가 선택.

3. **배치 크기 결정**:
   - 서브넷 2로 처리 가능한 최대 배치를 계산.
   - 요청 1, 요청 2, 요청 3을 함께 처리하는 배치 크기 = 3로 설정.

4. **결과**:
   - SlackFit은 서브넷 2와 배치 크기 3을 선택하여 모든 요청을 30ms 내에 처리.

---

### **SubNetAct와 SlackFit의 결합 동작**

#### **요청 흐름 예시**
1. 클라이언트가 다수의 요청(예: 이미지 분류 요청)을 전송.
2. **SlackFit 스케줄러**는 요청의 slack에 따라 서브넷과 배치를 선택.
3. **SubNetAct**는 선택된 서브넷을 활성화하고 최적의 채널과 레이어만 계산에 사용.
4. 추론 결과는 클라이언트로 반환.

#### **결과 요약**
- 지연(SLO): 모든 요청은 SLO 30ms 내에 처리됨.
- 정확도: 요청의 조건에 맞춰 76% 정확도로 추론 수행.
- 자원 사용 효율성: 메모리와 계산량을 최소화.

---

### 정리
- **SubNetAct**는 메모리 효율적이고 즉각적인 모델 활성화를 통해 지연 시간을 줄이고 시스템의 유연성을 극대화.
- **SlackFit**은 요청의 slack을 활용해 정확도와 처리량의 균형을 실시간으로 조정.
- 두 알고리즘은 결합하여 폭발적인 워크로드와 예측 불가능한 요청 패턴에서도 높은 성능을 보장함.




# Q : 이 논문에서 제시한 결과를 자세하게 보고 다른 방법론에 비하여 특출난 점과 논문에서 제기하는 어떠한 방법이 이러한 결과를 도출하게 되었는지 논문에서 제시하는 이유와 너의 생각을 알려줘



### 핵심 알고리즘: SubNetAct와 SlackFit

---

### **SubNetAct: 즉각적인 모델 활성화 기법**

SubNetAct는 SuperNet 기반의 서브넷을 즉각적으로 활성화하여 메모리 사용을 최적화하고 지연(Latency)을 줄이는 혁신적인 기법입니다. 이 알고리즘은 아래와 같은 세 가지 주요 연산자를 활용합니다: **LayerSelect**, **SubnetNorm**, **WeightSlice**.

#### **예시 상황**
- 입력: 이미지 분류 요청
- 서비스 레벨 목표(SLO): 30ms
- SuperNet에 포함된 서브넷들:
  - 서브넷 1: 정확도 73%, 추론 시간 10ms
  - 서브넷 2: 정확도 76%, 추론 시간 20ms
  - 서브넷 3: 정확도 80%, 추론 시간 50ms

#### **1. LayerSelect 연산자**
- **역할**: 요청의 SLO에 따라 서브넷의 깊이를 동적으로 결정.
- **작동 방식**:
  1. 요청이 30ms의 SLO를 요구한다고 가정.
  2. SuperNet의 서브넷 후보들 중 추론 시간이 30ms 이하인 서브넷 1과 서브넷 2가 후보로 선택됨.
  3. LayerSelect 연산자는 서브넷의 레이어를 활성화하거나 비활성화하여 최적의 레이어 깊이를 설정.
- **결과**: 서브넷 2(정확도 76%)가 선택됨.

#### **2. SubnetNorm 연산자**
- **역할**: 서브넷의 활성화된 레이어에 적합한 정규화 통계를 제공하여 정확도를 보장.
- **작동 방식**:
  1. 서브넷 2를 활성화한 후 Batch Normalization 레이어가 적절한 평균(mean)과 분산(variance) 값을 필요로 함.
  2. SubnetNorm은 SuperNet 학습 과정에서 미리 계산된 서브넷별 통계 데이터를 로드하여 적용.
- **결과**: 정규화 오류 없이 서브넷 2의 정확도 76% 유지.

#### **3. WeightSlice 연산자**
- **역할**: 추론 시 서브넷의 레이어에서 필요한 채널만 선택하여 메모리와 계산 비용 감소.
- **작동 방식**:
  1. 서브넷 2의 레이어 중 Expand Ratio(레이어 확장 비율)가 0.5로 설정.
  2. WeightSlice는 레이어의 입력/출력 채널에서 절반만 활성화.
  3. 활성화된 가중치만 사용해 계산을 수행.
- **결과**: 메모리 사용량 감소와 더불어 20ms 내에 서브넷 2의 추론 완료.

---

### **SlackFit: 온라인 스케줄링 정책**

SlackFit은 SubNetAct를 활용하여 요청의 남은 시간(slack)에 기반한 효율적인 서브넷과 배치 크기 조합을 선택하는 정책입니다.

#### **예시 상황**
- 요청 도착 시간: `t=0`
- 요청의 SLO: `30ms`
- 현재 대기열:
  - 요청 1: 남은 slack = 25ms
  - 요청 2: 남은 slack = 10ms
  - 요청 3: 남은 slack = 5ms

#### **작동 과정**
1. **Slack 계산**:
   - 각 요청의 남은 slack을 계산: `SLO - (현재 시간 - 도착 시간)`.

2. **서브넷 선택**:
   - SlackFit은 남은 slack이 가장 적은 요청(여기서는 요청 3)을 기준으로 최적의 서브넷을 선택.
   - 요청 3의 남은 slack = 5ms, 따라서 서브넷 1(추론 시간 10ms)은 제외되고, 서브넷 2(추론 시간 20ms)가 선택.

3. **배치 크기 결정**:
   - 서브넷 2로 처리 가능한 최대 배치를 계산.
   - 요청 1, 요청 2, 요청 3을 함께 처리하는 배치 크기 = 3로 설정.

4. **결과**:
   - SlackFit은 서브넷 2와 배치 크기 3을 선택하여 모든 요청을 30ms 내에 처리.

---

### **SubNetAct와 SlackFit의 결합 동작**

#### **요청 흐름 예시**
1. 클라이언트가 다수의 요청(예: 이미지 분류 요청)을 전송.
2. **SlackFit 스케줄러**는 요청의 slack에 따라 서브넷과 배치를 선택.
3. **SubNetAct**는 선택된 서브넷을 활성화하고 최적의 채널과 레이어만 계산에 사용.
4. 추론 결과는 클라이언트로 반환.

#### **결과 요약**
- 지연(SLO): 모든 요청은 SLO 30ms 내에 처리됨.
- 정확도: 요청의 조건에 맞춰 76% 정확도로 추론 수행.
- 자원 사용 효율성: 메모리와 계산량을 최소화.

---

### **결과 및 특출난 점**

#### **논문에서 제시한 결과**
1. **정확도 향상**:
   - SubNetAct와 SlackFit을 결합한 SuperServe 시스템은 Microsoft Azure Functions(MAF) 워크로드에서 4.67% 더 높은 정확도를 달성.
   - 같은 정확도에서 2.85배 더 높은 SLO 달성률을 기록.

2. **효율성 증대**:
   - 메모리 사용량을 최대 2.6배 감소.
   - SubNetAct를 통한 서브넷 활성화 시간이 <1ms로 거의 즉각적으로 처리.

3. **적응성**:
   - 폭발적인 워크로드에서도 정확도와 처리량의 균형을 자동으로 조정.

#### **SubNetAct와 SlackFit의 기여**
- SubNetAct는 SuperNet의 서브넷을 즉각적으로 활성화하여 동적 워크로드 처리에 있어 높은 유연성을 제공.
- SlackFit은 남은 slack을 기반으로 서브넷과 배치 크기를 조정하여 지연 및 정확도 목표를 균형 있게 달성.

#### **특출난 이유**
- SubNetAct의 LayerSelect, SubnetNorm, WeightSlice 연산자는 기존 모델 스위칭 방식 대비 메모리와 지연에서 압도적인 이점을 제공.
- SlackFit의 정책은 실시간으로 워크로드 변화에 적응하며 정확도와 지연 간의 최적 균형을 찾음.

#### **추가적인 의견**
- 이러한 결과는 특히 자원이 제한된 환경(예: 엣지 컴퓨팅)이나 급격한 요청 변화가 많은 상황에서 중요한 경쟁 우위를 제공.
- 다만, SuperNet 학습 비용이 높다는 점에서 저비용 환경에서는 도입이 제한적일 수 있음.

---

### **정리**
- **SubNetAct**는 메모리 효율적이고 즉각적인 모델 활성화를 통해 지연 시간을 줄이고 시스템의 유연성을 극대화.
- **SlackFit**은 요청의 slack을 활용해 정확도와 처리량의 균형을 실시간으로 조정.
- 두 알고리즘은 결합하여 폭발적인 워크로드와 예측 불가능한 요청 패턴에서도 높은 성능을 보장함.


